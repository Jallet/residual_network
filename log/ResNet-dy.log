/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 17:09:46.288442 27180 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar0/ResNet-cifar0"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar0.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 17:09:46.288483 27180 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar0.prototxt
I0413 17:09:46.288990 27180 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 17:09:46.289130 27180 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv2_1"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:09:46.289252 27180 layer_factory.hpp:77] Creating layer cifar
I0413 17:09:46.289870 27180 net.cpp:91] Creating Layer cifar
I0413 17:09:46.289886 27180 net.cpp:399] cifar -> data
I0413 17:09:46.289928 27180 net.cpp:399] cifar -> label
I0413 17:09:46.289950 27180 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:09:46.309381 27463 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 17:09:46.343348 27180 data_layer.cpp:41] output data size: 256,3,32,32
I0413 17:09:46.355808 27180 net.cpp:141] Setting up cifar
I0413 17:09:46.355847 27180 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 17:09:46.355856 27180 net.cpp:148] Top shape: 256 (256)
I0413 17:09:46.355861 27180 net.cpp:156] Memory required for data: 3146752
I0413 17:09:46.355872 27180 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:09:46.355895 27180 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:09:46.355902 27180 net.cpp:425] label_cifar_1_split <- label
I0413 17:09:46.355917 27180 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:09:46.355932 27180 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:09:46.355983 27180 net.cpp:141] Setting up label_cifar_1_split
I0413 17:09:46.355993 27180 net.cpp:148] Top shape: 256 (256)
I0413 17:09:46.355999 27180 net.cpp:148] Top shape: 256 (256)
I0413 17:09:46.356004 27180 net.cpp:156] Memory required for data: 3148800
I0413 17:09:46.356010 27180 layer_factory.hpp:77] Creating layer conv1
I0413 17:09:46.356029 27180 net.cpp:91] Creating Layer conv1
I0413 17:09:46.356035 27180 net.cpp:425] conv1 <- data
I0413 17:09:46.356045 27180 net.cpp:399] conv1 -> conv1
I0413 17:09:46.673980 27180 net.cpp:141] Setting up conv1
I0413 17:09:46.674029 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.674036 27180 net.cpp:156] Memory required for data: 19926016
I0413 17:09:46.674058 27180 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:09:46.674074 27180 net.cpp:91] Creating Layer bn_conv1
I0413 17:09:46.674082 27180 net.cpp:425] bn_conv1 <- conv1
I0413 17:09:46.674091 27180 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:09:46.674288 27180 net.cpp:141] Setting up bn_conv1
I0413 17:09:46.674299 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.674304 27180 net.cpp:156] Memory required for data: 36703232
I0413 17:09:46.674319 27180 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:09:46.674338 27180 net.cpp:91] Creating Layer scale_conv1
I0413 17:09:46.674345 27180 net.cpp:425] scale_conv1 <- conv1
I0413 17:09:46.674351 27180 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:09:46.674392 27180 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:09:46.674515 27180 net.cpp:141] Setting up scale_conv1
I0413 17:09:46.674525 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.674530 27180 net.cpp:156] Memory required for data: 53480448
I0413 17:09:46.674540 27180 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:09:46.674549 27180 net.cpp:91] Creating Layer conv1_relu
I0413 17:09:46.674554 27180 net.cpp:425] conv1_relu <- conv1
I0413 17:09:46.674562 27180 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:09:46.674983 27180 net.cpp:141] Setting up conv1_relu
I0413 17:09:46.675000 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.675006 27180 net.cpp:156] Memory required for data: 70257664
I0413 17:09:46.675012 27180 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:09:46.675021 27180 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:09:46.675027 27180 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:09:46.675035 27180 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:09:46.675045 27180 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:09:46.675089 27180 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:09:46.675099 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.675106 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.675110 27180 net.cpp:156] Memory required for data: 103812096
I0413 17:09:46.675115 27180 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:09:46.675129 27180 net.cpp:91] Creating Layer conv2_1a
I0413 17:09:46.675135 27180 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:09:46.675144 27180 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:09:46.678889 27180 net.cpp:141] Setting up conv2_1a
I0413 17:09:46.678906 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.678912 27180 net.cpp:156] Memory required for data: 120589312
I0413 17:09:46.678928 27180 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:09:46.678941 27180 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:09:46.678946 27180 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:09:46.678957 27180 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:09:46.679160 27180 net.cpp:141] Setting up bn_conv2_1a
I0413 17:09:46.679172 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.679177 27180 net.cpp:156] Memory required for data: 137366528
I0413 17:09:46.679186 27180 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:09:46.679196 27180 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:09:46.679201 27180 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:09:46.679208 27180 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:09:46.679249 27180 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:09:46.679369 27180 net.cpp:141] Setting up scale_conv2_1a
I0413 17:09:46.679380 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.679385 27180 net.cpp:156] Memory required for data: 154143744
I0413 17:09:46.679394 27180 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:09:46.679402 27180 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:09:46.679407 27180 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:09:46.679417 27180 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:09:46.679934 27180 net.cpp:141] Setting up conv2_1a_relu
I0413 17:09:46.679950 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.679955 27180 net.cpp:156] Memory required for data: 170920960
I0413 17:09:46.679961 27180 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:09:46.679976 27180 net.cpp:91] Creating Layer conv2_1b
I0413 17:09:46.679982 27180 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:09:46.679993 27180 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:09:46.683995 27180 net.cpp:141] Setting up conv2_1b
I0413 17:09:46.684013 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.684020 27180 net.cpp:156] Memory required for data: 187698176
I0413 17:09:46.684028 27180 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:09:46.684046 27180 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:09:46.684053 27180 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:09:46.684062 27180 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:09:46.684262 27180 net.cpp:141] Setting up bn_conv2_1b
I0413 17:09:46.684273 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.684278 27180 net.cpp:156] Memory required for data: 204475392
I0413 17:09:46.684291 27180 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:09:46.684303 27180 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:09:46.684309 27180 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:09:46.684316 27180 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:09:46.684356 27180 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:09:46.684481 27180 net.cpp:141] Setting up scale_conv2_1b
I0413 17:09:46.684492 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.684497 27180 net.cpp:156] Memory required for data: 221252608
I0413 17:09:46.684505 27180 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:09:46.684514 27180 net.cpp:91] Creating Layer conv2_1
I0413 17:09:46.684520 27180 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:09:46.684526 27180 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:09:46.684533 27180 net.cpp:399] conv2_1 -> conv2_1
I0413 17:09:46.684569 27180 net.cpp:141] Setting up conv2_1
I0413 17:09:46.684581 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.684587 27180 net.cpp:156] Memory required for data: 238029824
I0413 17:09:46.684592 27180 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:09:46.684598 27180 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:09:46.684604 27180 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:09:46.684610 27180 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:09:46.685024 27180 net.cpp:141] Setting up conv2_1_relu
I0413 17:09:46.685036 27180 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:09:46.685041 27180 net.cpp:156] Memory required for data: 254807040
I0413 17:09:46.685047 27180 layer_factory.hpp:77] Creating layer global_pool
I0413 17:09:46.685060 27180 net.cpp:91] Creating Layer global_pool
I0413 17:09:46.685066 27180 net.cpp:425] global_pool <- conv2_1
I0413 17:09:46.685075 27180 net.cpp:399] global_pool -> global_pool
I0413 17:09:46.686177 27180 net.cpp:141] Setting up global_pool
I0413 17:09:46.686194 27180 net.cpp:148] Top shape: 256 16 4 4 (65536)
I0413 17:09:46.686200 27180 net.cpp:156] Memory required for data: 255069184
I0413 17:09:46.686205 27180 layer_factory.hpp:77] Creating layer ip
I0413 17:09:46.686223 27180 net.cpp:91] Creating Layer ip
I0413 17:09:46.686228 27180 net.cpp:425] ip <- global_pool
I0413 17:09:46.686238 27180 net.cpp:399] ip -> ip
I0413 17:09:46.686359 27180 net.cpp:141] Setting up ip
I0413 17:09:46.686372 27180 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:09:46.686377 27180 net.cpp:156] Memory required for data: 255079424
I0413 17:09:46.686384 27180 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:09:46.686395 27180 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:09:46.686400 27180 net.cpp:425] ip_ip_0_split <- ip
I0413 17:09:46.686408 27180 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:09:46.686416 27180 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:09:46.686455 27180 net.cpp:141] Setting up ip_ip_0_split
I0413 17:09:46.686463 27180 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:09:46.686470 27180 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:09:46.686475 27180 net.cpp:156] Memory required for data: 255099904
I0413 17:09:46.686480 27180 layer_factory.hpp:77] Creating layer accuracy
I0413 17:09:46.686491 27180 net.cpp:91] Creating Layer accuracy
I0413 17:09:46.686497 27180 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:09:46.686503 27180 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:09:46.686511 27180 net.cpp:399] accuracy -> accuracy
I0413 17:09:46.686520 27180 net.cpp:141] Setting up accuracy
I0413 17:09:46.686527 27180 net.cpp:148] Top shape: (1)
I0413 17:09:46.686532 27180 net.cpp:156] Memory required for data: 255099908
I0413 17:09:46.686542 27180 layer_factory.hpp:77] Creating layer loss
I0413 17:09:46.686556 27180 net.cpp:91] Creating Layer loss
I0413 17:09:46.686563 27180 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:09:46.686568 27180 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:09:46.686575 27180 net.cpp:399] loss -> loss
I0413 17:09:46.686586 27180 layer_factory.hpp:77] Creating layer loss
I0413 17:09:46.687372 27180 net.cpp:141] Setting up loss
I0413 17:09:46.687386 27180 net.cpp:148] Top shape: (1)
I0413 17:09:46.687391 27180 net.cpp:151]     with loss weight 1
I0413 17:09:46.687403 27180 net.cpp:156] Memory required for data: 255099912
I0413 17:09:46.687409 27180 net.cpp:217] loss needs backward computation.
I0413 17:09:46.687415 27180 net.cpp:219] accuracy does not need backward computation.
I0413 17:09:46.687422 27180 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:09:46.687427 27180 net.cpp:217] ip needs backward computation.
I0413 17:09:46.687432 27180 net.cpp:217] global_pool needs backward computation.
I0413 17:09:46.687436 27180 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:09:46.687441 27180 net.cpp:217] conv2_1 needs backward computation.
I0413 17:09:46.687446 27180 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:09:46.687451 27180 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:09:46.687456 27180 net.cpp:217] conv2_1b needs backward computation.
I0413 17:09:46.687461 27180 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:09:46.687466 27180 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:09:46.687470 27180 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:09:46.687475 27180 net.cpp:217] conv2_1a needs backward computation.
I0413 17:09:46.687480 27180 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:09:46.687485 27180 net.cpp:217] conv1_relu needs backward computation.
I0413 17:09:46.687490 27180 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:09:46.687494 27180 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:09:46.687500 27180 net.cpp:217] conv1 needs backward computation.
I0413 17:09:46.687505 27180 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:09:46.687511 27180 net.cpp:219] cifar does not need backward computation.
I0413 17:09:46.687516 27180 net.cpp:261] This network produces output accuracy
I0413 17:09:46.687521 27180 net.cpp:261] This network produces output loss
I0413 17:09:46.687542 27180 net.cpp:274] Network initialization done.
I0413 17:09:46.688114 27180 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar0.prototxt
I0413 17:09:46.688159 27180 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 17:09:46.688307 27180 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv2_1"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:09:46.688422 27180 layer_factory.hpp:77] Creating layer cifar
I0413 17:09:46.688555 27180 net.cpp:91] Creating Layer cifar
I0413 17:09:46.688570 27180 net.cpp:399] cifar -> data
I0413 17:09:46.688581 27180 net.cpp:399] cifar -> label
I0413 17:09:46.688591 27180 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:09:46.690052 27469 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 17:09:46.690222 27180 data_layer.cpp:41] output data size: 100,3,32,32
I0413 17:09:46.695634 27180 net.cpp:141] Setting up cifar
I0413 17:09:46.695657 27180 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 17:09:46.695664 27180 net.cpp:148] Top shape: 100 (100)
I0413 17:09:46.695670 27180 net.cpp:156] Memory required for data: 1229200
I0413 17:09:46.695677 27180 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:09:46.695686 27180 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:09:46.695693 27180 net.cpp:425] label_cifar_1_split <- label
I0413 17:09:46.695701 27180 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:09:46.695751 27180 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:09:46.695897 27180 net.cpp:141] Setting up label_cifar_1_split
I0413 17:09:46.695909 27180 net.cpp:148] Top shape: 100 (100)
I0413 17:09:46.695915 27180 net.cpp:148] Top shape: 100 (100)
I0413 17:09:46.695920 27180 net.cpp:156] Memory required for data: 1230000
I0413 17:09:46.695926 27180 layer_factory.hpp:77] Creating layer conv1
I0413 17:09:46.695942 27180 net.cpp:91] Creating Layer conv1
I0413 17:09:46.695950 27180 net.cpp:425] conv1 <- data
I0413 17:09:46.695960 27180 net.cpp:399] conv1 -> conv1
I0413 17:09:46.699184 27180 net.cpp:141] Setting up conv1
I0413 17:09:46.699204 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.699211 27180 net.cpp:156] Memory required for data: 7783600
I0413 17:09:46.699224 27180 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:09:46.699236 27180 net.cpp:91] Creating Layer bn_conv1
I0413 17:09:46.699244 27180 net.cpp:425] bn_conv1 <- conv1
I0413 17:09:46.699250 27180 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:09:46.700539 27180 net.cpp:141] Setting up bn_conv1
I0413 17:09:46.700552 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.700568 27180 net.cpp:156] Memory required for data: 14337200
I0413 17:09:46.700582 27180 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:09:46.700593 27180 net.cpp:91] Creating Layer scale_conv1
I0413 17:09:46.700599 27180 net.cpp:425] scale_conv1 <- conv1
I0413 17:09:46.700606 27180 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:09:46.700659 27180 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:09:46.700801 27180 net.cpp:141] Setting up scale_conv1
I0413 17:09:46.700814 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.700819 27180 net.cpp:156] Memory required for data: 20890800
I0413 17:09:46.700827 27180 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:09:46.700834 27180 net.cpp:91] Creating Layer conv1_relu
I0413 17:09:46.700840 27180 net.cpp:425] conv1_relu <- conv1
I0413 17:09:46.700870 27180 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:09:46.701223 27180 net.cpp:141] Setting up conv1_relu
I0413 17:09:46.701241 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.701247 27180 net.cpp:156] Memory required for data: 27444400
I0413 17:09:46.701253 27180 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:09:46.701263 27180 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:09:46.701274 27180 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:09:46.701292 27180 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:09:46.701303 27180 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:09:46.701352 27180 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:09:46.701366 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.701375 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.701380 27180 net.cpp:156] Memory required for data: 40551600
I0413 17:09:46.701385 27180 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:09:46.701397 27180 net.cpp:91] Creating Layer conv2_1a
I0413 17:09:46.701403 27180 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:09:46.701427 27180 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:09:46.703752 27180 net.cpp:141] Setting up conv2_1a
I0413 17:09:46.703773 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.703779 27180 net.cpp:156] Memory required for data: 47105200
I0413 17:09:46.703793 27180 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:09:46.703804 27180 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:09:46.703822 27180 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:09:46.703831 27180 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:09:46.704047 27180 net.cpp:141] Setting up bn_conv2_1a
I0413 17:09:46.704059 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.704073 27180 net.cpp:156] Memory required for data: 53658800
I0413 17:09:46.704084 27180 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:09:46.704094 27180 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:09:46.704100 27180 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:09:46.704126 27180 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:09:46.704177 27180 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:09:46.704304 27180 net.cpp:141] Setting up scale_conv2_1a
I0413 17:09:46.704316 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.704331 27180 net.cpp:156] Memory required for data: 60212400
I0413 17:09:46.704339 27180 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:09:46.704347 27180 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:09:46.704352 27180 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:09:46.704360 27180 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:09:46.704778 27180 net.cpp:141] Setting up conv2_1a_relu
I0413 17:09:46.704807 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.704813 27180 net.cpp:156] Memory required for data: 66766000
I0413 17:09:46.704823 27180 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:09:46.704836 27180 net.cpp:91] Creating Layer conv2_1b
I0413 17:09:46.704851 27180 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:09:46.704860 27180 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:09:46.709403 27180 net.cpp:141] Setting up conv2_1b
I0413 17:09:46.709434 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.709441 27180 net.cpp:156] Memory required for data: 73319600
I0413 17:09:46.709452 27180 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:09:46.709463 27180 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:09:46.709470 27180 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:09:46.709480 27180 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:09:46.709702 27180 net.cpp:141] Setting up bn_conv2_1b
I0413 17:09:46.709712 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.709717 27180 net.cpp:156] Memory required for data: 79873200
I0413 17:09:46.709745 27180 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:09:46.709755 27180 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:09:46.709761 27180 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:09:46.709769 27180 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:09:46.709830 27180 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:09:46.709955 27180 net.cpp:141] Setting up scale_conv2_1b
I0413 17:09:46.709966 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.709972 27180 net.cpp:156] Memory required for data: 86426800
I0413 17:09:46.709996 27180 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:09:46.710005 27180 net.cpp:91] Creating Layer conv2_1
I0413 17:09:46.710011 27180 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:09:46.710037 27180 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:09:46.710047 27180 net.cpp:399] conv2_1 -> conv2_1
I0413 17:09:46.710075 27180 net.cpp:141] Setting up conv2_1
I0413 17:09:46.710085 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.710090 27180 net.cpp:156] Memory required for data: 92980400
I0413 17:09:46.710095 27180 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:09:46.710104 27180 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:09:46.710111 27180 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:09:46.710117 27180 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:09:46.710322 27180 net.cpp:141] Setting up conv2_1_relu
I0413 17:09:46.710336 27180 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:09:46.710341 27180 net.cpp:156] Memory required for data: 99534000
I0413 17:09:46.710346 27180 layer_factory.hpp:77] Creating layer global_pool
I0413 17:09:46.710358 27180 net.cpp:91] Creating Layer global_pool
I0413 17:09:46.710364 27180 net.cpp:425] global_pool <- conv2_1
I0413 17:09:46.710382 27180 net.cpp:399] global_pool -> global_pool
I0413 17:09:46.722751 27180 net.cpp:141] Setting up global_pool
I0413 17:09:46.722775 27180 net.cpp:148] Top shape: 100 16 4 4 (25600)
I0413 17:09:46.722781 27180 net.cpp:156] Memory required for data: 99636400
I0413 17:09:46.722787 27180 layer_factory.hpp:77] Creating layer ip
I0413 17:09:46.722796 27180 net.cpp:91] Creating Layer ip
I0413 17:09:46.722802 27180 net.cpp:425] ip <- global_pool
I0413 17:09:46.722810 27180 net.cpp:399] ip -> ip
I0413 17:09:46.722960 27180 net.cpp:141] Setting up ip
I0413 17:09:46.722973 27180 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:09:46.722978 27180 net.cpp:156] Memory required for data: 99640400
I0413 17:09:46.722987 27180 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:09:46.722995 27180 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:09:46.723001 27180 net.cpp:425] ip_ip_0_split <- ip
I0413 17:09:46.723011 27180 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:09:46.723019 27180 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:09:46.724066 27180 net.cpp:141] Setting up ip_ip_0_split
I0413 17:09:46.724120 27180 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:09:46.724134 27180 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:09:46.724153 27180 net.cpp:156] Memory required for data: 99648400
I0413 17:09:46.724165 27180 layer_factory.hpp:77] Creating layer accuracy
I0413 17:09:46.724180 27180 net.cpp:91] Creating Layer accuracy
I0413 17:09:46.724194 27180 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:09:46.724207 27180 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:09:46.724226 27180 net.cpp:399] accuracy -> accuracy
I0413 17:09:46.724256 27180 net.cpp:141] Setting up accuracy
I0413 17:09:46.724272 27180 net.cpp:148] Top shape: (1)
I0413 17:09:46.724293 27180 net.cpp:156] Memory required for data: 99648404
I0413 17:09:46.724303 27180 layer_factory.hpp:77] Creating layer loss
I0413 17:09:46.724318 27180 net.cpp:91] Creating Layer loss
I0413 17:09:46.724331 27180 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:09:46.724344 27180 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:09:46.724357 27180 net.cpp:399] loss -> loss
I0413 17:09:46.724380 27180 layer_factory.hpp:77] Creating layer loss
I0413 17:09:46.733295 27180 net.cpp:141] Setting up loss
I0413 17:09:46.733316 27180 net.cpp:148] Top shape: (1)
I0413 17:09:46.733322 27180 net.cpp:151]     with loss weight 1
I0413 17:09:46.733331 27180 net.cpp:156] Memory required for data: 99648408
I0413 17:09:46.733336 27180 net.cpp:217] loss needs backward computation.
I0413 17:09:46.733343 27180 net.cpp:219] accuracy does not need backward computation.
I0413 17:09:46.733350 27180 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:09:46.733355 27180 net.cpp:217] ip needs backward computation.
I0413 17:09:46.733360 27180 net.cpp:217] global_pool needs backward computation.
I0413 17:09:46.733364 27180 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:09:46.733368 27180 net.cpp:217] conv2_1 needs backward computation.
I0413 17:09:46.733374 27180 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:09:46.733379 27180 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:09:46.733383 27180 net.cpp:217] conv2_1b needs backward computation.
I0413 17:09:46.733389 27180 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:09:46.733393 27180 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:09:46.733398 27180 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:09:46.733403 27180 net.cpp:217] conv2_1a needs backward computation.
I0413 17:09:46.733408 27180 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:09:46.733413 27180 net.cpp:217] conv1_relu needs backward computation.
I0413 17:09:46.733418 27180 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:09:46.733422 27180 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:09:46.733428 27180 net.cpp:217] conv1 needs backward computation.
I0413 17:09:46.733433 27180 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:09:46.733439 27180 net.cpp:219] cifar does not need backward computation.
I0413 17:09:46.733443 27180 net.cpp:261] This network produces output accuracy
I0413 17:09:46.733449 27180 net.cpp:261] This network produces output loss
I0413 17:09:46.733470 27180 net.cpp:274] Network initialization done.
I0413 17:09:46.733542 27180 solver.cpp:60] Solver scaffolding done.
I0413 17:09:46.839134 27180 solver.cpp:228] Iteration 0, loss = 2.30259
I0413 17:09:46.839187 27180 solver.cpp:244]     Train net output #0: accuracy = 0.113281
I0413 17:09:46.839206 27180 solver.cpp:244]     Train net output #1: loss = 2.30259 (* 1 = 2.30259 loss)
I0413 17:09:46.839220 27180 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 17:09:48.227469 27180 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 17:09:49.332919 27180 solver.cpp:404]     Test net output #0: accuracy = 0.3791
I0413 17:09:49.332988 27180 solver.cpp:404]     Test net output #1: loss = 1.79253 (* 1 = 1.79253 loss)
I0413 17:09:49.352983 27180 solver.cpp:228] Iteration 20, loss = 1.80207
I0413 17:09:49.353020 27180 solver.cpp:244]     Train net output #0: accuracy = 0.375
I0413 17:09:49.353031 27180 solver.cpp:244]     Train net output #1: loss = 1.80207 (* 1 = 1.80207 loss)
I0413 17:09:49.353051 27180 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 17:09:50.869187 27180 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 17:09:52.070392 27180 solver.cpp:404]     Test net output #0: accuracy = 0.4037
I0413 17:09:52.070472 27180 solver.cpp:404]     Test net output #1: loss = 1.7875 (* 1 = 1.7875 loss)
I0413 17:09:52.098283 27180 solver.cpp:228] Iteration 40, loss = 1.63091
I0413 17:09:52.098323 27180 solver.cpp:244]     Train net output #0: accuracy = 0.378906
I0413 17:09:52.098338 27180 solver.cpp:244]     Train net output #1: loss = 1.63091 (* 1 = 1.63091 loss)
I0413 17:09:52.098352 27180 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 17:09:53.695178 27180 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 17:09:54.916077 27180 solver.cpp:404]     Test net output #0: accuracy = 0.4442
I0413 17:09:54.916152 27180 solver.cpp:404]     Test net output #1: loss = 1.64787 (* 1 = 1.64787 loss)
I0413 17:09:54.944350 27180 solver.cpp:228] Iteration 60, loss = 1.60436
I0413 17:09:54.944370 27180 solver.cpp:244]     Train net output #0: accuracy = 0.4375
I0413 17:09:54.944380 27180 solver.cpp:244]     Train net output #1: loss = 1.60436 (* 1 = 1.60436 loss)
I0413 17:09:54.944397 27180 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 17:09:56.474650 27180 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 17:09:57.559469 27180 solver.cpp:404]     Test net output #0: accuracy = 0.4471
I0413 17:09:57.559528 27180 solver.cpp:404]     Test net output #1: loss = 1.62018 (* 1 = 1.62018 loss)
I0413 17:09:57.586488 27180 solver.cpp:228] Iteration 80, loss = 1.45491
I0413 17:09:57.586508 27180 solver.cpp:244]     Train net output #0: accuracy = 0.472656
I0413 17:09:57.586519 27180 solver.cpp:244]     Train net output #1: loss = 1.45491 (* 1 = 1.45491 loss)
I0413 17:09:57.586531 27180 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 17:09:58.980350 27180 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 17:10:00.258355 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5054
I0413 17:10:00.258436 27180 solver.cpp:404]     Test net output #1: loss = 1.40371 (* 1 = 1.40371 loss)
I0413 17:10:00.290766 27180 solver.cpp:228] Iteration 100, loss = 1.31888
I0413 17:10:00.290829 27180 solver.cpp:244]     Train net output #0: accuracy = 0.550781
I0413 17:10:00.290851 27180 solver.cpp:244]     Train net output #1: loss = 1.31888 (* 1 = 1.31888 loss)
I0413 17:10:00.290874 27180 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 17:10:01.857584 27180 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 17:10:03.108116 27180 solver.cpp:404]     Test net output #0: accuracy = 0.4731
I0413 17:10:03.108165 27180 solver.cpp:404]     Test net output #1: loss = 1.54548 (* 1 = 1.54548 loss)
I0413 17:10:03.134991 27180 solver.cpp:228] Iteration 120, loss = 1.31358
I0413 17:10:03.135046 27180 solver.cpp:244]     Train net output #0: accuracy = 0.574219
I0413 17:10:03.135067 27180 solver.cpp:244]     Train net output #1: loss = 1.31358 (* 1 = 1.31358 loss)
I0413 17:10:03.135082 27180 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 17:10:04.716493 27180 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 17:10:05.087771 27180 blocking_queue.cpp:50] Data layer prefetch queue empty
I0413 17:10:05.806531 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5102
I0413 17:10:05.806573 27180 solver.cpp:404]     Test net output #1: loss = 1.3929 (* 1 = 1.3929 loss)
I0413 17:10:05.830435 27180 solver.cpp:228] Iteration 140, loss = 1.27016
I0413 17:10:05.830493 27180 solver.cpp:244]     Train net output #0: accuracy = 0.558594
I0413 17:10:05.830516 27180 solver.cpp:244]     Train net output #1: loss = 1.27016 (* 1 = 1.27016 loss)
I0413 17:10:05.830534 27180 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 17:10:07.213227 27180 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 17:10:08.372328 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5044
I0413 17:10:08.372427 27180 solver.cpp:404]     Test net output #1: loss = 1.421 (* 1 = 1.421 loss)
I0413 17:10:08.411073 27180 solver.cpp:228] Iteration 160, loss = 1.31737
I0413 17:10:08.411139 27180 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0413 17:10:08.411162 27180 solver.cpp:244]     Train net output #1: loss = 1.31737 (* 1 = 1.31737 loss)
I0413 17:10:08.411180 27180 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 17:10:09.988160 27180 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 17:10:11.252946 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5511
I0413 17:10:11.252988 27180 solver.cpp:404]     Test net output #1: loss = 1.26145 (* 1 = 1.26145 loss)
I0413 17:10:11.281800 27180 solver.cpp:228] Iteration 180, loss = 1.20397
I0413 17:10:11.281853 27180 solver.cpp:244]     Train net output #0: accuracy = 0.570312
I0413 17:10:11.281867 27180 solver.cpp:244]     Train net output #1: loss = 1.20397 (* 1 = 1.20397 loss)
I0413 17:10:11.281878 27180 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 17:10:12.857097 27180 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 17:10:14.017446 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5241
I0413 17:10:14.017493 27180 solver.cpp:404]     Test net output #1: loss = 1.39493 (* 1 = 1.39493 loss)
I0413 17:10:14.040865 27180 solver.cpp:228] Iteration 200, loss = 1.17663
I0413 17:10:14.040917 27180 solver.cpp:244]     Train net output #0: accuracy = 0.585938
I0413 17:10:14.040940 27180 solver.cpp:244]     Train net output #1: loss = 1.17663 (* 1 = 1.17663 loss)
I0413 17:10:14.040957 27180 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 17:10:15.418642 27180 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 17:10:16.506779 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5423
I0413 17:10:16.506842 27180 solver.cpp:404]     Test net output #1: loss = 1.34022 (* 1 = 1.34022 loss)
I0413 17:10:16.534868 27180 solver.cpp:228] Iteration 220, loss = 1.19839
I0413 17:10:16.534890 27180 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0413 17:10:16.534904 27180 solver.cpp:244]     Train net output #1: loss = 1.19839 (* 1 = 1.19839 loss)
I0413 17:10:16.534914 27180 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 17:10:18.106976 27180 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 17:10:19.351341 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5126
I0413 17:10:19.351394 27180 solver.cpp:404]     Test net output #1: loss = 1.5183 (* 1 = 1.5183 loss)
I0413 17:10:19.377341 27180 solver.cpp:228] Iteration 240, loss = 1.21524
I0413 17:10:19.377400 27180 solver.cpp:244]     Train net output #0: accuracy = 0.550781
I0413 17:10:19.377424 27180 solver.cpp:244]     Train net output #1: loss = 1.21524 (* 1 = 1.21524 loss)
I0413 17:10:19.377440 27180 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 17:10:21.005789 27180 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 17:10:22.244303 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5391
I0413 17:10:22.244343 27180 solver.cpp:404]     Test net output #1: loss = 1.40148 (* 1 = 1.40148 loss)
I0413 17:10:22.271777 27180 solver.cpp:228] Iteration 260, loss = 1.22292
I0413 17:10:22.271796 27180 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0413 17:10:22.271806 27180 solver.cpp:244]     Train net output #1: loss = 1.22292 (* 1 = 1.22292 loss)
I0413 17:10:22.271814 27180 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 17:10:23.706197 27180 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 17:10:24.791502 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5676
I0413 17:10:24.791544 27180 solver.cpp:404]     Test net output #1: loss = 1.24295 (* 1 = 1.24295 loss)
I0413 17:10:24.809999 27180 solver.cpp:228] Iteration 280, loss = 1.17439
I0413 17:10:24.810021 27180 solver.cpp:244]     Train net output #0: accuracy = 0.558594
I0413 17:10:24.810032 27180 solver.cpp:244]     Train net output #1: loss = 1.17439 (* 1 = 1.17439 loss)
I0413 17:10:24.810041 27180 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 17:10:26.287425 27180 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 17:10:27.518406 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5706
I0413 17:10:27.518463 27180 solver.cpp:404]     Test net output #1: loss = 1.26855 (* 1 = 1.26855 loss)
I0413 17:10:27.549192 27180 solver.cpp:228] Iteration 300, loss = 1.1653
I0413 17:10:27.549229 27180 solver.cpp:244]     Train net output #0: accuracy = 0.585938
I0413 17:10:27.549244 27180 solver.cpp:244]     Train net output #1: loss = 1.1653 (* 1 = 1.1653 loss)
I0413 17:10:27.549255 27180 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 17:10:29.122069 27180 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 17:10:30.380483 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5375
I0413 17:10:30.380532 27180 solver.cpp:404]     Test net output #1: loss = 1.39566 (* 1 = 1.39566 loss)
I0413 17:10:30.397837 27180 solver.cpp:228] Iteration 320, loss = 1.15151
I0413 17:10:30.397897 27180 solver.cpp:244]     Train net output #0: accuracy = 0.605469
I0413 17:10:30.397910 27180 solver.cpp:244]     Train net output #1: loss = 1.15151 (* 1 = 1.15151 loss)
I0413 17:10:30.397920 27180 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 17:10:31.936651 27180 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 17:10:33.015908 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5894
I0413 17:10:33.015972 27180 solver.cpp:404]     Test net output #1: loss = 1.2258 (* 1 = 1.2258 loss)
I0413 17:10:33.043447 27180 solver.cpp:228] Iteration 340, loss = 1.18803
I0413 17:10:33.043496 27180 solver.cpp:244]     Train net output #0: accuracy = 0.601562
I0413 17:10:33.043514 27180 solver.cpp:244]     Train net output #1: loss = 1.18803 (* 1 = 1.18803 loss)
I0413 17:10:33.043529 27180 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 17:10:34.413394 27180 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 17:10:35.645730 27180 solver.cpp:404]     Test net output #0: accuracy = 0.596
I0413 17:10:35.645779 27180 solver.cpp:404]     Test net output #1: loss = 1.16984 (* 1 = 1.16984 loss)
I0413 17:10:35.672777 27180 solver.cpp:228] Iteration 360, loss = 1.03736
I0413 17:10:35.672834 27180 solver.cpp:244]     Train net output #0: accuracy = 0.648438
I0413 17:10:35.672858 27180 solver.cpp:244]     Train net output #1: loss = 1.03736 (* 1 = 1.03736 loss)
I0413 17:10:35.672875 27180 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 17:10:37.229923 27180 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 17:10:38.478516 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5872
I0413 17:10:38.478586 27180 solver.cpp:404]     Test net output #1: loss = 1.22502 (* 1 = 1.22502 loss)
I0413 17:10:38.501093 27180 solver.cpp:228] Iteration 380, loss = 1.11652
I0413 17:10:38.501173 27180 solver.cpp:244]     Train net output #0: accuracy = 0.601562
I0413 17:10:38.501197 27180 solver.cpp:244]     Train net output #1: loss = 1.11652 (* 1 = 1.11652 loss)
I0413 17:10:38.501219 27180 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 17:10:40.091333 27180 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 17:10:41.203577 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5916
I0413 17:10:41.203625 27180 solver.cpp:404]     Test net output #1: loss = 1.19032 (* 1 = 1.19032 loss)
I0413 17:10:41.228744 27180 solver.cpp:228] Iteration 400, loss = 0.982476
I0413 17:10:41.228822 27180 solver.cpp:244]     Train net output #0: accuracy = 0.632812
I0413 17:10:41.228835 27180 solver.cpp:244]     Train net output #1: loss = 0.982476 (* 1 = 0.982476 loss)
I0413 17:10:41.228844 27180 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 17:10:42.630566 27180 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 17:10:43.741834 27180 solver.cpp:404]     Test net output #0: accuracy = 0.592
I0413 17:10:43.741874 27180 solver.cpp:404]     Test net output #1: loss = 1.22152 (* 1 = 1.22152 loss)
I0413 17:10:43.765128 27180 solver.cpp:228] Iteration 420, loss = 1.12369
I0413 17:10:43.765156 27180 solver.cpp:244]     Train net output #0: accuracy = 0.601562
I0413 17:10:43.765167 27180 solver.cpp:244]     Train net output #1: loss = 1.12369 (* 1 = 1.12369 loss)
I0413 17:10:43.765177 27180 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 17:10:45.359597 27180 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 17:10:46.548034 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5609
I0413 17:10:46.548084 27180 solver.cpp:404]     Test net output #1: loss = 1.40083 (* 1 = 1.40083 loss)
I0413 17:10:46.575917 27180 solver.cpp:228] Iteration 440, loss = 1.05484
I0413 17:10:46.575935 27180 solver.cpp:244]     Train net output #0: accuracy = 0.644531
I0413 17:10:46.575944 27180 solver.cpp:244]     Train net output #1: loss = 1.05484 (* 1 = 1.05484 loss)
I0413 17:10:46.575953 27180 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 17:10:48.158874 27180 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 17:10:49.381585 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6153
I0413 17:10:49.381633 27180 solver.cpp:404]     Test net output #1: loss = 1.11677 (* 1 = 1.11677 loss)
I0413 17:10:49.409613 27180 solver.cpp:228] Iteration 460, loss = 1.04077
I0413 17:10:49.409632 27180 solver.cpp:244]     Train net output #0: accuracy = 0.632812
I0413 17:10:49.409642 27180 solver.cpp:244]     Train net output #1: loss = 1.04077 (* 1 = 1.04077 loss)
I0413 17:10:49.409651 27180 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 17:10:50.796190 27180 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 17:10:51.878996 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5948
I0413 17:10:51.879037 27180 solver.cpp:404]     Test net output #1: loss = 1.16851 (* 1 = 1.16851 loss)
I0413 17:10:51.905764 27180 solver.cpp:228] Iteration 480, loss = 1.01535
I0413 17:10:51.905807 27180 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:10:51.905822 27180 solver.cpp:244]     Train net output #1: loss = 1.01535 (* 1 = 1.01535 loss)
I0413 17:10:51.905834 27180 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 17:10:53.417173 27180 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 17:10:54.663817 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5617
I0413 17:10:54.663874 27180 solver.cpp:404]     Test net output #1: loss = 1.36654 (* 1 = 1.36654 loss)
I0413 17:10:54.696112 27180 solver.cpp:228] Iteration 500, loss = 0.957759
I0413 17:10:54.696163 27180 solver.cpp:244]     Train net output #0: accuracy = 0.640625
I0413 17:10:54.696183 27180 solver.cpp:244]     Train net output #1: loss = 0.957759 (* 1 = 0.957759 loss)
I0413 17:10:54.696199 27180 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 17:10:56.261634 27180 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 17:10:57.518122 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6037
I0413 17:10:57.518165 27180 solver.cpp:404]     Test net output #1: loss = 1.16724 (* 1 = 1.16724 loss)
I0413 17:10:57.535660 27180 solver.cpp:228] Iteration 520, loss = 1.00078
I0413 17:10:57.535715 27180 solver.cpp:244]     Train net output #0: accuracy = 0.621094
I0413 17:10:57.535738 27180 solver.cpp:244]     Train net output #1: loss = 1.00078 (* 1 = 1.00078 loss)
I0413 17:10:57.535760 27180 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 17:10:59.002791 27180 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 17:11:00.090713 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5866
I0413 17:11:00.090761 27180 solver.cpp:404]     Test net output #1: loss = 1.26985 (* 1 = 1.26985 loss)
I0413 17:11:00.111402 27180 solver.cpp:228] Iteration 540, loss = 1.01109
I0413 17:11:00.111424 27180 solver.cpp:244]     Train net output #0: accuracy = 0.617188
I0413 17:11:00.111436 27180 solver.cpp:244]     Train net output #1: loss = 1.01109 (* 1 = 1.01109 loss)
I0413 17:11:00.111448 27180 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 17:11:01.495187 27180 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 17:11:02.747119 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5888
I0413 17:11:02.747162 27180 solver.cpp:404]     Test net output #1: loss = 1.27474 (* 1 = 1.27474 loss)
I0413 17:11:02.774677 27180 solver.cpp:228] Iteration 560, loss = 1.02503
I0413 17:11:02.774720 27180 solver.cpp:244]     Train net output #0: accuracy = 0.671875
I0413 17:11:02.774734 27180 solver.cpp:244]     Train net output #1: loss = 1.02503 (* 1 = 1.02503 loss)
I0413 17:11:02.774756 27180 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 17:11:04.322479 27180 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 17:11:05.565084 27180 solver.cpp:404]     Test net output #0: accuracy = 0.59
I0413 17:11:05.565152 27180 solver.cpp:404]     Test net output #1: loss = 1.24454 (* 1 = 1.24454 loss)
I0413 17:11:05.591403 27180 solver.cpp:228] Iteration 580, loss = 0.982443
I0413 17:11:05.591444 27180 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:11:05.591456 27180 solver.cpp:244]     Train net output #1: loss = 0.982443 (* 1 = 0.982443 loss)
I0413 17:11:05.591471 27180 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 17:11:07.181362 27180 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 17:11:08.205242 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5868
I0413 17:11:08.205302 27180 solver.cpp:404]     Test net output #1: loss = 1.29414 (* 1 = 1.29414 loss)
I0413 17:11:08.229718 27180 solver.cpp:228] Iteration 600, loss = 0.840907
I0413 17:11:08.229742 27180 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:11:08.229751 27180 solver.cpp:244]     Train net output #1: loss = 0.840907 (* 1 = 0.840907 loss)
I0413 17:11:08.229763 27180 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 17:11:09.607722 27180 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 17:11:10.768249 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5883
I0413 17:11:10.768290 27180 solver.cpp:404]     Test net output #1: loss = 1.2594 (* 1 = 1.2594 loss)
I0413 17:11:10.795938 27180 solver.cpp:228] Iteration 620, loss = 1.08958
I0413 17:11:10.795958 27180 solver.cpp:244]     Train net output #0: accuracy = 0.621094
I0413 17:11:10.795967 27180 solver.cpp:244]     Train net output #1: loss = 1.08958 (* 1 = 1.08958 loss)
I0413 17:11:10.795976 27180 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 17:11:12.355726 27180 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 17:11:13.600715 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5823
I0413 17:11:13.600765 27180 solver.cpp:404]     Test net output #1: loss = 1.28116 (* 1 = 1.28116 loss)
I0413 17:11:13.620431 27180 solver.cpp:228] Iteration 640, loss = 0.917164
I0413 17:11:13.620453 27180 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:11:13.620465 27180 solver.cpp:244]     Train net output #1: loss = 0.917164 (* 1 = 0.917164 loss)
I0413 17:11:13.620476 27180 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 17:11:15.204126 27180 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 17:11:16.404495 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5977
I0413 17:11:16.404561 27180 solver.cpp:404]     Test net output #1: loss = 1.21816 (* 1 = 1.21816 loss)
I0413 17:11:16.415918 27180 solver.cpp:228] Iteration 660, loss = 0.977546
I0413 17:11:16.415937 27180 solver.cpp:244]     Train net output #0: accuracy = 0.621094
I0413 17:11:16.415946 27180 solver.cpp:244]     Train net output #1: loss = 0.977546 (* 1 = 0.977546 loss)
I0413 17:11:16.415954 27180 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 17:11:17.789914 27180 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 17:11:18.881855 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6119
I0413 17:11:18.881913 27180 solver.cpp:404]     Test net output #1: loss = 1.16393 (* 1 = 1.16393 loss)
I0413 17:11:18.910197 27180 solver.cpp:228] Iteration 680, loss = 0.834844
I0413 17:11:18.910249 27180 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:11:18.910271 27180 solver.cpp:244]     Train net output #1: loss = 0.834844 (* 1 = 0.834844 loss)
I0413 17:11:18.910289 27180 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 17:11:20.428717 27180 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 17:11:21.659991 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6092
I0413 17:11:21.660027 27180 solver.cpp:404]     Test net output #1: loss = 1.19008 (* 1 = 1.19008 loss)
I0413 17:11:21.684214 27180 solver.cpp:228] Iteration 700, loss = 0.792543
I0413 17:11:21.684244 27180 solver.cpp:244]     Train net output #0: accuracy = 0.707031
I0413 17:11:21.684253 27180 solver.cpp:244]     Train net output #1: loss = 0.792543 (* 1 = 0.792543 loss)
I0413 17:11:21.684262 27180 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 17:11:23.259572 27180 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 17:11:24.455188 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6129
I0413 17:11:24.455245 27180 solver.cpp:404]     Test net output #1: loss = 1.13524 (* 1 = 1.13524 loss)
I0413 17:11:24.478718 27180 solver.cpp:228] Iteration 720, loss = 0.968689
I0413 17:11:24.478737 27180 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:11:24.478747 27180 solver.cpp:244]     Train net output #1: loss = 0.968689 (* 1 = 0.968689 loss)
I0413 17:11:24.478761 27180 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 17:11:25.951714 27180 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 17:11:27.028391 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6033
I0413 17:11:27.028445 27180 solver.cpp:404]     Test net output #1: loss = 1.19205 (* 1 = 1.19205 loss)
I0413 17:11:27.055745 27180 solver.cpp:228] Iteration 740, loss = 0.99706
I0413 17:11:27.055765 27180 solver.cpp:244]     Train net output #0: accuracy = 0.644531
I0413 17:11:27.055775 27180 solver.cpp:244]     Train net output #1: loss = 0.99706 (* 1 = 0.99706 loss)
I0413 17:11:27.055785 27180 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 17:11:28.433953 27180 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 17:11:29.695983 27180 solver.cpp:404]     Test net output #0: accuracy = 0.59
I0413 17:11:29.696044 27180 solver.cpp:404]     Test net output #1: loss = 1.27861 (* 1 = 1.27861 loss)
I0413 17:11:29.709815 27180 solver.cpp:228] Iteration 760, loss = 0.970585
I0413 17:11:29.709836 27180 solver.cpp:244]     Train net output #0: accuracy = 0.644531
I0413 17:11:29.709844 27180 solver.cpp:244]     Train net output #1: loss = 0.970585 (* 1 = 0.970585 loss)
I0413 17:11:29.709853 27180 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 17:11:31.273525 27180 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 17:11:32.515435 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5491
I0413 17:11:32.515480 27180 solver.cpp:404]     Test net output #1: loss = 1.56029 (* 1 = 1.56029 loss)
I0413 17:11:32.536593 27180 solver.cpp:228] Iteration 780, loss = 0.939389
I0413 17:11:32.536612 27180 solver.cpp:244]     Train net output #0: accuracy = 0.691406
I0413 17:11:32.536620 27180 solver.cpp:244]     Train net output #1: loss = 0.939389 (* 1 = 0.939389 loss)
I0413 17:11:32.536630 27180 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 17:11:34.126925 27180 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 17:11:35.197537 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5828
I0413 17:11:35.197585 27180 solver.cpp:404]     Test net output #1: loss = 1.28179 (* 1 = 1.28179 loss)
I0413 17:11:35.222905 27180 solver.cpp:228] Iteration 800, loss = 1.0811
I0413 17:11:35.222925 27180 solver.cpp:244]     Train net output #0: accuracy = 0.621094
I0413 17:11:35.222935 27180 solver.cpp:244]     Train net output #1: loss = 1.0811 (* 1 = 1.0811 loss)
I0413 17:11:35.222944 27180 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 17:11:36.663833 27180 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 17:11:37.828047 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5911
I0413 17:11:37.828100 27180 solver.cpp:404]     Test net output #1: loss = 1.32755 (* 1 = 1.32755 loss)
I0413 17:11:37.856186 27180 solver.cpp:228] Iteration 820, loss = 0.976991
I0413 17:11:37.856205 27180 solver.cpp:244]     Train net output #0: accuracy = 0.636719
I0413 17:11:37.856215 27180 solver.cpp:244]     Train net output #1: loss = 0.976991 (* 1 = 0.976991 loss)
I0413 17:11:37.856225 27180 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 17:11:39.440150 27180 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 17:11:40.657140 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6099
I0413 17:11:40.657199 27180 solver.cpp:404]     Test net output #1: loss = 1.24051 (* 1 = 1.24051 loss)
I0413 17:11:40.690089 27180 solver.cpp:228] Iteration 840, loss = 0.968026
I0413 17:11:40.690145 27180 solver.cpp:244]     Train net output #0: accuracy = 0.660156
I0413 17:11:40.690167 27180 solver.cpp:244]     Train net output #1: loss = 0.968026 (* 1 = 0.968026 loss)
I0413 17:11:40.690183 27180 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 17:11:42.325633 27180 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 17:11:43.465929 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6046
I0413 17:11:43.465972 27180 solver.cpp:404]     Test net output #1: loss = 1.23461 (* 1 = 1.23461 loss)
I0413 17:11:43.500327 27180 solver.cpp:228] Iteration 860, loss = 0.975039
I0413 17:11:43.500366 27180 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:11:43.500377 27180 solver.cpp:244]     Train net output #1: loss = 0.975039 (* 1 = 0.975039 loss)
I0413 17:11:43.500386 27180 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 17:11:44.884389 27180 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 17:11:45.961954 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6135
I0413 17:11:45.962047 27180 solver.cpp:404]     Test net output #1: loss = 1.18999 (* 1 = 1.18999 loss)
I0413 17:11:45.993631 27180 solver.cpp:228] Iteration 880, loss = 0.945026
I0413 17:11:45.993659 27180 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:11:45.993669 27180 solver.cpp:244]     Train net output #1: loss = 0.945026 (* 1 = 0.945026 loss)
I0413 17:11:45.993680 27180 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 17:11:47.575474 27180 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 17:11:48.810483 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6212
I0413 17:11:48.810546 27180 solver.cpp:404]     Test net output #1: loss = 1.16756 (* 1 = 1.16756 loss)
I0413 17:11:48.837822 27180 solver.cpp:228] Iteration 900, loss = 0.965567
I0413 17:11:48.837842 27180 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:11:48.837852 27180 solver.cpp:244]     Train net output #1: loss = 0.965567 (* 1 = 0.965567 loss)
I0413 17:11:48.837862 27180 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 17:11:50.432399 27180 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 17:11:51.672358 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6123
I0413 17:11:51.672418 27180 solver.cpp:404]     Test net output #1: loss = 1.18702 (* 1 = 1.18702 loss)
I0413 17:11:51.699829 27180 solver.cpp:228] Iteration 920, loss = 0.9456
I0413 17:11:51.699849 27180 solver.cpp:244]     Train net output #0: accuracy = 0.648438
I0413 17:11:51.699859 27180 solver.cpp:244]     Train net output #1: loss = 0.9456 (* 1 = 0.9456 loss)
I0413 17:11:51.699868 27180 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 17:11:53.116225 27180 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 17:11:54.205508 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6382
I0413 17:11:54.205546 27180 solver.cpp:404]     Test net output #1: loss = 1.0793 (* 1 = 1.0793 loss)
I0413 17:11:54.234586 27180 solver.cpp:228] Iteration 940, loss = 0.938327
I0413 17:11:54.234642 27180 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:11:54.234664 27180 solver.cpp:244]     Train net output #1: loss = 0.938327 (* 1 = 0.938327 loss)
I0413 17:11:54.234681 27180 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 17:11:55.723948 27180 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 17:11:56.917618 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5995
I0413 17:11:56.917709 27180 solver.cpp:404]     Test net output #1: loss = 1.24124 (* 1 = 1.24124 loss)
I0413 17:11:56.947675 27180 solver.cpp:228] Iteration 960, loss = 0.89935
I0413 17:11:56.947736 27180 solver.cpp:244]     Train net output #0: accuracy = 0.683594
I0413 17:11:56.947751 27180 solver.cpp:244]     Train net output #1: loss = 0.89935 (* 1 = 0.89935 loss)
I0413 17:11:56.947764 27180 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 17:11:58.523710 27180 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 17:11:59.777007 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6279
I0413 17:11:59.777050 27180 solver.cpp:404]     Test net output #1: loss = 1.12058 (* 1 = 1.12058 loss)
I0413 17:11:59.794697 27180 solver.cpp:228] Iteration 980, loss = 0.849784
I0413 17:11:59.794715 27180 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:11:59.794726 27180 solver.cpp:244]     Train net output #1: loss = 0.849784 (* 1 = 0.849784 loss)
I0413 17:11:59.794735 27180 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 17:12:01.340564 27180 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 17:12:02.429560 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5849
I0413 17:12:02.429606 27180 solver.cpp:404]     Test net output #1: loss = 1.36134 (* 1 = 1.36134 loss)
I0413 17:12:02.455008 27180 solver.cpp:228] Iteration 1000, loss = 0.972856
I0413 17:12:02.455065 27180 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0413 17:12:02.455088 27180 solver.cpp:244]     Train net output #1: loss = 0.972856 (* 1 = 0.972856 loss)
I0413 17:12:02.455106 27180 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 17:12:03.857391 27180 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 17:12:05.083092 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6265
I0413 17:12:05.083153 27180 solver.cpp:404]     Test net output #1: loss = 1.18347 (* 1 = 1.18347 loss)
I0413 17:12:05.104949 27180 solver.cpp:228] Iteration 1020, loss = 0.903035
I0413 17:12:05.104974 27180 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:12:05.104985 27180 solver.cpp:244]     Train net output #1: loss = 0.903035 (* 1 = 0.903035 loss)
I0413 17:12:05.105001 27180 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 17:12:06.692350 27180 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 17:12:07.908964 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6203
I0413 17:12:07.909126 27180 solver.cpp:404]     Test net output #1: loss = 1.1868 (* 1 = 1.1868 loss)
I0413 17:12:07.939347 27180 solver.cpp:228] Iteration 1040, loss = 0.888784
I0413 17:12:07.939378 27180 solver.cpp:244]     Train net output #0: accuracy = 0.707031
I0413 17:12:07.939396 27180 solver.cpp:244]     Train net output #1: loss = 0.888784 (* 1 = 0.888784 loss)
I0413 17:12:07.939411 27180 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 17:12:09.527756 27180 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 17:12:10.624375 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6051
I0413 17:12:10.624544 27180 solver.cpp:404]     Test net output #1: loss = 1.25446 (* 1 = 1.25446 loss)
I0413 17:12:10.645311 27180 solver.cpp:228] Iteration 1060, loss = 1.0042
I0413 17:12:10.645339 27180 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:12:10.645350 27180 solver.cpp:244]     Train net output #1: loss = 1.0042 (* 1 = 1.0042 loss)
I0413 17:12:10.645361 27180 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 17:12:12.047489 27180 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 17:12:13.163449 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5703
I0413 17:12:13.163491 27180 solver.cpp:404]     Test net output #1: loss = 1.49231 (* 1 = 1.49231 loss)
I0413 17:12:13.194321 27180 solver.cpp:228] Iteration 1080, loss = 0.881015
I0413 17:12:13.194376 27180 solver.cpp:244]     Train net output #0: accuracy = 0.675781
I0413 17:12:13.194397 27180 solver.cpp:244]     Train net output #1: loss = 0.881015 (* 1 = 0.881015 loss)
I0413 17:12:13.194413 27180 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 17:12:14.782968 27180 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 17:12:16.024626 27180 solver.cpp:404]     Test net output #0: accuracy = 0.647
I0413 17:12:16.024675 27180 solver.cpp:404]     Test net output #1: loss = 1.04826 (* 1 = 1.04826 loss)
I0413 17:12:16.053951 27180 solver.cpp:228] Iteration 1100, loss = 0.901114
I0413 17:12:16.053972 27180 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:12:16.053992 27180 solver.cpp:244]     Train net output #1: loss = 0.901114 (* 1 = 0.901114 loss)
I0413 17:12:16.054000 27180 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 17:12:17.644525 27180 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 17:12:18.893776 27180 solver.cpp:404]     Test net output #0: accuracy = 0.621
I0413 17:12:18.893827 27180 solver.cpp:404]     Test net output #1: loss = 1.16191 (* 1 = 1.16191 loss)
I0413 17:12:18.924484 27180 solver.cpp:228] Iteration 1120, loss = 1.0275
I0413 17:12:18.924535 27180 solver.cpp:244]     Train net output #0: accuracy = 0.671875
I0413 17:12:18.924557 27180 solver.cpp:244]     Train net output #1: loss = 1.0275 (* 1 = 1.0275 loss)
I0413 17:12:18.924572 27180 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 17:12:20.261871 27180 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 17:12:21.349894 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6268
I0413 17:12:21.349942 27180 solver.cpp:404]     Test net output #1: loss = 1.10611 (* 1 = 1.10611 loss)
I0413 17:12:21.379791 27180 solver.cpp:228] Iteration 1140, loss = 0.994542
I0413 17:12:21.379844 27180 solver.cpp:244]     Train net output #0: accuracy = 0.660156
I0413 17:12:21.379865 27180 solver.cpp:244]     Train net output #1: loss = 0.994542 (* 1 = 0.994542 loss)
I0413 17:12:21.379881 27180 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 17:12:22.902842 27180 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 17:12:24.152866 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6351
I0413 17:12:24.152915 27180 solver.cpp:404]     Test net output #1: loss = 1.06936 (* 1 = 1.06936 loss)
I0413 17:12:24.179095 27180 solver.cpp:228] Iteration 1160, loss = 0.900618
I0413 17:12:24.179134 27180 solver.cpp:244]     Train net output #0: accuracy = 0.660156
I0413 17:12:24.179148 27180 solver.cpp:244]     Train net output #1: loss = 0.900618 (* 1 = 0.900618 loss)
I0413 17:12:24.179160 27180 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 17:12:25.736575 27180 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 17:12:26.967782 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6644
I0413 17:12:26.967821 27180 solver.cpp:404]     Test net output #1: loss = 0.972736 (* 1 = 0.972736 loss)
I0413 17:12:26.996125 27180 solver.cpp:228] Iteration 1180, loss = 0.782777
I0413 17:12:26.996186 27180 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:12:26.996209 27180 solver.cpp:244]     Train net output #1: loss = 0.782777 (* 1 = 0.782777 loss)
I0413 17:12:26.996225 27180 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 17:12:28.499150 27180 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 17:12:29.561187 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6512
I0413 17:12:29.561233 27180 solver.cpp:404]     Test net output #1: loss = 1.00301 (* 1 = 1.00301 loss)
I0413 17:12:29.586063 27180 solver.cpp:228] Iteration 1200, loss = 0.837566
I0413 17:12:29.586117 27180 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:12:29.586140 27180 solver.cpp:244]     Train net output #1: loss = 0.837566 (* 1 = 0.837566 loss)
I0413 17:12:29.586158 27180 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 17:12:30.985921 27180 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 17:12:32.227033 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6439
I0413 17:12:32.227082 27180 solver.cpp:404]     Test net output #1: loss = 1.06504 (* 1 = 1.06504 loss)
I0413 17:12:32.247210 27180 solver.cpp:228] Iteration 1220, loss = 0.878085
I0413 17:12:32.247233 27180 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:12:32.247243 27180 solver.cpp:244]     Train net output #1: loss = 0.878085 (* 1 = 0.878085 loss)
I0413 17:12:32.247253 27180 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 17:12:33.826009 27180 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 17:12:35.077035 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6286
I0413 17:12:35.077090 27180 solver.cpp:404]     Test net output #1: loss = 1.16396 (* 1 = 1.16396 loss)
I0413 17:12:35.104334 27180 solver.cpp:228] Iteration 1240, loss = 0.910654
I0413 17:12:35.104357 27180 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:12:35.104368 27180 solver.cpp:244]     Train net output #1: loss = 0.910654 (* 1 = 0.910654 loss)
I0413 17:12:35.104378 27180 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 17:12:36.711110 27180 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 17:12:37.776352 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6308
I0413 17:12:37.776394 27180 solver.cpp:404]     Test net output #1: loss = 1.11991 (* 1 = 1.11991 loss)
I0413 17:12:37.802100 27180 solver.cpp:228] Iteration 1260, loss = 0.881676
I0413 17:12:37.802121 27180 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:12:37.802130 27180 solver.cpp:244]     Train net output #1: loss = 0.881676 (* 1 = 0.881676 loss)
I0413 17:12:37.802139 27180 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 17:12:39.203490 27180 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 17:12:40.377957 27180 solver.cpp:404]     Test net output #0: accuracy = 0.621
I0413 17:12:40.378007 27180 solver.cpp:404]     Test net output #1: loss = 1.1675 (* 1 = 1.1675 loss)
I0413 17:12:40.404883 27180 solver.cpp:228] Iteration 1280, loss = 0.8049
I0413 17:12:40.404942 27180 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:12:40.404955 27180 solver.cpp:244]     Train net output #1: loss = 0.8049 (* 1 = 0.8049 loss)
I0413 17:12:40.404964 27180 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 17:12:41.999480 27180 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 17:12:43.238648 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6246
I0413 17:12:43.238692 27180 solver.cpp:404]     Test net output #1: loss = 1.13454 (* 1 = 1.13454 loss)
I0413 17:12:43.267184 27180 solver.cpp:228] Iteration 1300, loss = 1.00861
I0413 17:12:43.267222 27180 solver.cpp:244]     Train net output #0: accuracy = 0.652344
I0413 17:12:43.267235 27180 solver.cpp:244]     Train net output #1: loss = 1.00861 (* 1 = 1.00861 loss)
I0413 17:12:43.267243 27180 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 17:12:44.833865 27180 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 17:12:45.983434 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6073
I0413 17:12:45.983476 27180 solver.cpp:404]     Test net output #1: loss = 1.20617 (* 1 = 1.20617 loss)
I0413 17:12:46.009572 27180 solver.cpp:228] Iteration 1320, loss = 0.981327
I0413 17:12:46.009595 27180 solver.cpp:244]     Train net output #0: accuracy = 0.652344
I0413 17:12:46.009605 27180 solver.cpp:244]     Train net output #1: loss = 0.981327 (* 1 = 0.981327 loss)
I0413 17:12:46.009614 27180 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 17:12:47.406810 27180 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 17:12:48.481395 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6306
I0413 17:12:48.481441 27180 solver.cpp:404]     Test net output #1: loss = 1.09374 (* 1 = 1.09374 loss)
I0413 17:12:48.506397 27180 solver.cpp:228] Iteration 1340, loss = 0.896843
I0413 17:12:48.506419 27180 solver.cpp:244]     Train net output #0: accuracy = 0.675781
I0413 17:12:48.506429 27180 solver.cpp:244]     Train net output #1: loss = 0.896843 (* 1 = 0.896843 loss)
I0413 17:12:48.506438 27180 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 17:12:50.085747 27180 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 17:12:51.343832 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6397
I0413 17:12:51.343879 27180 solver.cpp:404]     Test net output #1: loss = 1.07476 (* 1 = 1.07476 loss)
I0413 17:12:51.360987 27180 solver.cpp:228] Iteration 1360, loss = 0.875843
I0413 17:12:51.361042 27180 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:12:51.361063 27180 solver.cpp:244]     Train net output #1: loss = 0.875843 (* 1 = 0.875843 loss)
I0413 17:12:51.361078 27180 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 17:12:52.925201 27180 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 17:12:54.170863 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6228
I0413 17:12:54.170930 27180 solver.cpp:404]     Test net output #1: loss = 1.16724 (* 1 = 1.16724 loss)
I0413 17:12:54.192847 27180 solver.cpp:228] Iteration 1380, loss = 0.978208
I0413 17:12:54.192876 27180 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:12:54.192888 27180 solver.cpp:244]     Train net output #1: loss = 0.978208 (* 1 = 0.978208 loss)
I0413 17:12:54.192896 27180 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 17:12:55.654888 27180 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 17:12:56.753360 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5386
I0413 17:12:56.753486 27180 solver.cpp:404]     Test net output #1: loss = 1.60021 (* 1 = 1.60021 loss)
I0413 17:12:56.781512 27180 solver.cpp:228] Iteration 1400, loss = 0.988707
I0413 17:12:56.781545 27180 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:12:56.781563 27180 solver.cpp:244]     Train net output #1: loss = 0.988707 (* 1 = 0.988707 loss)
I0413 17:12:56.781577 27180 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 17:12:58.213769 27180 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 17:12:59.451625 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6411
I0413 17:12:59.451686 27180 solver.cpp:404]     Test net output #1: loss = 1.14571 (* 1 = 1.14571 loss)
I0413 17:12:59.482471 27180 solver.cpp:228] Iteration 1420, loss = 0.93992
I0413 17:12:59.482522 27180 solver.cpp:244]     Train net output #0: accuracy = 0.699219
I0413 17:12:59.482543 27180 solver.cpp:244]     Train net output #1: loss = 0.93992 (* 1 = 0.93992 loss)
I0413 17:12:59.482560 27180 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 17:13:01.071353 27180 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 17:13:02.300783 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6302
I0413 17:13:02.300827 27180 solver.cpp:404]     Test net output #1: loss = 1.12443 (* 1 = 1.12443 loss)
I0413 17:13:02.328694 27180 solver.cpp:228] Iteration 1440, loss = 0.850951
I0413 17:13:02.328716 27180 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:13:02.328725 27180 solver.cpp:244]     Train net output #1: loss = 0.850951 (* 1 = 0.850951 loss)
I0413 17:13:02.328735 27180 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 17:13:03.913959 27180 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 17:13:04.934134 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6364
I0413 17:13:04.934175 27180 solver.cpp:404]     Test net output #1: loss = 1.0689 (* 1 = 1.0689 loss)
I0413 17:13:04.960371 27180 solver.cpp:228] Iteration 1460, loss = 0.720513
I0413 17:13:04.960422 27180 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:13:04.960433 27180 solver.cpp:244]     Train net output #1: loss = 0.720513 (* 1 = 0.720513 loss)
I0413 17:13:04.960443 27180 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 17:13:06.336908 27180 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 17:13:07.540185 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6056
I0413 17:13:07.540227 27180 solver.cpp:404]     Test net output #1: loss = 1.27518 (* 1 = 1.27518 loss)
I0413 17:13:07.568156 27180 solver.cpp:228] Iteration 1480, loss = 0.835594
I0413 17:13:07.568176 27180 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:13:07.568186 27180 solver.cpp:244]     Train net output #1: loss = 0.835594 (* 1 = 0.835594 loss)
I0413 17:13:07.568194 27180 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 17:13:09.154573 27180 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 17:13:10.365278 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5976
I0413 17:13:10.365327 27180 solver.cpp:404]     Test net output #1: loss = 1.29447 (* 1 = 1.29447 loss)
I0413 17:13:10.396241 27180 solver.cpp:228] Iteration 1500, loss = 0.853271
I0413 17:13:10.396301 27180 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:13:10.396323 27180 solver.cpp:244]     Train net output #1: loss = 0.853271 (* 1 = 0.853271 loss)
I0413 17:13:10.396355 27180 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 17:13:11.980352 27180 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 17:13:13.093641 27180 solver.cpp:404]     Test net output #0: accuracy = 0.5643
I0413 17:13:13.093693 27180 solver.cpp:404]     Test net output #1: loss = 1.36598 (* 1 = 1.36598 loss)
I0413 17:13:13.113522 27180 solver.cpp:228] Iteration 1520, loss = 0.93005
I0413 17:13:13.113543 27180 solver.cpp:244]     Train net output #0: accuracy = 0.671875
I0413 17:13:13.113553 27180 solver.cpp:244]     Train net output #1: loss = 0.93005 (* 1 = 0.93005 loss)
I0413 17:13:13.113561 27180 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 17:13:14.503756 27180 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 17:13:15.592458 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6165
I0413 17:13:15.592496 27180 solver.cpp:404]     Test net output #1: loss = 1.20764 (* 1 = 1.20764 loss)
I0413 17:13:15.619942 27180 solver.cpp:228] Iteration 1540, loss = 0.991144
I0413 17:13:15.619962 27180 solver.cpp:244]     Train net output #0: accuracy = 0.648438
I0413 17:13:15.619972 27180 solver.cpp:244]     Train net output #1: loss = 0.991144 (* 1 = 0.991144 loss)
I0413 17:13:15.619982 27180 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 17:13:17.211057 27180 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 17:13:18.454630 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6514
I0413 17:13:18.454673 27180 solver.cpp:404]     Test net output #1: loss = 1.06251 (* 1 = 1.06251 loss)
I0413 17:13:18.483006 27180 solver.cpp:228] Iteration 1560, loss = 0.999624
I0413 17:13:18.483027 27180 solver.cpp:244]     Train net output #0: accuracy = 0.671875
I0413 17:13:18.483036 27180 solver.cpp:244]     Train net output #1: loss = 0.999624 (* 1 = 0.999624 loss)
I0413 17:13:18.483045 27180 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 17:13:20.049471 27180 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 17:13:21.307430 27180 solver.cpp:404]     Test net output #0: accuracy = 0.635
I0413 17:13:21.307474 27180 solver.cpp:404]     Test net output #1: loss = 1.15766 (* 1 = 1.15766 loss)
I0413 17:13:21.320333 27180 solver.cpp:228] Iteration 1580, loss = 0.845291
I0413 17:13:21.320353 27180 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:13:21.320363 27180 solver.cpp:244]     Train net output #1: loss = 0.845291 (* 1 = 0.845291 loss)
I0413 17:13:21.320371 27180 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 17:13:22.738342 27180 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 17:13:23.827404 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6548
I0413 17:13:23.827440 27180 solver.cpp:404]     Test net output #1: loss = 1.03515 (* 1 = 1.03515 loss)
I0413 17:13:23.847446 27180 solver.cpp:228] Iteration 1600, loss = 0.869029
I0413 17:13:23.847466 27180 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:13:23.847476 27180 solver.cpp:244]     Train net output #1: loss = 0.869029 (* 1 = 0.869029 loss)
I0413 17:13:23.847486 27180 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 17:13:25.344660 27180 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 17:13:26.597585 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6573
I0413 17:13:26.597646 27180 solver.cpp:404]     Test net output #1: loss = 1.01534 (* 1 = 1.01534 loss)
I0413 17:13:26.622576 27180 solver.cpp:228] Iteration 1620, loss = 0.830228
I0413 17:13:26.622620 27180 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:13:26.622638 27180 solver.cpp:244]     Train net output #1: loss = 0.830228 (* 1 = 0.830228 loss)
I0413 17:13:26.622653 27180 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 17:13:28.199373 27180 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 17:13:29.438783 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6264
I0413 17:13:29.438849 27180 solver.cpp:404]     Test net output #1: loss = 1.19224 (* 1 = 1.19224 loss)
I0413 17:13:29.465991 27180 solver.cpp:228] Iteration 1640, loss = 0.835743
I0413 17:13:29.466022 27180 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:13:29.466034 27180 solver.cpp:244]     Train net output #1: loss = 0.835743 (* 1 = 0.835743 loss)
I0413 17:13:29.466043 27180 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 17:13:30.971760 27180 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 17:13:32.050345 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6318
I0413 17:13:32.050386 27180 solver.cpp:404]     Test net output #1: loss = 1.13862 (* 1 = 1.13862 loss)
I0413 17:13:32.073627 27180 solver.cpp:228] Iteration 1660, loss = 0.745936
I0413 17:13:32.073650 27180 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:13:32.073660 27180 solver.cpp:244]     Train net output #1: loss = 0.745936 (* 1 = 0.745936 loss)
I0413 17:13:32.073669 27180 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 17:13:33.470402 27180 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 17:13:34.670333 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6632
I0413 17:13:34.670389 27180 solver.cpp:404]     Test net output #1: loss = 1.05447 (* 1 = 1.05447 loss)
I0413 17:13:34.698178 27180 solver.cpp:228] Iteration 1680, loss = 0.798516
I0413 17:13:34.698196 27180 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:13:34.698205 27180 solver.cpp:244]     Train net output #1: loss = 0.798516 (* 1 = 0.798516 loss)
I0413 17:13:34.698215 27180 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 17:13:36.295227 27180 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 17:13:37.519685 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6526
I0413 17:13:37.519731 27180 solver.cpp:404]     Test net output #1: loss = 1.06033 (* 1 = 1.06033 loss)
I0413 17:13:37.547688 27180 solver.cpp:228] Iteration 1700, loss = 0.909858
I0413 17:13:37.547714 27180 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:13:37.547724 27180 solver.cpp:244]     Train net output #1: loss = 0.909858 (* 1 = 0.909858 loss)
I0413 17:13:37.547732 27180 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 17:13:39.132056 27180 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 17:13:40.217604 27180 solver.cpp:404]     Test net output #0: accuracy = 0.676
I0413 17:13:40.217648 27180 solver.cpp:404]     Test net output #1: loss = 0.980197 (* 1 = 0.980197 loss)
I0413 17:13:40.244482 27180 solver.cpp:228] Iteration 1720, loss = 0.940399
I0413 17:13:40.244527 27180 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:13:40.244539 27180 solver.cpp:244]     Train net output #1: loss = 0.940399 (* 1 = 0.940399 loss)
I0413 17:13:40.244547 27180 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 17:13:41.646955 27180 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 17:13:42.788650 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6661
I0413 17:13:42.788688 27180 solver.cpp:404]     Test net output #1: loss = 1.00485 (* 1 = 1.00485 loss)
I0413 17:13:42.819838 27180 solver.cpp:228] Iteration 1740, loss = 0.834859
I0413 17:13:42.819895 27180 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:13:42.819918 27180 solver.cpp:244]     Train net output #1: loss = 0.834859 (* 1 = 0.834859 loss)
I0413 17:13:42.819934 27180 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 17:13:44.410452 27180 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 17:13:45.608960 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6308
I0413 17:13:45.609011 27180 solver.cpp:404]     Test net output #1: loss = 1.20457 (* 1 = 1.20457 loss)
I0413 17:13:45.637665 27180 solver.cpp:228] Iteration 1760, loss = 0.978848
I0413 17:13:45.637684 27180 solver.cpp:244]     Train net output #0: accuracy = 0.683594
I0413 17:13:45.637693 27180 solver.cpp:244]     Train net output #1: loss = 0.978848 (* 1 = 0.978848 loss)
I0413 17:13:45.637702 27180 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 17:13:47.214735 27180 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 17:13:48.472781 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6414
I0413 17:13:48.472828 27180 solver.cpp:404]     Test net output #1: loss = 1.11456 (* 1 = 1.11456 loss)
I0413 17:13:48.486147 27180 solver.cpp:228] Iteration 1780, loss = 0.870872
I0413 17:13:48.486166 27180 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:13:48.486176 27180 solver.cpp:244]     Train net output #1: loss = 0.870872 (* 1 = 0.870872 loss)
I0413 17:13:48.486184 27180 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 17:13:49.835978 27180 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 17:13:50.926404 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6712
I0413 17:13:50.926450 27180 solver.cpp:404]     Test net output #1: loss = 1.04763 (* 1 = 1.04763 loss)
I0413 17:13:50.951748 27180 solver.cpp:228] Iteration 1800, loss = 0.861386
I0413 17:13:50.951769 27180 solver.cpp:244]     Train net output #0: accuracy = 0.679688
I0413 17:13:50.951778 27180 solver.cpp:244]     Train net output #1: loss = 0.861386 (* 1 = 0.861386 loss)
I0413 17:13:50.951787 27180 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 17:13:52.476797 27180 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 17:13:53.714583 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6537
I0413 17:13:53.714633 27180 solver.cpp:404]     Test net output #1: loss = 1.07127 (* 1 = 1.07127 loss)
I0413 17:13:53.739807 27180 solver.cpp:228] Iteration 1820, loss = 0.864631
I0413 17:13:53.739866 27180 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:13:53.739888 27180 solver.cpp:244]     Train net output #1: loss = 0.864631 (* 1 = 0.864631 loss)
I0413 17:13:53.739904 27180 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 17:13:55.318833 27180 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 17:13:56.547116 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6612
I0413 17:13:56.547161 27180 solver.cpp:404]     Test net output #1: loss = 1.05508 (* 1 = 1.05508 loss)
I0413 17:13:56.573194 27180 solver.cpp:228] Iteration 1840, loss = 0.767418
I0413 17:13:56.573238 27180 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:13:56.573252 27180 solver.cpp:244]     Train net output #1: loss = 0.767418 (* 1 = 0.767418 loss)
I0413 17:13:56.573263 27180 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 17:13:58.040556 27180 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 17:13:59.128404 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6401
I0413 17:13:59.128455 27180 solver.cpp:404]     Test net output #1: loss = 1.07051 (* 1 = 1.07051 loss)
I0413 17:13:59.155871 27180 solver.cpp:228] Iteration 1860, loss = 0.795286
I0413 17:13:59.155926 27180 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:13:59.155949 27180 solver.cpp:244]     Train net output #1: loss = 0.795286 (* 1 = 0.795286 loss)
I0413 17:13:59.155966 27180 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 17:14:00.541388 27180 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 17:14:01.776731 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6433
I0413 17:14:01.776969 27180 solver.cpp:404]     Test net output #1: loss = 1.08236 (* 1 = 1.08236 loss)
I0413 17:14:01.796022 27180 solver.cpp:228] Iteration 1880, loss = 0.770751
I0413 17:14:01.796044 27180 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:14:01.796054 27180 solver.cpp:244]     Train net output #1: loss = 0.770751 (* 1 = 0.770751 loss)
I0413 17:14:01.796064 27180 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 17:14:03.368988 27180 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 17:14:04.612154 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6562
I0413 17:14:04.612192 27180 solver.cpp:404]     Test net output #1: loss = 1.06064 (* 1 = 1.06064 loss)
I0413 17:14:04.639178 27180 solver.cpp:228] Iteration 1900, loss = 0.905906
I0413 17:14:04.639199 27180 solver.cpp:244]     Train net output #0: accuracy = 0.679688
I0413 17:14:04.639209 27180 solver.cpp:244]     Train net output #1: loss = 0.905906 (* 1 = 0.905906 loss)
I0413 17:14:04.639219 27180 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 17:14:06.226167 27180 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 17:14:07.306031 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6562
I0413 17:14:07.306082 27180 solver.cpp:404]     Test net output #1: loss = 1.06401 (* 1 = 1.06401 loss)
I0413 17:14:07.333240 27180 solver.cpp:228] Iteration 1920, loss = 0.947911
I0413 17:14:07.333259 27180 solver.cpp:244]     Train net output #0: accuracy = 0.675781
I0413 17:14:07.333268 27180 solver.cpp:244]     Train net output #1: loss = 0.947911 (* 1 = 0.947911 loss)
I0413 17:14:07.333277 27180 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 17:14:08.704905 27180 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 17:14:09.861357 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6694
I0413 17:14:09.861414 27180 solver.cpp:404]     Test net output #1: loss = 0.969284 (* 1 = 0.969284 loss)
I0413 17:14:09.882827 27180 solver.cpp:228] Iteration 1940, loss = 0.809338
I0413 17:14:09.882856 27180 solver.cpp:244]     Train net output #0: accuracy = 0.710938
I0413 17:14:09.882868 27180 solver.cpp:244]     Train net output #1: loss = 0.809338 (* 1 = 0.809338 loss)
I0413 17:14:09.882877 27180 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 17:14:11.481773 27180 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 17:14:12.697809 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6647
I0413 17:14:12.697852 27180 solver.cpp:404]     Test net output #1: loss = 0.991936 (* 1 = 0.991936 loss)
I0413 17:14:12.725364 27180 solver.cpp:228] Iteration 1960, loss = 0.850166
I0413 17:14:12.725383 27180 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:14:12.725392 27180 solver.cpp:244]     Train net output #1: loss = 0.850166 (* 1 = 0.850166 loss)
I0413 17:14:12.725401 27180 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 17:14:14.341774 27180 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 17:14:15.469866 27180 solver.cpp:404]     Test net output #0: accuracy = 0.6626
I0413 17:14:15.469923 27180 solver.cpp:404]     Test net output #1: loss = 1.03581 (* 1 = 1.03581 loss)
I0413 17:14:15.492331 27180 solver.cpp:228] Iteration 1980, loss = 0.886698
I0413 17:14:15.492362 27180 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:14:15.492377 27180 solver.cpp:244]     Train net output #1: loss = 0.886698 (* 1 = 0.886698 loss)
I0413 17:14:15.492391 27180 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 17:14:16.887024 27180 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar0/ResNet-cifar0_iter_2000.caffemodel
I0413 17:14:16.888422 27180 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar0/ResNet-cifar0_iter_2000.solverstate
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 17:14:19.278916  8324 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "/home/liangjiang/code/residual_network-dy/results/snapshots/ResNet-cifar1/ResNet-cifar1"
solver_mode: GPU
net: "/home/liangjiang/code/residual_network-dy/prototxt/DyResNet/ResNet-cifar1.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 17:14:19.278969  8324 solver.cpp:91] Creating training net from net file: /home/liangjiang/code/residual_network-dy/prototxt/DyResNet/ResNet-cifar1.prototxt
I0413 17:14:19.279548  8324 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 17:14:19.279698  8324 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "/home/liangjiang/code/residual_network-dy/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/liangjiang/code/residual_network-dy/data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv2_2"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:14:19.279821  8324 layer_factory.hpp:77] Creating layer cifar
I0413 17:14:19.280349  8324 net.cpp:91] Creating Layer cifar
I0413 17:14:19.280361  8324 net.cpp:399] cifar -> data
I0413 17:14:19.280376  8324 net.cpp:399] cifar -> label
I0413 17:14:19.280387  8324 data_transformer.cpp:25] Loading mean file from: /home/liangjiang/code/residual_network-dy/data/cifar10/mean.binaryproto
I0413 17:14:19.283963  8398 db_lmdb.cpp:38] Opened lmdb /home/liangjiang/code/residual_network-dy/data/cifar10/cifar10_train_lmdb
I0413 17:14:19.330890  8324 data_layer.cpp:41] output data size: 256,3,32,32
I0413 17:14:19.341454  8324 net.cpp:141] Setting up cifar
I0413 17:14:19.341480  8324 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 17:14:19.341486  8324 net.cpp:148] Top shape: 256 (256)
I0413 17:14:19.341492  8324 net.cpp:156] Memory required for data: 3146752
I0413 17:14:19.341501  8324 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:14:19.341519  8324 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:14:19.341526  8324 net.cpp:425] label_cifar_1_split <- label
I0413 17:14:19.341534  8324 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:14:19.341547  8324 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:14:19.341600  8324 net.cpp:141] Setting up label_cifar_1_split
I0413 17:14:19.341609  8324 net.cpp:148] Top shape: 256 (256)
I0413 17:14:19.341614  8324 net.cpp:148] Top shape: 256 (256)
I0413 17:14:19.341617  8324 net.cpp:156] Memory required for data: 3148800
I0413 17:14:19.341621  8324 layer_factory.hpp:77] Creating layer conv1
I0413 17:14:19.341636  8324 net.cpp:91] Creating Layer conv1
I0413 17:14:19.341641  8324 net.cpp:425] conv1 <- data
I0413 17:14:19.341650  8324 net.cpp:399] conv1 -> conv1
I0413 17:14:19.602823  8324 net.cpp:141] Setting up conv1
I0413 17:14:19.602870  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.602876  8324 net.cpp:156] Memory required for data: 19926016
I0413 17:14:19.602895  8324 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:14:19.602910  8324 net.cpp:91] Creating Layer bn_conv1
I0413 17:14:19.602916  8324 net.cpp:425] bn_conv1 <- conv1
I0413 17:14:19.602923  8324 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:14:19.603083  8324 net.cpp:141] Setting up bn_conv1
I0413 17:14:19.603092  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.603096  8324 net.cpp:156] Memory required for data: 36703232
I0413 17:14:19.603108  8324 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:14:19.603119  8324 net.cpp:91] Creating Layer scale_conv1
I0413 17:14:19.603124  8324 net.cpp:425] scale_conv1 <- conv1
I0413 17:14:19.603129  8324 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:14:19.603164  8324 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:14:19.603263  8324 net.cpp:141] Setting up scale_conv1
I0413 17:14:19.603271  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.603276  8324 net.cpp:156] Memory required for data: 53480448
I0413 17:14:19.603293  8324 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:14:19.603302  8324 net.cpp:91] Creating Layer conv1_relu
I0413 17:14:19.603305  8324 net.cpp:425] conv1_relu <- conv1
I0413 17:14:19.603312  8324 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:14:19.603845  8324 net.cpp:141] Setting up conv1_relu
I0413 17:14:19.603859  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.603864  8324 net.cpp:156] Memory required for data: 70257664
I0413 17:14:19.603869  8324 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:14:19.603878  8324 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:14:19.603881  8324 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:14:19.603888  8324 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:14:19.603896  8324 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:14:19.603932  8324 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:14:19.603940  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.603945  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.603948  8324 net.cpp:156] Memory required for data: 103812096
I0413 17:14:19.603952  8324 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:14:19.603965  8324 net.cpp:91] Creating Layer conv2_1a
I0413 17:14:19.603970  8324 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:14:19.603976  8324 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:14:19.607338  8324 net.cpp:141] Setting up conv2_1a
I0413 17:14:19.607354  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.607359  8324 net.cpp:156] Memory required for data: 120589312
I0413 17:14:19.607369  8324 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:14:19.607393  8324 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:14:19.607398  8324 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:14:19.607403  8324 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:14:19.607589  8324 net.cpp:141] Setting up bn_conv2_1a
I0413 17:14:19.607597  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.607601  8324 net.cpp:156] Memory required for data: 137366528
I0413 17:14:19.607610  8324 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:14:19.607619  8324 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:14:19.607623  8324 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:14:19.607630  8324 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:14:19.607664  8324 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:14:19.607767  8324 net.cpp:141] Setting up scale_conv2_1a
I0413 17:14:19.607779  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.607795  8324 net.cpp:156] Memory required for data: 154143744
I0413 17:14:19.607802  8324 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:14:19.607808  8324 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:14:19.607812  8324 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:14:19.607817  8324 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:14:19.609501  8324 net.cpp:141] Setting up conv2_1a_relu
I0413 17:14:19.609515  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.609520  8324 net.cpp:156] Memory required for data: 170920960
I0413 17:14:19.609525  8324 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:14:19.609539  8324 net.cpp:91] Creating Layer conv2_1b
I0413 17:14:19.609544  8324 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:14:19.609551  8324 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:14:19.613183  8324 net.cpp:141] Setting up conv2_1b
I0413 17:14:19.613225  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.613231  8324 net.cpp:156] Memory required for data: 187698176
I0413 17:14:19.613243  8324 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:14:19.613260  8324 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:14:19.613266  8324 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:14:19.613276  8324 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:14:19.613477  8324 net.cpp:141] Setting up bn_conv2_1b
I0413 17:14:19.613487  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.613490  8324 net.cpp:156] Memory required for data: 204475392
I0413 17:14:19.613508  8324 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:14:19.613518  8324 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:14:19.613534  8324 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:14:19.613540  8324 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:14:19.613581  8324 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:14:19.613687  8324 net.cpp:141] Setting up scale_conv2_1b
I0413 17:14:19.613697  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.613700  8324 net.cpp:156] Memory required for data: 221252608
I0413 17:14:19.613708  8324 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:14:19.613716  8324 net.cpp:91] Creating Layer conv2_1
I0413 17:14:19.613720  8324 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:14:19.613726  8324 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:14:19.613732  8324 net.cpp:399] conv2_1 -> conv2_1
I0413 17:14:19.613757  8324 net.cpp:141] Setting up conv2_1
I0413 17:14:19.613765  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.613768  8324 net.cpp:156] Memory required for data: 238029824
I0413 17:14:19.613772  8324 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:14:19.613778  8324 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:14:19.613782  8324 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:14:19.613790  8324 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:14:19.614140  8324 net.cpp:141] Setting up conv2_1_relu
I0413 17:14:19.614151  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.614156  8324 net.cpp:156] Memory required for data: 254807040
I0413 17:14:19.614161  8324 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:14:19.614169  8324 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:14:19.614174  8324 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:14:19.614181  8324 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:14:19.614190  8324 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:14:19.614228  8324 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:14:19.614235  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.614240  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.614244  8324 net.cpp:156] Memory required for data: 288361472
I0413 17:14:19.614248  8324 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:14:19.614264  8324 net.cpp:91] Creating Layer conv2_2a
I0413 17:14:19.614267  8324 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:14:19.614274  8324 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:14:19.617655  8324 net.cpp:141] Setting up conv2_2a
I0413 17:14:19.617671  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.617676  8324 net.cpp:156] Memory required for data: 305138688
I0413 17:14:19.617683  8324 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:14:19.617693  8324 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:14:19.617697  8324 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:14:19.617705  8324 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:14:19.617861  8324 net.cpp:141] Setting up bn_conv2_2a
I0413 17:14:19.617869  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.617872  8324 net.cpp:156] Memory required for data: 321915904
I0413 17:14:19.617880  8324 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:14:19.617889  8324 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:14:19.617893  8324 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:14:19.617898  8324 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:14:19.617933  8324 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:14:19.618027  8324 net.cpp:141] Setting up scale_conv2_2a
I0413 17:14:19.618041  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.618046  8324 net.cpp:156] Memory required for data: 338693120
I0413 17:14:19.618052  8324 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:14:19.618058  8324 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:14:19.618062  8324 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:14:19.618067  8324 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:14:19.619842  8324 net.cpp:141] Setting up conv2_2a_relu
I0413 17:14:19.619854  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.619858  8324 net.cpp:156] Memory required for data: 355470336
I0413 17:14:19.619863  8324 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:14:19.619874  8324 net.cpp:91] Creating Layer conv2_2b
I0413 17:14:19.619880  8324 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:14:19.619887  8324 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:14:19.623340  8324 net.cpp:141] Setting up conv2_2b
I0413 17:14:19.623355  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.623359  8324 net.cpp:156] Memory required for data: 372247552
I0413 17:14:19.623366  8324 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:14:19.623375  8324 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:14:19.623380  8324 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:14:19.623386  8324 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:14:19.623546  8324 net.cpp:141] Setting up bn_conv2_2b
I0413 17:14:19.623554  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.623558  8324 net.cpp:156] Memory required for data: 389024768
I0413 17:14:19.623572  8324 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:14:19.623579  8324 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:14:19.623584  8324 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:14:19.623589  8324 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:14:19.623620  8324 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:14:19.623714  8324 net.cpp:141] Setting up scale_conv2_2b
I0413 17:14:19.623723  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.623726  8324 net.cpp:156] Memory required for data: 405801984
I0413 17:14:19.623733  8324 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:14:19.623740  8324 net.cpp:91] Creating Layer conv2_2
I0413 17:14:19.623744  8324 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:14:19.623749  8324 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:14:19.623754  8324 net.cpp:399] conv2_2 -> conv2_2
I0413 17:14:19.623777  8324 net.cpp:141] Setting up conv2_2
I0413 17:14:19.623783  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.623787  8324 net.cpp:156] Memory required for data: 422579200
I0413 17:14:19.623791  8324 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:14:19.623796  8324 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:14:19.623800  8324 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:14:19.623806  8324 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:14:19.624402  8324 net.cpp:141] Setting up conv2_2_relu
I0413 17:14:19.624414  8324 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:14:19.624418  8324 net.cpp:156] Memory required for data: 439356416
I0413 17:14:19.624423  8324 layer_factory.hpp:77] Creating layer global_pool
I0413 17:14:19.624434  8324 net.cpp:91] Creating Layer global_pool
I0413 17:14:19.624439  8324 net.cpp:425] global_pool <- conv2_2
I0413 17:14:19.624444  8324 net.cpp:399] global_pool -> global_pool
I0413 17:14:19.625555  8324 net.cpp:141] Setting up global_pool
I0413 17:14:19.625569  8324 net.cpp:148] Top shape: 256 16 4 4 (65536)
I0413 17:14:19.625573  8324 net.cpp:156] Memory required for data: 439618560
I0413 17:14:19.625577  8324 layer_factory.hpp:77] Creating layer ip
I0413 17:14:19.625586  8324 net.cpp:91] Creating Layer ip
I0413 17:14:19.625589  8324 net.cpp:425] ip <- global_pool
I0413 17:14:19.625596  8324 net.cpp:399] ip -> ip
I0413 17:14:19.625692  8324 net.cpp:141] Setting up ip
I0413 17:14:19.625700  8324 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:14:19.625708  8324 net.cpp:156] Memory required for data: 439628800
I0413 17:14:19.625715  8324 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:14:19.625722  8324 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:14:19.625726  8324 net.cpp:425] ip_ip_0_split <- ip
I0413 17:14:19.625732  8324 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:14:19.625738  8324 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:14:19.625768  8324 net.cpp:141] Setting up ip_ip_0_split
I0413 17:14:19.625774  8324 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:14:19.625779  8324 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:14:19.625783  8324 net.cpp:156] Memory required for data: 439649280
I0413 17:14:19.625787  8324 layer_factory.hpp:77] Creating layer accuracy
I0413 17:14:19.625797  8324 net.cpp:91] Creating Layer accuracy
I0413 17:14:19.625800  8324 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:14:19.625805  8324 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:14:19.625813  8324 net.cpp:399] accuracy -> accuracy
I0413 17:14:19.625819  8324 net.cpp:141] Setting up accuracy
I0413 17:14:19.625824  8324 net.cpp:148] Top shape: (1)
I0413 17:14:19.625828  8324 net.cpp:156] Memory required for data: 439649284
I0413 17:14:19.625833  8324 layer_factory.hpp:77] Creating layer loss
I0413 17:14:19.625838  8324 net.cpp:91] Creating Layer loss
I0413 17:14:19.625841  8324 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:14:19.625846  8324 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:14:19.625851  8324 net.cpp:399] loss -> loss
I0413 17:14:19.625864  8324 layer_factory.hpp:77] Creating layer loss
I0413 17:14:19.626742  8324 net.cpp:141] Setting up loss
I0413 17:14:19.626752  8324 net.cpp:148] Top shape: (1)
I0413 17:14:19.626756  8324 net.cpp:151]     with loss weight 1
I0413 17:14:19.626770  8324 net.cpp:156] Memory required for data: 439649288
I0413 17:14:19.626775  8324 net.cpp:217] loss needs backward computation.
I0413 17:14:19.626778  8324 net.cpp:219] accuracy does not need backward computation.
I0413 17:14:19.626783  8324 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:14:19.626786  8324 net.cpp:217] ip needs backward computation.
I0413 17:14:19.626791  8324 net.cpp:217] global_pool needs backward computation.
I0413 17:14:19.626794  8324 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:14:19.626798  8324 net.cpp:217] conv2_2 needs backward computation.
I0413 17:14:19.626802  8324 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:14:19.626806  8324 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:14:19.626809  8324 net.cpp:217] conv2_2b needs backward computation.
I0413 17:14:19.626813  8324 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:14:19.626816  8324 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:14:19.626819  8324 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:14:19.626823  8324 net.cpp:217] conv2_2a needs backward computation.
I0413 17:14:19.626827  8324 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:14:19.626830  8324 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:14:19.626834  8324 net.cpp:217] conv2_1 needs backward computation.
I0413 17:14:19.626838  8324 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:14:19.626842  8324 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:14:19.626845  8324 net.cpp:217] conv2_1b needs backward computation.
I0413 17:14:19.626849  8324 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:14:19.626853  8324 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:14:19.626857  8324 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:14:19.626860  8324 net.cpp:217] conv2_1a needs backward computation.
I0413 17:14:19.626864  8324 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:14:19.626868  8324 net.cpp:217] conv1_relu needs backward computation.
I0413 17:14:19.626873  8324 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:14:19.626880  8324 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:14:19.626884  8324 net.cpp:217] conv1 needs backward computation.
I0413 17:14:19.626889  8324 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:14:19.626893  8324 net.cpp:219] cifar does not need backward computation.
I0413 17:14:19.626898  8324 net.cpp:261] This network produces output accuracy
I0413 17:14:19.626901  8324 net.cpp:261] This network produces output loss
I0413 17:14:19.626922  8324 net.cpp:274] Network initialization done.
I0413 17:14:19.627534  8324 solver.cpp:181] Creating test net (#0) specified by net file: /home/liangjiang/code/residual_network-dy/prototxt/DyResNet/ResNet-cifar1.prototxt
I0413 17:14:19.627579  8324 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 17:14:19.627728  8324 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/liangjiang/code/residual_network-dy/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/liangjiang/code/residual_network-dy/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv2_2"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:14:19.627846  8324 layer_factory.hpp:77] Creating layer cifar
I0413 17:14:19.628199  8324 net.cpp:91] Creating Layer cifar
I0413 17:14:19.628211  8324 net.cpp:399] cifar -> data
I0413 17:14:19.628221  8324 net.cpp:399] cifar -> label
I0413 17:14:19.628228  8324 data_transformer.cpp:25] Loading mean file from: /home/liangjiang/code/residual_network-dy/data/cifar10/mean.binaryproto
I0413 17:14:19.629640  8409 db_lmdb.cpp:38] Opened lmdb /home/liangjiang/code/residual_network-dy/data/cifar10/cifar10_test_lmdb
I0413 17:14:19.629793  8324 data_layer.cpp:41] output data size: 100,3,32,32
I0413 17:14:19.632693  8324 net.cpp:141] Setting up cifar
I0413 17:14:19.632709  8324 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 17:14:19.632715  8324 net.cpp:148] Top shape: 100 (100)
I0413 17:14:19.632719  8324 net.cpp:156] Memory required for data: 1229200
I0413 17:14:19.632725  8324 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:14:19.632732  8324 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:14:19.632737  8324 net.cpp:425] label_cifar_1_split <- label
I0413 17:14:19.632774  8324 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:14:19.632786  8324 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:14:19.632835  8324 net.cpp:141] Setting up label_cifar_1_split
I0413 17:14:19.632843  8324 net.cpp:148] Top shape: 100 (100)
I0413 17:14:19.632848  8324 net.cpp:148] Top shape: 100 (100)
I0413 17:14:19.632854  8324 net.cpp:156] Memory required for data: 1230000
I0413 17:14:19.632859  8324 layer_factory.hpp:77] Creating layer conv1
I0413 17:14:19.632884  8324 net.cpp:91] Creating Layer conv1
I0413 17:14:19.632890  8324 net.cpp:425] conv1 <- data
I0413 17:14:19.632897  8324 net.cpp:399] conv1 -> conv1
I0413 17:14:19.634300  8324 net.cpp:141] Setting up conv1
I0413 17:14:19.634317  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.634321  8324 net.cpp:156] Memory required for data: 7783600
I0413 17:14:19.634335  8324 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:14:19.634342  8324 net.cpp:91] Creating Layer bn_conv1
I0413 17:14:19.634346  8324 net.cpp:425] bn_conv1 <- conv1
I0413 17:14:19.634354  8324 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:14:19.634564  8324 net.cpp:141] Setting up bn_conv1
I0413 17:14:19.634574  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.634578  8324 net.cpp:156] Memory required for data: 14337200
I0413 17:14:19.634590  8324 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:14:19.634603  8324 net.cpp:91] Creating Layer scale_conv1
I0413 17:14:19.634608  8324 net.cpp:425] scale_conv1 <- conv1
I0413 17:14:19.634616  8324 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:14:19.634665  8324 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:14:19.635098  8324 net.cpp:141] Setting up scale_conv1
I0413 17:14:19.635112  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.635115  8324 net.cpp:156] Memory required for data: 20890800
I0413 17:14:19.635128  8324 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:14:19.635134  8324 net.cpp:91] Creating Layer conv1_relu
I0413 17:14:19.635138  8324 net.cpp:425] conv1_relu <- conv1
I0413 17:14:19.635143  8324 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:14:19.635314  8324 net.cpp:141] Setting up conv1_relu
I0413 17:14:19.635325  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.635329  8324 net.cpp:156] Memory required for data: 27444400
I0413 17:14:19.635334  8324 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:14:19.635340  8324 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:14:19.635347  8324 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:14:19.635354  8324 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:14:19.635361  8324 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:14:19.635401  8324 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:14:19.635408  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.635413  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.635417  8324 net.cpp:156] Memory required for data: 40551600
I0413 17:14:19.635428  8324 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:14:19.635439  8324 net.cpp:91] Creating Layer conv2_1a
I0413 17:14:19.635443  8324 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:14:19.635452  8324 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:14:19.637547  8324 net.cpp:141] Setting up conv2_1a
I0413 17:14:19.637563  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.637568  8324 net.cpp:156] Memory required for data: 47105200
I0413 17:14:19.637578  8324 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:14:19.637588  8324 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:14:19.637605  8324 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:14:19.637612  8324 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:14:19.637791  8324 net.cpp:141] Setting up bn_conv2_1a
I0413 17:14:19.637799  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.637804  8324 net.cpp:156] Memory required for data: 53658800
I0413 17:14:19.637811  8324 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:14:19.637819  8324 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:14:19.637823  8324 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:14:19.637830  8324 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:14:19.637867  8324 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:14:19.637969  8324 net.cpp:141] Setting up scale_conv2_1a
I0413 17:14:19.637977  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.637981  8324 net.cpp:156] Memory required for data: 60212400
I0413 17:14:19.637987  8324 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:14:19.637994  8324 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:14:19.638005  8324 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:14:19.638015  8324 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:14:19.638656  8324 net.cpp:141] Setting up conv2_1a_relu
I0413 17:14:19.638675  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.638680  8324 net.cpp:156] Memory required for data: 66766000
I0413 17:14:19.638684  8324 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:14:19.638696  8324 net.cpp:91] Creating Layer conv2_1b
I0413 17:14:19.638701  8324 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:14:19.638710  8324 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:14:19.641530  8324 net.cpp:141] Setting up conv2_1b
I0413 17:14:19.641549  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.641554  8324 net.cpp:156] Memory required for data: 73319600
I0413 17:14:19.641563  8324 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:14:19.641574  8324 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:14:19.641582  8324 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:14:19.641588  8324 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:14:19.641775  8324 net.cpp:141] Setting up bn_conv2_1b
I0413 17:14:19.641784  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.641796  8324 net.cpp:156] Memory required for data: 79873200
I0413 17:14:19.641809  8324 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:14:19.641818  8324 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:14:19.641821  8324 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:14:19.641827  8324 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:14:19.641871  8324 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:14:19.641980  8324 net.cpp:141] Setting up scale_conv2_1b
I0413 17:14:19.641989  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.641993  8324 net.cpp:156] Memory required for data: 86426800
I0413 17:14:19.642000  8324 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:14:19.642007  8324 net.cpp:91] Creating Layer conv2_1
I0413 17:14:19.642012  8324 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:14:19.642024  8324 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:14:19.642031  8324 net.cpp:399] conv2_1 -> conv2_1
I0413 17:14:19.642056  8324 net.cpp:141] Setting up conv2_1
I0413 17:14:19.642063  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.642067  8324 net.cpp:156] Memory required for data: 92980400
I0413 17:14:19.642072  8324 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:14:19.642081  8324 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:14:19.642084  8324 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:14:19.642091  8324 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:14:19.642547  8324 net.cpp:141] Setting up conv2_1_relu
I0413 17:14:19.642559  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.642562  8324 net.cpp:156] Memory required for data: 99534000
I0413 17:14:19.642567  8324 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:14:19.642583  8324 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:14:19.642588  8324 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:14:19.642595  8324 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:14:19.642602  8324 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:14:19.642643  8324 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:14:19.642657  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.642662  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.642665  8324 net.cpp:156] Memory required for data: 112641200
I0413 17:14:19.642669  8324 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:14:19.642681  8324 net.cpp:91] Creating Layer conv2_2a
I0413 17:14:19.642690  8324 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:14:19.642699  8324 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:14:19.646330  8324 net.cpp:141] Setting up conv2_2a
I0413 17:14:19.646356  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.646361  8324 net.cpp:156] Memory required for data: 119194800
I0413 17:14:19.646369  8324 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:14:19.646379  8324 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:14:19.646385  8324 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:14:19.646391  8324 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:14:19.646584  8324 net.cpp:141] Setting up bn_conv2_2a
I0413 17:14:19.646592  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.646608  8324 net.cpp:156] Memory required for data: 125748400
I0413 17:14:19.646617  8324 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:14:19.646625  8324 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:14:19.646633  8324 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:14:19.646641  8324 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:14:19.646685  8324 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:14:19.646792  8324 net.cpp:141] Setting up scale_conv2_2a
I0413 17:14:19.646801  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.646806  8324 net.cpp:156] Memory required for data: 132302000
I0413 17:14:19.646812  8324 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:14:19.646821  8324 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:14:19.646824  8324 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:14:19.646831  8324 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:14:19.647004  8324 net.cpp:141] Setting up conv2_2a_relu
I0413 17:14:19.647023  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.647027  8324 net.cpp:156] Memory required for data: 138855600
I0413 17:14:19.647032  8324 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:14:19.647047  8324 net.cpp:91] Creating Layer conv2_2b
I0413 17:14:19.647053  8324 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:14:19.647059  8324 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:14:19.649210  8324 net.cpp:141] Setting up conv2_2b
I0413 17:14:19.649230  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.649235  8324 net.cpp:156] Memory required for data: 145409200
I0413 17:14:19.649251  8324 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:14:19.649260  8324 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:14:19.649266  8324 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:14:19.649276  8324 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:14:19.649484  8324 net.cpp:141] Setting up bn_conv2_2b
I0413 17:14:19.649495  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.649505  8324 net.cpp:156] Memory required for data: 151962800
I0413 17:14:19.649519  8324 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:14:19.649526  8324 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:14:19.649533  8324 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:14:19.649543  8324 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:14:19.649586  8324 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:14:19.649694  8324 net.cpp:141] Setting up scale_conv2_2b
I0413 17:14:19.649703  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.649710  8324 net.cpp:156] Memory required for data: 158516400
I0413 17:14:19.649718  8324 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:14:19.649725  8324 net.cpp:91] Creating Layer conv2_2
I0413 17:14:19.649729  8324 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:14:19.649735  8324 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:14:19.649741  8324 net.cpp:399] conv2_2 -> conv2_2
I0413 17:14:19.649767  8324 net.cpp:141] Setting up conv2_2
I0413 17:14:19.649775  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.649780  8324 net.cpp:156] Memory required for data: 165070000
I0413 17:14:19.649786  8324 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:14:19.649797  8324 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:14:19.649801  8324 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:14:19.649807  8324 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:14:19.650336  8324 net.cpp:141] Setting up conv2_2_relu
I0413 17:14:19.650349  8324 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:14:19.650354  8324 net.cpp:156] Memory required for data: 171623600
I0413 17:14:19.650359  8324 layer_factory.hpp:77] Creating layer global_pool
I0413 17:14:19.650369  8324 net.cpp:91] Creating Layer global_pool
I0413 17:14:19.650374  8324 net.cpp:425] global_pool <- conv2_2
I0413 17:14:19.650380  8324 net.cpp:399] global_pool -> global_pool
I0413 17:14:19.651458  8324 net.cpp:141] Setting up global_pool
I0413 17:14:19.651470  8324 net.cpp:148] Top shape: 100 16 4 4 (25600)
I0413 17:14:19.651474  8324 net.cpp:156] Memory required for data: 171726000
I0413 17:14:19.651479  8324 layer_factory.hpp:77] Creating layer ip
I0413 17:14:19.651486  8324 net.cpp:91] Creating Layer ip
I0413 17:14:19.651491  8324 net.cpp:425] ip <- global_pool
I0413 17:14:19.651499  8324 net.cpp:399] ip -> ip
I0413 17:14:19.651612  8324 net.cpp:141] Setting up ip
I0413 17:14:19.651619  8324 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:14:19.651623  8324 net.cpp:156] Memory required for data: 171730000
I0413 17:14:19.651631  8324 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:14:19.651638  8324 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:14:19.651641  8324 net.cpp:425] ip_ip_0_split <- ip
I0413 17:14:19.651649  8324 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:14:19.651656  8324 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:14:19.651691  8324 net.cpp:141] Setting up ip_ip_0_split
I0413 17:14:19.651700  8324 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:14:19.651705  8324 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:14:19.651708  8324 net.cpp:156] Memory required for data: 171738000
I0413 17:14:19.651712  8324 layer_factory.hpp:77] Creating layer accuracy
I0413 17:14:19.651720  8324 net.cpp:91] Creating Layer accuracy
I0413 17:14:19.651723  8324 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:14:19.651728  8324 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:14:19.651734  8324 net.cpp:399] accuracy -> accuracy
I0413 17:14:19.651743  8324 net.cpp:141] Setting up accuracy
I0413 17:14:19.651748  8324 net.cpp:148] Top shape: (1)
I0413 17:14:19.651752  8324 net.cpp:156] Memory required for data: 171738004
I0413 17:14:19.651757  8324 layer_factory.hpp:77] Creating layer loss
I0413 17:14:19.651764  8324 net.cpp:91] Creating Layer loss
I0413 17:14:19.651768  8324 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:14:19.651773  8324 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:14:19.651778  8324 net.cpp:399] loss -> loss
I0413 17:14:19.651787  8324 layer_factory.hpp:77] Creating layer loss
I0413 17:14:19.652156  8324 net.cpp:141] Setting up loss
I0413 17:14:19.652170  8324 net.cpp:148] Top shape: (1)
I0413 17:14:19.652175  8324 net.cpp:151]     with loss weight 1
I0413 17:14:19.652184  8324 net.cpp:156] Memory required for data: 171738008
I0413 17:14:19.652189  8324 net.cpp:217] loss needs backward computation.
I0413 17:14:19.652194  8324 net.cpp:219] accuracy does not need backward computation.
I0413 17:14:19.652199  8324 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:14:19.652204  8324 net.cpp:217] ip needs backward computation.
I0413 17:14:19.652207  8324 net.cpp:217] global_pool needs backward computation.
I0413 17:14:19.652211  8324 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:14:19.652215  8324 net.cpp:217] conv2_2 needs backward computation.
I0413 17:14:19.652220  8324 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:14:19.652225  8324 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:14:19.652227  8324 net.cpp:217] conv2_2b needs backward computation.
I0413 17:14:19.652232  8324 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:14:19.652236  8324 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:14:19.652240  8324 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:14:19.652243  8324 net.cpp:217] conv2_2a needs backward computation.
I0413 17:14:19.652248  8324 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:14:19.652252  8324 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:14:19.652256  8324 net.cpp:217] conv2_1 needs backward computation.
I0413 17:14:19.652261  8324 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:14:19.652264  8324 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:14:19.652268  8324 net.cpp:217] conv2_1b needs backward computation.
I0413 17:14:19.652272  8324 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:14:19.652281  8324 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:14:19.652287  8324 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:14:19.652289  8324 net.cpp:217] conv2_1a needs backward computation.
I0413 17:14:19.652294  8324 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:14:19.652298  8324 net.cpp:217] conv1_relu needs backward computation.
I0413 17:14:19.652302  8324 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:14:19.652307  8324 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:14:19.652310  8324 net.cpp:217] conv1 needs backward computation.
I0413 17:14:19.652315  8324 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:14:19.652321  8324 net.cpp:219] cifar does not need backward computation.
I0413 17:14:19.652325  8324 net.cpp:261] This network produces output accuracy
I0413 17:14:19.652330  8324 net.cpp:261] This network produces output loss
I0413 17:14:19.652353  8324 net.cpp:274] Network initialization done.
I0413 17:14:19.652459  8324 solver.cpp:60] Solver scaffolding done.
I0413 17:14:19.844928  8324 solver.cpp:228] Iteration 0, loss = 1.92904
I0413 17:14:19.845024  8324 solver.cpp:244]     Train net output #0: accuracy = 0.46875
I0413 17:14:19.845046  8324 solver.cpp:244]     Train net output #1: loss = 1.92904 (* 1 = 1.92904 loss)
I0413 17:14:19.845062  8324 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 17:14:22.402873  8324 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 17:14:23.862442  8324 solver.cpp:404]     Test net output #0: accuracy = 0.5757
I0413 17:14:23.862503  8324 solver.cpp:404]     Test net output #1: loss = 1.43224 (* 1 = 1.43224 loss)
I0413 17:14:23.916782  8324 solver.cpp:228] Iteration 20, loss = 0.931961
I0413 17:14:23.916831  8324 solver.cpp:244]     Train net output #0: accuracy = 0.667969
I0413 17:14:23.916843  8324 solver.cpp:244]     Train net output #1: loss = 0.931961 (* 1 = 0.931961 loss)
I0413 17:14:23.916852  8324 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 17:14:26.299962  8324 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 17:14:27.917876  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6585
I0413 17:14:27.917925  8324 solver.cpp:404]     Test net output #1: loss = 1.05512 (* 1 = 1.05512 loss)
I0413 17:14:27.983657  8324 solver.cpp:228] Iteration 40, loss = 1.07273
I0413 17:14:27.983727  8324 solver.cpp:244]     Train net output #0: accuracy = 0.644531
I0413 17:14:27.983742  8324 solver.cpp:244]     Train net output #1: loss = 1.07273 (* 1 = 1.07273 loss)
I0413 17:14:27.983755  8324 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 17:14:30.615815  8324 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 17:14:32.214646  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6363
I0413 17:14:32.214694  8324 solver.cpp:404]     Test net output #1: loss = 1.12352 (* 1 = 1.12352 loss)
I0413 17:14:32.279276  8324 solver.cpp:228] Iteration 60, loss = 0.8685
I0413 17:14:32.279310  8324 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:14:32.279320  8324 solver.cpp:244]     Train net output #1: loss = 0.8685 (* 1 = 0.8685 loss)
I0413 17:14:32.279331  8324 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 17:14:34.649574  8324 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 17:14:36.055253  8324 solver.cpp:404]     Test net output #0: accuracy = 0.667
I0413 17:14:36.055312  8324 solver.cpp:404]     Test net output #1: loss = 0.97979 (* 1 = 0.97979 loss)
I0413 17:14:36.121459  8324 solver.cpp:228] Iteration 80, loss = 0.898543
I0413 17:14:36.121507  8324 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:14:36.121518  8324 solver.cpp:244]     Train net output #1: loss = 0.898543 (* 1 = 0.898543 loss)
I0413 17:14:36.121527  8324 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 17:14:38.722044  8324 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 17:14:40.324487  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6559
I0413 17:14:40.324538  8324 solver.cpp:404]     Test net output #1: loss = 1.0231 (* 1 = 1.0231 loss)
I0413 17:14:40.388698  8324 solver.cpp:228] Iteration 100, loss = 0.844139
I0413 17:14:40.388726  8324 solver.cpp:244]     Train net output #0: accuracy = 0.683594
I0413 17:14:40.388736  8324 solver.cpp:244]     Train net output #1: loss = 0.844139 (* 1 = 0.844139 loss)
I0413 17:14:40.388746  8324 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 17:14:42.981256  8324 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 17:14:44.327873  8324 solver.cpp:404]     Test net output #0: accuracy = 0.647
I0413 17:14:44.327919  8324 solver.cpp:404]     Test net output #1: loss = 1.11077 (* 1 = 1.11077 loss)
I0413 17:14:44.375653  8324 solver.cpp:228] Iteration 120, loss = 0.905445
I0413 17:14:44.375677  8324 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:14:44.375689  8324 solver.cpp:244]     Train net output #1: loss = 0.905445 (* 1 = 0.905445 loss)
I0413 17:14:44.375699  8324 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 17:14:46.879056  8324 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 17:14:48.487496  8324 solver.cpp:404]     Test net output #0: accuracy = 0.63
I0413 17:14:48.487547  8324 solver.cpp:404]     Test net output #1: loss = 1.15407 (* 1 = 1.15407 loss)
I0413 17:14:48.552803  8324 solver.cpp:228] Iteration 140, loss = 0.855931
I0413 17:14:48.552845  8324 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:14:48.552858  8324 solver.cpp:244]     Train net output #1: loss = 0.855931 (* 1 = 0.855931 loss)
I0413 17:14:48.552870  8324 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 17:14:51.162513  8324 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 17:14:52.691269  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6819
I0413 17:14:52.691313  8324 solver.cpp:404]     Test net output #1: loss = 0.94071 (* 1 = 0.94071 loss)
I0413 17:14:52.743896  8324 solver.cpp:228] Iteration 160, loss = 0.801782
I0413 17:14:52.743944  8324 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:14:52.743957  8324 solver.cpp:244]     Train net output #1: loss = 0.801782 (* 1 = 0.801782 loss)
I0413 17:14:52.743966  8324 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 17:14:55.118573  8324 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 17:14:56.661497  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6807
I0413 17:14:56.661557  8324 solver.cpp:404]     Test net output #1: loss = 0.949963 (* 1 = 0.949963 loss)
I0413 17:14:56.727526  8324 solver.cpp:228] Iteration 180, loss = 0.889034
I0413 17:14:56.727569  8324 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:14:56.727581  8324 solver.cpp:244]     Train net output #1: loss = 0.889034 (* 1 = 0.889034 loss)
I0413 17:14:56.727589  8324 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 17:14:59.335449  8324 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 17:15:00.961060  8324 solver.cpp:404]     Test net output #0: accuracy = 0.663
I0413 17:15:00.961129  8324 solver.cpp:404]     Test net output #1: loss = 1.02575 (* 1 = 1.02575 loss)
I0413 17:15:01.025146  8324 solver.cpp:228] Iteration 200, loss = 0.81865
I0413 17:15:01.025189  8324 solver.cpp:244]     Train net output #0: accuracy = 0.707031
I0413 17:15:01.025202  8324 solver.cpp:244]     Train net output #1: loss = 0.81865 (* 1 = 0.81865 loss)
I0413 17:15:01.025212  8324 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 17:15:03.455482  8324 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 17:15:04.820559  8324 solver.cpp:404]     Test net output #0: accuracy = 0.655
I0413 17:15:04.820611  8324 solver.cpp:404]     Test net output #1: loss = 1.06463 (* 1 = 1.06463 loss)
I0413 17:15:04.874133  8324 solver.cpp:228] Iteration 220, loss = 0.799332
I0413 17:15:04.874176  8324 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:15:04.874187  8324 solver.cpp:244]     Train net output #1: loss = 0.799332 (* 1 = 0.799332 loss)
I0413 17:15:04.874198  8324 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 17:15:07.442513  8324 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 17:15:09.040612  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6493
I0413 17:15:09.040657  8324 solver.cpp:404]     Test net output #1: loss = 1.1177 (* 1 = 1.1177 loss)
I0413 17:15:09.095095  8324 solver.cpp:228] Iteration 240, loss = 0.677344
I0413 17:15:09.095139  8324 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:15:09.095151  8324 solver.cpp:244]     Train net output #1: loss = 0.677344 (* 1 = 0.677344 loss)
I0413 17:15:09.095160  8324 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 17:15:11.708422  8324 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 17:15:13.123874  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6387
I0413 17:15:13.123937  8324 solver.cpp:404]     Test net output #1: loss = 1.10233 (* 1 = 1.10233 loss)
I0413 17:15:13.175074  8324 solver.cpp:228] Iteration 260, loss = 0.878267
I0413 17:15:13.175120  8324 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:15:13.175133  8324 solver.cpp:244]     Train net output #1: loss = 0.878267 (* 1 = 0.878267 loss)
I0413 17:15:13.175143  8324 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 17:15:15.581673  8324 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 17:15:17.198058  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6773
I0413 17:15:17.198113  8324 solver.cpp:404]     Test net output #1: loss = 0.975358 (* 1 = 0.975358 loss)
I0413 17:15:17.261605  8324 solver.cpp:228] Iteration 280, loss = 0.897629
I0413 17:15:17.261642  8324 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:15:17.261654  8324 solver.cpp:244]     Train net output #1: loss = 0.897629 (* 1 = 0.897629 loss)
I0413 17:15:17.261665  8324 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 17:15:19.881955  8324 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 17:15:21.503221  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6224
I0413 17:15:21.503265  8324 solver.cpp:404]     Test net output #1: loss = 1.18141 (* 1 = 1.18141 loss)
I0413 17:15:21.558480  8324 solver.cpp:228] Iteration 300, loss = 0.967183
I0413 17:15:21.558506  8324 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:15:21.558517  8324 solver.cpp:244]     Train net output #1: loss = 0.967183 (* 1 = 0.967183 loss)
I0413 17:15:21.558526  8324 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 17:15:23.947000  8324 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 17:15:25.364897  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6424
I0413 17:15:25.364948  8324 solver.cpp:404]     Test net output #1: loss = 1.07354 (* 1 = 1.07354 loss)
I0413 17:15:25.427069  8324 solver.cpp:228] Iteration 320, loss = 0.832936
I0413 17:15:25.427103  8324 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:15:25.427114  8324 solver.cpp:244]     Train net output #1: loss = 0.832936 (* 1 = 0.832936 loss)
I0413 17:15:25.427122  8324 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 17:15:28.029243  8324 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 17:15:29.658859  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6821
I0413 17:15:29.658902  8324 solver.cpp:404]     Test net output #1: loss = 0.956292 (* 1 = 0.956292 loss)
I0413 17:15:29.723031  8324 solver.cpp:228] Iteration 340, loss = 0.878572
I0413 17:15:29.723081  8324 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:15:29.723093  8324 solver.cpp:244]     Train net output #1: loss = 0.878572 (* 1 = 0.878572 loss)
I0413 17:15:29.723104  8324 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 17:15:32.281738  8324 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 17:15:33.636270  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6555
I0413 17:15:33.636350  8324 solver.cpp:404]     Test net output #1: loss = 1.01835 (* 1 = 1.01835 loss)
I0413 17:15:33.687672  8324 solver.cpp:228] Iteration 360, loss = 0.733102
I0413 17:15:33.687705  8324 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:15:33.687716  8324 solver.cpp:244]     Train net output #1: loss = 0.733102 (* 1 = 0.733102 loss)
I0413 17:15:33.687733  8324 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 17:15:36.183826  8324 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 17:15:37.785569  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6488
I0413 17:15:37.785610  8324 solver.cpp:404]     Test net output #1: loss = 1.06844 (* 1 = 1.06844 loss)
I0413 17:15:37.848194  8324 solver.cpp:228] Iteration 380, loss = 0.825031
I0413 17:15:37.848255  8324 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:15:37.848276  8324 solver.cpp:244]     Train net output #1: loss = 0.825031 (* 1 = 0.825031 loss)
I0413 17:15:37.848285  8324 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 17:15:40.479476  8324 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 17:15:41.972777  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6678
I0413 17:15:41.972818  8324 solver.cpp:404]     Test net output #1: loss = 0.9816 (* 1 = 0.9816 loss)
I0413 17:15:42.021045  8324 solver.cpp:228] Iteration 400, loss = 0.673897
I0413 17:15:42.021085  8324 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:15:42.021097  8324 solver.cpp:244]     Train net output #1: loss = 0.673897 (* 1 = 0.673897 loss)
I0413 17:15:42.021114  8324 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 17:15:44.410943  8324 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 17:15:45.956141  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6882
I0413 17:15:45.956187  8324 solver.cpp:404]     Test net output #1: loss = 0.917387 (* 1 = 0.917387 loss)
I0413 17:15:46.019510  8324 solver.cpp:228] Iteration 420, loss = 0.835587
I0413 17:15:46.019554  8324 solver.cpp:244]     Train net output #0: accuracy = 0.679688
I0413 17:15:46.019567  8324 solver.cpp:244]     Train net output #1: loss = 0.835587 (* 1 = 0.835587 loss)
I0413 17:15:46.019577  8324 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 17:15:48.640460  8324 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 17:15:50.266741  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6516
I0413 17:15:50.266794  8324 solver.cpp:404]     Test net output #1: loss = 1.09428 (* 1 = 1.09428 loss)
I0413 17:15:50.329218  8324 solver.cpp:228] Iteration 440, loss = 0.796048
I0413 17:15:50.329260  8324 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:15:50.329273  8324 solver.cpp:244]     Train net output #1: loss = 0.796048 (* 1 = 0.796048 loss)
I0413 17:15:50.329284  8324 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 17:15:52.772100  8324 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 17:15:54.125879  8324 solver.cpp:404]     Test net output #0: accuracy = 0.682
I0413 17:15:54.125926  8324 solver.cpp:404]     Test net output #1: loss = 0.947971 (* 1 = 0.947971 loss)
I0413 17:15:54.174294  8324 solver.cpp:228] Iteration 460, loss = 0.770288
I0413 17:15:54.174312  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:15:54.174321  8324 solver.cpp:244]     Train net output #1: loss = 0.770288 (* 1 = 0.770288 loss)
I0413 17:15:54.174330  8324 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 17:15:56.790146  8324 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 17:15:58.406004  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6505
I0413 17:15:58.406046  8324 solver.cpp:404]     Test net output #1: loss = 1.04832 (* 1 = 1.04832 loss)
I0413 17:15:58.469665  8324 solver.cpp:228] Iteration 480, loss = 0.782302
I0413 17:15:58.469719  8324 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:15:58.469732  8324 solver.cpp:244]     Train net output #1: loss = 0.782302 (* 1 = 0.782302 loss)
I0413 17:15:58.469743  8324 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 17:16:01.076782  8324 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 17:16:02.436097  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6494
I0413 17:16:02.436154  8324 solver.cpp:404]     Test net output #1: loss = 1.09173 (* 1 = 1.09173 loss)
I0413 17:16:02.485755  8324 solver.cpp:228] Iteration 500, loss = 0.756044
I0413 17:16:02.485780  8324 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:16:02.485790  8324 solver.cpp:244]     Train net output #1: loss = 0.756044 (* 1 = 0.756044 loss)
I0413 17:16:02.485797  8324 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 17:16:04.920549  8324 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 17:16:06.534780  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6386
I0413 17:16:06.534826  8324 solver.cpp:404]     Test net output #1: loss = 1.12352 (* 1 = 1.12352 loss)
I0413 17:16:06.598933  8324 solver.cpp:228] Iteration 520, loss = 0.77616
I0413 17:16:06.598968  8324 solver.cpp:244]     Train net output #0: accuracy = 0.691406
I0413 17:16:06.598979  8324 solver.cpp:244]     Train net output #1: loss = 0.77616 (* 1 = 0.77616 loss)
I0413 17:16:06.598989  8324 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 17:16:09.223839  8324 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 17:16:10.803871  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6709
I0413 17:16:10.803910  8324 solver.cpp:404]     Test net output #1: loss = 0.947622 (* 1 = 0.947622 loss)
I0413 17:16:10.859033  8324 solver.cpp:228] Iteration 540, loss = 0.832586
I0413 17:16:10.859073  8324 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:16:10.859086  8324 solver.cpp:244]     Train net output #1: loss = 0.832586 (* 1 = 0.832586 loss)
I0413 17:16:10.859094  8324 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 17:16:13.219290  8324 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 17:16:14.684224  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6306
I0413 17:16:14.684270  8324 solver.cpp:404]     Test net output #1: loss = 1.11228 (* 1 = 1.11228 loss)
I0413 17:16:14.746930  8324 solver.cpp:228] Iteration 560, loss = 0.834773
I0413 17:16:14.746959  8324 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:16:14.746969  8324 solver.cpp:244]     Train net output #1: loss = 0.834773 (* 1 = 0.834773 loss)
I0413 17:16:14.746978  8324 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 17:16:17.354357  8324 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 17:16:18.966270  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6944
I0413 17:16:18.966313  8324 solver.cpp:404]     Test net output #1: loss = 0.894013 (* 1 = 0.894013 loss)
I0413 17:16:19.029777  8324 solver.cpp:228] Iteration 580, loss = 0.793769
I0413 17:16:19.029830  8324 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:16:19.029844  8324 solver.cpp:244]     Train net output #1: loss = 0.793769 (* 1 = 0.793769 loss)
I0413 17:16:19.029855  8324 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 17:16:21.564699  8324 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 17:16:22.920682  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6798
I0413 17:16:22.920749  8324 solver.cpp:404]     Test net output #1: loss = 0.949874 (* 1 = 0.949874 loss)
I0413 17:16:22.969460  8324 solver.cpp:228] Iteration 600, loss = 0.677345
I0413 17:16:22.969537  8324 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:16:22.969555  8324 solver.cpp:244]     Train net output #1: loss = 0.677345 (* 1 = 0.677345 loss)
I0413 17:16:22.969570  8324 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 17:16:25.502948  8324 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 17:16:27.125305  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6686
I0413 17:16:27.125370  8324 solver.cpp:404]     Test net output #1: loss = 0.985761 (* 1 = 0.985761 loss)
I0413 17:16:27.187731  8324 solver.cpp:228] Iteration 620, loss = 0.857403
I0413 17:16:27.187772  8324 solver.cpp:244]     Train net output #0: accuracy = 0.683594
I0413 17:16:27.187784  8324 solver.cpp:244]     Train net output #1: loss = 0.857403 (* 1 = 0.857403 loss)
I0413 17:16:27.187793  8324 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 17:16:29.892814  8324 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 17:16:31.320266  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6577
I0413 17:16:31.320312  8324 solver.cpp:404]     Test net output #1: loss = 1.0637 (* 1 = 1.0637 loss)
I0413 17:16:31.368043  8324 solver.cpp:228] Iteration 640, loss = 0.786194
I0413 17:16:31.368062  8324 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:16:31.368070  8324 solver.cpp:244]     Train net output #1: loss = 0.786194 (* 1 = 0.786194 loss)
I0413 17:16:31.368078  8324 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 17:16:33.751873  8324 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 17:16:35.395819  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6838
I0413 17:16:35.395865  8324 solver.cpp:404]     Test net output #1: loss = 0.949595 (* 1 = 0.949595 loss)
I0413 17:16:35.442564  8324 solver.cpp:228] Iteration 660, loss = 0.808235
I0413 17:16:35.442584  8324 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:16:35.442592  8324 solver.cpp:244]     Train net output #1: loss = 0.808235 (* 1 = 0.808235 loss)
I0413 17:16:35.442600  8324 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 17:16:38.071485  8324 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 17:16:39.714671  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6795
I0413 17:16:39.714718  8324 solver.cpp:404]     Test net output #1: loss = 0.97231 (* 1 = 0.97231 loss)
I0413 17:16:39.751448  8324 solver.cpp:228] Iteration 680, loss = 0.649538
I0413 17:16:39.751466  8324 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:16:39.751474  8324 solver.cpp:244]     Train net output #1: loss = 0.649538 (* 1 = 0.649538 loss)
I0413 17:16:39.751483  8324 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 17:16:42.138689  8324 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 17:16:43.561353  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6969
I0413 17:16:43.561403  8324 solver.cpp:404]     Test net output #1: loss = 0.897474 (* 1 = 0.897474 loss)
I0413 17:16:43.616883  8324 solver.cpp:228] Iteration 700, loss = 0.648229
I0413 17:16:43.616900  8324 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:16:43.616909  8324 solver.cpp:244]     Train net output #1: loss = 0.648229 (* 1 = 0.648229 loss)
I0413 17:16:43.616919  8324 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 17:16:46.223757  8324 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 17:16:47.857363  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6462
I0413 17:16:47.857414  8324 solver.cpp:404]     Test net output #1: loss = 1.07655 (* 1 = 1.07655 loss)
I0413 17:16:47.911682  8324 solver.cpp:228] Iteration 720, loss = 0.774455
I0413 17:16:47.911700  8324 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:16:47.911708  8324 solver.cpp:244]     Train net output #1: loss = 0.774455 (* 1 = 0.774455 loss)
I0413 17:16:47.911716  8324 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 17:16:50.459386  8324 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 17:16:51.822552  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6428
I0413 17:16:51.822609  8324 solver.cpp:404]     Test net output #1: loss = 1.08593 (* 1 = 1.08593 loss)
I0413 17:16:51.876792  8324 solver.cpp:228] Iteration 740, loss = 0.800758
I0413 17:16:51.876811  8324 solver.cpp:244]     Train net output #0: accuracy = 0.699219
I0413 17:16:51.876819  8324 solver.cpp:244]     Train net output #1: loss = 0.800758 (* 1 = 0.800758 loss)
I0413 17:16:51.876828  8324 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 17:16:54.355393  8324 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 17:16:55.974475  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6515
I0413 17:16:55.974529  8324 solver.cpp:404]     Test net output #1: loss = 1.09555 (* 1 = 1.09555 loss)
I0413 17:16:56.017774  8324 solver.cpp:228] Iteration 760, loss = 0.808532
I0413 17:16:56.017809  8324 solver.cpp:244]     Train net output #0: accuracy = 0.710938
I0413 17:16:56.017822  8324 solver.cpp:244]     Train net output #1: loss = 0.808532 (* 1 = 0.808532 loss)
I0413 17:16:56.017830  8324 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 17:16:58.657727  8324 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 17:17:00.136514  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6739
I0413 17:17:00.136560  8324 solver.cpp:404]     Test net output #1: loss = 0.966536 (* 1 = 0.966536 loss)
I0413 17:17:00.190732  8324 solver.cpp:228] Iteration 780, loss = 0.746836
I0413 17:17:00.190752  8324 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:17:00.190762  8324 solver.cpp:244]     Train net output #1: loss = 0.746836 (* 1 = 0.746836 loss)
I0413 17:17:00.190769  8324 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 17:17:02.583514  8324 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 17:17:04.118675  8324 solver.cpp:404]     Test net output #0: accuracy = 0.661
I0413 17:17:04.118736  8324 solver.cpp:404]     Test net output #1: loss = 1.00665 (* 1 = 1.00665 loss)
I0413 17:17:04.158184  8324 solver.cpp:228] Iteration 800, loss = 0.887429
I0413 17:17:04.158231  8324 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:17:04.158242  8324 solver.cpp:244]     Train net output #1: loss = 0.887429 (* 1 = 0.887429 loss)
I0413 17:17:04.158252  8324 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 17:17:06.794406  8324 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 17:17:08.433392  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6819
I0413 17:17:08.433444  8324 solver.cpp:404]     Test net output #1: loss = 0.941986 (* 1 = 0.941986 loss)
I0413 17:17:08.471560  8324 solver.cpp:228] Iteration 820, loss = 0.828388
I0413 17:17:08.471578  8324 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:17:08.471587  8324 solver.cpp:244]     Train net output #1: loss = 0.828388 (* 1 = 0.828388 loss)
I0413 17:17:08.471596  8324 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 17:17:10.931526  8324 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 17:17:12.310446  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6892
I0413 17:17:12.310485  8324 solver.cpp:404]     Test net output #1: loss = 0.916367 (* 1 = 0.916367 loss)
I0413 17:17:12.358300  8324 solver.cpp:228] Iteration 840, loss = 0.723915
I0413 17:17:12.358326  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:17:12.358336  8324 solver.cpp:244]     Train net output #1: loss = 0.723915 (* 1 = 0.723915 loss)
I0413 17:17:12.358346  8324 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 17:17:14.967298  8324 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 17:17:16.601047  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6983
I0413 17:17:16.601083  8324 solver.cpp:404]     Test net output #1: loss = 0.874666 (* 1 = 0.874666 loss)
I0413 17:17:16.654711  8324 solver.cpp:228] Iteration 860, loss = 0.826238
I0413 17:17:16.654731  8324 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:17:16.654739  8324 solver.cpp:244]     Train net output #1: loss = 0.826238 (* 1 = 0.826238 loss)
I0413 17:17:16.654748  8324 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 17:17:19.282455  8324 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 17:17:20.635936  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6797
I0413 17:17:20.635987  8324 solver.cpp:404]     Test net output #1: loss = 0.950658 (* 1 = 0.950658 loss)
I0413 17:17:20.689616  8324 solver.cpp:228] Iteration 880, loss = 0.767073
I0413 17:17:20.689666  8324 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:17:20.689678  8324 solver.cpp:244]     Train net output #1: loss = 0.767073 (* 1 = 0.767073 loss)
I0413 17:17:20.689687  8324 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 17:17:23.118005  8324 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 17:17:24.760748  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6548
I0413 17:17:24.760787  8324 solver.cpp:404]     Test net output #1: loss = 1.08135 (* 1 = 1.08135 loss)
I0413 17:17:24.812098  8324 solver.cpp:228] Iteration 900, loss = 0.823386
I0413 17:17:24.812141  8324 solver.cpp:244]     Train net output #0: accuracy = 0.707031
I0413 17:17:24.812162  8324 solver.cpp:244]     Train net output #1: loss = 0.823386 (* 1 = 0.823386 loss)
I0413 17:17:24.812172  8324 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 17:17:27.441171  8324 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 17:17:29.076323  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6702
I0413 17:17:29.076370  8324 solver.cpp:404]     Test net output #1: loss = 0.986662 (* 1 = 0.986662 loss)
I0413 17:17:29.105499  8324 solver.cpp:228] Iteration 920, loss = 0.663632
I0413 17:17:29.105554  8324 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:17:29.105566  8324 solver.cpp:244]     Train net output #1: loss = 0.663632 (* 1 = 0.663632 loss)
I0413 17:17:29.105576  8324 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 17:17:31.456439  8324 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 17:17:32.898073  8324 solver.cpp:404]     Test net output #0: accuracy = 0.7006
I0413 17:17:32.898115  8324 solver.cpp:404]     Test net output #1: loss = 0.86126 (* 1 = 0.86126 loss)
I0413 17:17:32.951462  8324 solver.cpp:228] Iteration 940, loss = 0.781486
I0413 17:17:32.951503  8324 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:17:32.951515  8324 solver.cpp:244]     Train net output #1: loss = 0.781486 (* 1 = 0.781486 loss)
I0413 17:17:32.951524  8324 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 17:17:35.572538  8324 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 17:17:37.204941  8324 solver.cpp:404]     Test net output #0: accuracy = 0.696
I0413 17:17:37.204993  8324 solver.cpp:404]     Test net output #1: loss = 0.889566 (* 1 = 0.889566 loss)
I0413 17:17:37.245893  8324 solver.cpp:228] Iteration 960, loss = 0.681591
I0413 17:17:37.245926  8324 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:17:37.245937  8324 solver.cpp:244]     Train net output #1: loss = 0.681591 (* 1 = 0.681591 loss)
I0413 17:17:37.245945  8324 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 17:17:39.792717  8324 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 17:17:41.150738  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6871
I0413 17:17:41.150784  8324 solver.cpp:404]     Test net output #1: loss = 0.952213 (* 1 = 0.952213 loss)
I0413 17:17:41.202797  8324 solver.cpp:228] Iteration 980, loss = 0.706473
I0413 17:17:41.202836  8324 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:17:41.202847  8324 solver.cpp:244]     Train net output #1: loss = 0.706473 (* 1 = 0.706473 loss)
I0413 17:17:41.202857  8324 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 17:17:43.737720  8324 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 17:17:45.369989  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6622
I0413 17:17:45.370053  8324 solver.cpp:404]     Test net output #1: loss = 1.03215 (* 1 = 1.03215 loss)
I0413 17:17:45.424150  8324 solver.cpp:228] Iteration 1000, loss = 0.767787
I0413 17:17:45.424204  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:17:45.424216  8324 solver.cpp:244]     Train net output #1: loss = 0.767787 (* 1 = 0.767787 loss)
I0413 17:17:45.424226  8324 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 17:17:48.042611  8324 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 17:17:49.509222  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6853
I0413 17:17:49.509260  8324 solver.cpp:404]     Test net output #1: loss = 0.930676 (* 1 = 0.930676 loss)
I0413 17:17:49.560816  8324 solver.cpp:228] Iteration 1020, loss = 0.752612
I0413 17:17:49.560835  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:17:49.560844  8324 solver.cpp:244]     Train net output #1: loss = 0.752612 (* 1 = 0.752612 loss)
I0413 17:17:49.560853  8324 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 17:17:51.953614  8324 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 17:17:53.560938  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6779
I0413 17:17:53.560978  8324 solver.cpp:404]     Test net output #1: loss = 0.971957 (* 1 = 0.971957 loss)
I0413 17:17:53.626163  8324 solver.cpp:228] Iteration 1040, loss = 0.737192
I0413 17:17:53.626206  8324 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:17:53.626219  8324 solver.cpp:244]     Train net output #1: loss = 0.737192 (* 1 = 0.737192 loss)
I0413 17:17:53.626226  8324 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 17:17:56.241665  8324 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 17:17:57.865514  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6902
I0413 17:17:57.865562  8324 solver.cpp:404]     Test net output #1: loss = 0.901348 (* 1 = 0.901348 loss)
I0413 17:17:57.929399  8324 solver.cpp:228] Iteration 1060, loss = 0.923673
I0413 17:17:57.929443  8324 solver.cpp:244]     Train net output #0: accuracy = 0.664062
I0413 17:17:57.929455  8324 solver.cpp:244]     Train net output #1: loss = 0.923673 (* 1 = 0.923673 loss)
I0413 17:17:57.929476  8324 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 17:18:00.354557  8324 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 17:18:01.749874  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6492
I0413 17:18:01.749917  8324 solver.cpp:404]     Test net output #1: loss = 1.05678 (* 1 = 1.05678 loss)
I0413 17:18:01.815479  8324 solver.cpp:228] Iteration 1080, loss = 0.790127
I0413 17:18:01.815513  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:18:01.815524  8324 solver.cpp:244]     Train net output #1: loss = 0.790127 (* 1 = 0.790127 loss)
I0413 17:18:01.815533  8324 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 17:18:04.459686  8324 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 17:18:06.072213  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6722
I0413 17:18:06.072250  8324 solver.cpp:404]     Test net output #1: loss = 0.981789 (* 1 = 0.981789 loss)
I0413 17:18:06.137809  8324 solver.cpp:228] Iteration 1100, loss = 0.727002
I0413 17:18:06.137851  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:18:06.137863  8324 solver.cpp:244]     Train net output #1: loss = 0.727002 (* 1 = 0.727002 loss)
I0413 17:18:06.137873  8324 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 17:18:08.721765  8324 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 17:18:10.086007  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6767
I0413 17:18:10.086066  8324 solver.cpp:404]     Test net output #1: loss = 0.94694 (* 1 = 0.94694 loss)
I0413 17:18:10.133013  8324 solver.cpp:228] Iteration 1120, loss = 0.885937
I0413 17:18:10.133050  8324 solver.cpp:244]     Train net output #0: accuracy = 0.710938
I0413 17:18:10.133061  8324 solver.cpp:244]     Train net output #1: loss = 0.885937 (* 1 = 0.885937 loss)
I0413 17:18:10.133070  8324 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 17:18:12.644807  8324 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 17:18:14.234812  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6656
I0413 17:18:14.234851  8324 solver.cpp:404]     Test net output #1: loss = 0.980892 (* 1 = 0.980892 loss)
I0413 17:18:14.301415  8324 solver.cpp:228] Iteration 1140, loss = 0.888864
I0413 17:18:14.301460  8324 solver.cpp:244]     Train net output #0: accuracy = 0.691406
I0413 17:18:14.301483  8324 solver.cpp:244]     Train net output #1: loss = 0.888864 (* 1 = 0.888864 loss)
I0413 17:18:14.301493  8324 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 17:18:16.915485  8324 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 17:18:18.436640  8324 solver.cpp:404]     Test net output #0: accuracy = 0.699
I0413 17:18:18.436676  8324 solver.cpp:404]     Test net output #1: loss = 0.879632 (* 1 = 0.879632 loss)
I0413 17:18:18.489439  8324 solver.cpp:228] Iteration 1160, loss = 0.745705
I0413 17:18:18.489501  8324 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:18:18.489512  8324 solver.cpp:244]     Train net output #1: loss = 0.745705 (* 1 = 0.745705 loss)
I0413 17:18:18.489522  8324 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 17:18:20.885988  8324 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 17:18:22.435745  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6616
I0413 17:18:22.435786  8324 solver.cpp:404]     Test net output #1: loss = 0.992178 (* 1 = 0.992178 loss)
I0413 17:18:22.473836  8324 solver.cpp:228] Iteration 1180, loss = 0.698144
I0413 17:18:22.473907  8324 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:18:22.473937  8324 solver.cpp:244]     Train net output #1: loss = 0.698144 (* 1 = 0.698144 loss)
I0413 17:18:22.473968  8324 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 17:18:25.119561  8324 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 17:18:26.764086  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6959
I0413 17:18:26.764133  8324 solver.cpp:404]     Test net output #1: loss = 0.89399 (* 1 = 0.89399 loss)
I0413 17:18:26.801406  8324 solver.cpp:228] Iteration 1200, loss = 0.779265
I0413 17:18:26.801424  8324 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:18:26.801434  8324 solver.cpp:244]     Train net output #1: loss = 0.779265 (* 1 = 0.779265 loss)
I0413 17:18:26.801445  8324 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 17:18:29.266212  8324 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 17:18:30.634928  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6924
I0413 17:18:30.634989  8324 solver.cpp:404]     Test net output #1: loss = 0.901382 (* 1 = 0.901382 loss)
I0413 17:18:30.681777  8324 solver.cpp:228] Iteration 1220, loss = 0.785541
I0413 17:18:30.681815  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:18:30.681826  8324 solver.cpp:244]     Train net output #1: loss = 0.785541 (* 1 = 0.785541 loss)
I0413 17:18:30.681834  8324 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 17:18:33.276664  8324 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 17:18:34.908864  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6805
I0413 17:18:34.908912  8324 solver.cpp:404]     Test net output #1: loss = 0.937988 (* 1 = 0.937988 loss)
I0413 17:18:34.947866  8324 solver.cpp:228] Iteration 1240, loss = 0.757154
I0413 17:18:34.947932  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:18:34.947971  8324 solver.cpp:244]     Train net output #1: loss = 0.757154 (* 1 = 0.757154 loss)
I0413 17:18:34.947991  8324 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 17:18:37.601191  8324 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 17:18:38.963999  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6634
I0413 17:18:38.964040  8324 solver.cpp:404]     Test net output #1: loss = 0.990894 (* 1 = 0.990894 loss)
I0413 17:18:39.013383  8324 solver.cpp:228] Iteration 1260, loss = 0.725666
I0413 17:18:39.013443  8324 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:18:39.013458  8324 solver.cpp:244]     Train net output #1: loss = 0.725666 (* 1 = 0.725666 loss)
I0413 17:18:39.013468  8324 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 17:18:41.438009  8324 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 17:18:43.079816  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6912
I0413 17:18:43.079860  8324 solver.cpp:404]     Test net output #1: loss = 0.937453 (* 1 = 0.937453 loss)
I0413 17:18:43.117852  8324 solver.cpp:228] Iteration 1280, loss = 0.76069
I0413 17:18:43.117897  8324 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:18:43.117909  8324 solver.cpp:244]     Train net output #1: loss = 0.76069 (* 1 = 0.76069 loss)
I0413 17:18:43.117918  8324 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 17:18:45.756310  8324 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 17:18:47.375927  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6563
I0413 17:18:47.375983  8324 solver.cpp:404]     Test net output #1: loss = 1.02912 (* 1 = 1.02912 loss)
I0413 17:18:47.441154  8324 solver.cpp:228] Iteration 1300, loss = 0.805451
I0413 17:18:47.441211  8324 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:18:47.441236  8324 solver.cpp:244]     Train net output #1: loss = 0.805451 (* 1 = 0.805451 loss)
I0413 17:18:47.441259  8324 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 17:18:49.788913  8324 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 17:18:51.250089  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6749
I0413 17:18:51.250133  8324 solver.cpp:404]     Test net output #1: loss = 0.946435 (* 1 = 0.946435 loss)
I0413 17:18:51.300937  8324 solver.cpp:228] Iteration 1320, loss = 0.893452
I0413 17:18:51.300977  8324 solver.cpp:244]     Train net output #0: accuracy = 0.691406
I0413 17:18:51.300989  8324 solver.cpp:244]     Train net output #1: loss = 0.893452 (* 1 = 0.893452 loss)
I0413 17:18:51.300997  8324 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 17:18:53.933038  8324 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 17:18:55.562098  8324 solver.cpp:404]     Test net output #0: accuracy = 0.7107
I0413 17:18:55.562142  8324 solver.cpp:404]     Test net output #1: loss = 0.844672 (* 1 = 0.844672 loss)
I0413 17:18:55.614006  8324 solver.cpp:228] Iteration 1340, loss = 0.823243
I0413 17:18:55.614068  8324 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:18:55.614083  8324 solver.cpp:244]     Train net output #1: loss = 0.823243 (* 1 = 0.823243 loss)
I0413 17:18:55.614094  8324 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 17:18:58.140167  8324 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 17:18:59.503010  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6768
I0413 17:18:59.503059  8324 solver.cpp:404]     Test net output #1: loss = 0.959929 (* 1 = 0.959929 loss)
I0413 17:18:59.555752  8324 solver.cpp:228] Iteration 1360, loss = 0.701586
I0413 17:18:59.555785  8324 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:18:59.555797  8324 solver.cpp:244]     Train net output #1: loss = 0.701586 (* 1 = 0.701586 loss)
I0413 17:18:59.555807  8324 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 17:19:02.106948  8324 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 17:19:03.713702  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6337
I0413 17:19:03.713750  8324 solver.cpp:404]     Test net output #1: loss = 1.16754 (* 1 = 1.16754 loss)
I0413 17:19:03.764683  8324 solver.cpp:228] Iteration 1380, loss = 0.81437
I0413 17:19:03.764732  8324 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:19:03.764745  8324 solver.cpp:244]     Train net output #1: loss = 0.81437 (* 1 = 0.81437 loss)
I0413 17:19:03.764755  8324 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 17:19:06.398720  8324 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 17:19:07.869868  8324 solver.cpp:404]     Test net output #0: accuracy = 0.7101
I0413 17:19:07.869905  8324 solver.cpp:404]     Test net output #1: loss = 0.845566 (* 1 = 0.845566 loss)
I0413 17:19:07.921244  8324 solver.cpp:228] Iteration 1400, loss = 0.857056
I0413 17:19:07.921265  8324 solver.cpp:244]     Train net output #0: accuracy = 0.710938
I0413 17:19:07.921274  8324 solver.cpp:244]     Train net output #1: loss = 0.857056 (* 1 = 0.857056 loss)
I0413 17:19:07.921283  8324 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 17:19:10.305215  8324 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 17:19:11.916636  8324 solver.cpp:404]     Test net output #0: accuracy = 0.7067
I0413 17:19:11.916709  8324 solver.cpp:404]     Test net output #1: loss = 0.897885 (* 1 = 0.897885 loss)
I0413 17:19:11.977236  8324 solver.cpp:228] Iteration 1420, loss = 0.847678
I0413 17:19:11.977282  8324 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:19:11.977293  8324 solver.cpp:244]     Train net output #1: loss = 0.847678 (* 1 = 0.847678 loss)
I0413 17:19:11.977306  8324 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 17:19:14.586773  8324 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 17:19:16.167091  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6905
I0413 17:19:16.167130  8324 solver.cpp:404]     Test net output #1: loss = 0.917177 (* 1 = 0.917177 loss)
I0413 17:19:16.217541  8324 solver.cpp:228] Iteration 1440, loss = 0.749385
I0413 17:19:16.217560  8324 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:19:16.217567  8324 solver.cpp:244]     Train net output #1: loss = 0.749385 (* 1 = 0.749385 loss)
I0413 17:19:16.217576  8324 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 17:19:18.586468  8324 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 17:19:19.934845  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6819
I0413 17:19:19.934885  8324 solver.cpp:404]     Test net output #1: loss = 0.928322 (* 1 = 0.928322 loss)
I0413 17:19:19.989514  8324 solver.cpp:228] Iteration 1460, loss = 0.599312
I0413 17:19:19.989563  8324 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:19:19.989574  8324 solver.cpp:244]     Train net output #1: loss = 0.599312 (* 1 = 0.599312 loss)
I0413 17:19:19.989583  8324 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 17:19:22.631544  8324 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 17:19:24.234880  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6587
I0413 17:19:24.234925  8324 solver.cpp:404]     Test net output #1: loss = 1.02977 (* 1 = 1.02977 loss)
I0413 17:19:24.302100  8324 solver.cpp:228] Iteration 1480, loss = 0.673667
I0413 17:19:24.302136  8324 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:19:24.302147  8324 solver.cpp:244]     Train net output #1: loss = 0.673667 (* 1 = 0.673667 loss)
I0413 17:19:24.302156  8324 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 17:19:26.915341  8324 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 17:19:28.268702  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6092
I0413 17:19:28.268772  8324 solver.cpp:404]     Test net output #1: loss = 1.24378 (* 1 = 1.24378 loss)
I0413 17:19:28.320252  8324 solver.cpp:228] Iteration 1500, loss = 0.73636
I0413 17:19:28.320272  8324 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:19:28.320281  8324 solver.cpp:244]     Train net output #1: loss = 0.73636 (* 1 = 0.73636 loss)
I0413 17:19:28.320289  8324 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 17:19:30.766650  8324 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 17:19:32.370087  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6237
I0413 17:19:32.370127  8324 solver.cpp:404]     Test net output #1: loss = 1.15339 (* 1 = 1.15339 loss)
I0413 17:19:32.434437  8324 solver.cpp:228] Iteration 1520, loss = 0.76772
I0413 17:19:32.434470  8324 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:19:32.434481  8324 solver.cpp:244]     Train net output #1: loss = 0.76772 (* 1 = 0.76772 loss)
I0413 17:19:32.434490  8324 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 17:19:35.037283  8324 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 17:19:36.619846  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6603
I0413 17:19:36.619889  8324 solver.cpp:404]     Test net output #1: loss = 1.04367 (* 1 = 1.04367 loss)
I0413 17:19:36.665068  8324 solver.cpp:228] Iteration 1540, loss = 0.805803
I0413 17:19:36.665086  8324 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:19:36.665094  8324 solver.cpp:244]     Train net output #1: loss = 0.805803 (* 1 = 0.805803 loss)
I0413 17:19:36.665102  8324 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 17:19:39.022512  8324 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 17:19:40.501616  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6853
I0413 17:19:40.501674  8324 solver.cpp:404]     Test net output #1: loss = 0.961337 (* 1 = 0.961337 loss)
I0413 17:19:40.563534  8324 solver.cpp:228] Iteration 1560, loss = 0.871836
I0413 17:19:40.563570  8324 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:19:40.563580  8324 solver.cpp:244]     Train net output #1: loss = 0.871836 (* 1 = 0.871836 loss)
I0413 17:19:40.563588  8324 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 17:19:43.178392  8324 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 17:19:44.786794  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6491
I0413 17:19:44.786839  8324 solver.cpp:404]     Test net output #1: loss = 1.06718 (* 1 = 1.06718 loss)
I0413 17:19:44.846859  8324 solver.cpp:228] Iteration 1580, loss = 0.752647
I0413 17:19:44.846930  8324 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:19:44.846946  8324 solver.cpp:244]     Train net output #1: loss = 0.752647 (* 1 = 0.752647 loss)
I0413 17:19:44.846956  8324 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 17:19:47.362422  8324 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 17:19:48.719717  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6926
I0413 17:19:48.719759  8324 solver.cpp:404]     Test net output #1: loss = 0.900788 (* 1 = 0.900788 loss)
I0413 17:19:48.767652  8324 solver.cpp:228] Iteration 1600, loss = 0.79518
I0413 17:19:48.767691  8324 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:19:48.767702  8324 solver.cpp:244]     Train net output #1: loss = 0.79518 (* 1 = 0.79518 loss)
I0413 17:19:48.767711  8324 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 17:19:51.292919  8324 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 17:19:52.923470  8324 solver.cpp:404]     Test net output #0: accuracy = 0.687
I0413 17:19:52.923512  8324 solver.cpp:404]     Test net output #1: loss = 0.91656 (* 1 = 0.91656 loss)
I0413 17:19:52.980094  8324 solver.cpp:228] Iteration 1620, loss = 0.724189
I0413 17:19:52.980151  8324 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:19:52.980170  8324 solver.cpp:244]     Train net output #1: loss = 0.724189 (* 1 = 0.724189 loss)
I0413 17:19:52.980183  8324 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 17:19:55.600489  8324 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 17:19:57.056681  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6739
I0413 17:19:57.056730  8324 solver.cpp:404]     Test net output #1: loss = 0.96125 (* 1 = 0.96125 loss)
I0413 17:19:57.110309  8324 solver.cpp:228] Iteration 1640, loss = 0.735145
I0413 17:19:57.110355  8324 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:19:57.110368  8324 solver.cpp:244]     Train net output #1: loss = 0.735145 (* 1 = 0.735145 loss)
I0413 17:19:57.110381  8324 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 17:19:59.485200  8324 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 17:20:01.073099  8324 solver.cpp:404]     Test net output #0: accuracy = 0.684
I0413 17:20:01.073160  8324 solver.cpp:404]     Test net output #1: loss = 0.911726 (* 1 = 0.911726 loss)
I0413 17:20:01.132216  8324 solver.cpp:228] Iteration 1660, loss = 0.711901
I0413 17:20:01.132248  8324 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:20:01.132258  8324 solver.cpp:244]     Train net output #1: loss = 0.711901 (* 1 = 0.711901 loss)
I0413 17:20:01.132271  8324 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 17:20:03.751049  8324 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 17:20:05.386932  8324 solver.cpp:404]     Test net output #0: accuracy = 0.714
I0413 17:20:05.386983  8324 solver.cpp:404]     Test net output #1: loss = 0.839015 (* 1 = 0.839015 loss)
I0413 17:20:05.441478  8324 solver.cpp:228] Iteration 1680, loss = 0.68132
I0413 17:20:05.441567  8324 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:20:05.441579  8324 solver.cpp:244]     Train net output #1: loss = 0.68132 (* 1 = 0.68132 loss)
I0413 17:20:05.441591  8324 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 17:20:07.869159  8324 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 17:20:09.246683  8324 solver.cpp:404]     Test net output #0: accuracy = 0.649
I0413 17:20:09.246731  8324 solver.cpp:404]     Test net output #1: loss = 1.03826 (* 1 = 1.03826 loss)
I0413 17:20:09.308545  8324 solver.cpp:228] Iteration 1700, loss = 0.714433
I0413 17:20:09.308564  8324 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:20:09.308573  8324 solver.cpp:244]     Train net output #1: loss = 0.714433 (* 1 = 0.714433 loss)
I0413 17:20:09.308593  8324 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 17:20:11.936563  8324 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 17:20:13.570847  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6602
I0413 17:20:13.570888  8324 solver.cpp:404]     Test net output #1: loss = 1.03812 (* 1 = 1.03812 loss)
I0413 17:20:13.629504  8324 solver.cpp:228] Iteration 1720, loss = 0.790464
I0413 17:20:13.629549  8324 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:20:13.629560  8324 solver.cpp:244]     Train net output #1: loss = 0.790464 (* 1 = 0.790464 loss)
I0413 17:20:13.629570  8324 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 17:20:16.221088  8324 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 17:20:17.571310  8324 solver.cpp:404]     Test net output #0: accuracy = 0.7062
I0413 17:20:17.571373  8324 solver.cpp:404]     Test net output #1: loss = 0.867139 (* 1 = 0.867139 loss)
I0413 17:20:17.623750  8324 solver.cpp:228] Iteration 1740, loss = 0.661378
I0413 17:20:17.623793  8324 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:20:17.623808  8324 solver.cpp:244]     Train net output #1: loss = 0.661378 (* 1 = 0.661378 loss)
I0413 17:20:17.623822  8324 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 17:20:20.055251  8324 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 17:20:21.690665  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6771
I0413 17:20:21.690706  8324 solver.cpp:404]     Test net output #1: loss = 0.994956 (* 1 = 0.994956 loss)
I0413 17:20:21.745887  8324 solver.cpp:228] Iteration 1760, loss = 0.874878
I0413 17:20:21.745906  8324 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:20:21.745914  8324 solver.cpp:244]     Train net output #1: loss = 0.874878 (* 1 = 0.874878 loss)
I0413 17:20:21.745923  8324 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 17:20:24.373961  8324 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 17:20:25.913570  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6297
I0413 17:20:25.913614  8324 solver.cpp:404]     Test net output #1: loss = 1.18835 (* 1 = 1.18835 loss)
I0413 17:20:25.961499  8324 solver.cpp:228] Iteration 1780, loss = 0.742229
I0413 17:20:25.961551  8324 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:20:25.961562  8324 solver.cpp:244]     Train net output #1: loss = 0.742229 (* 1 = 0.742229 loss)
I0413 17:20:25.961572  8324 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 17:20:28.355157  8324 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 17:20:29.848208  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6882
I0413 17:20:29.848256  8324 solver.cpp:404]     Test net output #1: loss = 0.940977 (* 1 = 0.940977 loss)
I0413 17:20:29.911566  8324 solver.cpp:228] Iteration 1800, loss = 0.821669
I0413 17:20:29.911582  8324 solver.cpp:244]     Train net output #0: accuracy = 0.683594
I0413 17:20:29.911592  8324 solver.cpp:244]     Train net output #1: loss = 0.821669 (* 1 = 0.821669 loss)
I0413 17:20:29.911599  8324 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 17:20:32.540923  8324 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 17:20:34.173856  8324 solver.cpp:404]     Test net output #0: accuracy = 0.7042
I0413 17:20:34.173893  8324 solver.cpp:404]     Test net output #1: loss = 0.897863 (* 1 = 0.897863 loss)
I0413 17:20:34.229825  8324 solver.cpp:228] Iteration 1820, loss = 0.720303
I0413 17:20:34.229851  8324 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:20:34.229861  8324 solver.cpp:244]     Train net output #1: loss = 0.720303 (* 1 = 0.720303 loss)
I0413 17:20:34.229871  8324 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 17:20:36.721141  8324 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 17:20:38.088901  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6645
I0413 17:20:38.088951  8324 solver.cpp:404]     Test net output #1: loss = 1.02261 (* 1 = 1.02261 loss)
I0413 17:20:38.141510  8324 solver.cpp:228] Iteration 1840, loss = 0.684466
I0413 17:20:38.141547  8324 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:20:38.141558  8324 solver.cpp:244]     Train net output #1: loss = 0.684466 (* 1 = 0.684466 loss)
I0413 17:20:38.141567  8324 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 17:20:40.725288  8324 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 17:20:42.353152  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6335
I0413 17:20:42.353191  8324 solver.cpp:404]     Test net output #1: loss = 1.21074 (* 1 = 1.21074 loss)
I0413 17:20:42.417138  8324 solver.cpp:228] Iteration 1860, loss = 0.683922
I0413 17:20:42.417207  8324 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:20:42.417223  8324 solver.cpp:244]     Train net output #1: loss = 0.683922 (* 1 = 0.683922 loss)
I0413 17:20:42.417234  8324 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 17:20:45.035646  8324 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 17:20:46.450778  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6336
I0413 17:20:46.450814  8324 solver.cpp:404]     Test net output #1: loss = 1.14636 (* 1 = 1.14636 loss)
I0413 17:20:46.498071  8324 solver.cpp:228] Iteration 1880, loss = 0.628081
I0413 17:20:46.498090  8324 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:20:46.498100  8324 solver.cpp:244]     Train net output #1: loss = 0.628081 (* 1 = 0.628081 loss)
I0413 17:20:46.498108  8324 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 17:20:48.908849  8324 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 17:20:50.503660  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6741
I0413 17:20:50.503710  8324 solver.cpp:404]     Test net output #1: loss = 0.964289 (* 1 = 0.964289 loss)
I0413 17:20:50.567201  8324 solver.cpp:228] Iteration 1900, loss = 0.798099
I0413 17:20:50.567286  8324 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:20:50.567328  8324 solver.cpp:244]     Train net output #1: loss = 0.798099 (* 1 = 0.798099 loss)
I0413 17:20:50.567350  8324 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 17:20:53.182346  8324 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 17:20:54.803566  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6563
I0413 17:20:54.803678  8324 solver.cpp:404]     Test net output #1: loss = 1.03142 (* 1 = 1.03142 loss)
I0413 17:20:54.865213  8324 solver.cpp:228] Iteration 1920, loss = 0.825049
I0413 17:20:54.865258  8324 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:20:54.865270  8324 solver.cpp:244]     Train net output #1: loss = 0.825049 (* 1 = 0.825049 loss)
I0413 17:20:54.865283  8324 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 17:20:57.248807  8324 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 17:20:58.712020  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6146
I0413 17:20:58.712062  8324 solver.cpp:404]     Test net output #1: loss = 1.16695 (* 1 = 1.16695 loss)
I0413 17:20:58.776558  8324 solver.cpp:228] Iteration 1940, loss = 0.729361
I0413 17:20:58.776621  8324 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:20:58.776644  8324 solver.cpp:244]     Train net output #1: loss = 0.729361 (* 1 = 0.729361 loss)
I0413 17:20:58.776659  8324 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 17:21:01.408810  8324 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 17:21:03.020694  8324 solver.cpp:404]     Test net output #0: accuracy = 0.6533
I0413 17:21:03.020745  8324 solver.cpp:404]     Test net output #1: loss = 1.03945 (* 1 = 1.03945 loss)
I0413 17:21:03.084640  8324 solver.cpp:228] Iteration 1960, loss = 0.642401
I0413 17:21:03.084692  8324 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:21:03.084703  8324 solver.cpp:244]     Train net output #1: loss = 0.642401 (* 1 = 0.642401 loss)
I0413 17:21:03.084715  8324 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 17:21:05.605830  8324 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 17:21:06.956153  8324 solver.cpp:404]     Test net output #0: accuracy = 0.665
I0413 17:21:06.956202  8324 solver.cpp:404]     Test net output #1: loss = 1.04357 (* 1 = 1.04357 loss)
I0413 17:21:07.001034  8324 solver.cpp:228] Iteration 1980, loss = 0.795914
I0413 17:21:07.001068  8324 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:21:07.001080  8324 solver.cpp:244]     Train net output #1: loss = 0.795914 (* 1 = 0.795914 loss)
I0413 17:21:07.001088  8324 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 17:21:09.541690  8324 solver.cpp:454] Snapshotting to binary proto file /home/liangjiang/code/residual_network-dy/results/snapshots/ResNet-cifar1/ResNet-cifar1_iter_2000.caffemodel
I0413 17:21:09.543495  8324 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/liangjiang/code/residual_network-dy/results/snapshots/ResNet-cifar1/ResNet-cifar1_iter_2000.solverstate
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 17:21:11.792675 28395 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar2/ResNet-cifar2"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar2.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 17:21:11.792722 28395 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar2.prototxt
I0413 17:21:11.793638 28395 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 17:21:11.793867 28395 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv2_3"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:21:11.794080 28395 layer_factory.hpp:77] Creating layer cifar
I0413 17:21:11.795074 28395 net.cpp:91] Creating Layer cifar
I0413 17:21:11.795091 28395 net.cpp:399] cifar -> data
I0413 17:21:11.795106 28395 net.cpp:399] cifar -> label
I0413 17:21:11.795120 28395 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:21:11.811081 28444 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 17:21:11.838934 28395 data_layer.cpp:41] output data size: 256,3,32,32
I0413 17:21:11.850752 28395 net.cpp:141] Setting up cifar
I0413 17:21:11.850776 28395 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 17:21:11.850785 28395 net.cpp:148] Top shape: 256 (256)
I0413 17:21:11.850790 28395 net.cpp:156] Memory required for data: 3146752
I0413 17:21:11.850800 28395 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:21:11.850850 28395 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:21:11.850860 28395 net.cpp:425] label_cifar_1_split <- label
I0413 17:21:11.850870 28395 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:21:11.850883 28395 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:21:11.850935 28395 net.cpp:141] Setting up label_cifar_1_split
I0413 17:21:11.850945 28395 net.cpp:148] Top shape: 256 (256)
I0413 17:21:11.850951 28395 net.cpp:148] Top shape: 256 (256)
I0413 17:21:11.850956 28395 net.cpp:156] Memory required for data: 3148800
I0413 17:21:11.850961 28395 layer_factory.hpp:77] Creating layer conv1
I0413 17:21:11.850980 28395 net.cpp:91] Creating Layer conv1
I0413 17:21:11.850986 28395 net.cpp:425] conv1 <- data
I0413 17:21:11.850996 28395 net.cpp:399] conv1 -> conv1
I0413 17:21:12.128352 28395 net.cpp:141] Setting up conv1
I0413 17:21:12.128399 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.128406 28395 net.cpp:156] Memory required for data: 19926016
I0413 17:21:12.128424 28395 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:21:12.128440 28395 net.cpp:91] Creating Layer bn_conv1
I0413 17:21:12.128445 28395 net.cpp:425] bn_conv1 <- conv1
I0413 17:21:12.128453 28395 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:21:12.128607 28395 net.cpp:141] Setting up bn_conv1
I0413 17:21:12.128615 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.128619 28395 net.cpp:156] Memory required for data: 36703232
I0413 17:21:12.128630 28395 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:21:12.128640 28395 net.cpp:91] Creating Layer scale_conv1
I0413 17:21:12.128645 28395 net.cpp:425] scale_conv1 <- conv1
I0413 17:21:12.128650 28395 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:21:12.128684 28395 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:21:12.128777 28395 net.cpp:141] Setting up scale_conv1
I0413 17:21:12.128785 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.128789 28395 net.cpp:156] Memory required for data: 53480448
I0413 17:21:12.128796 28395 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:21:12.128803 28395 net.cpp:91] Creating Layer conv1_relu
I0413 17:21:12.128808 28395 net.cpp:425] conv1_relu <- conv1
I0413 17:21:12.128813 28395 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:21:12.129380 28395 net.cpp:141] Setting up conv1_relu
I0413 17:21:12.129395 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.129400 28395 net.cpp:156] Memory required for data: 70257664
I0413 17:21:12.129405 28395 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:21:12.129423 28395 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:21:12.129428 28395 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:21:12.129436 28395 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:21:12.129456 28395 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:21:12.129500 28395 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:21:12.129508 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.129513 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.129516 28395 net.cpp:156] Memory required for data: 103812096
I0413 17:21:12.129520 28395 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:21:12.129531 28395 net.cpp:91] Creating Layer conv2_1a
I0413 17:21:12.129536 28395 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:21:12.129542 28395 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:21:12.134385 28395 net.cpp:141] Setting up conv2_1a
I0413 17:21:12.134400 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.134405 28395 net.cpp:156] Memory required for data: 120589312
I0413 17:21:12.134415 28395 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:21:12.134423 28395 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:21:12.134428 28395 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:21:12.134433 28395 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:21:12.134572 28395 net.cpp:141] Setting up bn_conv2_1a
I0413 17:21:12.134579 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.134583 28395 net.cpp:156] Memory required for data: 137366528
I0413 17:21:12.134590 28395 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:21:12.134598 28395 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:21:12.134601 28395 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:21:12.134606 28395 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:21:12.134634 28395 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:21:12.134716 28395 net.cpp:141] Setting up scale_conv2_1a
I0413 17:21:12.134723 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.134727 28395 net.cpp:156] Memory required for data: 154143744
I0413 17:21:12.134733 28395 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:21:12.134739 28395 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:21:12.134743 28395 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:21:12.134749 28395 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:21:12.135452 28395 net.cpp:141] Setting up conv2_1a_relu
I0413 17:21:12.135465 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.135469 28395 net.cpp:156] Memory required for data: 170920960
I0413 17:21:12.135474 28395 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:21:12.135484 28395 net.cpp:91] Creating Layer conv2_1b
I0413 17:21:12.135489 28395 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:21:12.135495 28395 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:21:12.138937 28395 net.cpp:141] Setting up conv2_1b
I0413 17:21:12.138952 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.138957 28395 net.cpp:156] Memory required for data: 187698176
I0413 17:21:12.138964 28395 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:21:12.138972 28395 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:21:12.138975 28395 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:21:12.138981 28395 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:21:12.139118 28395 net.cpp:141] Setting up bn_conv2_1b
I0413 17:21:12.139127 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.139129 28395 net.cpp:156] Memory required for data: 204475392
I0413 17:21:12.139140 28395 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:21:12.139147 28395 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:21:12.139150 28395 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:21:12.139156 28395 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:21:12.139184 28395 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:21:12.139272 28395 net.cpp:141] Setting up scale_conv2_1b
I0413 17:21:12.139281 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.139284 28395 net.cpp:156] Memory required for data: 221252608
I0413 17:21:12.139291 28395 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:21:12.139297 28395 net.cpp:91] Creating Layer conv2_1
I0413 17:21:12.139302 28395 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:21:12.139307 28395 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:21:12.139312 28395 net.cpp:399] conv2_1 -> conv2_1
I0413 17:21:12.139333 28395 net.cpp:141] Setting up conv2_1
I0413 17:21:12.139340 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.139344 28395 net.cpp:156] Memory required for data: 238029824
I0413 17:21:12.139348 28395 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:21:12.139353 28395 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:21:12.139358 28395 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:21:12.139364 28395 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:21:12.140013 28395 net.cpp:141] Setting up conv2_1_relu
I0413 17:21:12.140023 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.140027 28395 net.cpp:156] Memory required for data: 254807040
I0413 17:21:12.140032 28395 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:21:12.140038 28395 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:21:12.140043 28395 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:21:12.140048 28395 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:21:12.140055 28395 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:21:12.140086 28395 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:21:12.140092 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.140097 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.140100 28395 net.cpp:156] Memory required for data: 288361472
I0413 17:21:12.140105 28395 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:21:12.140113 28395 net.cpp:91] Creating Layer conv2_2a
I0413 17:21:12.140118 28395 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:21:12.140125 28395 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:21:12.143499 28395 net.cpp:141] Setting up conv2_2a
I0413 17:21:12.143515 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.143519 28395 net.cpp:156] Memory required for data: 305138688
I0413 17:21:12.143527 28395 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:21:12.143534 28395 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:21:12.143538 28395 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:21:12.143544 28395 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:21:12.143684 28395 net.cpp:141] Setting up bn_conv2_2a
I0413 17:21:12.143692 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.143697 28395 net.cpp:156] Memory required for data: 321915904
I0413 17:21:12.143703 28395 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:21:12.143710 28395 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:21:12.143714 28395 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:21:12.143719 28395 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:21:12.143748 28395 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:21:12.143829 28395 net.cpp:141] Setting up scale_conv2_2a
I0413 17:21:12.143837 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.143841 28395 net.cpp:156] Memory required for data: 338693120
I0413 17:21:12.143847 28395 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:21:12.143853 28395 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:21:12.143857 28395 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:21:12.143862 28395 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:21:12.145973 28395 net.cpp:141] Setting up conv2_2a_relu
I0413 17:21:12.145987 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.145992 28395 net.cpp:156] Memory required for data: 355470336
I0413 17:21:12.146000 28395 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:21:12.146010 28395 net.cpp:91] Creating Layer conv2_2b
I0413 17:21:12.146015 28395 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:21:12.146023 28395 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:21:12.149507 28395 net.cpp:141] Setting up conv2_2b
I0413 17:21:12.149520 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.149525 28395 net.cpp:156] Memory required for data: 372247552
I0413 17:21:12.149533 28395 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:21:12.149540 28395 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:21:12.149545 28395 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:21:12.149551 28395 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:21:12.149698 28395 net.cpp:141] Setting up bn_conv2_2b
I0413 17:21:12.149706 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.149710 28395 net.cpp:156] Memory required for data: 389024768
I0413 17:21:12.149723 28395 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:21:12.149729 28395 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:21:12.149734 28395 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:21:12.149739 28395 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:21:12.149767 28395 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:21:12.149849 28395 net.cpp:141] Setting up scale_conv2_2b
I0413 17:21:12.149857 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.149860 28395 net.cpp:156] Memory required for data: 405801984
I0413 17:21:12.149866 28395 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:21:12.149873 28395 net.cpp:91] Creating Layer conv2_2
I0413 17:21:12.149878 28395 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:21:12.149883 28395 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:21:12.149888 28395 net.cpp:399] conv2_2 -> conv2_2
I0413 17:21:12.149907 28395 net.cpp:141] Setting up conv2_2
I0413 17:21:12.149914 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.149919 28395 net.cpp:156] Memory required for data: 422579200
I0413 17:21:12.149922 28395 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:21:12.149927 28395 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:21:12.149931 28395 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:21:12.149937 28395 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:21:12.150562 28395 net.cpp:141] Setting up conv2_2_relu
I0413 17:21:12.150573 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.150578 28395 net.cpp:156] Memory required for data: 439356416
I0413 17:21:12.150583 28395 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:21:12.150588 28395 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:21:12.150593 28395 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:21:12.150599 28395 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:21:12.150606 28395 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:21:12.150640 28395 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:21:12.150647 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.150653 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.150656 28395 net.cpp:156] Memory required for data: 472910848
I0413 17:21:12.150660 28395 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:21:12.150671 28395 net.cpp:91] Creating Layer conv2_3a
I0413 17:21:12.150674 28395 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:21:12.150681 28395 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:21:12.154080 28395 net.cpp:141] Setting up conv2_3a
I0413 17:21:12.154094 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.154098 28395 net.cpp:156] Memory required for data: 489688064
I0413 17:21:12.154106 28395 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:21:12.154114 28395 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:21:12.154122 28395 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:21:12.154130 28395 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:21:12.154271 28395 net.cpp:141] Setting up bn_conv2_3a
I0413 17:21:12.154279 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.154284 28395 net.cpp:156] Memory required for data: 506465280
I0413 17:21:12.154290 28395 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:21:12.154297 28395 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:21:12.154301 28395 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:21:12.154307 28395 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:21:12.154336 28395 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:21:12.154420 28395 net.cpp:141] Setting up scale_conv2_3a
I0413 17:21:12.154428 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.154431 28395 net.cpp:156] Memory required for data: 523242496
I0413 17:21:12.154438 28395 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:21:12.154444 28395 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:21:12.154448 28395 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:21:12.154453 28395 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:21:12.155145 28395 net.cpp:141] Setting up conv2_3a_relu
I0413 17:21:12.155155 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.155159 28395 net.cpp:156] Memory required for data: 540019712
I0413 17:21:12.155164 28395 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:21:12.155174 28395 net.cpp:91] Creating Layer conv2_3b
I0413 17:21:12.155177 28395 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:21:12.155184 28395 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:21:12.159982 28395 net.cpp:141] Setting up conv2_3b
I0413 17:21:12.159996 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.160001 28395 net.cpp:156] Memory required for data: 556796928
I0413 17:21:12.160008 28395 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:21:12.160017 28395 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:21:12.160022 28395 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:21:12.160028 28395 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:21:12.160174 28395 net.cpp:141] Setting up bn_conv2_3b
I0413 17:21:12.160182 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.160186 28395 net.cpp:156] Memory required for data: 573574144
I0413 17:21:12.160193 28395 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:21:12.160199 28395 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:21:12.160204 28395 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:21:12.160209 28395 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:21:12.160238 28395 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:21:12.160321 28395 net.cpp:141] Setting up scale_conv2_3b
I0413 17:21:12.160329 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.160333 28395 net.cpp:156] Memory required for data: 590351360
I0413 17:21:12.160339 28395 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:21:12.160346 28395 net.cpp:91] Creating Layer conv2_3
I0413 17:21:12.160351 28395 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:21:12.160356 28395 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:21:12.160361 28395 net.cpp:399] conv2_3 -> conv2_3
I0413 17:21:12.160380 28395 net.cpp:141] Setting up conv2_3
I0413 17:21:12.160387 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.160392 28395 net.cpp:156] Memory required for data: 607128576
I0413 17:21:12.160394 28395 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:21:12.160400 28395 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:21:12.160404 28395 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:21:12.160410 28395 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:21:12.161051 28395 net.cpp:141] Setting up conv2_3_relu
I0413 17:21:12.161064 28395 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:21:12.161068 28395 net.cpp:156] Memory required for data: 623905792
I0413 17:21:12.161077 28395 layer_factory.hpp:77] Creating layer global_pool
I0413 17:21:12.161087 28395 net.cpp:91] Creating Layer global_pool
I0413 17:21:12.161090 28395 net.cpp:425] global_pool <- conv2_3
I0413 17:21:12.161097 28395 net.cpp:399] global_pool -> global_pool
I0413 17:21:12.162196 28395 net.cpp:141] Setting up global_pool
I0413 17:21:12.162209 28395 net.cpp:148] Top shape: 256 16 4 4 (65536)
I0413 17:21:12.162212 28395 net.cpp:156] Memory required for data: 624167936
I0413 17:21:12.162216 28395 layer_factory.hpp:77] Creating layer ip
I0413 17:21:12.162225 28395 net.cpp:91] Creating Layer ip
I0413 17:21:12.162230 28395 net.cpp:425] ip <- global_pool
I0413 17:21:12.162235 28395 net.cpp:399] ip -> ip
I0413 17:21:12.162323 28395 net.cpp:141] Setting up ip
I0413 17:21:12.162331 28395 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:21:12.162335 28395 net.cpp:156] Memory required for data: 624178176
I0413 17:21:12.162343 28395 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:21:12.162348 28395 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:21:12.162353 28395 net.cpp:425] ip_ip_0_split <- ip
I0413 17:21:12.162358 28395 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:21:12.162365 28395 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:21:12.162391 28395 net.cpp:141] Setting up ip_ip_0_split
I0413 17:21:12.162398 28395 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:21:12.162402 28395 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:21:12.162406 28395 net.cpp:156] Memory required for data: 624198656
I0413 17:21:12.162410 28395 layer_factory.hpp:77] Creating layer accuracy
I0413 17:21:12.162421 28395 net.cpp:91] Creating Layer accuracy
I0413 17:21:12.162425 28395 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:21:12.162431 28395 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:21:12.162436 28395 net.cpp:399] accuracy -> accuracy
I0413 17:21:12.162444 28395 net.cpp:141] Setting up accuracy
I0413 17:21:12.162451 28395 net.cpp:148] Top shape: (1)
I0413 17:21:12.162453 28395 net.cpp:156] Memory required for data: 624198660
I0413 17:21:12.162457 28395 layer_factory.hpp:77] Creating layer loss
I0413 17:21:12.162463 28395 net.cpp:91] Creating Layer loss
I0413 17:21:12.162467 28395 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:21:12.162472 28395 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:21:12.162477 28395 net.cpp:399] loss -> loss
I0413 17:21:12.162490 28395 layer_factory.hpp:77] Creating layer loss
I0413 17:21:12.163380 28395 net.cpp:141] Setting up loss
I0413 17:21:12.163393 28395 net.cpp:148] Top shape: (1)
I0413 17:21:12.163398 28395 net.cpp:151]     with loss weight 1
I0413 17:21:12.163408 28395 net.cpp:156] Memory required for data: 624198664
I0413 17:21:12.163413 28395 net.cpp:217] loss needs backward computation.
I0413 17:21:12.163417 28395 net.cpp:219] accuracy does not need backward computation.
I0413 17:21:12.163422 28395 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:21:12.163426 28395 net.cpp:217] ip needs backward computation.
I0413 17:21:12.163430 28395 net.cpp:217] global_pool needs backward computation.
I0413 17:21:12.163434 28395 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:21:12.163439 28395 net.cpp:217] conv2_3 needs backward computation.
I0413 17:21:12.163442 28395 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:21:12.163446 28395 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:21:12.163450 28395 net.cpp:217] conv2_3b needs backward computation.
I0413 17:21:12.163453 28395 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:21:12.163457 28395 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:21:12.163461 28395 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:21:12.163465 28395 net.cpp:217] conv2_3a needs backward computation.
I0413 17:21:12.163468 28395 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:21:12.163472 28395 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:21:12.163476 28395 net.cpp:217] conv2_2 needs backward computation.
I0413 17:21:12.163486 28395 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:21:12.163489 28395 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:21:12.163493 28395 net.cpp:217] conv2_2b needs backward computation.
I0413 17:21:12.163496 28395 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:21:12.163501 28395 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:21:12.163504 28395 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:21:12.163507 28395 net.cpp:217] conv2_2a needs backward computation.
I0413 17:21:12.163511 28395 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:21:12.163516 28395 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:21:12.163519 28395 net.cpp:217] conv2_1 needs backward computation.
I0413 17:21:12.163523 28395 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:21:12.163527 28395 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:21:12.163530 28395 net.cpp:217] conv2_1b needs backward computation.
I0413 17:21:12.163534 28395 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:21:12.163538 28395 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:21:12.163542 28395 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:21:12.163545 28395 net.cpp:217] conv2_1a needs backward computation.
I0413 17:21:12.163549 28395 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:21:12.163553 28395 net.cpp:217] conv1_relu needs backward computation.
I0413 17:21:12.163557 28395 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:21:12.163560 28395 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:21:12.163564 28395 net.cpp:217] conv1 needs backward computation.
I0413 17:21:12.163568 28395 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:21:12.163573 28395 net.cpp:219] cifar does not need backward computation.
I0413 17:21:12.163576 28395 net.cpp:261] This network produces output accuracy
I0413 17:21:12.163580 28395 net.cpp:261] This network produces output loss
I0413 17:21:12.163604 28395 net.cpp:274] Network initialization done.
I0413 17:21:12.164366 28395 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar2.prototxt
I0413 17:21:12.164419 28395 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 17:21:12.164600 28395 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv2_3"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:21:12.164744 28395 layer_factory.hpp:77] Creating layer cifar
I0413 17:21:12.164851 28395 net.cpp:91] Creating Layer cifar
I0413 17:21:12.164861 28395 net.cpp:399] cifar -> data
I0413 17:21:12.164871 28395 net.cpp:399] cifar -> label
I0413 17:21:12.164880 28395 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:21:12.166115 28460 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 17:21:12.166251 28395 data_layer.cpp:41] output data size: 100,3,32,32
I0413 17:21:12.169011 28395 net.cpp:141] Setting up cifar
I0413 17:21:12.169039 28395 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 17:21:12.169046 28395 net.cpp:148] Top shape: 100 (100)
I0413 17:21:12.169051 28395 net.cpp:156] Memory required for data: 1229200
I0413 17:21:12.169056 28395 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:21:12.169064 28395 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:21:12.169070 28395 net.cpp:425] label_cifar_1_split <- label
I0413 17:21:12.169075 28395 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:21:12.169085 28395 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:21:12.169145 28395 net.cpp:141] Setting up label_cifar_1_split
I0413 17:21:12.169155 28395 net.cpp:148] Top shape: 100 (100)
I0413 17:21:12.169162 28395 net.cpp:148] Top shape: 100 (100)
I0413 17:21:12.169165 28395 net.cpp:156] Memory required for data: 1230000
I0413 17:21:12.169169 28395 layer_factory.hpp:77] Creating layer conv1
I0413 17:21:12.169181 28395 net.cpp:91] Creating Layer conv1
I0413 17:21:12.169186 28395 net.cpp:425] conv1 <- data
I0413 17:21:12.169195 28395 net.cpp:399] conv1 -> conv1
I0413 17:21:12.170553 28395 net.cpp:141] Setting up conv1
I0413 17:21:12.170569 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.170574 28395 net.cpp:156] Memory required for data: 7783600
I0413 17:21:12.170586 28395 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:21:12.170595 28395 net.cpp:91] Creating Layer bn_conv1
I0413 17:21:12.170600 28395 net.cpp:425] bn_conv1 <- conv1
I0413 17:21:12.170608 28395 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:21:12.170781 28395 net.cpp:141] Setting up bn_conv1
I0413 17:21:12.170789 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.170794 28395 net.cpp:156] Memory required for data: 14337200
I0413 17:21:12.170806 28395 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:21:12.170814 28395 net.cpp:91] Creating Layer scale_conv1
I0413 17:21:12.170819 28395 net.cpp:425] scale_conv1 <- conv1
I0413 17:21:12.170825 28395 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:21:12.170873 28395 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:21:12.170969 28395 net.cpp:141] Setting up scale_conv1
I0413 17:21:12.170977 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.170981 28395 net.cpp:156] Memory required for data: 20890800
I0413 17:21:12.170989 28395 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:21:12.170995 28395 net.cpp:91] Creating Layer conv1_relu
I0413 17:21:12.171000 28395 net.cpp:425] conv1_relu <- conv1
I0413 17:21:12.171005 28395 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:21:12.171156 28395 net.cpp:141] Setting up conv1_relu
I0413 17:21:12.171166 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.171171 28395 net.cpp:156] Memory required for data: 27444400
I0413 17:21:12.171175 28395 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:21:12.171186 28395 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:21:12.171191 28395 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:21:12.171197 28395 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:21:12.171205 28395 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:21:12.171255 28395 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:21:12.171263 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.171268 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.171272 28395 net.cpp:156] Memory required for data: 40551600
I0413 17:21:12.171277 28395 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:21:12.171288 28395 net.cpp:91] Creating Layer conv2_1a
I0413 17:21:12.171291 28395 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:21:12.171299 28395 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:21:12.173566 28395 net.cpp:141] Setting up conv2_1a
I0413 17:21:12.173588 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.173593 28395 net.cpp:156] Memory required for data: 47105200
I0413 17:21:12.173604 28395 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:21:12.173614 28395 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:21:12.173619 28395 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:21:12.173635 28395 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:21:12.173807 28395 net.cpp:141] Setting up bn_conv2_1a
I0413 17:21:12.173816 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.173838 28395 net.cpp:156] Memory required for data: 53658800
I0413 17:21:12.173846 28395 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:21:12.173854 28395 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:21:12.173858 28395 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:21:12.173866 28395 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:21:12.173904 28395 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:21:12.174006 28395 net.cpp:141] Setting up scale_conv2_1a
I0413 17:21:12.174015 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.174036 28395 net.cpp:156] Memory required for data: 60212400
I0413 17:21:12.174043 28395 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:21:12.174049 28395 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:21:12.174053 28395 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:21:12.174059 28395 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:21:12.174676 28395 net.cpp:141] Setting up conv2_1a_relu
I0413 17:21:12.174695 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.174700 28395 net.cpp:156] Memory required for data: 66766000
I0413 17:21:12.174703 28395 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:21:12.174715 28395 net.cpp:91] Creating Layer conv2_1b
I0413 17:21:12.174720 28395 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:21:12.174727 28395 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:21:12.177285 28395 net.cpp:141] Setting up conv2_1b
I0413 17:21:12.177302 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.177307 28395 net.cpp:156] Memory required for data: 73319600
I0413 17:21:12.177315 28395 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:21:12.177325 28395 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:21:12.177330 28395 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:21:12.177337 28395 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:21:12.177526 28395 net.cpp:141] Setting up bn_conv2_1b
I0413 17:21:12.177536 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.177549 28395 net.cpp:156] Memory required for data: 79873200
I0413 17:21:12.177562 28395 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:21:12.177570 28395 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:21:12.177575 28395 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:21:12.177582 28395 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:21:12.177825 28395 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:21:12.177947 28395 net.cpp:141] Setting up scale_conv2_1b
I0413 17:21:12.177961 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.177976 28395 net.cpp:156] Memory required for data: 86426800
I0413 17:21:12.177984 28395 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:21:12.177991 28395 net.cpp:91] Creating Layer conv2_1
I0413 17:21:12.177996 28395 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:21:12.178002 28395 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:21:12.178009 28395 net.cpp:399] conv2_1 -> conv2_1
I0413 17:21:12.178038 28395 net.cpp:141] Setting up conv2_1
I0413 17:21:12.178046 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.178050 28395 net.cpp:156] Memory required for data: 92980400
I0413 17:21:12.178056 28395 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:21:12.178061 28395 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:21:12.178066 28395 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:21:12.178073 28395 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:21:12.178351 28395 net.cpp:141] Setting up conv2_1_relu
I0413 17:21:12.178370 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.178375 28395 net.cpp:156] Memory required for data: 99534000
I0413 17:21:12.178380 28395 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:21:12.178388 28395 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:21:12.178393 28395 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:21:12.178400 28395 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:21:12.178418 28395 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:21:12.178458 28395 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:21:12.178467 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.178472 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.178477 28395 net.cpp:156] Memory required for data: 112641200
I0413 17:21:12.178481 28395 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:21:12.178493 28395 net.cpp:91] Creating Layer conv2_2a
I0413 17:21:12.178498 28395 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:21:12.178505 28395 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:21:12.180789 28395 net.cpp:141] Setting up conv2_2a
I0413 17:21:12.180805 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.180810 28395 net.cpp:156] Memory required for data: 119194800
I0413 17:21:12.180819 28395 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:21:12.180827 28395 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:21:12.180835 28395 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:21:12.180850 28395 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:21:12.181043 28395 net.cpp:141] Setting up bn_conv2_2a
I0413 17:21:12.181051 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.181056 28395 net.cpp:156] Memory required for data: 125748400
I0413 17:21:12.181064 28395 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:21:12.181072 28395 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:21:12.181077 28395 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:21:12.181102 28395 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:21:12.181149 28395 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:21:12.181264 28395 net.cpp:141] Setting up scale_conv2_2a
I0413 17:21:12.181273 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.181278 28395 net.cpp:156] Memory required for data: 132302000
I0413 17:21:12.181285 28395 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:21:12.181293 28395 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:21:12.181303 28395 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:21:12.181309 28395 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:21:12.181838 28395 net.cpp:141] Setting up conv2_2a_relu
I0413 17:21:12.181849 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.181861 28395 net.cpp:156] Memory required for data: 138855600
I0413 17:21:12.181866 28395 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:21:12.181877 28395 net.cpp:91] Creating Layer conv2_2b
I0413 17:21:12.181884 28395 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:21:12.181890 28395 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:21:12.185925 28395 net.cpp:141] Setting up conv2_2b
I0413 17:21:12.185941 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.185946 28395 net.cpp:156] Memory required for data: 145409200
I0413 17:21:12.185956 28395 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:21:12.185964 28395 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:21:12.185969 28395 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:21:12.185977 28395 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:21:12.186159 28395 net.cpp:141] Setting up bn_conv2_2b
I0413 17:21:12.186177 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.186182 28395 net.cpp:156] Memory required for data: 151962800
I0413 17:21:12.186195 28395 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:21:12.186213 28395 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:21:12.186218 28395 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:21:12.186223 28395 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:21:12.186265 28395 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:21:12.186369 28395 net.cpp:141] Setting up scale_conv2_2b
I0413 17:21:12.186378 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.186386 28395 net.cpp:156] Memory required for data: 158516400
I0413 17:21:12.186394 28395 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:21:12.186401 28395 net.cpp:91] Creating Layer conv2_2
I0413 17:21:12.186406 28395 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:21:12.186413 28395 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:21:12.186419 28395 net.cpp:399] conv2_2 -> conv2_2
I0413 17:21:12.186444 28395 net.cpp:141] Setting up conv2_2
I0413 17:21:12.186451 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.186461 28395 net.cpp:156] Memory required for data: 165070000
I0413 17:21:12.186465 28395 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:21:12.186472 28395 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:21:12.186477 28395 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:21:12.186483 28395 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:21:12.186764 28395 net.cpp:141] Setting up conv2_2_relu
I0413 17:21:12.186780 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.186785 28395 net.cpp:156] Memory required for data: 171623600
I0413 17:21:12.186790 28395 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:21:12.186797 28395 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:21:12.186802 28395 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:21:12.186810 28395 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:21:12.186826 28395 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:21:12.186871 28395 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:21:12.186879 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.186887 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.186890 28395 net.cpp:156] Memory required for data: 184730800
I0413 17:21:12.186895 28395 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:21:12.186907 28395 net.cpp:91] Creating Layer conv2_3a
I0413 17:21:12.186911 28395 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:21:12.186920 28395 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:21:12.189414 28395 net.cpp:141] Setting up conv2_3a
I0413 17:21:12.189430 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.189435 28395 net.cpp:156] Memory required for data: 191284400
I0413 17:21:12.189443 28395 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:21:12.189451 28395 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:21:12.189461 28395 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:21:12.189470 28395 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:21:12.189648 28395 net.cpp:141] Setting up bn_conv2_3a
I0413 17:21:12.189657 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.189661 28395 net.cpp:156] Memory required for data: 197838000
I0413 17:21:12.189669 28395 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:21:12.189677 28395 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:21:12.189682 28395 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:21:12.189687 28395 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:21:12.189726 28395 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:21:12.189829 28395 net.cpp:141] Setting up scale_conv2_3a
I0413 17:21:12.189837 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.189841 28395 net.cpp:156] Memory required for data: 204391600
I0413 17:21:12.189849 28395 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:21:12.189856 28395 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:21:12.189860 28395 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:21:12.189867 28395 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:21:12.190446 28395 net.cpp:141] Setting up conv2_3a_relu
I0413 17:21:12.190459 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.190464 28395 net.cpp:156] Memory required for data: 210945200
I0413 17:21:12.190469 28395 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:21:12.190480 28395 net.cpp:91] Creating Layer conv2_3b
I0413 17:21:12.190485 28395 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:21:12.190493 28395 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:21:12.193521 28395 net.cpp:141] Setting up conv2_3b
I0413 17:21:12.193536 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.193542 28395 net.cpp:156] Memory required for data: 217498800
I0413 17:21:12.193549 28395 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:21:12.193560 28395 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:21:12.193565 28395 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:21:12.193572 28395 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:21:12.193750 28395 net.cpp:141] Setting up bn_conv2_3b
I0413 17:21:12.193758 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.193763 28395 net.cpp:156] Memory required for data: 224052400
I0413 17:21:12.193771 28395 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:21:12.193778 28395 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:21:12.193783 28395 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:21:12.193789 28395 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:21:12.193827 28395 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:21:12.193933 28395 net.cpp:141] Setting up scale_conv2_3b
I0413 17:21:12.193940 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.193944 28395 net.cpp:156] Memory required for data: 230606000
I0413 17:21:12.193951 28395 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:21:12.193958 28395 net.cpp:91] Creating Layer conv2_3
I0413 17:21:12.193964 28395 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:21:12.193969 28395 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:21:12.193975 28395 net.cpp:399] conv2_3 -> conv2_3
I0413 17:21:12.194000 28395 net.cpp:141] Setting up conv2_3
I0413 17:21:12.194007 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.194011 28395 net.cpp:156] Memory required for data: 237159600
I0413 17:21:12.194015 28395 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:21:12.194022 28395 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:21:12.194026 28395 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:21:12.194033 28395 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:21:12.194200 28395 net.cpp:141] Setting up conv2_3_relu
I0413 17:21:12.194211 28395 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:21:12.194216 28395 net.cpp:156] Memory required for data: 243713200
I0413 17:21:12.194224 28395 layer_factory.hpp:77] Creating layer global_pool
I0413 17:21:12.194232 28395 net.cpp:91] Creating Layer global_pool
I0413 17:21:12.194236 28395 net.cpp:425] global_pool <- conv2_3
I0413 17:21:12.194244 28395 net.cpp:399] global_pool -> global_pool
I0413 17:21:12.195010 28395 net.cpp:141] Setting up global_pool
I0413 17:21:12.195024 28395 net.cpp:148] Top shape: 100 16 4 4 (25600)
I0413 17:21:12.195029 28395 net.cpp:156] Memory required for data: 243815600
I0413 17:21:12.195034 28395 layer_factory.hpp:77] Creating layer ip
I0413 17:21:12.195041 28395 net.cpp:91] Creating Layer ip
I0413 17:21:12.195046 28395 net.cpp:425] ip <- global_pool
I0413 17:21:12.195053 28395 net.cpp:399] ip -> ip
I0413 17:21:12.195159 28395 net.cpp:141] Setting up ip
I0413 17:21:12.195168 28395 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:21:12.195171 28395 net.cpp:156] Memory required for data: 243819600
I0413 17:21:12.195179 28395 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:21:12.195185 28395 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:21:12.195190 28395 net.cpp:425] ip_ip_0_split <- ip
I0413 17:21:12.195197 28395 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:21:12.195204 28395 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:21:12.195240 28395 net.cpp:141] Setting up ip_ip_0_split
I0413 17:21:12.195246 28395 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:21:12.195251 28395 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:21:12.195255 28395 net.cpp:156] Memory required for data: 243827600
I0413 17:21:12.195260 28395 layer_factory.hpp:77] Creating layer accuracy
I0413 17:21:12.195266 28395 net.cpp:91] Creating Layer accuracy
I0413 17:21:12.195271 28395 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:21:12.195276 28395 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:21:12.195282 28395 net.cpp:399] accuracy -> accuracy
I0413 17:21:12.195291 28395 net.cpp:141] Setting up accuracy
I0413 17:21:12.195297 28395 net.cpp:148] Top shape: (1)
I0413 17:21:12.195300 28395 net.cpp:156] Memory required for data: 243827604
I0413 17:21:12.195304 28395 layer_factory.hpp:77] Creating layer loss
I0413 17:21:12.195312 28395 net.cpp:91] Creating Layer loss
I0413 17:21:12.195317 28395 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:21:12.195322 28395 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:21:12.195327 28395 net.cpp:399] loss -> loss
I0413 17:21:12.195335 28395 layer_factory.hpp:77] Creating layer loss
I0413 17:21:12.195572 28395 net.cpp:141] Setting up loss
I0413 17:21:12.195605 28395 net.cpp:148] Top shape: (1)
I0413 17:21:12.195611 28395 net.cpp:151]     with loss weight 1
I0413 17:21:12.195619 28395 net.cpp:156] Memory required for data: 243827608
I0413 17:21:12.195624 28395 net.cpp:217] loss needs backward computation.
I0413 17:21:12.195631 28395 net.cpp:219] accuracy does not need backward computation.
I0413 17:21:12.195636 28395 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:21:12.195641 28395 net.cpp:217] ip needs backward computation.
I0413 17:21:12.195646 28395 net.cpp:217] global_pool needs backward computation.
I0413 17:21:12.195649 28395 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:21:12.195654 28395 net.cpp:217] conv2_3 needs backward computation.
I0413 17:21:12.195659 28395 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:21:12.195663 28395 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:21:12.195668 28395 net.cpp:217] conv2_3b needs backward computation.
I0413 17:21:12.195672 28395 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:21:12.195677 28395 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:21:12.195682 28395 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:21:12.195685 28395 net.cpp:217] conv2_3a needs backward computation.
I0413 17:21:12.195690 28395 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:21:12.195694 28395 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:21:12.195699 28395 net.cpp:217] conv2_2 needs backward computation.
I0413 17:21:12.195708 28395 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:21:12.195713 28395 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:21:12.195718 28395 net.cpp:217] conv2_2b needs backward computation.
I0413 17:21:12.195722 28395 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:21:12.195726 28395 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:21:12.195731 28395 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:21:12.195735 28395 net.cpp:217] conv2_2a needs backward computation.
I0413 17:21:12.195739 28395 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:21:12.195744 28395 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:21:12.195749 28395 net.cpp:217] conv2_1 needs backward computation.
I0413 17:21:12.195755 28395 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:21:12.195758 28395 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:21:12.195762 28395 net.cpp:217] conv2_1b needs backward computation.
I0413 17:21:12.195766 28395 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:21:12.195771 28395 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:21:12.195775 28395 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:21:12.195780 28395 net.cpp:217] conv2_1a needs backward computation.
I0413 17:21:12.195785 28395 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:21:12.195788 28395 net.cpp:217] conv1_relu needs backward computation.
I0413 17:21:12.195793 28395 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:21:12.195797 28395 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:21:12.195801 28395 net.cpp:217] conv1 needs backward computation.
I0413 17:21:12.195806 28395 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:21:12.195811 28395 net.cpp:219] cifar does not need backward computation.
I0413 17:21:12.195816 28395 net.cpp:261] This network produces output accuracy
I0413 17:21:12.195822 28395 net.cpp:261] This network produces output loss
I0413 17:21:12.195848 28395 net.cpp:274] Network initialization done.
I0413 17:21:12.195987 28395 solver.cpp:60] Solver scaffolding done.
I0413 17:21:12.447105 28395 solver.cpp:228] Iteration 0, loss = 1.3458
I0413 17:21:12.447162 28395 solver.cpp:244]     Train net output #0: accuracy = 0.542969
I0413 17:21:12.447183 28395 solver.cpp:244]     Train net output #1: loss = 1.3458 (* 1 = 1.3458 loss)
I0413 17:21:12.447207 28395 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 17:21:15.641897 28395 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 17:21:17.545474 28395 solver.cpp:404]     Test net output #0: accuracy = 0.64
I0413 17:21:17.545521 28395 solver.cpp:404]     Test net output #1: loss = 1.32701 (* 1 = 1.32701 loss)
I0413 17:21:17.662317 28395 solver.cpp:228] Iteration 20, loss = 0.821357
I0413 17:21:17.662364 28395 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:21:17.662379 28395 solver.cpp:244]     Train net output #1: loss = 0.821357 (* 1 = 0.821357 loss)
I0413 17:21:17.662389 28395 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 17:21:21.315650 28395 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 17:21:23.182931 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6785
I0413 17:21:23.182983 28395 solver.cpp:404]     Test net output #1: loss = 0.949667 (* 1 = 0.949667 loss)
I0413 17:21:23.283540 28395 solver.cpp:228] Iteration 40, loss = 0.889589
I0413 17:21:23.283591 28395 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:21:23.283625 28395 solver.cpp:244]     Train net output #1: loss = 0.889589 (* 1 = 0.889589 loss)
I0413 17:21:23.283643 28395 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 17:21:26.523291 28395 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 17:21:28.482398 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7112
I0413 17:21:28.482446 28395 solver.cpp:404]     Test net output #1: loss = 0.837887 (* 1 = 0.837887 loss)
I0413 17:21:28.582331 28395 solver.cpp:228] Iteration 60, loss = 0.683981
I0413 17:21:28.582402 28395 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:21:28.582428 28395 solver.cpp:244]     Train net output #1: loss = 0.683981 (* 1 = 0.683981 loss)
I0413 17:21:28.582455 28395 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 17:21:32.226135 28395 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 17:21:34.092023 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0413 17:21:34.092079 28395 solver.cpp:404]     Test net output #1: loss = 0.893557 (* 1 = 0.893557 loss)
I0413 17:21:34.190243 28395 solver.cpp:228] Iteration 80, loss = 0.76524
I0413 17:21:34.190280 28395 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:21:34.190291 28395 solver.cpp:244]     Train net output #1: loss = 0.76524 (* 1 = 0.76524 loss)
I0413 17:21:34.190304 28395 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 17:21:37.477432 28395 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 17:21:39.485426 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6496
I0413 17:21:39.485478 28395 solver.cpp:404]     Test net output #1: loss = 1.09289 (* 1 = 1.09289 loss)
I0413 17:21:39.574129 28395 solver.cpp:228] Iteration 100, loss = 0.780972
I0413 17:21:39.574167 28395 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:21:39.574178 28395 solver.cpp:244]     Train net output #1: loss = 0.780972 (* 1 = 0.780972 loss)
I0413 17:21:39.574189 28395 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 17:21:43.217125 28395 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 17:21:45.003219 28395 solver.cpp:404]     Test net output #0: accuracy = 0.5941
I0413 17:21:45.003278 28395 solver.cpp:404]     Test net output #1: loss = 1.27075 (* 1 = 1.27075 loss)
I0413 17:21:45.094336 28395 solver.cpp:228] Iteration 120, loss = 0.711475
I0413 17:21:45.094354 28395 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:21:45.094364 28395 solver.cpp:244]     Train net output #1: loss = 0.711475 (* 1 = 0.711475 loss)
I0413 17:21:45.094375 28395 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 17:21:48.473345 28395 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 17:21:50.460304 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6618
I0413 17:21:50.460402 28395 solver.cpp:404]     Test net output #1: loss = 1.01467 (* 1 = 1.01467 loss)
I0413 17:21:50.572412 28395 solver.cpp:228] Iteration 140, loss = 0.709929
I0413 17:21:50.572432 28395 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:21:50.572443 28395 solver.cpp:244]     Train net output #1: loss = 0.709929 (* 1 = 0.709929 loss)
I0413 17:21:50.572453 28395 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 17:21:54.213608 28395 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 17:21:55.880265 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6524
I0413 17:21:55.880311 28395 solver.cpp:404]     Test net output #1: loss = 1.03173 (* 1 = 1.03173 loss)
I0413 17:21:55.978978 28395 solver.cpp:228] Iteration 160, loss = 0.704231
I0413 17:21:55.979008 28395 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:21:55.979018 28395 solver.cpp:244]     Train net output #1: loss = 0.704231 (* 1 = 0.704231 loss)
I0413 17:21:55.979027 28395 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 17:21:59.420265 28395 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 17:22:01.360605 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6579
I0413 17:22:01.360656 28395 solver.cpp:404]     Test net output #1: loss = 0.997226 (* 1 = 0.997226 loss)
I0413 17:22:01.477386 28395 solver.cpp:228] Iteration 180, loss = 0.778032
I0413 17:22:01.477432 28395 solver.cpp:244]     Train net output #0: accuracy = 0.710938
I0413 17:22:01.477444 28395 solver.cpp:244]     Train net output #1: loss = 0.778032 (* 1 = 0.778032 loss)
I0413 17:22:01.477457 28395 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 17:22:05.055541 28395 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 17:22:06.763095 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6917
I0413 17:22:06.763131 28395 solver.cpp:404]     Test net output #1: loss = 0.930147 (* 1 = 0.930147 loss)
I0413 17:22:06.858896 28395 solver.cpp:228] Iteration 200, loss = 0.72883
I0413 17:22:06.858914 28395 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:22:06.858922 28395 solver.cpp:244]     Train net output #1: loss = 0.72883 (* 1 = 0.72883 loss)
I0413 17:22:06.858930 28395 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 17:22:10.390223 28395 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 17:22:12.334764 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7013
I0413 17:22:12.334808 28395 solver.cpp:404]     Test net output #1: loss = 0.903831 (* 1 = 0.903831 loss)
I0413 17:22:12.449826 28395 solver.cpp:228] Iteration 220, loss = 0.677129
I0413 17:22:12.449848 28395 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:22:12.449857 28395 solver.cpp:244]     Train net output #1: loss = 0.677129 (* 1 = 0.677129 loss)
I0413 17:22:12.449870 28395 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 17:22:15.938016 28395 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 17:22:17.649349 28395 solver.cpp:404]     Test net output #0: accuracy = 0.71
I0413 17:22:17.649389 28395 solver.cpp:404]     Test net output #1: loss = 0.853269 (* 1 = 0.853269 loss)
I0413 17:22:17.749336 28395 solver.cpp:228] Iteration 240, loss = 0.624161
I0413 17:22:17.749377 28395 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:22:17.749387 28395 solver.cpp:244]     Train net output #1: loss = 0.624161 (* 1 = 0.624161 loss)
I0413 17:22:17.749397 28395 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 17:22:21.378784 28395 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 17:22:23.347275 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6723
I0413 17:22:23.347318 28395 solver.cpp:404]     Test net output #1: loss = 0.975685 (* 1 = 0.975685 loss)
I0413 17:22:23.456627 28395 solver.cpp:228] Iteration 260, loss = 0.774957
I0413 17:22:23.456645 28395 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:22:23.456655 28395 solver.cpp:244]     Train net output #1: loss = 0.774957 (* 1 = 0.774957 loss)
I0413 17:22:23.456662 28395 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 17:22:26.871963 28395 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 17:22:28.643357 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6857
I0413 17:22:28.643390 28395 solver.cpp:404]     Test net output #1: loss = 0.941587 (* 1 = 0.941587 loss)
I0413 17:22:28.729503 28395 solver.cpp:228] Iteration 280, loss = 0.882811
I0413 17:22:28.729581 28395 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 17:22:28.729622 28395 solver.cpp:244]     Train net output #1: loss = 0.882811 (* 1 = 0.882811 loss)
I0413 17:22:28.729635 28395 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 17:22:32.360772 28395 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 17:22:34.328225 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7006
I0413 17:22:34.328284 28395 solver.cpp:404]     Test net output #1: loss = 0.90279 (* 1 = 0.90279 loss)
I0413 17:22:34.430943 28395 solver.cpp:228] Iteration 300, loss = 0.81576
I0413 17:22:34.430960 28395 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:22:34.430969 28395 solver.cpp:244]     Train net output #1: loss = 0.81576 (* 1 = 0.81576 loss)
I0413 17:22:34.430977 28395 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 17:22:37.775162 28395 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 17:22:39.615870 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6838
I0413 17:22:39.615906 28395 solver.cpp:404]     Test net output #1: loss = 0.96726 (* 1 = 0.96726 loss)
I0413 17:22:39.725359 28395 solver.cpp:228] Iteration 320, loss = 0.733026
I0413 17:22:39.725419 28395 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:22:39.725432 28395 solver.cpp:244]     Train net output #1: loss = 0.733026 (* 1 = 0.733026 loss)
I0413 17:22:39.725463 28395 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 17:22:43.362946 28395 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 17:22:45.348467 28395 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0413 17:22:45.348505 28395 solver.cpp:404]     Test net output #1: loss = 1.0145 (* 1 = 1.0145 loss)
I0413 17:22:45.452253 28395 solver.cpp:228] Iteration 340, loss = 0.715416
I0413 17:22:45.452296 28395 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:22:45.452306 28395 solver.cpp:244]     Train net output #1: loss = 0.715416 (* 1 = 0.715416 loss)
I0413 17:22:45.452316 28395 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 17:22:48.698540 28395 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 17:22:50.584332 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6363
I0413 17:22:50.584370 28395 solver.cpp:404]     Test net output #1: loss = 1.10167 (* 1 = 1.10167 loss)
I0413 17:22:50.703223 28395 solver.cpp:228] Iteration 360, loss = 0.638109
I0413 17:22:50.703264 28395 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:22:50.703276 28395 solver.cpp:244]     Train net output #1: loss = 0.638109 (* 1 = 0.638109 loss)
I0413 17:22:50.703285 28395 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 17:22:54.328536 28395 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 17:22:56.258025 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6757
I0413 17:22:56.258069 28395 solver.cpp:404]     Test net output #1: loss = 0.964049 (* 1 = 0.964049 loss)
I0413 17:22:56.349431 28395 solver.cpp:228] Iteration 380, loss = 0.775049
I0413 17:22:56.349474 28395 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:22:56.349486 28395 solver.cpp:244]     Train net output #1: loss = 0.775049 (* 1 = 0.775049 loss)
I0413 17:22:56.349496 28395 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 17:22:59.594967 28395 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 17:23:01.555766 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6847
I0413 17:23:01.555814 28395 solver.cpp:404]     Test net output #1: loss = 0.961675 (* 1 = 0.961675 loss)
I0413 17:23:01.673245 28395 solver.cpp:228] Iteration 400, loss = 0.594701
I0413 17:23:01.673286 28395 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:23:01.673300 28395 solver.cpp:244]     Train net output #1: loss = 0.594701 (* 1 = 0.594701 loss)
I0413 17:23:01.673308 28395 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 17:23:05.327795 28395 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 17:23:07.155052 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6589
I0413 17:23:07.155099 28395 solver.cpp:404]     Test net output #1: loss = 1.04194 (* 1 = 1.04194 loss)
I0413 17:23:07.252835 28395 solver.cpp:228] Iteration 420, loss = 0.732745
I0413 17:23:07.252872 28395 solver.cpp:244]     Train net output #0: accuracy = 0.707031
I0413 17:23:07.252884 28395 solver.cpp:244]     Train net output #1: loss = 0.732745 (* 1 = 0.732745 loss)
I0413 17:23:07.252892 28395 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 17:23:10.567059 28395 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 17:23:12.547827 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6758
I0413 17:23:12.547878 28395 solver.cpp:404]     Test net output #1: loss = 1.04655 (* 1 = 1.04655 loss)
I0413 17:23:12.650825 28395 solver.cpp:228] Iteration 440, loss = 0.681685
I0413 17:23:12.650852 28395 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:23:12.650862 28395 solver.cpp:244]     Train net output #1: loss = 0.681685 (* 1 = 0.681685 loss)
I0413 17:23:12.650873 28395 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 17:23:16.304072 28395 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 17:23:18.084128 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7051
I0413 17:23:18.084167 28395 solver.cpp:404]     Test net output #1: loss = 0.879247 (* 1 = 0.879247 loss)
I0413 17:23:18.174407 28395 solver.cpp:228] Iteration 460, loss = 0.654165
I0413 17:23:18.174458 28395 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:23:18.174471 28395 solver.cpp:244]     Train net output #1: loss = 0.654165 (* 1 = 0.654165 loss)
I0413 17:23:18.174480 28395 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 17:23:21.544148 28395 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 17:23:23.544646 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6788
I0413 17:23:23.544688 28395 solver.cpp:404]     Test net output #1: loss = 0.953985 (* 1 = 0.953985 loss)
I0413 17:23:23.637769 28395 solver.cpp:228] Iteration 480, loss = 0.673954
I0413 17:23:23.637838 28395 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:23:23.637872 28395 solver.cpp:244]     Train net output #1: loss = 0.673954 (* 1 = 0.673954 loss)
I0413 17:23:23.637892 28395 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 17:23:27.283645 28395 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 17:23:28.987123 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6781
I0413 17:23:28.987169 28395 solver.cpp:404]     Test net output #1: loss = 1.04216 (* 1 = 1.04216 loss)
I0413 17:23:29.077679 28395 solver.cpp:228] Iteration 500, loss = 0.664215
I0413 17:23:29.077718 28395 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:23:29.077730 28395 solver.cpp:244]     Train net output #1: loss = 0.664215 (* 1 = 0.664215 loss)
I0413 17:23:29.077739 28395 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 17:23:32.547380 28395 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 17:23:34.563942 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6111
I0413 17:23:34.563983 28395 solver.cpp:404]     Test net output #1: loss = 1.19243 (* 1 = 1.19243 loss)
I0413 17:23:34.648852 28395 solver.cpp:228] Iteration 520, loss = 0.713334
I0413 17:23:34.648893 28395 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:23:34.648905 28395 solver.cpp:244]     Train net output #1: loss = 0.713334 (* 1 = 0.713334 loss)
I0413 17:23:34.648916 28395 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 17:23:38.194336 28395 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 17:23:39.905441 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6442
I0413 17:23:39.905477 28395 solver.cpp:404]     Test net output #1: loss = 1.05574 (* 1 = 1.05574 loss)
I0413 17:23:39.995762 28395 solver.cpp:228] Iteration 540, loss = 0.749024
I0413 17:23:39.995803 28395 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:23:39.995815 28395 solver.cpp:244]     Train net output #1: loss = 0.749024 (* 1 = 0.749024 loss)
I0413 17:23:39.995825 28395 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 17:23:43.540067 28395 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 17:23:45.542230 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6557
I0413 17:23:45.542270 28395 solver.cpp:404]     Test net output #1: loss = 1.02359 (* 1 = 1.02359 loss)
I0413 17:23:45.637557 28395 solver.cpp:228] Iteration 560, loss = 0.721125
I0413 17:23:45.637620 28395 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:23:45.637631 28395 solver.cpp:244]     Train net output #1: loss = 0.721125 (* 1 = 0.721125 loss)
I0413 17:23:45.637646 28395 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 17:23:49.125461 28395 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 17:23:50.824496 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7011
I0413 17:23:50.824534 28395 solver.cpp:404]     Test net output #1: loss = 0.865845 (* 1 = 0.865845 loss)
I0413 17:23:50.923007 28395 solver.cpp:228] Iteration 580, loss = 0.707721
I0413 17:23:50.923061 28395 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:23:50.923077 28395 solver.cpp:244]     Train net output #1: loss = 0.707721 (* 1 = 0.707721 loss)
I0413 17:23:50.923087 28395 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 17:23:54.557328 28395 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 17:23:56.536762 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6467
I0413 17:23:56.536798 28395 solver.cpp:404]     Test net output #1: loss = 1.25213 (* 1 = 1.25213 loss)
I0413 17:23:56.657558 28395 solver.cpp:228] Iteration 600, loss = 0.637814
I0413 17:23:56.657608 28395 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:23:56.657619 28395 solver.cpp:244]     Train net output #1: loss = 0.637814 (* 1 = 0.637814 loss)
I0413 17:23:56.657629 28395 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 17:24:00.033182 28395 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 17:24:01.801043 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7041
I0413 17:24:01.801096 28395 solver.cpp:404]     Test net output #1: loss = 0.920688 (* 1 = 0.920688 loss)
I0413 17:24:01.917672 28395 solver.cpp:228] Iteration 620, loss = 0.760171
I0413 17:24:01.917737 28395 solver.cpp:244]     Train net output #0: accuracy = 0.710938
I0413 17:24:01.917753 28395 solver.cpp:244]     Train net output #1: loss = 0.760171 (* 1 = 0.760171 loss)
I0413 17:24:01.917768 28395 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 17:24:05.565717 28395 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 17:24:07.540081 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6746
I0413 17:24:07.540118 28395 solver.cpp:404]     Test net output #1: loss = 1.0552 (* 1 = 1.0552 loss)
I0413 17:24:07.657277 28395 solver.cpp:228] Iteration 640, loss = 0.729572
I0413 17:24:07.657315 28395 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:24:07.657327 28395 solver.cpp:244]     Train net output #1: loss = 0.729572 (* 1 = 0.729572 loss)
I0413 17:24:07.657336 28395 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 17:24:10.947430 28395 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 17:24:12.780315 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6688
I0413 17:24:12.780359 28395 solver.cpp:404]     Test net output #1: loss = 1.01006 (* 1 = 1.01006 loss)
I0413 17:24:12.882251 28395 solver.cpp:228] Iteration 660, loss = 0.738076
I0413 17:24:12.882288 28395 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:24:12.882300 28395 solver.cpp:244]     Train net output #1: loss = 0.738076 (* 1 = 0.738076 loss)
I0413 17:24:12.882313 28395 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 17:24:16.575848 28395 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 17:24:18.518406 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7048
I0413 17:24:18.518447 28395 solver.cpp:404]     Test net output #1: loss = 0.875272 (* 1 = 0.875272 loss)
I0413 17:24:18.636308 28395 solver.cpp:228] Iteration 680, loss = 0.573217
I0413 17:24:18.636366 28395 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:24:18.636379 28395 solver.cpp:244]     Train net output #1: loss = 0.573217 (* 1 = 0.573217 loss)
I0413 17:24:18.636389 28395 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 17:24:21.871351 28395 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 17:24:23.810377 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6801
I0413 17:24:23.810421 28395 solver.cpp:404]     Test net output #1: loss = 1.00531 (* 1 = 1.00531 loss)
I0413 17:24:23.903637 28395 solver.cpp:228] Iteration 700, loss = 0.627952
I0413 17:24:23.903699 28395 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:24:23.903712 28395 solver.cpp:244]     Train net output #1: loss = 0.627952 (* 1 = 0.627952 loss)
I0413 17:24:23.903728 28395 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 17:24:27.547931 28395 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 17:24:29.440778 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6716
I0413 17:24:29.440845 28395 solver.cpp:404]     Test net output #1: loss = 1.02415 (* 1 = 1.02415 loss)
I0413 17:24:29.541424 28395 solver.cpp:228] Iteration 720, loss = 0.683213
I0413 17:24:29.541476 28395 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:24:29.541488 28395 solver.cpp:244]     Train net output #1: loss = 0.683213 (* 1 = 0.683213 loss)
I0413 17:24:29.541498 28395 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 17:24:32.764708 28395 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 17:24:34.740334 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6692
I0413 17:24:34.740370 28395 solver.cpp:404]     Test net output #1: loss = 1.00109 (* 1 = 1.00109 loss)
I0413 17:24:34.858532 28395 solver.cpp:228] Iteration 740, loss = 0.695412
I0413 17:24:34.858585 28395 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:24:34.858598 28395 solver.cpp:244]     Train net output #1: loss = 0.695412 (* 1 = 0.695412 loss)
I0413 17:24:34.858608 28395 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 17:24:38.512356 28395 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 17:24:40.355986 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6789
I0413 17:24:40.356026 28395 solver.cpp:404]     Test net output #1: loss = 0.94862 (* 1 = 0.94862 loss)
I0413 17:24:40.446604 28395 solver.cpp:228] Iteration 760, loss = 0.697293
I0413 17:24:40.446667 28395 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:24:40.446687 28395 solver.cpp:244]     Train net output #1: loss = 0.697293 (* 1 = 0.697293 loss)
I0413 17:24:40.446696 28395 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 17:24:43.780367 28395 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 17:24:45.738158 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7321
I0413 17:24:45.738193 28395 solver.cpp:404]     Test net output #1: loss = 0.790492 (* 1 = 0.790492 loss)
I0413 17:24:45.855305 28395 solver.cpp:228] Iteration 780, loss = 0.630332
I0413 17:24:45.855346 28395 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:24:45.855358 28395 solver.cpp:244]     Train net output #1: loss = 0.630332 (* 1 = 0.630332 loss)
I0413 17:24:45.855370 28395 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 17:24:49.492801 28395 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 17:24:51.257429 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7265
I0413 17:24:51.257477 28395 solver.cpp:404]     Test net output #1: loss = 0.806104 (* 1 = 0.806104 loss)
I0413 17:24:51.353775 28395 solver.cpp:228] Iteration 800, loss = 0.762352
I0413 17:24:51.353814 28395 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:24:51.353826 28395 solver.cpp:244]     Train net output #1: loss = 0.762352 (* 1 = 0.762352 loss)
I0413 17:24:51.353837 28395 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 17:24:54.762799 28395 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 17:24:56.705025 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6945
I0413 17:24:56.705066 28395 solver.cpp:404]     Test net output #1: loss = 0.910809 (* 1 = 0.910809 loss)
I0413 17:24:56.822903 28395 solver.cpp:228] Iteration 820, loss = 0.709825
I0413 17:24:56.822943 28395 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:24:56.822955 28395 solver.cpp:244]     Train net output #1: loss = 0.709825 (* 1 = 0.709825 loss)
I0413 17:24:56.822964 28395 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 17:25:00.472311 28395 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 17:25:02.132247 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7209
I0413 17:25:02.132297 28395 solver.cpp:404]     Test net output #1: loss = 0.8185 (* 1 = 0.8185 loss)
I0413 17:25:02.228853 28395 solver.cpp:228] Iteration 840, loss = 0.623331
I0413 17:25:02.228873 28395 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:25:02.228883 28395 solver.cpp:244]     Train net output #1: loss = 0.623331 (* 1 = 0.623331 loss)
I0413 17:25:02.228893 28395 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 17:25:05.715912 28395 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 17:25:07.706898 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7162
I0413 17:25:07.706943 28395 solver.cpp:404]     Test net output #1: loss = 0.844116 (* 1 = 0.844116 loss)
I0413 17:25:07.817405 28395 solver.cpp:228] Iteration 860, loss = 0.775294
I0413 17:25:07.817457 28395 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:25:07.817469 28395 solver.cpp:244]     Train net output #1: loss = 0.775294 (* 1 = 0.775294 loss)
I0413 17:25:07.817486 28395 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 17:25:11.373013 28395 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 17:25:13.089010 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7085
I0413 17:25:13.089087 28395 solver.cpp:404]     Test net output #1: loss = 0.884615 (* 1 = 0.884615 loss)
I0413 17:25:13.182255 28395 solver.cpp:228] Iteration 880, loss = 0.653587
I0413 17:25:13.182291 28395 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:25:13.182302 28395 solver.cpp:244]     Train net output #1: loss = 0.653587 (* 1 = 0.653587 loss)
I0413 17:25:13.182312 28395 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 17:25:16.739348 28395 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 17:25:18.723018 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6746
I0413 17:25:18.723053 28395 solver.cpp:404]     Test net output #1: loss = 1.02381 (* 1 = 1.02381 loss)
I0413 17:25:18.835744 28395 solver.cpp:228] Iteration 900, loss = 0.710529
I0413 17:25:18.835800 28395 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:25:18.835811 28395 solver.cpp:244]     Train net output #1: loss = 0.710529 (* 1 = 0.710529 loss)
I0413 17:25:18.835820 28395 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 17:25:22.283409 28395 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 17:25:23.995118 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7147
I0413 17:25:23.995157 28395 solver.cpp:404]     Test net output #1: loss = 0.844934 (* 1 = 0.844934 loss)
I0413 17:25:24.085258 28395 solver.cpp:228] Iteration 920, loss = 0.638196
I0413 17:25:24.085309 28395 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:25:24.085322 28395 solver.cpp:244]     Train net output #1: loss = 0.638196 (* 1 = 0.638196 loss)
I0413 17:25:24.085333 28395 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 17:25:27.729843 28395 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 17:25:29.706217 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6963
I0413 17:25:29.706264 28395 solver.cpp:404]     Test net output #1: loss = 0.930922 (* 1 = 0.930922 loss)
I0413 17:25:29.809219 28395 solver.cpp:228] Iteration 940, loss = 0.655767
I0413 17:25:29.809262 28395 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:25:29.809276 28395 solver.cpp:244]     Train net output #1: loss = 0.655767 (* 1 = 0.655767 loss)
I0413 17:25:29.809310 28395 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 17:25:33.204900 28395 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 17:25:34.982004 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6941
I0413 17:25:34.982048 28395 solver.cpp:404]     Test net output #1: loss = 0.915625 (* 1 = 0.915625 loss)
I0413 17:25:35.096889 28395 solver.cpp:228] Iteration 960, loss = 0.580674
I0413 17:25:35.096927 28395 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:25:35.096940 28395 solver.cpp:244]     Train net output #1: loss = 0.580674 (* 1 = 0.580674 loss)
I0413 17:25:35.096949 28395 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 17:25:38.715221 28395 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 17:25:40.716210 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6836
I0413 17:25:40.716302 28395 solver.cpp:404]     Test net output #1: loss = 1.01721 (* 1 = 1.01721 loss)
I0413 17:25:40.806929 28395 solver.cpp:228] Iteration 980, loss = 0.621754
I0413 17:25:40.806967 28395 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:25:40.806978 28395 solver.cpp:244]     Train net output #1: loss = 0.621754 (* 1 = 0.621754 loss)
I0413 17:25:40.806988 28395 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 17:25:44.105101 28395 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 17:25:45.960641 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7067
I0413 17:25:45.960683 28395 solver.cpp:404]     Test net output #1: loss = 0.913168 (* 1 = 0.913168 loss)
I0413 17:25:46.079700 28395 solver.cpp:228] Iteration 1000, loss = 0.708148
I0413 17:25:46.079728 28395 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:25:46.079738 28395 solver.cpp:244]     Train net output #1: loss = 0.708148 (* 1 = 0.708148 loss)
I0413 17:25:46.079747 28395 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 17:25:49.722084 28395 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 17:25:51.736866 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6636
I0413 17:25:51.736906 28395 solver.cpp:404]     Test net output #1: loss = 1.06693 (* 1 = 1.06693 loss)
I0413 17:25:51.806020 28395 solver.cpp:228] Iteration 1020, loss = 0.693521
I0413 17:25:51.806062 28395 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:25:51.806074 28395 solver.cpp:244]     Train net output #1: loss = 0.693521 (* 1 = 0.693521 loss)
I0413 17:25:51.806084 28395 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 17:25:55.054019 28395 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 17:25:56.995934 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7011
I0413 17:25:56.995977 28395 solver.cpp:404]     Test net output #1: loss = 0.871127 (* 1 = 0.871127 loss)
I0413 17:25:57.119668 28395 solver.cpp:228] Iteration 1040, loss = 0.623246
I0413 17:25:57.119707 28395 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:25:57.119719 28395 solver.cpp:244]     Train net output #1: loss = 0.623246 (* 1 = 0.623246 loss)
I0413 17:25:57.119730 28395 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 17:26:00.755476 28395 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 17:26:02.629936 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6695
I0413 17:26:02.629973 28395 solver.cpp:404]     Test net output #1: loss = 1.00522 (* 1 = 1.00522 loss)
I0413 17:26:02.729306 28395 solver.cpp:228] Iteration 1060, loss = 0.740381
I0413 17:26:02.729368 28395 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:26:02.729390 28395 solver.cpp:244]     Train net output #1: loss = 0.740381 (* 1 = 0.740381 loss)
I0413 17:26:02.729404 28395 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 17:26:06.034723 28395 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 17:26:07.998137 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6091
I0413 17:26:07.998183 28395 solver.cpp:404]     Test net output #1: loss = 1.32868 (* 1 = 1.32868 loss)
I0413 17:26:08.118228 28395 solver.cpp:228] Iteration 1080, loss = 0.760453
I0413 17:26:08.118290 28395 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:26:08.118305 28395 solver.cpp:244]     Train net output #1: loss = 0.760453 (* 1 = 0.760453 loss)
I0413 17:26:08.118316 28395 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 17:26:11.744182 28395 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 17:26:13.532595 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6904
I0413 17:26:13.532665 28395 solver.cpp:404]     Test net output #1: loss = 0.934601 (* 1 = 0.934601 loss)
I0413 17:26:13.623703 28395 solver.cpp:228] Iteration 1100, loss = 0.620169
I0413 17:26:13.623745 28395 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:26:13.623757 28395 solver.cpp:244]     Train net output #1: loss = 0.620169 (* 1 = 0.620169 loss)
I0413 17:26:13.623769 28395 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 17:26:16.991971 28395 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 17:26:18.983603 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6881
I0413 17:26:18.983644 28395 solver.cpp:404]     Test net output #1: loss = 0.956214 (* 1 = 0.956214 loss)
I0413 17:26:19.099675 28395 solver.cpp:228] Iteration 1120, loss = 0.7976
I0413 17:26:19.099719 28395 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:26:19.099730 28395 solver.cpp:244]     Train net output #1: loss = 0.7976 (* 1 = 0.7976 loss)
I0413 17:26:19.099740 28395 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 17:26:22.739354 28395 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 17:26:24.431288 28395 solver.cpp:404]     Test net output #0: accuracy = 0.625
I0413 17:26:24.431334 28395 solver.cpp:404]     Test net output #1: loss = 1.14592 (* 1 = 1.14592 loss)
I0413 17:26:24.527686 28395 solver.cpp:228] Iteration 1140, loss = 0.836808
I0413 17:26:24.527704 28395 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:26:24.527712 28395 solver.cpp:244]     Train net output #1: loss = 0.836808 (* 1 = 0.836808 loss)
I0413 17:26:24.527721 28395 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 17:26:27.975644 28395 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 17:26:29.965957 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6891
I0413 17:26:29.966004 28395 solver.cpp:404]     Test net output #1: loss = 0.953518 (* 1 = 0.953518 loss)
I0413 17:26:30.075295 28395 solver.cpp:228] Iteration 1160, loss = 0.670221
I0413 17:26:30.075335 28395 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:26:30.075345 28395 solver.cpp:244]     Train net output #1: loss = 0.670221 (* 1 = 0.670221 loss)
I0413 17:26:30.075355 28395 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 17:26:33.668236 28395 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 17:26:35.378573 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6497
I0413 17:26:35.378608 28395 solver.cpp:404]     Test net output #1: loss = 1.10892 (* 1 = 1.10892 loss)
I0413 17:26:35.477442 28395 solver.cpp:228] Iteration 1180, loss = 0.640483
I0413 17:26:35.477491 28395 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:26:35.477504 28395 solver.cpp:244]     Train net output #1: loss = 0.640483 (* 1 = 0.640483 loss)
I0413 17:26:35.477512 28395 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 17:26:38.972699 28395 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 17:26:40.948726 28395 solver.cpp:404]     Test net output #0: accuracy = 0.636
I0413 17:26:40.948765 28395 solver.cpp:404]     Test net output #1: loss = 1.22559 (* 1 = 1.22559 loss)
I0413 17:26:41.032579 28395 solver.cpp:228] Iteration 1200, loss = 0.712116
I0413 17:26:41.032616 28395 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:26:41.032629 28395 solver.cpp:244]     Train net output #1: loss = 0.712116 (* 1 = 0.712116 loss)
I0413 17:26:41.032636 28395 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 17:26:44.552526 28395 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 17:26:46.246742 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7083
I0413 17:26:46.246784 28395 solver.cpp:404]     Test net output #1: loss = 0.900378 (* 1 = 0.900378 loss)
I0413 17:26:46.337937 28395 solver.cpp:228] Iteration 1220, loss = 0.721818
I0413 17:26:46.337976 28395 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:26:46.337987 28395 solver.cpp:244]     Train net output #1: loss = 0.721818 (* 1 = 0.721818 loss)
I0413 17:26:46.337996 28395 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 17:26:49.920119 28395 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 17:26:51.893818 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7116
I0413 17:26:51.893857 28395 solver.cpp:404]     Test net output #1: loss = 0.861254 (* 1 = 0.861254 loss)
I0413 17:26:52.016834 28395 solver.cpp:228] Iteration 1240, loss = 0.629682
I0413 17:26:52.016876 28395 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:26:52.016887 28395 solver.cpp:244]     Train net output #1: loss = 0.629682 (* 1 = 0.629682 loss)
I0413 17:26:52.016896 28395 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 17:26:55.421972 28395 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 17:26:57.134296 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7178
I0413 17:26:57.134335 28395 solver.cpp:404]     Test net output #1: loss = 0.844188 (* 1 = 0.844188 loss)
I0413 17:26:57.241641 28395 solver.cpp:228] Iteration 1260, loss = 0.65086
I0413 17:26:57.241682 28395 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:26:57.241693 28395 solver.cpp:244]     Train net output #1: loss = 0.65086 (* 1 = 0.65086 loss)
I0413 17:26:57.241711 28395 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 17:27:00.923990 28395 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 17:27:02.895701 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6846
I0413 17:27:02.895740 28395 solver.cpp:404]     Test net output #1: loss = 0.976445 (* 1 = 0.976445 loss)
I0413 17:27:03.015780 28395 solver.cpp:228] Iteration 1280, loss = 0.661954
I0413 17:27:03.015835 28395 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:27:03.015846 28395 solver.cpp:244]     Train net output #1: loss = 0.661954 (* 1 = 0.661954 loss)
I0413 17:27:03.015856 28395 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 17:27:06.365814 28395 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 17:27:08.172410 28395 solver.cpp:404]     Test net output #0: accuracy = 0.633
I0413 17:27:08.172453 28395 solver.cpp:404]     Test net output #1: loss = 1.14931 (* 1 = 1.14931 loss)
I0413 17:27:08.278460 28395 solver.cpp:228] Iteration 1300, loss = 0.761951
I0413 17:27:08.278502 28395 solver.cpp:244]     Train net output #0: accuracy = 0.699219
I0413 17:27:08.278514 28395 solver.cpp:244]     Train net output #1: loss = 0.761951 (* 1 = 0.761951 loss)
I0413 17:27:08.278524 28395 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 17:27:11.935248 28395 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 17:27:13.865685 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6841
I0413 17:27:13.865741 28395 solver.cpp:404]     Test net output #1: loss = 0.947452 (* 1 = 0.947452 loss)
I0413 17:27:13.984941 28395 solver.cpp:228] Iteration 1320, loss = 0.793929
I0413 17:27:13.984959 28395 solver.cpp:244]     Train net output #0: accuracy = 0.710938
I0413 17:27:13.984968 28395 solver.cpp:244]     Train net output #1: loss = 0.793929 (* 1 = 0.793929 loss)
I0413 17:27:13.984978 28395 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 17:27:17.268210 28395 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 17:27:19.146718 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6523
I0413 17:27:19.146754 28395 solver.cpp:404]     Test net output #1: loss = 1.03518 (* 1 = 1.03518 loss)
I0413 17:27:19.239845 28395 solver.cpp:228] Iteration 1340, loss = 0.73661
I0413 17:27:19.239886 28395 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:27:19.239898 28395 solver.cpp:244]     Train net output #1: loss = 0.73661 (* 1 = 0.73661 loss)
I0413 17:27:19.239907 28395 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 17:27:22.890678 28395 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 17:27:24.837846 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7346
I0413 17:27:24.837883 28395 solver.cpp:404]     Test net output #1: loss = 0.803302 (* 1 = 0.803302 loss)
I0413 17:27:24.934473 28395 solver.cpp:228] Iteration 1360, loss = 0.633434
I0413 17:27:24.934510 28395 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:27:24.934522 28395 solver.cpp:244]     Train net output #1: loss = 0.633434 (* 1 = 0.633434 loss)
I0413 17:27:24.934531 28395 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 17:27:28.178465 28395 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 17:27:30.137329 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6719
I0413 17:27:30.137375 28395 solver.cpp:404]     Test net output #1: loss = 1.10587 (* 1 = 1.10587 loss)
I0413 17:27:30.232493 28395 solver.cpp:228] Iteration 1380, loss = 0.77536
I0413 17:27:30.232535 28395 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:27:30.232547 28395 solver.cpp:244]     Train net output #1: loss = 0.77536 (* 1 = 0.77536 loss)
I0413 17:27:30.232555 28395 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 17:27:33.885602 28395 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 17:27:35.751188 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6502
I0413 17:27:35.751248 28395 solver.cpp:404]     Test net output #1: loss = 1.09703 (* 1 = 1.09703 loss)
I0413 17:27:35.850448 28395 solver.cpp:228] Iteration 1400, loss = 0.759948
I0413 17:27:35.850493 28395 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:27:35.850504 28395 solver.cpp:244]     Train net output #1: loss = 0.759948 (* 1 = 0.759948 loss)
I0413 17:27:35.850513 28395 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 17:27:39.149238 28395 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 17:27:41.107251 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7245
I0413 17:27:41.107290 28395 solver.cpp:404]     Test net output #1: loss = 0.868895 (* 1 = 0.868895 loss)
I0413 17:27:41.225504 28395 solver.cpp:228] Iteration 1420, loss = 0.81385
I0413 17:27:41.225561 28395 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:27:41.225574 28395 solver.cpp:244]     Train net output #1: loss = 0.81385 (* 1 = 0.81385 loss)
I0413 17:27:41.225582 28395 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 17:27:44.856580 28395 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 17:27:46.654952 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6683
I0413 17:27:46.654997 28395 solver.cpp:404]     Test net output #1: loss = 1.04292 (* 1 = 1.04292 loss)
I0413 17:27:46.758764 28395 solver.cpp:228] Iteration 1440, loss = 0.731671
I0413 17:27:46.758806 28395 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:27:46.758818 28395 solver.cpp:244]     Train net output #1: loss = 0.731671 (* 1 = 0.731671 loss)
I0413 17:27:46.758828 28395 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 17:27:50.135092 28395 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 17:27:52.093816 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6957
I0413 17:27:52.093878 28395 solver.cpp:404]     Test net output #1: loss = 0.936773 (* 1 = 0.936773 loss)
I0413 17:27:52.214053 28395 solver.cpp:228] Iteration 1460, loss = 0.608761
I0413 17:27:52.214118 28395 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:27:52.214139 28395 solver.cpp:244]     Train net output #1: loss = 0.608761 (* 1 = 0.608761 loss)
I0413 17:27:52.214155 28395 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 17:27:55.841691 28395 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 17:27:57.548826 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7241
I0413 17:27:57.548933 28395 solver.cpp:404]     Test net output #1: loss = 0.839936 (* 1 = 0.839936 loss)
I0413 17:27:57.648995 28395 solver.cpp:228] Iteration 1480, loss = 0.607296
I0413 17:27:57.649032 28395 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:27:57.649044 28395 solver.cpp:244]     Train net output #1: loss = 0.607296 (* 1 = 0.607296 loss)
I0413 17:27:57.649055 28395 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 17:28:01.086581 28395 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 17:28:03.042376 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6233
I0413 17:28:03.042414 28395 solver.cpp:404]     Test net output #1: loss = 1.21147 (* 1 = 1.21147 loss)
I0413 17:28:03.143316 28395 solver.cpp:228] Iteration 1500, loss = 0.639246
I0413 17:28:03.143381 28395 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:28:03.143399 28395 solver.cpp:244]     Train net output #1: loss = 0.639246 (* 1 = 0.639246 loss)
I0413 17:28:03.143409 28395 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 17:28:06.756055 28395 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 17:28:08.463773 28395 solver.cpp:404]     Test net output #0: accuracy = 0.5926
I0413 17:28:08.463807 28395 solver.cpp:404]     Test net output #1: loss = 1.31162 (* 1 = 1.31162 loss)
I0413 17:28:08.563719 28395 solver.cpp:228] Iteration 1520, loss = 0.620625
I0413 17:28:08.563758 28395 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:28:08.563771 28395 solver.cpp:244]     Train net output #1: loss = 0.620625 (* 1 = 0.620625 loss)
I0413 17:28:08.563779 28395 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 17:28:12.087913 28395 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 17:28:14.062336 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6582
I0413 17:28:14.062438 28395 solver.cpp:404]     Test net output #1: loss = 1.02426 (* 1 = 1.02426 loss)
I0413 17:28:14.167311 28395 solver.cpp:228] Iteration 1540, loss = 0.689712
I0413 17:28:14.167346 28395 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:28:14.167357 28395 solver.cpp:244]     Train net output #1: loss = 0.689712 (* 1 = 0.689712 loss)
I0413 17:28:14.167366 28395 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 17:28:17.679947 28395 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 17:28:19.371171 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6904
I0413 17:28:19.371212 28395 solver.cpp:404]     Test net output #1: loss = 0.957596 (* 1 = 0.957596 loss)
I0413 17:28:19.471547 28395 solver.cpp:228] Iteration 1560, loss = 0.793105
I0413 17:28:19.471596 28395 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:28:19.471612 28395 solver.cpp:244]     Train net output #1: loss = 0.793105 (* 1 = 0.793105 loss)
I0413 17:28:19.471622 28395 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 17:28:23.064568 28395 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 17:28:25.076884 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7079
I0413 17:28:25.076922 28395 solver.cpp:404]     Test net output #1: loss = 0.916515 (* 1 = 0.916515 loss)
I0413 17:28:25.168100 28395 solver.cpp:228] Iteration 1580, loss = 0.663686
I0413 17:28:25.168148 28395 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:28:25.168159 28395 solver.cpp:244]     Train net output #1: loss = 0.663686 (* 1 = 0.663686 loss)
I0413 17:28:25.168169 28395 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 17:28:28.593638 28395 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 17:28:30.330708 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6543
I0413 17:28:30.330749 28395 solver.cpp:404]     Test net output #1: loss = 1.13853 (* 1 = 1.13853 loss)
I0413 17:28:30.453037 28395 solver.cpp:228] Iteration 1600, loss = 0.658687
I0413 17:28:30.453058 28395 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:28:30.453068 28395 solver.cpp:244]     Train net output #1: loss = 0.658687 (* 1 = 0.658687 loss)
I0413 17:28:30.453076 28395 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 17:28:34.079345 28395 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 17:28:36.085543 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7461
I0413 17:28:36.085588 28395 solver.cpp:404]     Test net output #1: loss = 0.746559 (* 1 = 0.746559 loss)
I0413 17:28:36.170552 28395 solver.cpp:228] Iteration 1620, loss = 0.656318
I0413 17:28:36.170572 28395 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:28:36.170583 28395 solver.cpp:244]     Train net output #1: loss = 0.656318 (* 1 = 0.656318 loss)
I0413 17:28:36.170593 28395 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 17:28:39.512311 28395 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 17:28:41.344298 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7026
I0413 17:28:41.344343 28395 solver.cpp:404]     Test net output #1: loss = 0.877087 (* 1 = 0.877087 loss)
I0413 17:28:41.464263 28395 solver.cpp:228] Iteration 1640, loss = 0.653389
I0413 17:28:41.464320 28395 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:28:41.464339 28395 solver.cpp:244]     Train net output #1: loss = 0.653389 (* 1 = 0.653389 loss)
I0413 17:28:41.464349 28395 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 17:28:45.104612 28395 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 17:28:47.105259 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7137
I0413 17:28:47.105299 28395 solver.cpp:404]     Test net output #1: loss = 0.883652 (* 1 = 0.883652 loss)
I0413 17:28:47.197767 28395 solver.cpp:228] Iteration 1660, loss = 0.599781
I0413 17:28:47.197809 28395 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:28:47.197823 28395 solver.cpp:244]     Train net output #1: loss = 0.599781 (* 1 = 0.599781 loss)
I0413 17:28:47.197839 28395 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 17:28:50.470639 28395 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 17:28:52.371628 28395 solver.cpp:404]     Test net output #0: accuracy = 0.715
I0413 17:28:52.371670 28395 solver.cpp:404]     Test net output #1: loss = 0.880427 (* 1 = 0.880427 loss)
I0413 17:28:52.493208 28395 solver.cpp:228] Iteration 1680, loss = 0.64851
I0413 17:28:52.493253 28395 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:28:52.493268 28395 solver.cpp:244]     Train net output #1: loss = 0.64851 (* 1 = 0.64851 loss)
I0413 17:28:52.493276 28395 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 17:28:56.121176 28395 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 17:28:58.038552 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7199
I0413 17:28:58.038596 28395 solver.cpp:404]     Test net output #1: loss = 0.826461 (* 1 = 0.826461 loss)
I0413 17:28:58.137470 28395 solver.cpp:228] Iteration 1700, loss = 0.6391
I0413 17:28:58.137508 28395 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:28:58.137521 28395 solver.cpp:244]     Train net output #1: loss = 0.6391 (* 1 = 0.6391 loss)
I0413 17:28:58.137531 28395 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 17:29:01.374148 28395 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 17:29:03.322453 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7005
I0413 17:29:03.322487 28395 solver.cpp:404]     Test net output #1: loss = 0.898571 (* 1 = 0.898571 loss)
I0413 17:29:03.440049 28395 solver.cpp:228] Iteration 1720, loss = 0.776911
I0413 17:29:03.440090 28395 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:29:03.440101 28395 solver.cpp:244]     Train net output #1: loss = 0.776911 (* 1 = 0.776911 loss)
I0413 17:29:03.440110 28395 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 17:29:07.099253 28395 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 17:29:08.950565 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6502
I0413 17:29:08.950611 28395 solver.cpp:404]     Test net output #1: loss = 1.08771 (* 1 = 1.08771 loss)
I0413 17:29:09.040314 28395 solver.cpp:228] Iteration 1740, loss = 0.610523
I0413 17:29:09.040359 28395 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 17:29:09.040372 28395 solver.cpp:244]     Train net output #1: loss = 0.610523 (* 1 = 0.610523 loss)
I0413 17:29:09.040382 28395 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 17:29:12.359400 28395 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 17:29:14.316745 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6497
I0413 17:29:14.316786 28395 solver.cpp:404]     Test net output #1: loss = 1.09638 (* 1 = 1.09638 loss)
I0413 17:29:14.421613 28395 solver.cpp:228] Iteration 1760, loss = 0.851148
I0413 17:29:14.421645 28395 solver.cpp:244]     Train net output #0: accuracy = 0.707031
I0413 17:29:14.421658 28395 solver.cpp:244]     Train net output #1: loss = 0.851148 (* 1 = 0.851148 loss)
I0413 17:29:14.421666 28395 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 17:29:18.084796 28395 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 17:29:19.832141 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7372
I0413 17:29:19.832178 28395 solver.cpp:404]     Test net output #1: loss = 0.787092 (* 1 = 0.787092 loss)
I0413 17:29:19.931793 28395 solver.cpp:228] Iteration 1780, loss = 0.644643
I0413 17:29:19.931836 28395 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:29:19.931849 28395 solver.cpp:244]     Train net output #1: loss = 0.644643 (* 1 = 0.644643 loss)
I0413 17:29:19.931857 28395 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 17:29:23.311915 28395 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 17:29:25.318740 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6888
I0413 17:29:25.318778 28395 solver.cpp:404]     Test net output #1: loss = 1.00733 (* 1 = 1.00733 loss)
I0413 17:29:25.410987 28395 solver.cpp:228] Iteration 1800, loss = 0.714368
I0413 17:29:25.411031 28395 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:29:25.411053 28395 solver.cpp:244]     Train net output #1: loss = 0.714368 (* 1 = 0.714368 loss)
I0413 17:29:25.411062 28395 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 17:29:29.044651 28395 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 17:29:30.746086 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7416
I0413 17:29:30.746124 28395 solver.cpp:404]     Test net output #1: loss = 0.787049 (* 1 = 0.787049 loss)
I0413 17:29:30.835796 28395 solver.cpp:228] Iteration 1820, loss = 0.707312
I0413 17:29:30.835813 28395 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:29:30.835822 28395 solver.cpp:244]     Train net output #1: loss = 0.707312 (* 1 = 0.707312 loss)
I0413 17:29:30.835830 28395 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 17:29:34.288671 28395 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 17:29:36.265949 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7127
I0413 17:29:36.265985 28395 solver.cpp:404]     Test net output #1: loss = 0.88097 (* 1 = 0.88097 loss)
I0413 17:29:36.388079 28395 solver.cpp:228] Iteration 1840, loss = 0.586339
I0413 17:29:36.388119 28395 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:29:36.388133 28395 solver.cpp:244]     Train net output #1: loss = 0.586339 (* 1 = 0.586339 loss)
I0413 17:29:36.388141 28395 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 17:29:39.943514 28395 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 17:29:41.641324 28395 solver.cpp:404]     Test net output #0: accuracy = 0.636
I0413 17:29:41.641378 28395 solver.cpp:404]     Test net output #1: loss = 1.23338 (* 1 = 1.23338 loss)
I0413 17:29:41.738752 28395 solver.cpp:228] Iteration 1860, loss = 0.655611
I0413 17:29:41.738782 28395 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:29:41.738793 28395 solver.cpp:244]     Train net output #1: loss = 0.655611 (* 1 = 0.655611 loss)
I0413 17:29:41.738801 28395 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 17:29:45.289341 28395 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 17:29:47.245239 28395 solver.cpp:404]     Test net output #0: accuracy = 0.7012
I0413 17:29:47.245280 28395 solver.cpp:404]     Test net output #1: loss = 0.91102 (* 1 = 0.91102 loss)
I0413 17:29:47.364699 28395 solver.cpp:228] Iteration 1880, loss = 0.594317
I0413 17:29:47.364739 28395 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:29:47.364751 28395 solver.cpp:244]     Train net output #1: loss = 0.594317 (* 1 = 0.594317 loss)
I0413 17:29:47.364759 28395 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 17:29:50.849040 28395 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 17:29:52.564779 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6647
I0413 17:29:52.564827 28395 solver.cpp:404]     Test net output #1: loss = 1.01449 (* 1 = 1.01449 loss)
I0413 17:29:52.661269 28395 solver.cpp:228] Iteration 1900, loss = 0.692858
I0413 17:29:52.661319 28395 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:29:52.661334 28395 solver.cpp:244]     Train net output #1: loss = 0.692858 (* 1 = 0.692858 loss)
I0413 17:29:52.661345 28395 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 17:29:56.291079 28395 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 17:29:58.240612 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6516
I0413 17:29:58.240650 28395 solver.cpp:404]     Test net output #1: loss = 1.0424 (* 1 = 1.0424 loss)
I0413 17:29:58.358834 28395 solver.cpp:228] Iteration 1920, loss = 0.749057
I0413 17:29:58.358871 28395 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:29:58.358881 28395 solver.cpp:244]     Train net output #1: loss = 0.749057 (* 1 = 0.749057 loss)
I0413 17:29:58.358892 28395 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 17:30:01.757603 28395 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 17:30:03.505162 28395 solver.cpp:404]     Test net output #0: accuracy = 0.689
I0413 17:30:03.505192 28395 solver.cpp:404]     Test net output #1: loss = 0.97068 (* 1 = 0.97068 loss)
I0413 17:30:03.605844 28395 solver.cpp:228] Iteration 1940, loss = 0.688189
I0413 17:30:03.605885 28395 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:30:03.605896 28395 solver.cpp:244]     Train net output #1: loss = 0.688189 (* 1 = 0.688189 loss)
I0413 17:30:03.605906 28395 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 17:30:07.242343 28395 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 17:30:09.188482 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6244
I0413 17:30:09.188524 28395 solver.cpp:404]     Test net output #1: loss = 1.211 (* 1 = 1.211 loss)
I0413 17:30:09.297634 28395 solver.cpp:228] Iteration 1960, loss = 0.554288
I0413 17:30:09.297672 28395 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:30:09.297683 28395 solver.cpp:244]     Train net output #1: loss = 0.554288 (* 1 = 0.554288 loss)
I0413 17:30:09.297693 28395 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 17:30:12.624794 28395 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 17:30:14.452141 28395 solver.cpp:404]     Test net output #0: accuracy = 0.6511
I0413 17:30:14.452179 28395 solver.cpp:404]     Test net output #1: loss = 1.13314 (* 1 = 1.13314 loss)
I0413 17:30:14.550137 28395 solver.cpp:228] Iteration 1980, loss = 0.705086
I0413 17:30:14.550168 28395 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:30:14.550179 28395 solver.cpp:244]     Train net output #1: loss = 0.705086 (* 1 = 0.705086 loss)
I0413 17:30:14.550186 28395 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 17:30:18.168848 28395 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar2/ResNet-cifar2_iter_2000.caffemodel
I0413 17:30:18.171371 28395 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar2/ResNet-cifar2_iter_2000.solverstate
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 17:30:20.322973 22640 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar3/ResNet-cifar3"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar3.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 17:30:20.323024 22640 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar3.prototxt
I0413 17:30:20.324211 22640 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 17:30:20.324530 22640 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv3_1"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:30:20.324792 22640 layer_factory.hpp:77] Creating layer cifar
I0413 17:30:20.325426 22640 net.cpp:91] Creating Layer cifar
I0413 17:30:20.325444 22640 net.cpp:399] cifar -> data
I0413 17:30:20.325461 22640 net.cpp:399] cifar -> label
I0413 17:30:20.325474 22640 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:30:20.328917 22690 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 17:30:20.371645 22640 data_layer.cpp:41] output data size: 256,3,32,32
I0413 17:30:20.380692 22640 net.cpp:141] Setting up cifar
I0413 17:30:20.380728 22640 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 17:30:20.380738 22640 net.cpp:148] Top shape: 256 (256)
I0413 17:30:20.380743 22640 net.cpp:156] Memory required for data: 3146752
I0413 17:30:20.380754 22640 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:30:20.380779 22640 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:30:20.380786 22640 net.cpp:425] label_cifar_1_split <- label
I0413 17:30:20.380800 22640 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:30:20.380817 22640 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:30:20.380918 22640 net.cpp:141] Setting up label_cifar_1_split
I0413 17:30:20.380930 22640 net.cpp:148] Top shape: 256 (256)
I0413 17:30:20.380937 22640 net.cpp:148] Top shape: 256 (256)
I0413 17:30:20.380942 22640 net.cpp:156] Memory required for data: 3148800
I0413 17:30:20.380949 22640 layer_factory.hpp:77] Creating layer conv1
I0413 17:30:20.380967 22640 net.cpp:91] Creating Layer conv1
I0413 17:30:20.380973 22640 net.cpp:425] conv1 <- data
I0413 17:30:20.380985 22640 net.cpp:399] conv1 -> conv1
I0413 17:30:20.650936 22640 net.cpp:141] Setting up conv1
I0413 17:30:20.650980 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.650986 22640 net.cpp:156] Memory required for data: 19926016
I0413 17:30:20.651006 22640 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:30:20.651022 22640 net.cpp:91] Creating Layer bn_conv1
I0413 17:30:20.651028 22640 net.cpp:425] bn_conv1 <- conv1
I0413 17:30:20.651037 22640 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:30:20.651196 22640 net.cpp:141] Setting up bn_conv1
I0413 17:30:20.651206 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.651209 22640 net.cpp:156] Memory required for data: 36703232
I0413 17:30:20.651222 22640 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:30:20.651234 22640 net.cpp:91] Creating Layer scale_conv1
I0413 17:30:20.651239 22640 net.cpp:425] scale_conv1 <- conv1
I0413 17:30:20.651245 22640 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:30:20.651280 22640 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:30:20.651377 22640 net.cpp:141] Setting up scale_conv1
I0413 17:30:20.651386 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.651391 22640 net.cpp:156] Memory required for data: 53480448
I0413 17:30:20.651398 22640 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:30:20.651407 22640 net.cpp:91] Creating Layer conv1_relu
I0413 17:30:20.651412 22640 net.cpp:425] conv1_relu <- conv1
I0413 17:30:20.651417 22640 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:30:20.651957 22640 net.cpp:141] Setting up conv1_relu
I0413 17:30:20.651970 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.651975 22640 net.cpp:156] Memory required for data: 70257664
I0413 17:30:20.651981 22640 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:30:20.651989 22640 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:30:20.651994 22640 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:30:20.652000 22640 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:30:20.652009 22640 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:30:20.652045 22640 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:30:20.652052 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.652057 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.652062 22640 net.cpp:156] Memory required for data: 103812096
I0413 17:30:20.652066 22640 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:30:20.652079 22640 net.cpp:91] Creating Layer conv2_1a
I0413 17:30:20.652084 22640 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:30:20.652101 22640 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:30:20.653439 22640 net.cpp:141] Setting up conv2_1a
I0413 17:30:20.653455 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.653461 22640 net.cpp:156] Memory required for data: 120589312
I0413 17:30:20.653471 22640 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:30:20.653481 22640 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:30:20.653486 22640 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:30:20.653493 22640 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:30:20.653640 22640 net.cpp:141] Setting up bn_conv2_1a
I0413 17:30:20.653647 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.653651 22640 net.cpp:156] Memory required for data: 137366528
I0413 17:30:20.653661 22640 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:30:20.653667 22640 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:30:20.653672 22640 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:30:20.653678 22640 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:30:20.653707 22640 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:30:20.653791 22640 net.cpp:141] Setting up scale_conv2_1a
I0413 17:30:20.653800 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.653805 22640 net.cpp:156] Memory required for data: 154143744
I0413 17:30:20.653811 22640 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:30:20.653818 22640 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:30:20.653822 22640 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:30:20.653828 22640 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:30:20.654079 22640 net.cpp:141] Setting up conv2_1a_relu
I0413 17:30:20.654093 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.654098 22640 net.cpp:156] Memory required for data: 170920960
I0413 17:30:20.654103 22640 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:30:20.654114 22640 net.cpp:91] Creating Layer conv2_1b
I0413 17:30:20.654119 22640 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:30:20.654125 22640 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:30:20.656949 22640 net.cpp:141] Setting up conv2_1b
I0413 17:30:20.656965 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.656970 22640 net.cpp:156] Memory required for data: 187698176
I0413 17:30:20.656977 22640 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:30:20.656985 22640 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:30:20.656991 22640 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:30:20.656997 22640 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:30:20.657155 22640 net.cpp:141] Setting up bn_conv2_1b
I0413 17:30:20.657165 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.657169 22640 net.cpp:156] Memory required for data: 204475392
I0413 17:30:20.657181 22640 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:30:20.657188 22640 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:30:20.657192 22640 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:30:20.657198 22640 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:30:20.657228 22640 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:30:20.657315 22640 net.cpp:141] Setting up scale_conv2_1b
I0413 17:30:20.657323 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.657328 22640 net.cpp:156] Memory required for data: 221252608
I0413 17:30:20.657335 22640 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:30:20.657343 22640 net.cpp:91] Creating Layer conv2_1
I0413 17:30:20.657347 22640 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:30:20.657353 22640 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:30:20.657359 22640 net.cpp:399] conv2_1 -> conv2_1
I0413 17:30:20.657382 22640 net.cpp:141] Setting up conv2_1
I0413 17:30:20.657388 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.657392 22640 net.cpp:156] Memory required for data: 238029824
I0413 17:30:20.657397 22640 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:30:20.657408 22640 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:30:20.657413 22640 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:30:20.657419 22640 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:30:20.658040 22640 net.cpp:141] Setting up conv2_1_relu
I0413 17:30:20.658049 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.658054 22640 net.cpp:156] Memory required for data: 254807040
I0413 17:30:20.658059 22640 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:30:20.658066 22640 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:30:20.658071 22640 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:30:20.658077 22640 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:30:20.658085 22640 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:30:20.658118 22640 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:30:20.658125 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.658131 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.658135 22640 net.cpp:156] Memory required for data: 288361472
I0413 17:30:20.658139 22640 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:30:20.658150 22640 net.cpp:91] Creating Layer conv2_2a
I0413 17:30:20.658155 22640 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:30:20.658162 22640 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:30:20.661568 22640 net.cpp:141] Setting up conv2_2a
I0413 17:30:20.661586 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.661591 22640 net.cpp:156] Memory required for data: 305138688
I0413 17:30:20.661598 22640 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:30:20.661607 22640 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:30:20.661612 22640 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:30:20.661618 22640 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:30:20.661769 22640 net.cpp:141] Setting up bn_conv2_2a
I0413 17:30:20.661777 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.661782 22640 net.cpp:156] Memory required for data: 321915904
I0413 17:30:20.661789 22640 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:30:20.661798 22640 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:30:20.661801 22640 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:30:20.661808 22640 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:30:20.661837 22640 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:30:20.661923 22640 net.cpp:141] Setting up scale_conv2_2a
I0413 17:30:20.661931 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.661936 22640 net.cpp:156] Memory required for data: 338693120
I0413 17:30:20.661942 22640 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:30:20.661949 22640 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:30:20.661953 22640 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:30:20.661959 22640 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:30:20.662634 22640 net.cpp:141] Setting up conv2_2a_relu
I0413 17:30:20.662648 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.662653 22640 net.cpp:156] Memory required for data: 355470336
I0413 17:30:20.662658 22640 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:30:20.662668 22640 net.cpp:91] Creating Layer conv2_2b
I0413 17:30:20.662674 22640 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:30:20.662681 22640 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:30:20.666116 22640 net.cpp:141] Setting up conv2_2b
I0413 17:30:20.666131 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.666136 22640 net.cpp:156] Memory required for data: 372247552
I0413 17:30:20.666144 22640 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:30:20.666152 22640 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:30:20.666157 22640 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:30:20.666163 22640 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:30:20.666319 22640 net.cpp:141] Setting up bn_conv2_2b
I0413 17:30:20.666327 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.666332 22640 net.cpp:156] Memory required for data: 389024768
I0413 17:30:20.666344 22640 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:30:20.666352 22640 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:30:20.666357 22640 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:30:20.666363 22640 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:30:20.666393 22640 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:30:20.666478 22640 net.cpp:141] Setting up scale_conv2_2b
I0413 17:30:20.666486 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.666491 22640 net.cpp:156] Memory required for data: 405801984
I0413 17:30:20.666498 22640 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:30:20.666506 22640 net.cpp:91] Creating Layer conv2_2
I0413 17:30:20.666509 22640 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:30:20.666515 22640 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:30:20.666522 22640 net.cpp:399] conv2_2 -> conv2_2
I0413 17:30:20.666543 22640 net.cpp:141] Setting up conv2_2
I0413 17:30:20.666549 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.666553 22640 net.cpp:156] Memory required for data: 422579200
I0413 17:30:20.666558 22640 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:30:20.666564 22640 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:30:20.666569 22640 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:30:20.666574 22640 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:30:20.667227 22640 net.cpp:141] Setting up conv2_2_relu
I0413 17:30:20.667240 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.667244 22640 net.cpp:156] Memory required for data: 439356416
I0413 17:30:20.667249 22640 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:30:20.667256 22640 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:30:20.667261 22640 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:30:20.667268 22640 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:30:20.667275 22640 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:30:20.667311 22640 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:30:20.667318 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.667325 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.667330 22640 net.cpp:156] Memory required for data: 472910848
I0413 17:30:20.667333 22640 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:30:20.667343 22640 net.cpp:91] Creating Layer conv2_3a
I0413 17:30:20.667348 22640 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:30:20.667356 22640 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:30:20.669555 22640 net.cpp:141] Setting up conv2_3a
I0413 17:30:20.669570 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.669575 22640 net.cpp:156] Memory required for data: 489688064
I0413 17:30:20.669584 22640 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:30:20.669591 22640 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:30:20.669597 22640 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:30:20.669603 22640 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:30:20.669755 22640 net.cpp:141] Setting up bn_conv2_3a
I0413 17:30:20.669764 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.669769 22640 net.cpp:156] Memory required for data: 506465280
I0413 17:30:20.669776 22640 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:30:20.669783 22640 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:30:20.669787 22640 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:30:20.669793 22640 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:30:20.669822 22640 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:30:20.669910 22640 net.cpp:141] Setting up scale_conv2_3a
I0413 17:30:20.669919 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.669929 22640 net.cpp:156] Memory required for data: 523242496
I0413 17:30:20.669936 22640 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:30:20.669942 22640 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:30:20.669947 22640 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:30:20.669953 22640 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:30:20.670099 22640 net.cpp:141] Setting up conv2_3a_relu
I0413 17:30:20.670109 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.670114 22640 net.cpp:156] Memory required for data: 540019712
I0413 17:30:20.670119 22640 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:30:20.670128 22640 net.cpp:91] Creating Layer conv2_3b
I0413 17:30:20.670133 22640 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:30:20.670140 22640 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:30:20.673135 22640 net.cpp:141] Setting up conv2_3b
I0413 17:30:20.673151 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.673156 22640 net.cpp:156] Memory required for data: 556796928
I0413 17:30:20.673164 22640 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:30:20.673174 22640 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:30:20.673179 22640 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:30:20.673185 22640 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:30:20.673342 22640 net.cpp:141] Setting up bn_conv2_3b
I0413 17:30:20.673351 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.673354 22640 net.cpp:156] Memory required for data: 573574144
I0413 17:30:20.673363 22640 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:30:20.673370 22640 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:30:20.673375 22640 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:30:20.673380 22640 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:30:20.673411 22640 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:30:20.673501 22640 net.cpp:141] Setting up scale_conv2_3b
I0413 17:30:20.673508 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.673512 22640 net.cpp:156] Memory required for data: 590351360
I0413 17:30:20.673519 22640 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:30:20.673527 22640 net.cpp:91] Creating Layer conv2_3
I0413 17:30:20.673532 22640 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:30:20.673537 22640 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:30:20.673542 22640 net.cpp:399] conv2_3 -> conv2_3
I0413 17:30:20.673564 22640 net.cpp:141] Setting up conv2_3
I0413 17:30:20.673571 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.673575 22640 net.cpp:156] Memory required for data: 607128576
I0413 17:30:20.673579 22640 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:30:20.673585 22640 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:30:20.673590 22640 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:30:20.673596 22640 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:30:20.674226 22640 net.cpp:141] Setting up conv2_3_relu
I0413 17:30:20.674239 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.674244 22640 net.cpp:156] Memory required for data: 623905792
I0413 17:30:20.674249 22640 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 17:30:20.674257 22640 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 17:30:20.674262 22640 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 17:30:20.674268 22640 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 17:30:20.674276 22640 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 17:30:20.674312 22640 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 17:30:20.674319 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.674325 22640 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:30:20.674329 22640 net.cpp:156] Memory required for data: 657460224
I0413 17:30:20.674335 22640 layer_factory.hpp:77] Creating layer conv2_sub
I0413 17:30:20.674348 22640 net.cpp:91] Creating Layer conv2_sub
I0413 17:30:20.674355 22640 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 17:30:20.674361 22640 net.cpp:399] conv2_sub -> conv2_sub
I0413 17:30:20.677875 22640 net.cpp:141] Setting up conv2_sub
I0413 17:30:20.677891 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.677896 22640 net.cpp:156] Memory required for data: 665848832
I0413 17:30:20.677906 22640 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 17:30:20.677913 22640 net.cpp:91] Creating Layer bn_conv2_sub
I0413 17:30:20.677919 22640 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 17:30:20.677925 22640 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 17:30:20.678089 22640 net.cpp:141] Setting up bn_conv2_sub
I0413 17:30:20.678097 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.678102 22640 net.cpp:156] Memory required for data: 674237440
I0413 17:30:20.678110 22640 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:30:20.678117 22640 net.cpp:91] Creating Layer scale_conv2_sub
I0413 17:30:20.678122 22640 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 17:30:20.678128 22640 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 17:30:20.678158 22640 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:30:20.678246 22640 net.cpp:141] Setting up scale_conv2_sub
I0413 17:30:20.678253 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.678257 22640 net.cpp:156] Memory required for data: 682626048
I0413 17:30:20.678264 22640 layer_factory.hpp:77] Creating layer conv3_1a
I0413 17:30:20.678275 22640 net.cpp:91] Creating Layer conv3_1a
I0413 17:30:20.678280 22640 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 17:30:20.678287 22640 net.cpp:399] conv3_1a -> conv3_1a
I0413 17:30:20.681186 22640 net.cpp:141] Setting up conv3_1a
I0413 17:30:20.681202 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.681207 22640 net.cpp:156] Memory required for data: 691014656
I0413 17:30:20.681215 22640 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 17:30:20.681222 22640 net.cpp:91] Creating Layer bn_conv3_1a
I0413 17:30:20.681228 22640 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 17:30:20.681236 22640 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 17:30:20.681386 22640 net.cpp:141] Setting up bn_conv3_1a
I0413 17:30:20.681394 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.681399 22640 net.cpp:156] Memory required for data: 699403264
I0413 17:30:20.681407 22640 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:30:20.681414 22640 net.cpp:91] Creating Layer scale_conv3_1a
I0413 17:30:20.681419 22640 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 17:30:20.681426 22640 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 17:30:20.681455 22640 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:30:20.681543 22640 net.cpp:141] Setting up scale_conv3_1a
I0413 17:30:20.681551 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.681555 22640 net.cpp:156] Memory required for data: 707791872
I0413 17:30:20.681562 22640 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 17:30:20.681570 22640 net.cpp:91] Creating Layer conv3_1a_relu
I0413 17:30:20.681574 22640 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 17:30:20.681579 22640 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 17:30:20.682236 22640 net.cpp:141] Setting up conv3_1a_relu
I0413 17:30:20.682250 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.682255 22640 net.cpp:156] Memory required for data: 716180480
I0413 17:30:20.682260 22640 layer_factory.hpp:77] Creating layer conv3_1b
I0413 17:30:20.682271 22640 net.cpp:91] Creating Layer conv3_1b
I0413 17:30:20.682276 22640 net.cpp:425] conv3_1b <- conv3_1a
I0413 17:30:20.682283 22640 net.cpp:399] conv3_1b -> conv3_1b
I0413 17:30:20.685547 22640 net.cpp:141] Setting up conv3_1b
I0413 17:30:20.685564 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.685570 22640 net.cpp:156] Memory required for data: 724569088
I0413 17:30:20.685588 22640 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 17:30:20.685597 22640 net.cpp:91] Creating Layer bn_conv3_1b
I0413 17:30:20.685603 22640 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 17:30:20.685609 22640 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 17:30:20.685765 22640 net.cpp:141] Setting up bn_conv3_1b
I0413 17:30:20.685773 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.685778 22640 net.cpp:156] Memory required for data: 732957696
I0413 17:30:20.685786 22640 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:30:20.685794 22640 net.cpp:91] Creating Layer scale_conv3_1b
I0413 17:30:20.685799 22640 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 17:30:20.685804 22640 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 17:30:20.685835 22640 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:30:20.685926 22640 net.cpp:141] Setting up scale_conv3_1b
I0413 17:30:20.685933 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.685938 22640 net.cpp:156] Memory required for data: 741346304
I0413 17:30:20.685945 22640 layer_factory.hpp:77] Creating layer conv3_1
I0413 17:30:20.685952 22640 net.cpp:91] Creating Layer conv3_1
I0413 17:30:20.685956 22640 net.cpp:425] conv3_1 <- conv3_1b
I0413 17:30:20.685962 22640 net.cpp:425] conv3_1 <- conv2_sub
I0413 17:30:20.685968 22640 net.cpp:399] conv3_1 -> conv3_1
I0413 17:30:20.685986 22640 net.cpp:141] Setting up conv3_1
I0413 17:30:20.685993 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.685998 22640 net.cpp:156] Memory required for data: 749734912
I0413 17:30:20.686002 22640 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 17:30:20.686009 22640 net.cpp:91] Creating Layer conv3_1_relu
I0413 17:30:20.686013 22640 net.cpp:425] conv3_1_relu <- conv3_1
I0413 17:30:20.686019 22640 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 17:30:20.686166 22640 net.cpp:141] Setting up conv3_1_relu
I0413 17:30:20.686175 22640 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:30:20.686180 22640 net.cpp:156] Memory required for data: 758123520
I0413 17:30:20.686185 22640 layer_factory.hpp:77] Creating layer global_pool
I0413 17:30:20.686193 22640 net.cpp:91] Creating Layer global_pool
I0413 17:30:20.686198 22640 net.cpp:425] global_pool <- conv3_1
I0413 17:30:20.686204 22640 net.cpp:399] global_pool -> global_pool
I0413 17:30:20.686905 22640 net.cpp:141] Setting up global_pool
I0413 17:30:20.686919 22640 net.cpp:148] Top shape: 256 32 2 2 (32768)
I0413 17:30:20.686924 22640 net.cpp:156] Memory required for data: 758254592
I0413 17:30:20.686929 22640 layer_factory.hpp:77] Creating layer ip
I0413 17:30:20.686944 22640 net.cpp:91] Creating Layer ip
I0413 17:30:20.686949 22640 net.cpp:425] ip <- global_pool
I0413 17:30:20.686955 22640 net.cpp:399] ip -> ip
I0413 17:30:20.687052 22640 net.cpp:141] Setting up ip
I0413 17:30:20.687060 22640 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:30:20.687065 22640 net.cpp:156] Memory required for data: 758264832
I0413 17:30:20.687072 22640 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:30:20.687079 22640 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:30:20.687083 22640 net.cpp:425] ip_ip_0_split <- ip
I0413 17:30:20.687089 22640 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:30:20.687098 22640 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:30:20.687125 22640 net.cpp:141] Setting up ip_ip_0_split
I0413 17:30:20.687132 22640 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:30:20.687137 22640 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:30:20.687142 22640 net.cpp:156] Memory required for data: 758285312
I0413 17:30:20.687146 22640 layer_factory.hpp:77] Creating layer accuracy
I0413 17:30:20.687158 22640 net.cpp:91] Creating Layer accuracy
I0413 17:30:20.687163 22640 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:30:20.687170 22640 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:30:20.687175 22640 net.cpp:399] accuracy -> accuracy
I0413 17:30:20.687185 22640 net.cpp:141] Setting up accuracy
I0413 17:30:20.687194 22640 net.cpp:148] Top shape: (1)
I0413 17:30:20.687199 22640 net.cpp:156] Memory required for data: 758285316
I0413 17:30:20.687203 22640 layer_factory.hpp:77] Creating layer loss
I0413 17:30:20.687211 22640 net.cpp:91] Creating Layer loss
I0413 17:30:20.687216 22640 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:30:20.687221 22640 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:30:20.687227 22640 net.cpp:399] loss -> loss
I0413 17:30:20.687235 22640 layer_factory.hpp:77] Creating layer loss
I0413 17:30:20.688089 22640 net.cpp:141] Setting up loss
I0413 17:30:20.688102 22640 net.cpp:148] Top shape: (1)
I0413 17:30:20.688107 22640 net.cpp:151]     with loss weight 1
I0413 17:30:20.688117 22640 net.cpp:156] Memory required for data: 758285320
I0413 17:30:20.688122 22640 net.cpp:217] loss needs backward computation.
I0413 17:30:20.688127 22640 net.cpp:219] accuracy does not need backward computation.
I0413 17:30:20.688133 22640 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:30:20.688136 22640 net.cpp:217] ip needs backward computation.
I0413 17:30:20.688141 22640 net.cpp:217] global_pool needs backward computation.
I0413 17:30:20.688145 22640 net.cpp:217] conv3_1_relu needs backward computation.
I0413 17:30:20.688149 22640 net.cpp:217] conv3_1 needs backward computation.
I0413 17:30:20.688154 22640 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 17:30:20.688159 22640 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 17:30:20.688163 22640 net.cpp:217] conv3_1b needs backward computation.
I0413 17:30:20.688168 22640 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 17:30:20.688172 22640 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 17:30:20.688176 22640 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 17:30:20.688180 22640 net.cpp:217] conv3_1a needs backward computation.
I0413 17:30:20.688184 22640 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 17:30:20.688189 22640 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 17:30:20.688194 22640 net.cpp:217] conv2_sub needs backward computation.
I0413 17:30:20.688197 22640 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 17:30:20.688202 22640 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:30:20.688206 22640 net.cpp:217] conv2_3 needs backward computation.
I0413 17:30:20.688211 22640 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:30:20.688215 22640 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:30:20.688220 22640 net.cpp:217] conv2_3b needs backward computation.
I0413 17:30:20.688225 22640 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:30:20.688228 22640 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:30:20.688232 22640 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:30:20.688236 22640 net.cpp:217] conv2_3a needs backward computation.
I0413 17:30:20.688241 22640 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:30:20.688246 22640 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:30:20.688249 22640 net.cpp:217] conv2_2 needs backward computation.
I0413 17:30:20.688254 22640 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:30:20.688259 22640 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:30:20.688263 22640 net.cpp:217] conv2_2b needs backward computation.
I0413 17:30:20.688267 22640 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:30:20.688271 22640 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:30:20.688276 22640 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:30:20.688279 22640 net.cpp:217] conv2_2a needs backward computation.
I0413 17:30:20.688284 22640 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:30:20.688288 22640 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:30:20.688292 22640 net.cpp:217] conv2_1 needs backward computation.
I0413 17:30:20.688302 22640 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:30:20.688307 22640 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:30:20.688310 22640 net.cpp:217] conv2_1b needs backward computation.
I0413 17:30:20.688314 22640 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:30:20.688319 22640 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:30:20.688323 22640 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:30:20.688328 22640 net.cpp:217] conv2_1a needs backward computation.
I0413 17:30:20.688331 22640 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:30:20.688336 22640 net.cpp:217] conv1_relu needs backward computation.
I0413 17:30:20.688340 22640 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:30:20.688344 22640 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:30:20.688349 22640 net.cpp:217] conv1 needs backward computation.
I0413 17:30:20.688354 22640 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:30:20.688359 22640 net.cpp:219] cifar does not need backward computation.
I0413 17:30:20.688364 22640 net.cpp:261] This network produces output accuracy
I0413 17:30:20.688369 22640 net.cpp:261] This network produces output loss
I0413 17:30:20.688397 22640 net.cpp:274] Network initialization done.
I0413 17:30:20.689471 22640 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar3.prototxt
I0413 17:30:20.689543 22640 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 17:30:20.689788 22640 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv3_1"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:30:20.689980 22640 layer_factory.hpp:77] Creating layer cifar
I0413 17:30:20.690101 22640 net.cpp:91] Creating Layer cifar
I0413 17:30:20.690112 22640 net.cpp:399] cifar -> data
I0413 17:30:20.690124 22640 net.cpp:399] cifar -> label
I0413 17:30:20.690134 22640 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:30:20.690901 22710 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 17:30:20.691051 22640 data_layer.cpp:41] output data size: 100,3,32,32
I0413 17:30:20.695818 22640 net.cpp:141] Setting up cifar
I0413 17:30:20.695837 22640 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 17:30:20.695843 22640 net.cpp:148] Top shape: 100 (100)
I0413 17:30:20.695847 22640 net.cpp:156] Memory required for data: 1229200
I0413 17:30:20.695853 22640 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:30:20.695861 22640 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:30:20.695868 22640 net.cpp:425] label_cifar_1_split <- label
I0413 17:30:20.695874 22640 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:30:20.695883 22640 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:30:20.695936 22640 net.cpp:141] Setting up label_cifar_1_split
I0413 17:30:20.695945 22640 net.cpp:148] Top shape: 100 (100)
I0413 17:30:20.695950 22640 net.cpp:148] Top shape: 100 (100)
I0413 17:30:20.695955 22640 net.cpp:156] Memory required for data: 1230000
I0413 17:30:20.695960 22640 layer_factory.hpp:77] Creating layer conv1
I0413 17:30:20.695969 22640 net.cpp:91] Creating Layer conv1
I0413 17:30:20.695974 22640 net.cpp:425] conv1 <- data
I0413 17:30:20.695981 22640 net.cpp:399] conv1 -> conv1
I0413 17:30:20.699411 22640 net.cpp:141] Setting up conv1
I0413 17:30:20.699430 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.699435 22640 net.cpp:156] Memory required for data: 7783600
I0413 17:30:20.699447 22640 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:30:20.699455 22640 net.cpp:91] Creating Layer bn_conv1
I0413 17:30:20.699460 22640 net.cpp:425] bn_conv1 <- conv1
I0413 17:30:20.699470 22640 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:30:20.700775 22640 net.cpp:141] Setting up bn_conv1
I0413 17:30:20.700785 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.700790 22640 net.cpp:156] Memory required for data: 14337200
I0413 17:30:20.700804 22640 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:30:20.700812 22640 net.cpp:91] Creating Layer scale_conv1
I0413 17:30:20.700817 22640 net.cpp:425] scale_conv1 <- conv1
I0413 17:30:20.700824 22640 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:30:20.700865 22640 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:30:20.700973 22640 net.cpp:141] Setting up scale_conv1
I0413 17:30:20.700999 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.701002 22640 net.cpp:156] Memory required for data: 20890800
I0413 17:30:20.701010 22640 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:30:20.701016 22640 net.cpp:91] Creating Layer conv1_relu
I0413 17:30:20.701035 22640 net.cpp:425] conv1_relu <- conv1
I0413 17:30:20.701040 22640 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:30:20.701340 22640 net.cpp:141] Setting up conv1_relu
I0413 17:30:20.701355 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.701360 22640 net.cpp:156] Memory required for data: 27444400
I0413 17:30:20.701365 22640 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:30:20.701372 22640 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:30:20.701376 22640 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:30:20.701385 22640 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:30:20.701398 22640 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:30:20.701442 22640 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:30:20.701452 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.701457 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.701462 22640 net.cpp:156] Memory required for data: 40551600
I0413 17:30:20.701465 22640 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:30:20.701478 22640 net.cpp:91] Creating Layer conv2_1a
I0413 17:30:20.701493 22640 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:30:20.701501 22640 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:30:20.704212 22640 net.cpp:141] Setting up conv2_1a
I0413 17:30:20.704227 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.704238 22640 net.cpp:156] Memory required for data: 47105200
I0413 17:30:20.704263 22640 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:30:20.704274 22640 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:30:20.704280 22640 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:30:20.704290 22640 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:30:20.704475 22640 net.cpp:141] Setting up bn_conv2_1a
I0413 17:30:20.704485 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.704489 22640 net.cpp:156] Memory required for data: 53658800
I0413 17:30:20.704499 22640 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:30:20.704509 22640 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:30:20.704514 22640 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:30:20.704535 22640 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:30:20.704576 22640 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:30:20.704684 22640 net.cpp:141] Setting up scale_conv2_1a
I0413 17:30:20.704692 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.704696 22640 net.cpp:156] Memory required for data: 60212400
I0413 17:30:20.704704 22640 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:30:20.704710 22640 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:30:20.704716 22640 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:30:20.704731 22640 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:30:20.705294 22640 net.cpp:141] Setting up conv2_1a_relu
I0413 17:30:20.705309 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.705314 22640 net.cpp:156] Memory required for data: 66766000
I0413 17:30:20.705323 22640 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:30:20.705338 22640 net.cpp:91] Creating Layer conv2_1b
I0413 17:30:20.705343 22640 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:30:20.705350 22640 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:30:20.708897 22640 net.cpp:141] Setting up conv2_1b
I0413 17:30:20.708914 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.708919 22640 net.cpp:156] Memory required for data: 73319600
I0413 17:30:20.708926 22640 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:30:20.708933 22640 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:30:20.708938 22640 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:30:20.708947 22640 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:30:20.709149 22640 net.cpp:141] Setting up bn_conv2_1b
I0413 17:30:20.709159 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.709163 22640 net.cpp:156] Memory required for data: 79873200
I0413 17:30:20.709192 22640 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:30:20.709200 22640 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:30:20.709223 22640 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:30:20.709230 22640 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:30:20.709272 22640 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:30:20.709393 22640 net.cpp:141] Setting up scale_conv2_1b
I0413 17:30:20.709403 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.709417 22640 net.cpp:156] Memory required for data: 86426800
I0413 17:30:20.709430 22640 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:30:20.709436 22640 net.cpp:91] Creating Layer conv2_1
I0413 17:30:20.709441 22640 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:30:20.709447 22640 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:30:20.709456 22640 net.cpp:399] conv2_1 -> conv2_1
I0413 17:30:20.709481 22640 net.cpp:141] Setting up conv2_1
I0413 17:30:20.709498 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.709502 22640 net.cpp:156] Memory required for data: 92980400
I0413 17:30:20.709506 22640 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:30:20.709512 22640 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:30:20.709528 22640 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:30:20.709534 22640 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:30:20.709862 22640 net.cpp:141] Setting up conv2_1_relu
I0413 17:30:20.709887 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.709892 22640 net.cpp:156] Memory required for data: 99534000
I0413 17:30:20.709897 22640 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:30:20.709906 22640 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:30:20.709913 22640 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:30:20.709918 22640 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:30:20.709925 22640 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:30:20.709969 22640 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:30:20.709975 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.709981 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.709985 22640 net.cpp:156] Memory required for data: 112641200
I0413 17:30:20.709990 22640 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:30:20.710002 22640 net.cpp:91] Creating Layer conv2_2a
I0413 17:30:20.710007 22640 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:30:20.710016 22640 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:30:20.714618 22640 net.cpp:141] Setting up conv2_2a
I0413 17:30:20.714639 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.714645 22640 net.cpp:156] Memory required for data: 119194800
I0413 17:30:20.714654 22640 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:30:20.714663 22640 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:30:20.714682 22640 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:30:20.714690 22640 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:30:20.714890 22640 net.cpp:141] Setting up bn_conv2_2a
I0413 17:30:20.714906 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.714911 22640 net.cpp:156] Memory required for data: 125748400
I0413 17:30:20.714920 22640 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:30:20.714926 22640 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:30:20.714932 22640 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:30:20.714939 22640 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:30:20.714982 22640 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:30:20.715095 22640 net.cpp:141] Setting up scale_conv2_2a
I0413 17:30:20.715102 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.715106 22640 net.cpp:156] Memory required for data: 132302000
I0413 17:30:20.715113 22640 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:30:20.715119 22640 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:30:20.715137 22640 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:30:20.715143 22640 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:30:20.715432 22640 net.cpp:141] Setting up conv2_2a_relu
I0413 17:30:20.715447 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.715453 22640 net.cpp:156] Memory required for data: 138855600
I0413 17:30:20.715458 22640 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:30:20.715471 22640 net.cpp:91] Creating Layer conv2_2b
I0413 17:30:20.715476 22640 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:30:20.715500 22640 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:30:20.717979 22640 net.cpp:141] Setting up conv2_2b
I0413 17:30:20.717996 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.718001 22640 net.cpp:156] Memory required for data: 145409200
I0413 17:30:20.718009 22640 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:30:20.718019 22640 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:30:20.718024 22640 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:30:20.718031 22640 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:30:20.718222 22640 net.cpp:141] Setting up bn_conv2_2b
I0413 17:30:20.718231 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.718236 22640 net.cpp:156] Memory required for data: 151962800
I0413 17:30:20.718250 22640 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:30:20.718256 22640 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:30:20.718261 22640 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:30:20.718267 22640 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:30:20.718308 22640 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:30:20.718415 22640 net.cpp:141] Setting up scale_conv2_2b
I0413 17:30:20.718423 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.718427 22640 net.cpp:156] Memory required for data: 158516400
I0413 17:30:20.718435 22640 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:30:20.718442 22640 net.cpp:91] Creating Layer conv2_2
I0413 17:30:20.718447 22640 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:30:20.718452 22640 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:30:20.718458 22640 net.cpp:399] conv2_2 -> conv2_2
I0413 17:30:20.718483 22640 net.cpp:141] Setting up conv2_2
I0413 17:30:20.718490 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.718494 22640 net.cpp:156] Memory required for data: 165070000
I0413 17:30:20.718498 22640 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:30:20.718504 22640 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:30:20.718509 22640 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:30:20.718516 22640 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:30:20.718791 22640 net.cpp:141] Setting up conv2_2_relu
I0413 17:30:20.718806 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.718811 22640 net.cpp:156] Memory required for data: 171623600
I0413 17:30:20.718818 22640 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:30:20.718827 22640 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:30:20.718832 22640 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:30:20.718838 22640 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:30:20.718847 22640 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:30:20.718890 22640 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:30:20.718897 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.718905 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.718909 22640 net.cpp:156] Memory required for data: 184730800
I0413 17:30:20.718914 22640 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:30:20.718924 22640 net.cpp:91] Creating Layer conv2_3a
I0413 17:30:20.718927 22640 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:30:20.718937 22640 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:30:20.721683 22640 net.cpp:141] Setting up conv2_3a
I0413 17:30:20.721699 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.721704 22640 net.cpp:156] Memory required for data: 191284400
I0413 17:30:20.721711 22640 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:30:20.721721 22640 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:30:20.721726 22640 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:30:20.721734 22640 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:30:20.721923 22640 net.cpp:141] Setting up bn_conv2_3a
I0413 17:30:20.721932 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.721936 22640 net.cpp:156] Memory required for data: 197838000
I0413 17:30:20.721945 22640 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:30:20.721951 22640 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:30:20.721956 22640 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:30:20.721963 22640 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:30:20.722002 22640 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:30:20.722107 22640 net.cpp:141] Setting up scale_conv2_3a
I0413 17:30:20.722116 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.722121 22640 net.cpp:156] Memory required for data: 204391600
I0413 17:30:20.722127 22640 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:30:20.722133 22640 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:30:20.722138 22640 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:30:20.722143 22640 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:30:20.722759 22640 net.cpp:141] Setting up conv2_3a_relu
I0413 17:30:20.722769 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.722774 22640 net.cpp:156] Memory required for data: 210945200
I0413 17:30:20.722779 22640 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:30:20.722790 22640 net.cpp:91] Creating Layer conv2_3b
I0413 17:30:20.722795 22640 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:30:20.722805 22640 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:30:20.726281 22640 net.cpp:141] Setting up conv2_3b
I0413 17:30:20.726296 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.726301 22640 net.cpp:156] Memory required for data: 217498800
I0413 17:30:20.726310 22640 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:30:20.726320 22640 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:30:20.726326 22640 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:30:20.726335 22640 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:30:20.726523 22640 net.cpp:141] Setting up bn_conv2_3b
I0413 17:30:20.726531 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.726536 22640 net.cpp:156] Memory required for data: 224052400
I0413 17:30:20.726544 22640 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:30:20.726552 22640 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:30:20.726557 22640 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:30:20.726562 22640 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:30:20.726608 22640 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:30:20.726717 22640 net.cpp:141] Setting up scale_conv2_3b
I0413 17:30:20.726725 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.726729 22640 net.cpp:156] Memory required for data: 230606000
I0413 17:30:20.726737 22640 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:30:20.726744 22640 net.cpp:91] Creating Layer conv2_3
I0413 17:30:20.726749 22640 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:30:20.726754 22640 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:30:20.726760 22640 net.cpp:399] conv2_3 -> conv2_3
I0413 17:30:20.726785 22640 net.cpp:141] Setting up conv2_3
I0413 17:30:20.726794 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.726797 22640 net.cpp:156] Memory required for data: 237159600
I0413 17:30:20.726801 22640 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:30:20.726807 22640 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:30:20.726811 22640 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:30:20.726819 22640 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:30:20.727335 22640 net.cpp:141] Setting up conv2_3_relu
I0413 17:30:20.727349 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.727355 22640 net.cpp:156] Memory required for data: 243713200
I0413 17:30:20.727358 22640 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 17:30:20.727367 22640 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 17:30:20.727372 22640 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 17:30:20.727378 22640 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 17:30:20.727386 22640 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 17:30:20.727429 22640 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 17:30:20.727437 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.727442 22640 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:30:20.727447 22640 net.cpp:156] Memory required for data: 256820400
I0413 17:30:20.727450 22640 layer_factory.hpp:77] Creating layer conv2_sub
I0413 17:30:20.727461 22640 net.cpp:91] Creating Layer conv2_sub
I0413 17:30:20.727466 22640 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 17:30:20.727474 22640 net.cpp:399] conv2_sub -> conv2_sub
I0413 17:30:20.730846 22640 net.cpp:141] Setting up conv2_sub
I0413 17:30:20.730862 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.730867 22640 net.cpp:156] Memory required for data: 260097200
I0413 17:30:20.730875 22640 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 17:30:20.730885 22640 net.cpp:91] Creating Layer bn_conv2_sub
I0413 17:30:20.730890 22640 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 17:30:20.730898 22640 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 17:30:20.731078 22640 net.cpp:141] Setting up bn_conv2_sub
I0413 17:30:20.731086 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.731091 22640 net.cpp:156] Memory required for data: 263374000
I0413 17:30:20.731098 22640 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:30:20.731106 22640 net.cpp:91] Creating Layer scale_conv2_sub
I0413 17:30:20.731109 22640 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 17:30:20.731117 22640 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 17:30:20.731155 22640 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:30:20.731264 22640 net.cpp:141] Setting up scale_conv2_sub
I0413 17:30:20.731272 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.731276 22640 net.cpp:156] Memory required for data: 266650800
I0413 17:30:20.731283 22640 layer_factory.hpp:77] Creating layer conv3_1a
I0413 17:30:20.731294 22640 net.cpp:91] Creating Layer conv3_1a
I0413 17:30:20.731299 22640 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 17:30:20.731308 22640 net.cpp:399] conv3_1a -> conv3_1a
I0413 17:30:20.734139 22640 net.cpp:141] Setting up conv3_1a
I0413 17:30:20.734159 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.734164 22640 net.cpp:156] Memory required for data: 269927600
I0413 17:30:20.734172 22640 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 17:30:20.734181 22640 net.cpp:91] Creating Layer bn_conv3_1a
I0413 17:30:20.734187 22640 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 17:30:20.734194 22640 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 17:30:20.734375 22640 net.cpp:141] Setting up bn_conv3_1a
I0413 17:30:20.734383 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.734387 22640 net.cpp:156] Memory required for data: 273204400
I0413 17:30:20.734395 22640 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:30:20.734401 22640 net.cpp:91] Creating Layer scale_conv3_1a
I0413 17:30:20.734406 22640 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 17:30:20.734413 22640 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 17:30:20.734452 22640 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:30:20.734558 22640 net.cpp:141] Setting up scale_conv3_1a
I0413 17:30:20.734566 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.734571 22640 net.cpp:156] Memory required for data: 276481200
I0413 17:30:20.734577 22640 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 17:30:20.734583 22640 net.cpp:91] Creating Layer conv3_1a_relu
I0413 17:30:20.734588 22640 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 17:30:20.734593 22640 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 17:30:20.734866 22640 net.cpp:141] Setting up conv3_1a_relu
I0413 17:30:20.734880 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.734885 22640 net.cpp:156] Memory required for data: 279758000
I0413 17:30:20.734889 22640 layer_factory.hpp:77] Creating layer conv3_1b
I0413 17:30:20.734901 22640 net.cpp:91] Creating Layer conv3_1b
I0413 17:30:20.734906 22640 net.cpp:425] conv3_1b <- conv3_1a
I0413 17:30:20.734915 22640 net.cpp:399] conv3_1b -> conv3_1b
I0413 17:30:20.737869 22640 net.cpp:141] Setting up conv3_1b
I0413 17:30:20.737884 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.737889 22640 net.cpp:156] Memory required for data: 283034800
I0413 17:30:20.737906 22640 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 17:30:20.737916 22640 net.cpp:91] Creating Layer bn_conv3_1b
I0413 17:30:20.737921 22640 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 17:30:20.737929 22640 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 17:30:20.738111 22640 net.cpp:141] Setting up bn_conv3_1b
I0413 17:30:20.738118 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.738123 22640 net.cpp:156] Memory required for data: 286311600
I0413 17:30:20.738131 22640 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:30:20.738139 22640 net.cpp:91] Creating Layer scale_conv3_1b
I0413 17:30:20.738144 22640 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 17:30:20.738150 22640 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 17:30:20.738190 22640 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:30:20.738298 22640 net.cpp:141] Setting up scale_conv3_1b
I0413 17:30:20.738306 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.738311 22640 net.cpp:156] Memory required for data: 289588400
I0413 17:30:20.738317 22640 layer_factory.hpp:77] Creating layer conv3_1
I0413 17:30:20.738323 22640 net.cpp:91] Creating Layer conv3_1
I0413 17:30:20.738328 22640 net.cpp:425] conv3_1 <- conv3_1b
I0413 17:30:20.738333 22640 net.cpp:425] conv3_1 <- conv2_sub
I0413 17:30:20.738340 22640 net.cpp:399] conv3_1 -> conv3_1
I0413 17:30:20.738361 22640 net.cpp:141] Setting up conv3_1
I0413 17:30:20.738370 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.738374 22640 net.cpp:156] Memory required for data: 292865200
I0413 17:30:20.738379 22640 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 17:30:20.738384 22640 net.cpp:91] Creating Layer conv3_1_relu
I0413 17:30:20.738389 22640 net.cpp:425] conv3_1_relu <- conv3_1
I0413 17:30:20.738399 22640 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 17:30:20.739033 22640 net.cpp:141] Setting up conv3_1_relu
I0413 17:30:20.739048 22640 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:30:20.739051 22640 net.cpp:156] Memory required for data: 296142000
I0413 17:30:20.739056 22640 layer_factory.hpp:77] Creating layer global_pool
I0413 17:30:20.739063 22640 net.cpp:91] Creating Layer global_pool
I0413 17:30:20.739068 22640 net.cpp:425] global_pool <- conv3_1
I0413 17:30:20.739078 22640 net.cpp:399] global_pool -> global_pool
I0413 17:30:20.740088 22640 net.cpp:141] Setting up global_pool
I0413 17:30:20.740103 22640 net.cpp:148] Top shape: 100 32 2 2 (12800)
I0413 17:30:20.740108 22640 net.cpp:156] Memory required for data: 296193200
I0413 17:30:20.740113 22640 layer_factory.hpp:77] Creating layer ip
I0413 17:30:20.740121 22640 net.cpp:91] Creating Layer ip
I0413 17:30:20.740126 22640 net.cpp:425] ip <- global_pool
I0413 17:30:20.740133 22640 net.cpp:399] ip -> ip
I0413 17:30:20.740243 22640 net.cpp:141] Setting up ip
I0413 17:30:20.740252 22640 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:30:20.740257 22640 net.cpp:156] Memory required for data: 296197200
I0413 17:30:20.740263 22640 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:30:20.740269 22640 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:30:20.740274 22640 net.cpp:425] ip_ip_0_split <- ip
I0413 17:30:20.740281 22640 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:30:20.740289 22640 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:30:20.740325 22640 net.cpp:141] Setting up ip_ip_0_split
I0413 17:30:20.740332 22640 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:30:20.740337 22640 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:30:20.740341 22640 net.cpp:156] Memory required for data: 296205200
I0413 17:30:20.740345 22640 layer_factory.hpp:77] Creating layer accuracy
I0413 17:30:20.740353 22640 net.cpp:91] Creating Layer accuracy
I0413 17:30:20.740357 22640 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:30:20.740362 22640 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:30:20.740368 22640 net.cpp:399] accuracy -> accuracy
I0413 17:30:20.740376 22640 net.cpp:141] Setting up accuracy
I0413 17:30:20.740381 22640 net.cpp:148] Top shape: (1)
I0413 17:30:20.740386 22640 net.cpp:156] Memory required for data: 296205204
I0413 17:30:20.740391 22640 layer_factory.hpp:77] Creating layer loss
I0413 17:30:20.740397 22640 net.cpp:91] Creating Layer loss
I0413 17:30:20.740401 22640 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:30:20.740407 22640 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:30:20.740412 22640 net.cpp:399] loss -> loss
I0413 17:30:20.740420 22640 layer_factory.hpp:77] Creating layer loss
I0413 17:30:20.741288 22640 net.cpp:141] Setting up loss
I0413 17:30:20.741302 22640 net.cpp:148] Top shape: (1)
I0413 17:30:20.741305 22640 net.cpp:151]     with loss weight 1
I0413 17:30:20.741312 22640 net.cpp:156] Memory required for data: 296205208
I0413 17:30:20.741317 22640 net.cpp:217] loss needs backward computation.
I0413 17:30:20.741322 22640 net.cpp:219] accuracy does not need backward computation.
I0413 17:30:20.741328 22640 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:30:20.741331 22640 net.cpp:217] ip needs backward computation.
I0413 17:30:20.741335 22640 net.cpp:217] global_pool needs backward computation.
I0413 17:30:20.741340 22640 net.cpp:217] conv3_1_relu needs backward computation.
I0413 17:30:20.741344 22640 net.cpp:217] conv3_1 needs backward computation.
I0413 17:30:20.741350 22640 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 17:30:20.741354 22640 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 17:30:20.741358 22640 net.cpp:217] conv3_1b needs backward computation.
I0413 17:30:20.741364 22640 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 17:30:20.741367 22640 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 17:30:20.741371 22640 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 17:30:20.741379 22640 net.cpp:217] conv3_1a needs backward computation.
I0413 17:30:20.741384 22640 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 17:30:20.741387 22640 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 17:30:20.741391 22640 net.cpp:217] conv2_sub needs backward computation.
I0413 17:30:20.741396 22640 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 17:30:20.741400 22640 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:30:20.741405 22640 net.cpp:217] conv2_3 needs backward computation.
I0413 17:30:20.741410 22640 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:30:20.741413 22640 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:30:20.741417 22640 net.cpp:217] conv2_3b needs backward computation.
I0413 17:30:20.741421 22640 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:30:20.741425 22640 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:30:20.741430 22640 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:30:20.741433 22640 net.cpp:217] conv2_3a needs backward computation.
I0413 17:30:20.741437 22640 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:30:20.741442 22640 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:30:20.741446 22640 net.cpp:217] conv2_2 needs backward computation.
I0413 17:30:20.741451 22640 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:30:20.741454 22640 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:30:20.741458 22640 net.cpp:217] conv2_2b needs backward computation.
I0413 17:30:20.741463 22640 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:30:20.741467 22640 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:30:20.741471 22640 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:30:20.741474 22640 net.cpp:217] conv2_2a needs backward computation.
I0413 17:30:20.741479 22640 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:30:20.741483 22640 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:30:20.741487 22640 net.cpp:217] conv2_1 needs backward computation.
I0413 17:30:20.741492 22640 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:30:20.741495 22640 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:30:20.741499 22640 net.cpp:217] conv2_1b needs backward computation.
I0413 17:30:20.741503 22640 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:30:20.741508 22640 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:30:20.741511 22640 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:30:20.741515 22640 net.cpp:217] conv2_1a needs backward computation.
I0413 17:30:20.741519 22640 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:30:20.741524 22640 net.cpp:217] conv1_relu needs backward computation.
I0413 17:30:20.741528 22640 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:30:20.741533 22640 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:30:20.741536 22640 net.cpp:217] conv1 needs backward computation.
I0413 17:30:20.741540 22640 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:30:20.741545 22640 net.cpp:219] cifar does not need backward computation.
I0413 17:30:20.741549 22640 net.cpp:261] This network produces output accuracy
I0413 17:30:20.741554 22640 net.cpp:261] This network produces output loss
I0413 17:30:20.741588 22640 net.cpp:274] Network initialization done.
I0413 17:30:20.741721 22640 solver.cpp:60] Solver scaffolding done.
I0413 17:30:21.028612 22640 solver.cpp:228] Iteration 0, loss = 2.57853
I0413 17:30:21.028690 22640 solver.cpp:244]     Train net output #0: accuracy = 0.0820312
I0413 17:30:21.028707 22640 solver.cpp:244]     Train net output #1: loss = 2.57853 (* 1 = 2.57853 loss)
I0413 17:30:21.028718 22640 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 17:30:25.325507 22640 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 17:30:27.610973 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4692
I0413 17:30:27.611027 22640 solver.cpp:404]     Test net output #1: loss = 1.58998 (* 1 = 1.58998 loss)
I0413 17:30:27.751143 22640 solver.cpp:228] Iteration 20, loss = 1.33812
I0413 17:30:27.751216 22640 solver.cpp:244]     Train net output #0: accuracy = 0.519531
I0413 17:30:27.751231 22640 solver.cpp:244]     Train net output #1: loss = 1.33812 (* 1 = 1.33812 loss)
I0413 17:30:27.751245 22640 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 17:30:31.820811 22640 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 17:30:34.041049 22640 solver.cpp:404]     Test net output #0: accuracy = 0.507
I0413 17:30:34.041107 22640 solver.cpp:404]     Test net output #1: loss = 1.48174 (* 1 = 1.48174 loss)
I0413 17:30:34.181901 22640 solver.cpp:228] Iteration 40, loss = 1.10201
I0413 17:30:34.181946 22640 solver.cpp:244]     Train net output #0: accuracy = 0.609375
I0413 17:30:34.181958 22640 solver.cpp:244]     Train net output #1: loss = 1.10201 (* 1 = 1.10201 loss)
I0413 17:30:34.181972 22640 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 17:30:38.640372 22640 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 17:30:40.700074 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4878
I0413 17:30:40.700146 22640 solver.cpp:404]     Test net output #1: loss = 1.9471 (* 1 = 1.9471 loss)
I0413 17:30:40.829895 22640 solver.cpp:228] Iteration 60, loss = 1.04116
I0413 17:30:40.829943 22640 solver.cpp:244]     Train net output #0: accuracy = 0.652344
I0413 17:30:40.829958 22640 solver.cpp:244]     Train net output #1: loss = 1.04116 (* 1 = 1.04116 loss)
I0413 17:30:40.829973 22640 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 17:30:45.049909 22640 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 17:30:47.329311 22640 solver.cpp:404]     Test net output #0: accuracy = 0.578
I0413 17:30:47.329362 22640 solver.cpp:404]     Test net output #1: loss = 1.28166 (* 1 = 1.28166 loss)
I0413 17:30:47.494518 22640 solver.cpp:228] Iteration 80, loss = 0.927698
I0413 17:30:47.494562 22640 solver.cpp:244]     Train net output #0: accuracy = 0.671875
I0413 17:30:47.494575 22640 solver.cpp:244]     Train net output #1: loss = 0.927698 (* 1 = 0.927698 loss)
I0413 17:30:47.494586 22640 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 17:30:51.663990 22640 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 17:30:53.729358 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5006
I0413 17:30:53.729429 22640 solver.cpp:404]     Test net output #1: loss = 2.156 (* 1 = 2.156 loss)
I0413 17:30:53.853951 22640 solver.cpp:228] Iteration 100, loss = 0.898716
I0413 17:30:53.853999 22640 solver.cpp:244]     Train net output #0: accuracy = 0.648438
I0413 17:30:53.854012 22640 solver.cpp:244]     Train net output #1: loss = 0.898716 (* 1 = 0.898716 loss)
I0413 17:30:53.854022 22640 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 17:30:58.314324 22640 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 17:31:00.500092 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6272
I0413 17:31:00.500138 22640 solver.cpp:404]     Test net output #1: loss = 1.20593 (* 1 = 1.20593 loss)
I0413 17:31:00.625390 22640 solver.cpp:228] Iteration 120, loss = 1.00686
I0413 17:31:00.625438 22640 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0413 17:31:00.625454 22640 solver.cpp:244]     Train net output #1: loss = 1.00686 (* 1 = 1.00686 loss)
I0413 17:31:00.625464 22640 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 17:31:04.696508 22640 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 17:31:07.007364 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5936
I0413 17:31:07.007411 22640 solver.cpp:404]     Test net output #1: loss = 1.52439 (* 1 = 1.52439 loss)
I0413 17:31:07.134994 22640 solver.cpp:228] Iteration 140, loss = 0.823485
I0413 17:31:07.135038 22640 solver.cpp:244]     Train net output #0: accuracy = 0.699219
I0413 17:31:07.135051 22640 solver.cpp:244]     Train net output #1: loss = 0.823485 (* 1 = 0.823485 loss)
I0413 17:31:07.135063 22640 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 17:31:11.484257 22640 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 17:31:13.443102 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5742
I0413 17:31:13.443152 22640 solver.cpp:404]     Test net output #1: loss = 1.50727 (* 1 = 1.50727 loss)
I0413 17:31:13.575963 22640 solver.cpp:228] Iteration 160, loss = 0.91362
I0413 17:31:13.576009 22640 solver.cpp:244]     Train net output #0: accuracy = 0.671875
I0413 17:31:13.576021 22640 solver.cpp:244]     Train net output #1: loss = 0.91362 (* 1 = 0.91362 loss)
I0413 17:31:13.576032 22640 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 17:31:17.972476 22640 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 17:31:20.238106 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5983
I0413 17:31:20.238150 22640 solver.cpp:404]     Test net output #1: loss = 1.36746 (* 1 = 1.36746 loss)
I0413 17:31:20.401583 22640 solver.cpp:228] Iteration 180, loss = 0.914742
I0413 17:31:20.401629 22640 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:31:20.401643 22640 solver.cpp:244]     Train net output #1: loss = 0.914742 (* 1 = 0.914742 loss)
I0413 17:31:20.401651 22640 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 17:31:24.422896 22640 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 17:31:26.669747 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4768
I0413 17:31:26.669805 22640 solver.cpp:404]     Test net output #1: loss = 2.51657 (* 1 = 2.51657 loss)
I0413 17:31:26.794739 22640 solver.cpp:228] Iteration 200, loss = 0.788779
I0413 17:31:26.794759 22640 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:31:26.794769 22640 solver.cpp:244]     Train net output #1: loss = 0.788779 (* 1 = 0.788779 loss)
I0413 17:31:26.794778 22640 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 17:31:31.256499 22640 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 17:31:33.258229 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5622
I0413 17:31:33.258275 22640 solver.cpp:404]     Test net output #1: loss = 1.62448 (* 1 = 1.62448 loss)
I0413 17:31:33.392499 22640 solver.cpp:228] Iteration 220, loss = 0.773816
I0413 17:31:33.392549 22640 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:31:33.392566 22640 solver.cpp:244]     Train net output #1: loss = 0.773816 (* 1 = 0.773816 loss)
I0413 17:31:33.392578 22640 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 17:31:37.614233 22640 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 17:31:39.874498 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5849
I0413 17:31:39.874549 22640 solver.cpp:404]     Test net output #1: loss = 1.65915 (* 1 = 1.65915 loss)
I0413 17:31:40.036753 22640 solver.cpp:228] Iteration 240, loss = 0.734011
I0413 17:31:40.036774 22640 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:31:40.036784 22640 solver.cpp:244]     Train net output #1: loss = 0.734011 (* 1 = 0.734011 loss)
I0413 17:31:40.036797 22640 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 17:31:44.247076 22640 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 17:31:46.327688 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5345
I0413 17:31:46.327739 22640 solver.cpp:404]     Test net output #1: loss = 1.70829 (* 1 = 1.70829 loss)
I0413 17:31:46.454848 22640 solver.cpp:228] Iteration 260, loss = 0.863685
I0413 17:31:46.454907 22640 solver.cpp:244]     Train net output #0: accuracy = 0.671875
I0413 17:31:46.454923 22640 solver.cpp:244]     Train net output #1: loss = 0.863685 (* 1 = 0.863685 loss)
I0413 17:31:46.454937 22640 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 17:31:50.914712 22640 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 17:31:53.093017 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5524
I0413 17:31:53.093078 22640 solver.cpp:404]     Test net output #1: loss = 1.85162 (* 1 = 1.85162 loss)
I0413 17:31:53.224442 22640 solver.cpp:228] Iteration 280, loss = 0.870754
I0413 17:31:53.224494 22640 solver.cpp:244]     Train net output #0: accuracy = 0.683594
I0413 17:31:53.224520 22640 solver.cpp:244]     Train net output #1: loss = 0.870754 (* 1 = 0.870754 loss)
I0413 17:31:53.224535 22640 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 17:31:57.298925 22640 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 17:31:59.578905 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5778
I0413 17:31:59.578958 22640 solver.cpp:404]     Test net output #1: loss = 1.58693 (* 1 = 1.58693 loss)
I0413 17:31:59.739182 22640 solver.cpp:228] Iteration 300, loss = 0.839508
I0413 17:31:59.739217 22640 solver.cpp:244]     Train net output #0: accuracy = 0.695312
I0413 17:31:59.739228 22640 solver.cpp:244]     Train net output #1: loss = 0.839508 (* 1 = 0.839508 loss)
I0413 17:31:59.739238 22640 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 17:32:04.094594 22640 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 17:32:06.061221 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5444
I0413 17:32:06.061266 22640 solver.cpp:404]     Test net output #1: loss = 1.8867 (* 1 = 1.8867 loss)
I0413 17:32:06.194025 22640 solver.cpp:228] Iteration 320, loss = 0.823469
I0413 17:32:06.194092 22640 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:32:06.194108 22640 solver.cpp:244]     Train net output #1: loss = 0.823469 (* 1 = 0.823469 loss)
I0413 17:32:06.194120 22640 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 17:32:10.589802 22640 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 17:32:12.806257 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5046
I0413 17:32:12.806315 22640 solver.cpp:404]     Test net output #1: loss = 1.96261 (* 1 = 1.96261 loss)
I0413 17:32:12.936532 22640 solver.cpp:228] Iteration 340, loss = 0.862819
I0413 17:32:12.936569 22640 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:32:12.936583 22640 solver.cpp:244]     Train net output #1: loss = 0.862819 (* 1 = 0.862819 loss)
I0413 17:32:12.936596 22640 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 17:32:17.006054 22640 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 17:32:19.215767 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5591
I0413 17:32:19.215811 22640 solver.cpp:404]     Test net output #1: loss = 1.53808 (* 1 = 1.53808 loss)
I0413 17:32:19.372828 22640 solver.cpp:228] Iteration 360, loss = 0.698218
I0413 17:32:19.372886 22640 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:32:19.372902 22640 solver.cpp:244]     Train net output #1: loss = 0.698218 (* 1 = 0.698218 loss)
I0413 17:32:19.372915 22640 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 17:32:23.779500 22640 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 17:32:25.834215 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5725
I0413 17:32:25.834272 22640 solver.cpp:404]     Test net output #1: loss = 1.58518 (* 1 = 1.58518 loss)
I0413 17:32:25.966523 22640 solver.cpp:228] Iteration 380, loss = 0.866315
I0413 17:32:25.966578 22640 solver.cpp:244]     Train net output #0: accuracy = 0.703125
I0413 17:32:25.966593 22640 solver.cpp:244]     Train net output #1: loss = 0.866315 (* 1 = 0.866315 loss)
I0413 17:32:25.966604 22640 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 17:32:30.193544 22640 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 17:32:32.442052 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5178
I0413 17:32:32.442114 22640 solver.cpp:404]     Test net output #1: loss = 2.07489 (* 1 = 2.07489 loss)
I0413 17:32:32.579278 22640 solver.cpp:228] Iteration 400, loss = 0.618288
I0413 17:32:32.579299 22640 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:32:32.579310 22640 solver.cpp:244]     Train net output #1: loss = 0.618288 (* 1 = 0.618288 loss)
I0413 17:32:32.579320 22640 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 17:32:36.841800 22640 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 17:32:38.926066 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5997
I0413 17:32:38.926113 22640 solver.cpp:404]     Test net output #1: loss = 1.40341 (* 1 = 1.40341 loss)
I0413 17:32:39.044229 22640 solver.cpp:228] Iteration 420, loss = 0.781716
I0413 17:32:39.044247 22640 solver.cpp:244]     Train net output #0: accuracy = 0.714844
I0413 17:32:39.044256 22640 solver.cpp:244]     Train net output #1: loss = 0.781716 (* 1 = 0.781716 loss)
I0413 17:32:39.044265 22640 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 17:32:43.510211 22640 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 17:32:45.693946 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4936
I0413 17:32:45.693995 22640 solver.cpp:404]     Test net output #1: loss = 1.97489 (* 1 = 1.97489 loss)
I0413 17:32:45.830317 22640 solver.cpp:228] Iteration 440, loss = 0.647795
I0413 17:32:45.830384 22640 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:32:45.830409 22640 solver.cpp:244]     Train net output #1: loss = 0.647795 (* 1 = 0.647795 loss)
I0413 17:32:45.830430 22640 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 17:32:49.860254 22640 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 17:32:52.116279 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6099
I0413 17:32:52.116349 22640 solver.cpp:404]     Test net output #1: loss = 1.39125 (* 1 = 1.39125 loss)
I0413 17:32:52.275055 22640 solver.cpp:228] Iteration 460, loss = 0.770875
I0413 17:32:52.275089 22640 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:32:52.275100 22640 solver.cpp:244]     Train net output #1: loss = 0.770875 (* 1 = 0.770875 loss)
I0413 17:32:52.275110 22640 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 17:32:56.633154 22640 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 17:32:58.585131 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5581
I0413 17:32:58.585175 22640 solver.cpp:404]     Test net output #1: loss = 1.72157 (* 1 = 1.72157 loss)
I0413 17:32:58.719944 22640 solver.cpp:228] Iteration 480, loss = 0.73188
I0413 17:32:58.719986 22640 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:32:58.719997 22640 solver.cpp:244]     Train net output #1: loss = 0.73188 (* 1 = 0.73188 loss)
I0413 17:32:58.720007 22640 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 17:33:03.066400 22640 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 17:33:05.347630 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5966
I0413 17:33:05.347694 22640 solver.cpp:404]     Test net output #1: loss = 1.41601 (* 1 = 1.41601 loss)
I0413 17:33:05.487081 22640 solver.cpp:228] Iteration 500, loss = 0.693563
I0413 17:33:05.487100 22640 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:33:05.487112 22640 solver.cpp:244]     Train net output #1: loss = 0.693563 (* 1 = 0.693563 loss)
I0413 17:33:05.487120 22640 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 17:33:09.555444 22640 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 17:33:11.736022 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6156
I0413 17:33:11.736064 22640 solver.cpp:404]     Test net output #1: loss = 1.31126 (* 1 = 1.31126 loss)
I0413 17:33:11.881758 22640 solver.cpp:228] Iteration 520, loss = 0.857576
I0413 17:33:11.881817 22640 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:33:11.881830 22640 solver.cpp:244]     Train net output #1: loss = 0.857576 (* 1 = 0.857576 loss)
I0413 17:33:11.881841 22640 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 17:33:16.306715 22640 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 17:33:18.359370 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5151
I0413 17:33:18.359427 22640 solver.cpp:404]     Test net output #1: loss = 1.80732 (* 1 = 1.80732 loss)
I0413 17:33:18.485347 22640 solver.cpp:228] Iteration 540, loss = 0.749034
I0413 17:33:18.485375 22640 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:33:18.485388 22640 solver.cpp:244]     Train net output #1: loss = 0.749034 (* 1 = 0.749034 loss)
I0413 17:33:18.485401 22640 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 17:33:22.661504 22640 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 17:33:24.941001 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5383
I0413 17:33:24.941040 22640 solver.cpp:404]     Test net output #1: loss = 1.68494 (* 1 = 1.68494 loss)
I0413 17:33:25.104156 22640 solver.cpp:228] Iteration 560, loss = 0.813005
I0413 17:33:25.104194 22640 solver.cpp:244]     Train net output #0: accuracy = 0.707031
I0413 17:33:25.104207 22640 solver.cpp:244]     Train net output #1: loss = 0.813005 (* 1 = 0.813005 loss)
I0413 17:33:25.104215 22640 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 17:33:29.327682 22640 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 17:33:31.345682 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5507
I0413 17:33:31.345742 22640 solver.cpp:404]     Test net output #1: loss = 1.71467 (* 1 = 1.71467 loss)
I0413 17:33:31.493746 22640 solver.cpp:228] Iteration 580, loss = 0.731808
I0413 17:33:31.493849 22640 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:33:31.493870 22640 solver.cpp:244]     Train net output #1: loss = 0.731808 (* 1 = 0.731808 loss)
I0413 17:33:31.493883 22640 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 17:33:35.937557 22640 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 17:33:38.162557 22640 solver.cpp:404]     Test net output #0: accuracy = 0.447
I0413 17:33:38.162600 22640 solver.cpp:404]     Test net output #1: loss = 2.86141 (* 1 = 2.86141 loss)
I0413 17:33:38.285158 22640 solver.cpp:228] Iteration 600, loss = 0.679542
I0413 17:33:38.285181 22640 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:33:38.285192 22640 solver.cpp:244]     Train net output #1: loss = 0.679542 (* 1 = 0.679542 loss)
I0413 17:33:38.285202 22640 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 17:33:42.357535 22640 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 17:33:44.626715 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6134
I0413 17:33:44.626761 22640 solver.cpp:404]     Test net output #1: loss = 1.38122 (* 1 = 1.38122 loss)
I0413 17:33:44.755296 22640 solver.cpp:228] Iteration 620, loss = 0.73739
I0413 17:33:44.755347 22640 solver.cpp:244]     Train net output #0: accuracy = 0.726562
I0413 17:33:44.755362 22640 solver.cpp:244]     Train net output #1: loss = 0.73739 (* 1 = 0.73739 loss)
I0413 17:33:44.755373 22640 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 17:33:49.128051 22640 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 17:33:51.131898 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4944
I0413 17:33:51.131963 22640 solver.cpp:404]     Test net output #1: loss = 2.2911 (* 1 = 2.2911 loss)
I0413 17:33:51.263775 22640 solver.cpp:228] Iteration 640, loss = 0.71983
I0413 17:33:51.263835 22640 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:33:51.263854 22640 solver.cpp:244]     Train net output #1: loss = 0.71983 (* 1 = 0.71983 loss)
I0413 17:33:51.263870 22640 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 17:33:55.637209 22640 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 17:33:57.914649 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5412
I0413 17:33:57.914757 22640 solver.cpp:404]     Test net output #1: loss = 1.83376 (* 1 = 1.83376 loss)
I0413 17:33:58.054059 22640 solver.cpp:228] Iteration 660, loss = 0.883317
I0413 17:33:58.054107 22640 solver.cpp:244]     Train net output #0: accuracy = 0.691406
I0413 17:33:58.054121 22640 solver.cpp:244]     Train net output #1: loss = 0.883317 (* 1 = 0.883317 loss)
I0413 17:33:58.054136 22640 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 17:34:02.097309 22640 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 17:34:04.270438 22640 solver.cpp:404]     Test net output #0: accuracy = 0.457
I0413 17:34:04.270488 22640 solver.cpp:404]     Test net output #1: loss = 2.34702 (* 1 = 2.34702 loss)
I0413 17:34:04.420397 22640 solver.cpp:228] Iteration 680, loss = 0.593568
I0413 17:34:04.420442 22640 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:34:04.420454 22640 solver.cpp:244]     Train net output #1: loss = 0.593568 (* 1 = 0.593568 loss)
I0413 17:34:04.420475 22640 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 17:34:08.854408 22640 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 17:34:10.945521 22640 solver.cpp:404]     Test net output #0: accuracy = 0.496
I0413 17:34:10.945569 22640 solver.cpp:404]     Test net output #1: loss = 2.05507 (* 1 = 2.05507 loss)
I0413 17:34:11.078068 22640 solver.cpp:228] Iteration 700, loss = 0.523183
I0413 17:34:11.078115 22640 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:34:11.078130 22640 solver.cpp:244]     Train net output #1: loss = 0.523183 (* 1 = 0.523183 loss)
I0413 17:34:11.078142 22640 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 17:34:15.283159 22640 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 17:34:17.543457 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5213
I0413 17:34:17.543498 22640 solver.cpp:404]     Test net output #1: loss = 1.75003 (* 1 = 1.75003 loss)
I0413 17:34:17.687386 22640 solver.cpp:228] Iteration 720, loss = 0.658361
I0413 17:34:17.687427 22640 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:34:17.687440 22640 solver.cpp:244]     Train net output #1: loss = 0.658361 (* 1 = 0.658361 loss)
I0413 17:34:17.687451 22640 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 17:34:21.922852 22640 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 17:34:24.012305 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4688
I0413 17:34:24.012358 22640 solver.cpp:404]     Test net output #1: loss = 1.91754 (* 1 = 1.91754 loss)
I0413 17:34:24.135893 22640 solver.cpp:228] Iteration 740, loss = 0.72835
I0413 17:34:24.135913 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:34:24.135923 22640 solver.cpp:244]     Train net output #1: loss = 0.72835 (* 1 = 0.72835 loss)
I0413 17:34:24.135932 22640 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 17:34:28.601630 22640 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 17:34:30.778304 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5768
I0413 17:34:30.778352 22640 solver.cpp:404]     Test net output #1: loss = 1.7111 (* 1 = 1.7111 loss)
I0413 17:34:30.913321 22640 solver.cpp:228] Iteration 760, loss = 0.692729
I0413 17:34:30.913363 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:34:30.913377 22640 solver.cpp:244]     Train net output #1: loss = 0.692729 (* 1 = 0.692729 loss)
I0413 17:34:30.913388 22640 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 17:34:34.977869 22640 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 17:34:37.215572 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6279
I0413 17:34:37.215620 22640 solver.cpp:404]     Test net output #1: loss = 1.2456 (* 1 = 1.2456 loss)
I0413 17:34:37.378355 22640 solver.cpp:228] Iteration 780, loss = 0.668284
I0413 17:34:37.378442 22640 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:34:37.378463 22640 solver.cpp:244]     Train net output #1: loss = 0.668284 (* 1 = 0.668284 loss)
I0413 17:34:37.378479 22640 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 17:34:41.712916 22640 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 17:34:43.661409 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5223
I0413 17:34:43.661458 22640 solver.cpp:404]     Test net output #1: loss = 2.06556 (* 1 = 2.06556 loss)
I0413 17:34:43.791007 22640 solver.cpp:228] Iteration 800, loss = 0.796955
I0413 17:34:43.791028 22640 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 17:34:43.791038 22640 solver.cpp:244]     Train net output #1: loss = 0.796955 (* 1 = 0.796955 loss)
I0413 17:34:43.791049 22640 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 17:34:48.165720 22640 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 17:34:50.418944 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5304
I0413 17:34:50.418987 22640 solver.cpp:404]     Test net output #1: loss = 2.00298 (* 1 = 2.00298 loss)
I0413 17:34:50.561642 22640 solver.cpp:228] Iteration 820, loss = 0.695034
I0413 17:34:50.561681 22640 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:34:50.561702 22640 solver.cpp:244]     Train net output #1: loss = 0.695034 (* 1 = 0.695034 loss)
I0413 17:34:50.561712 22640 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 17:34:54.597801 22640 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 17:34:56.795737 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6393
I0413 17:34:56.795806 22640 solver.cpp:404]     Test net output #1: loss = 1.27656 (* 1 = 1.27656 loss)
I0413 17:34:56.958170 22640 solver.cpp:228] Iteration 840, loss = 0.750278
I0413 17:34:56.958264 22640 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:34:56.958287 22640 solver.cpp:244]     Train net output #1: loss = 0.750278 (* 1 = 0.750278 loss)
I0413 17:34:56.958375 22640 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 17:35:01.373785 22640 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 17:35:03.422493 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4749
I0413 17:35:03.422547 22640 solver.cpp:404]     Test net output #1: loss = 2.35139 (* 1 = 2.35139 loss)
I0413 17:35:03.557446 22640 solver.cpp:228] Iteration 860, loss = 0.716867
I0413 17:35:03.557497 22640 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:35:03.557509 22640 solver.cpp:244]     Train net output #1: loss = 0.716867 (* 1 = 0.716867 loss)
I0413 17:35:03.557524 22640 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 17:35:07.787855 22640 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 17:35:10.032518 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4965
I0413 17:35:10.032563 22640 solver.cpp:404]     Test net output #1: loss = 2.4574 (* 1 = 2.4574 loss)
I0413 17:35:10.175468 22640 solver.cpp:228] Iteration 880, loss = 0.626384
I0413 17:35:10.175515 22640 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:35:10.175529 22640 solver.cpp:244]     Train net output #1: loss = 0.626384 (* 1 = 0.626384 loss)
I0413 17:35:10.175540 22640 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 17:35:14.386386 22640 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 17:35:16.424757 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5669
I0413 17:35:16.424804 22640 solver.cpp:404]     Test net output #1: loss = 1.58742 (* 1 = 1.58742 loss)
I0413 17:35:16.590886 22640 solver.cpp:228] Iteration 900, loss = 0.674748
I0413 17:35:16.590937 22640 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:35:16.590950 22640 solver.cpp:244]     Train net output #1: loss = 0.674748 (* 1 = 0.674748 loss)
I0413 17:35:16.590960 22640 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 17:35:20.975766 22640 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 17:35:23.202431 22640 solver.cpp:404]     Test net output #0: accuracy = 0.553
I0413 17:35:23.202488 22640 solver.cpp:404]     Test net output #1: loss = 1.96433 (* 1 = 1.96433 loss)
I0413 17:35:23.326961 22640 solver.cpp:228] Iteration 920, loss = 0.652387
I0413 17:35:23.326982 22640 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:35:23.326992 22640 solver.cpp:244]     Train net output #1: loss = 0.652387 (* 1 = 0.652387 loss)
I0413 17:35:23.327004 22640 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 17:35:27.360255 22640 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 17:35:29.646813 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4457
I0413 17:35:29.646885 22640 solver.cpp:404]     Test net output #1: loss = 2.32387 (* 1 = 2.32387 loss)
I0413 17:35:29.773468 22640 solver.cpp:228] Iteration 940, loss = 0.687596
I0413 17:35:29.773517 22640 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:35:29.773535 22640 solver.cpp:244]     Train net output #1: loss = 0.687596 (* 1 = 0.687596 loss)
I0413 17:35:29.773546 22640 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 17:35:34.157132 22640 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 17:35:36.122262 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5464
I0413 17:35:36.122313 22640 solver.cpp:404]     Test net output #1: loss = 1.76003 (* 1 = 1.76003 loss)
I0413 17:35:36.253501 22640 solver.cpp:228] Iteration 960, loss = 0.614289
I0413 17:35:36.253533 22640 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:35:36.253545 22640 solver.cpp:244]     Train net output #1: loss = 0.614289 (* 1 = 0.614289 loss)
I0413 17:35:36.253556 22640 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 17:35:40.607440 22640 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 17:35:42.903934 22640 solver.cpp:404]     Test net output #0: accuracy = 0.457
I0413 17:35:42.904002 22640 solver.cpp:404]     Test net output #1: loss = 2.46789 (* 1 = 2.46789 loss)
I0413 17:35:43.045594 22640 solver.cpp:228] Iteration 980, loss = 0.640317
I0413 17:35:43.045621 22640 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:35:43.045634 22640 solver.cpp:244]     Train net output #1: loss = 0.640317 (* 1 = 0.640317 loss)
I0413 17:35:43.045646 22640 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 17:35:47.129106 22640 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 17:35:49.306834 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5712
I0413 17:35:49.306887 22640 solver.cpp:404]     Test net output #1: loss = 1.90644 (* 1 = 1.90644 loss)
I0413 17:35:49.459539 22640 solver.cpp:228] Iteration 1000, loss = 0.640775
I0413 17:35:49.459560 22640 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:35:49.459570 22640 solver.cpp:244]     Train net output #1: loss = 0.640775 (* 1 = 0.640775 loss)
I0413 17:35:49.459580 22640 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 17:35:53.892506 22640 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 17:35:55.955888 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5703
I0413 17:35:55.955960 22640 solver.cpp:404]     Test net output #1: loss = 1.72074 (* 1 = 1.72074 loss)
I0413 17:35:56.083048 22640 solver.cpp:228] Iteration 1020, loss = 0.687195
I0413 17:35:56.083096 22640 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:35:56.083112 22640 solver.cpp:244]     Train net output #1: loss = 0.687195 (* 1 = 0.687195 loss)
I0413 17:35:56.083122 22640 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 17:36:00.293272 22640 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 17:36:02.570080 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4777
I0413 17:36:02.570135 22640 solver.cpp:404]     Test net output #1: loss = 2.2927 (* 1 = 2.2927 loss)
I0413 17:36:02.690676 22640 solver.cpp:228] Iteration 1040, loss = 0.699724
I0413 17:36:02.690723 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:36:02.690738 22640 solver.cpp:244]     Train net output #1: loss = 0.699724 (* 1 = 0.699724 loss)
I0413 17:36:02.690750 22640 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 17:36:06.884467 22640 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 17:36:08.922436 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4036
I0413 17:36:08.922480 22640 solver.cpp:404]     Test net output #1: loss = 3.75441 (* 1 = 3.75441 loss)
I0413 17:36:09.081969 22640 solver.cpp:228] Iteration 1060, loss = 0.708975
I0413 17:36:09.082027 22640 solver.cpp:244]     Train net output #0: accuracy = 0.722656
I0413 17:36:09.082047 22640 solver.cpp:244]     Train net output #1: loss = 0.708975 (* 1 = 0.708975 loss)
I0413 17:36:09.082062 22640 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 17:36:13.549600 22640 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 17:36:15.759932 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4117
I0413 17:36:15.759995 22640 solver.cpp:404]     Test net output #1: loss = 3.05792 (* 1 = 3.05792 loss)
I0413 17:36:15.892266 22640 solver.cpp:228] Iteration 1080, loss = 0.635248
I0413 17:36:15.892299 22640 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:36:15.892313 22640 solver.cpp:244]     Train net output #1: loss = 0.635248 (* 1 = 0.635248 loss)
I0413 17:36:15.892329 22640 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 17:36:19.954718 22640 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 17:36:22.213104 22640 solver.cpp:404]     Test net output #0: accuracy = 0.4377
I0413 17:36:22.213167 22640 solver.cpp:404]     Test net output #1: loss = 2.97676 (* 1 = 2.97676 loss)
I0413 17:36:22.360807 22640 solver.cpp:228] Iteration 1100, loss = 0.576748
I0413 17:36:22.360852 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:36:22.360863 22640 solver.cpp:244]     Train net output #1: loss = 0.576748 (* 1 = 0.576748 loss)
I0413 17:36:22.360872 22640 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 17:36:26.723109 22640 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 17:36:28.690856 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5412
I0413 17:36:28.690901 22640 solver.cpp:404]     Test net output #1: loss = 1.91274 (* 1 = 1.91274 loss)
I0413 17:36:28.817030 22640 solver.cpp:228] Iteration 1120, loss = 0.787731
I0413 17:36:28.817049 22640 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:36:28.817057 22640 solver.cpp:244]     Train net output #1: loss = 0.787731 (* 1 = 0.787731 loss)
I0413 17:36:28.817065 22640 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 17:36:33.162672 22640 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 17:36:35.446975 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5486
I0413 17:36:35.447057 22640 solver.cpp:404]     Test net output #1: loss = 1.67243 (* 1 = 1.67243 loss)
I0413 17:36:35.581364 22640 solver.cpp:228] Iteration 1140, loss = 0.739264
I0413 17:36:35.581393 22640 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:36:35.581404 22640 solver.cpp:244]     Train net output #1: loss = 0.739264 (* 1 = 0.739264 loss)
I0413 17:36:35.581418 22640 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 17:36:39.647078 22640 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 17:36:41.834760 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5432
I0413 17:36:41.834815 22640 solver.cpp:404]     Test net output #1: loss = 1.6398 (* 1 = 1.6398 loss)
I0413 17:36:41.988029 22640 solver.cpp:228] Iteration 1160, loss = 0.641703
I0413 17:36:41.988073 22640 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:36:41.988085 22640 solver.cpp:244]     Train net output #1: loss = 0.641703 (* 1 = 0.641703 loss)
I0413 17:36:41.988095 22640 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 17:36:46.423135 22640 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 17:36:48.440619 22640 solver.cpp:404]     Test net output #0: accuracy = 0.505
I0413 17:36:48.440665 22640 solver.cpp:404]     Test net output #1: loss = 2.0689 (* 1 = 2.0689 loss)
I0413 17:36:48.566360 22640 solver.cpp:228] Iteration 1180, loss = 0.531677
I0413 17:36:48.566411 22640 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:36:48.566426 22640 solver.cpp:244]     Train net output #1: loss = 0.531677 (* 1 = 0.531677 loss)
I0413 17:36:48.566438 22640 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 17:36:52.753689 22640 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 17:36:55.018472 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5923
I0413 17:36:55.018532 22640 solver.cpp:404]     Test net output #1: loss = 1.48441 (* 1 = 1.48441 loss)
I0413 17:36:55.183168 22640 solver.cpp:228] Iteration 1200, loss = 0.63532
I0413 17:36:55.183207 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:36:55.183218 22640 solver.cpp:244]     Train net output #1: loss = 0.63532 (* 1 = 0.63532 loss)
I0413 17:36:55.183228 22640 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 17:36:59.403518 22640 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 17:37:01.414268 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6239
I0413 17:37:01.414309 22640 solver.cpp:404]     Test net output #1: loss = 1.26131 (* 1 = 1.26131 loss)
I0413 17:37:01.559000 22640 solver.cpp:228] Iteration 1220, loss = 0.636769
I0413 17:37:01.559052 22640 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:37:01.559064 22640 solver.cpp:244]     Train net output #1: loss = 0.636769 (* 1 = 0.636769 loss)
I0413 17:37:01.559087 22640 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 17:37:06.026371 22640 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 17:37:08.254228 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5667
I0413 17:37:08.254276 22640 solver.cpp:404]     Test net output #1: loss = 1.57486 (* 1 = 1.57486 loss)
I0413 17:37:08.384197 22640 solver.cpp:228] Iteration 1240, loss = 0.696846
I0413 17:37:08.384238 22640 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:37:08.384253 22640 solver.cpp:244]     Train net output #1: loss = 0.696846 (* 1 = 0.696846 loss)
I0413 17:37:08.384264 22640 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 17:37:12.441402 22640 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 17:37:14.722553 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6466
I0413 17:37:14.722610 22640 solver.cpp:404]     Test net output #1: loss = 1.35199 (* 1 = 1.35199 loss)
I0413 17:37:14.843720 22640 solver.cpp:228] Iteration 1260, loss = 0.691145
I0413 17:37:14.843770 22640 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:37:14.843783 22640 solver.cpp:244]     Train net output #1: loss = 0.691145 (* 1 = 0.691145 loss)
I0413 17:37:14.843796 22640 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 17:37:19.269078 22640 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 17:37:21.237284 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5364
I0413 17:37:21.237334 22640 solver.cpp:404]     Test net output #1: loss = 2.4238 (* 1 = 2.4238 loss)
I0413 17:37:21.370976 22640 solver.cpp:228] Iteration 1280, loss = 0.565116
I0413 17:37:21.371026 22640 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:37:21.371037 22640 solver.cpp:244]     Train net output #1: loss = 0.565116 (* 1 = 0.565116 loss)
I0413 17:37:21.371052 22640 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 17:37:25.723745 22640 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 17:37:28.001649 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6874
I0413 17:37:28.001703 22640 solver.cpp:404]     Test net output #1: loss = 1.04407 (* 1 = 1.04407 loss)
I0413 17:37:28.137094 22640 solver.cpp:228] Iteration 1300, loss = 0.717316
I0413 17:37:28.137194 22640 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:37:28.137220 22640 solver.cpp:244]     Train net output #1: loss = 0.717316 (* 1 = 0.717316 loss)
I0413 17:37:28.137234 22640 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 17:37:32.207674 22640 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 17:37:34.390311 22640 solver.cpp:404]     Test net output #0: accuracy = 0.561
I0413 17:37:34.390354 22640 solver.cpp:404]     Test net output #1: loss = 1.61984 (* 1 = 1.61984 loss)
I0413 17:37:34.542188 22640 solver.cpp:228] Iteration 1320, loss = 0.673046
I0413 17:37:34.542229 22640 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:37:34.542242 22640 solver.cpp:244]     Train net output #1: loss = 0.673046 (* 1 = 0.673046 loss)
I0413 17:37:34.542251 22640 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 17:37:38.976241 22640 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 17:37:41.021638 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6061
I0413 17:37:41.021688 22640 solver.cpp:404]     Test net output #1: loss = 1.33783 (* 1 = 1.33783 loss)
I0413 17:37:41.153069 22640 solver.cpp:228] Iteration 1340, loss = 0.721188
I0413 17:37:41.153100 22640 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:37:41.153118 22640 solver.cpp:244]     Train net output #1: loss = 0.721188 (* 1 = 0.721188 loss)
I0413 17:37:41.153131 22640 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 17:37:45.375555 22640 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 17:37:47.639618 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5691
I0413 17:37:47.639703 22640 solver.cpp:404]     Test net output #1: loss = 1.8481 (* 1 = 1.8481 loss)
I0413 17:37:47.766978 22640 solver.cpp:228] Iteration 1360, loss = 0.578156
I0413 17:37:47.767004 22640 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:37:47.767016 22640 solver.cpp:244]     Train net output #1: loss = 0.578156 (* 1 = 0.578156 loss)
I0413 17:37:47.767027 22640 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 17:37:51.986598 22640 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 17:37:54.017099 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6193
I0413 17:37:54.017164 22640 solver.cpp:404]     Test net output #1: loss = 1.37677 (* 1 = 1.37677 loss)
I0413 17:37:54.177522 22640 solver.cpp:228] Iteration 1380, loss = 0.711024
I0413 17:37:54.177579 22640 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:37:54.177595 22640 solver.cpp:244]     Train net output #1: loss = 0.711024 (* 1 = 0.711024 loss)
I0413 17:37:54.177611 22640 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 17:37:58.598242 22640 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 17:38:00.815040 22640 solver.cpp:404]     Test net output #0: accuracy = 0.7075
I0413 17:38:00.815088 22640 solver.cpp:404]     Test net output #1: loss = 0.948358 (* 1 = 0.948358 loss)
I0413 17:38:00.946600 22640 solver.cpp:228] Iteration 1400, loss = 0.645324
I0413 17:38:00.946653 22640 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:38:00.946666 22640 solver.cpp:244]     Train net output #1: loss = 0.645324 (* 1 = 0.645324 loss)
I0413 17:38:00.946677 22640 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 17:38:04.999656 22640 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 17:38:07.251519 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6797
I0413 17:38:07.251572 22640 solver.cpp:404]     Test net output #1: loss = 1.14511 (* 1 = 1.14511 loss)
I0413 17:38:07.399471 22640 solver.cpp:228] Iteration 1420, loss = 0.745503
I0413 17:38:07.399535 22640 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:38:07.399551 22640 solver.cpp:244]     Train net output #1: loss = 0.745503 (* 1 = 0.745503 loss)
I0413 17:38:07.399564 22640 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 17:38:11.759099 22640 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 17:38:13.728330 22640 solver.cpp:404]     Test net output #0: accuracy = 0.533
I0413 17:38:13.728402 22640 solver.cpp:404]     Test net output #1: loss = 1.97395 (* 1 = 1.97395 loss)
I0413 17:38:13.859999 22640 solver.cpp:228] Iteration 1440, loss = 0.594866
I0413 17:38:13.860044 22640 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:38:13.860059 22640 solver.cpp:244]     Train net output #1: loss = 0.594866 (* 1 = 0.594866 loss)
I0413 17:38:13.860069 22640 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 17:38:18.215958 22640 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 17:38:20.505491 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5924
I0413 17:38:20.505533 22640 solver.cpp:404]     Test net output #1: loss = 1.58892 (* 1 = 1.58892 loss)
I0413 17:38:20.645483 22640 solver.cpp:228] Iteration 1460, loss = 0.665511
I0413 17:38:20.645534 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:38:20.645550 22640 solver.cpp:244]     Train net output #1: loss = 0.665511 (* 1 = 0.665511 loss)
I0413 17:38:20.645560 22640 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 17:38:24.724884 22640 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 17:38:26.915097 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6394
I0413 17:38:26.915159 22640 solver.cpp:404]     Test net output #1: loss = 1.35866 (* 1 = 1.35866 loss)
I0413 17:38:27.063535 22640 solver.cpp:228] Iteration 1480, loss = 0.609203
I0413 17:38:27.063585 22640 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:38:27.063599 22640 solver.cpp:244]     Train net output #1: loss = 0.609203 (* 1 = 0.609203 loss)
I0413 17:38:27.063614 22640 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 17:38:31.527158 22640 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 17:38:33.608613 22640 solver.cpp:404]     Test net output #0: accuracy = 0.565
I0413 17:38:33.608670 22640 solver.cpp:404]     Test net output #1: loss = 1.79716 (* 1 = 1.79716 loss)
I0413 17:38:33.742281 22640 solver.cpp:228] Iteration 1500, loss = 0.583656
I0413 17:38:33.742354 22640 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:38:33.742377 22640 solver.cpp:244]     Train net output #1: loss = 0.583656 (* 1 = 0.583656 loss)
I0413 17:38:33.742396 22640 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 17:38:37.947155 22640 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 17:38:40.199070 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5678
I0413 17:38:40.199112 22640 solver.cpp:404]     Test net output #1: loss = 1.75343 (* 1 = 1.75343 loss)
I0413 17:38:40.348423 22640 solver.cpp:228] Iteration 1520, loss = 0.568608
I0413 17:38:40.348464 22640 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:38:40.348476 22640 solver.cpp:244]     Train net output #1: loss = 0.568608 (* 1 = 0.568608 loss)
I0413 17:38:40.348486 22640 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 17:38:44.548815 22640 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 17:38:46.604460 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6475
I0413 17:38:46.604555 22640 solver.cpp:404]     Test net output #1: loss = 1.30069 (* 1 = 1.30069 loss)
I0413 17:38:46.742928 22640 solver.cpp:228] Iteration 1540, loss = 0.650267
I0413 17:38:46.742959 22640 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:38:46.742969 22640 solver.cpp:244]     Train net output #1: loss = 0.650267 (* 1 = 0.650267 loss)
I0413 17:38:46.742981 22640 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 17:38:51.191897 22640 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 17:38:53.414041 22640 solver.cpp:404]     Test net output #0: accuracy = 0.57
I0413 17:38:53.414095 22640 solver.cpp:404]     Test net output #1: loss = 1.89138 (* 1 = 1.89138 loss)
I0413 17:38:53.538435 22640 solver.cpp:228] Iteration 1560, loss = 0.710943
I0413 17:38:53.538492 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:38:53.538508 22640 solver.cpp:244]     Train net output #1: loss = 0.710943 (* 1 = 0.710943 loss)
I0413 17:38:53.538519 22640 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 17:38:57.606166 22640 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 17:38:59.873811 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5645
I0413 17:38:59.873857 22640 solver.cpp:404]     Test net output #1: loss = 1.66721 (* 1 = 1.66721 loss)
I0413 17:39:00.036247 22640 solver.cpp:228] Iteration 1580, loss = 0.644333
I0413 17:39:00.036291 22640 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:39:00.036305 22640 solver.cpp:244]     Train net output #1: loss = 0.644333 (* 1 = 0.644333 loss)
I0413 17:39:00.036316 22640 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 17:39:04.390933 22640 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 17:39:06.374572 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6165
I0413 17:39:06.374625 22640 solver.cpp:404]     Test net output #1: loss = 1.42325 (* 1 = 1.42325 loss)
I0413 17:39:06.507221 22640 solver.cpp:228] Iteration 1600, loss = 0.585552
I0413 17:39:06.507259 22640 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:39:06.507273 22640 solver.cpp:244]     Train net output #1: loss = 0.585552 (* 1 = 0.585552 loss)
I0413 17:39:06.507287 22640 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 17:39:10.889930 22640 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 17:39:13.149485 22640 solver.cpp:404]     Test net output #0: accuracy = 0.7226
I0413 17:39:13.149544 22640 solver.cpp:404]     Test net output #1: loss = 0.845293 (* 1 = 0.845293 loss)
I0413 17:39:13.307453 22640 solver.cpp:228] Iteration 1620, loss = 0.601517
I0413 17:39:13.307485 22640 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:39:13.307499 22640 solver.cpp:244]     Train net output #1: loss = 0.601517 (* 1 = 0.601517 loss)
I0413 17:39:13.307535 22640 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 17:39:17.358675 22640 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 17:39:19.580377 22640 solver.cpp:404]     Test net output #0: accuracy = 0.7121
I0413 17:39:19.580443 22640 solver.cpp:404]     Test net output #1: loss = 0.904558 (* 1 = 0.904558 loss)
I0413 17:39:19.706408 22640 solver.cpp:228] Iteration 1640, loss = 0.629256
I0413 17:39:19.706425 22640 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:39:19.706434 22640 solver.cpp:244]     Train net output #1: loss = 0.629256 (* 1 = 0.629256 loss)
I0413 17:39:19.706444 22640 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 17:39:24.127452 22640 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 17:39:26.199646 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5868
I0413 17:39:26.199698 22640 solver.cpp:404]     Test net output #1: loss = 1.50147 (* 1 = 1.50147 loss)
I0413 17:39:26.328933 22640 solver.cpp:228] Iteration 1660, loss = 0.555957
I0413 17:39:26.328991 22640 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:39:26.329006 22640 solver.cpp:244]     Train net output #1: loss = 0.555957 (* 1 = 0.555957 loss)
I0413 17:39:26.329017 22640 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 17:39:30.554568 22640 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 17:39:32.797719 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6364
I0413 17:39:32.797786 22640 solver.cpp:404]     Test net output #1: loss = 1.15406 (* 1 = 1.15406 loss)
I0413 17:39:32.964972 22640 solver.cpp:228] Iteration 1680, loss = 0.58927
I0413 17:39:32.965018 22640 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:39:32.965029 22640 solver.cpp:244]     Train net output #1: loss = 0.58927 (* 1 = 0.58927 loss)
I0413 17:39:32.965042 22640 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 17:39:37.113284 22640 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 17:39:39.166067 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5278
I0413 17:39:39.166143 22640 solver.cpp:404]     Test net output #1: loss = 1.96895 (* 1 = 1.96895 loss)
I0413 17:39:39.290403 22640 solver.cpp:228] Iteration 1700, loss = 0.617739
I0413 17:39:39.290468 22640 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:39:39.290484 22640 solver.cpp:244]     Train net output #1: loss = 0.617739 (* 1 = 0.617739 loss)
I0413 17:39:39.290498 22640 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 17:39:43.756057 22640 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 17:39:45.929167 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6501
I0413 17:39:45.929239 22640 solver.cpp:404]     Test net output #1: loss = 1.0873 (* 1 = 1.0873 loss)
I0413 17:39:46.053329 22640 solver.cpp:228] Iteration 1720, loss = 0.658683
I0413 17:39:46.053367 22640 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:39:46.053380 22640 solver.cpp:244]     Train net output #1: loss = 0.658683 (* 1 = 0.658683 loss)
I0413 17:39:46.053391 22640 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 17:39:50.127800 22640 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 17:39:52.421934 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6897
I0413 17:39:52.422004 22640 solver.cpp:404]     Test net output #1: loss = 0.978185 (* 1 = 0.978185 loss)
I0413 17:39:52.558554 22640 solver.cpp:228] Iteration 1740, loss = 0.595383
I0413 17:39:52.558583 22640 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:39:52.558598 22640 solver.cpp:244]     Train net output #1: loss = 0.595383 (* 1 = 0.595383 loss)
I0413 17:39:52.558614 22640 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 17:39:56.912989 22640 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 17:39:58.868235 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5456
I0413 17:39:58.868281 22640 solver.cpp:404]     Test net output #1: loss = 1.75157 (* 1 = 1.75157 loss)
I0413 17:39:59.000597 22640 solver.cpp:228] Iteration 1760, loss = 0.815452
I0413 17:39:59.000803 22640 solver.cpp:244]     Train net output #0: accuracy = 0.742188
I0413 17:39:59.000869 22640 solver.cpp:244]     Train net output #1: loss = 0.815452 (* 1 = 0.815452 loss)
I0413 17:39:59.000896 22640 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 17:40:03.398409 22640 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 17:40:05.648617 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5494
I0413 17:40:05.648669 22640 solver.cpp:404]     Test net output #1: loss = 1.85887 (* 1 = 1.85887 loss)
I0413 17:40:05.798203 22640 solver.cpp:228] Iteration 1780, loss = 0.604543
I0413 17:40:05.798249 22640 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:40:05.798262 22640 solver.cpp:244]     Train net output #1: loss = 0.604543 (* 1 = 0.604543 loss)
I0413 17:40:05.798274 22640 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 17:40:09.861611 22640 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 17:40:12.078066 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5289
I0413 17:40:12.078130 22640 solver.cpp:404]     Test net output #1: loss = 1.93337 (* 1 = 1.93337 loss)
I0413 17:40:12.204373 22640 solver.cpp:228] Iteration 1800, loss = 0.633001
I0413 17:40:12.204398 22640 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:40:12.204411 22640 solver.cpp:244]     Train net output #1: loss = 0.633001 (* 1 = 0.633001 loss)
I0413 17:40:12.204421 22640 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 17:40:16.668367 22640 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 17:40:18.659708 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6494
I0413 17:40:18.659749 22640 solver.cpp:404]     Test net output #1: loss = 1.1791 (* 1 = 1.1791 loss)
I0413 17:40:18.785054 22640 solver.cpp:228] Iteration 1820, loss = 0.604001
I0413 17:40:18.785174 22640 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:40:18.785203 22640 solver.cpp:244]     Train net output #1: loss = 0.604001 (* 1 = 0.604001 loss)
I0413 17:40:18.785218 22640 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 17:40:22.984877 22640 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 17:40:25.239650 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5461
I0413 17:40:25.239704 22640 solver.cpp:404]     Test net output #1: loss = 1.53102 (* 1 = 1.53102 loss)
I0413 17:40:25.393695 22640 solver.cpp:228] Iteration 1840, loss = 0.590585
I0413 17:40:25.393757 22640 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:40:25.393772 22640 solver.cpp:244]     Train net output #1: loss = 0.590585 (* 1 = 0.590585 loss)
I0413 17:40:25.393789 22640 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 17:40:29.608494 22640 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 17:40:31.699497 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5322
I0413 17:40:31.699550 22640 solver.cpp:404]     Test net output #1: loss = 1.82135 (* 1 = 1.82135 loss)
I0413 17:40:31.817950 22640 solver.cpp:228] Iteration 1860, loss = 0.571694
I0413 17:40:31.817996 22640 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:40:31.818009 22640 solver.cpp:244]     Train net output #1: loss = 0.571694 (* 1 = 0.571694 loss)
I0413 17:40:31.818022 22640 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 17:40:36.262681 22640 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 17:40:38.443841 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6008
I0413 17:40:38.443883 22640 solver.cpp:404]     Test net output #1: loss = 1.4544 (* 1 = 1.4544 loss)
I0413 17:40:38.576664 22640 solver.cpp:228] Iteration 1880, loss = 0.568807
I0413 17:40:38.576707 22640 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:40:38.576719 22640 solver.cpp:244]     Train net output #1: loss = 0.568807 (* 1 = 0.568807 loss)
I0413 17:40:38.576730 22640 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 17:40:42.628032 22640 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 17:40:44.906435 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6611
I0413 17:40:44.906510 22640 solver.cpp:404]     Test net output #1: loss = 1.17895 (* 1 = 1.17895 loss)
I0413 17:40:45.067654 22640 solver.cpp:228] Iteration 1900, loss = 0.591704
I0413 17:40:45.067710 22640 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:40:45.067725 22640 solver.cpp:244]     Train net output #1: loss = 0.591704 (* 1 = 0.591704 loss)
I0413 17:40:45.067736 22640 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 17:40:49.439342 22640 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 17:40:51.410082 22640 solver.cpp:404]     Test net output #0: accuracy = 0.6805
I0413 17:40:51.410135 22640 solver.cpp:404]     Test net output #1: loss = 1.04793 (* 1 = 1.04793 loss)
I0413 17:40:51.539206 22640 solver.cpp:228] Iteration 1920, loss = 0.691222
I0413 17:40:51.539257 22640 solver.cpp:244]     Train net output #0: accuracy = 0.753906
I0413 17:40:51.539271 22640 solver.cpp:244]     Train net output #1: loss = 0.691222 (* 1 = 0.691222 loss)
I0413 17:40:51.539283 22640 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 17:40:55.944478 22640 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 17:40:58.231454 22640 solver.cpp:404]     Test net output #0: accuracy = 0.666
I0413 17:40:58.231511 22640 solver.cpp:404]     Test net output #1: loss = 1.15626 (* 1 = 1.15626 loss)
I0413 17:40:58.392091 22640 solver.cpp:228] Iteration 1940, loss = 0.527416
I0413 17:40:58.392148 22640 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:40:58.392165 22640 solver.cpp:244]     Train net output #1: loss = 0.527416 (* 1 = 0.527416 loss)
I0413 17:40:58.392181 22640 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 17:41:02.402674 22640 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 17:41:04.649726 22640 solver.cpp:404]     Test net output #0: accuracy = 0.5758
I0413 17:41:04.649780 22640 solver.cpp:404]     Test net output #1: loss = 1.57138 (* 1 = 1.57138 loss)
I0413 17:41:04.783804 22640 solver.cpp:228] Iteration 1960, loss = 0.545753
I0413 17:41:04.783856 22640 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:41:04.783869 22640 solver.cpp:244]     Train net output #1: loss = 0.545753 (* 1 = 0.545753 loss)
I0413 17:41:04.783879 22640 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 17:41:09.225853 22640 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 17:41:11.261523 22640 solver.cpp:404]     Test net output #0: accuracy = 0.632
I0413 17:41:11.261565 22640 solver.cpp:404]     Test net output #1: loss = 1.35857 (* 1 = 1.35857 loss)
I0413 17:41:11.391638 22640 solver.cpp:228] Iteration 1980, loss = 0.618747
I0413 17:41:11.391680 22640 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:41:11.391695 22640 solver.cpp:244]     Train net output #1: loss = 0.618747 (* 1 = 0.618747 loss)
I0413 17:41:11.391705 22640 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 17:41:15.643332 22640 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar3/ResNet-cifar3_iter_2000.caffemodel
I0413 17:41:15.647893 22640 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar3/ResNet-cifar3_iter_2000.solverstate
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 17:41:18.131744 22831 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar4/ResNet-cifar4"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar4.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 17:41:18.131794 22831 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar4.prototxt
I0413 17:41:18.132841 22831 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 17:41:18.133127 22831 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv3_2"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:41:18.133409 22831 layer_factory.hpp:77] Creating layer cifar
I0413 17:41:18.133955 22831 net.cpp:91] Creating Layer cifar
I0413 17:41:18.133970 22831 net.cpp:399] cifar -> data
I0413 17:41:18.133980 22831 net.cpp:399] cifar -> label
I0413 17:41:18.133991 22831 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:41:18.137853 22897 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 17:41:18.173159 22831 data_layer.cpp:41] output data size: 256,3,32,32
I0413 17:41:18.201817 22831 net.cpp:141] Setting up cifar
I0413 17:41:18.201840 22831 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 17:41:18.201848 22831 net.cpp:148] Top shape: 256 (256)
I0413 17:41:18.201853 22831 net.cpp:156] Memory required for data: 3146752
I0413 17:41:18.201861 22831 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:41:18.201889 22831 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:41:18.201895 22831 net.cpp:425] label_cifar_1_split <- label
I0413 17:41:18.201915 22831 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:41:18.201927 22831 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:41:18.201974 22831 net.cpp:141] Setting up label_cifar_1_split
I0413 17:41:18.201982 22831 net.cpp:148] Top shape: 256 (256)
I0413 17:41:18.201987 22831 net.cpp:148] Top shape: 256 (256)
I0413 17:41:18.201989 22831 net.cpp:156] Memory required for data: 3148800
I0413 17:41:18.201993 22831 layer_factory.hpp:77] Creating layer conv1
I0413 17:41:18.202023 22831 net.cpp:91] Creating Layer conv1
I0413 17:41:18.202028 22831 net.cpp:425] conv1 <- data
I0413 17:41:18.202034 22831 net.cpp:399] conv1 -> conv1
I0413 17:41:18.436192 22831 net.cpp:141] Setting up conv1
I0413 17:41:18.436230 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.436235 22831 net.cpp:156] Memory required for data: 19926016
I0413 17:41:18.436255 22831 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:41:18.436270 22831 net.cpp:91] Creating Layer bn_conv1
I0413 17:41:18.436275 22831 net.cpp:425] bn_conv1 <- conv1
I0413 17:41:18.436283 22831 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:41:18.436444 22831 net.cpp:141] Setting up bn_conv1
I0413 17:41:18.436452 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.436456 22831 net.cpp:156] Memory required for data: 36703232
I0413 17:41:18.436468 22831 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:41:18.436478 22831 net.cpp:91] Creating Layer scale_conv1
I0413 17:41:18.436483 22831 net.cpp:425] scale_conv1 <- conv1
I0413 17:41:18.436489 22831 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:41:18.436523 22831 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:41:18.436619 22831 net.cpp:141] Setting up scale_conv1
I0413 17:41:18.436628 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.436632 22831 net.cpp:156] Memory required for data: 53480448
I0413 17:41:18.436640 22831 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:41:18.436647 22831 net.cpp:91] Creating Layer conv1_relu
I0413 17:41:18.436651 22831 net.cpp:425] conv1_relu <- conv1
I0413 17:41:18.436656 22831 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:41:18.436929 22831 net.cpp:141] Setting up conv1_relu
I0413 17:41:18.436944 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.436947 22831 net.cpp:156] Memory required for data: 70257664
I0413 17:41:18.436952 22831 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:41:18.436959 22831 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:41:18.436964 22831 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:41:18.436970 22831 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:41:18.436980 22831 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:41:18.437013 22831 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:41:18.437021 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.437026 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.437031 22831 net.cpp:156] Memory required for data: 103812096
I0413 17:41:18.437034 22831 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:41:18.437046 22831 net.cpp:91] Creating Layer conv2_1a
I0413 17:41:18.437049 22831 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:41:18.437057 22831 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:41:18.440152 22831 net.cpp:141] Setting up conv2_1a
I0413 17:41:18.440167 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.440172 22831 net.cpp:156] Memory required for data: 120589312
I0413 17:41:18.440183 22831 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:41:18.440192 22831 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:41:18.440197 22831 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:41:18.440203 22831 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:41:18.440351 22831 net.cpp:141] Setting up bn_conv2_1a
I0413 17:41:18.440359 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.440363 22831 net.cpp:156] Memory required for data: 137366528
I0413 17:41:18.440371 22831 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:41:18.440378 22831 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:41:18.440382 22831 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:41:18.440388 22831 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:41:18.440418 22831 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:41:18.440505 22831 net.cpp:141] Setting up scale_conv2_1a
I0413 17:41:18.440520 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.440523 22831 net.cpp:156] Memory required for data: 154143744
I0413 17:41:18.440531 22831 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:41:18.440537 22831 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:41:18.440542 22831 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:41:18.440547 22831 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:41:18.441221 22831 net.cpp:141] Setting up conv2_1a_relu
I0413 17:41:18.441237 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.441241 22831 net.cpp:156] Memory required for data: 170920960
I0413 17:41:18.441246 22831 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:41:18.441257 22831 net.cpp:91] Creating Layer conv2_1b
I0413 17:41:18.441263 22831 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:41:18.441270 22831 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:41:18.444774 22831 net.cpp:141] Setting up conv2_1b
I0413 17:41:18.444792 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.444797 22831 net.cpp:156] Memory required for data: 187698176
I0413 17:41:18.444805 22831 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:41:18.444814 22831 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:41:18.444819 22831 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:41:18.444826 22831 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:41:18.444989 22831 net.cpp:141] Setting up bn_conv2_1b
I0413 17:41:18.444998 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.445001 22831 net.cpp:156] Memory required for data: 204475392
I0413 17:41:18.445013 22831 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:41:18.445020 22831 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:41:18.445024 22831 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:41:18.445029 22831 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:41:18.445063 22831 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:41:18.445184 22831 net.cpp:141] Setting up scale_conv2_1b
I0413 17:41:18.445194 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.445199 22831 net.cpp:156] Memory required for data: 221252608
I0413 17:41:18.445205 22831 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:41:18.445214 22831 net.cpp:91] Creating Layer conv2_1
I0413 17:41:18.445219 22831 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:41:18.445224 22831 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:41:18.445231 22831 net.cpp:399] conv2_1 -> conv2_1
I0413 17:41:18.445255 22831 net.cpp:141] Setting up conv2_1
I0413 17:41:18.445264 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.445268 22831 net.cpp:156] Memory required for data: 238029824
I0413 17:41:18.445272 22831 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:41:18.445281 22831 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:41:18.445284 22831 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:41:18.445289 22831 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:41:18.445835 22831 net.cpp:141] Setting up conv2_1_relu
I0413 17:41:18.445847 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.445850 22831 net.cpp:156] Memory required for data: 254807040
I0413 17:41:18.445855 22831 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:41:18.445865 22831 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:41:18.445869 22831 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:41:18.445875 22831 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:41:18.445883 22831 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:41:18.445924 22831 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:41:18.445930 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.445935 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.445940 22831 net.cpp:156] Memory required for data: 288361472
I0413 17:41:18.445943 22831 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:41:18.445960 22831 net.cpp:91] Creating Layer conv2_2a
I0413 17:41:18.445966 22831 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:41:18.445973 22831 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:41:18.449368 22831 net.cpp:141] Setting up conv2_2a
I0413 17:41:18.449385 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.449390 22831 net.cpp:156] Memory required for data: 305138688
I0413 17:41:18.449398 22831 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:41:18.449416 22831 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:41:18.449421 22831 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:41:18.449427 22831 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:41:18.449609 22831 net.cpp:141] Setting up bn_conv2_2a
I0413 17:41:18.449617 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.449621 22831 net.cpp:156] Memory required for data: 321915904
I0413 17:41:18.449630 22831 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:41:18.449636 22831 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:41:18.449640 22831 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:41:18.449646 22831 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:41:18.449678 22831 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:41:18.449777 22831 net.cpp:141] Setting up scale_conv2_2a
I0413 17:41:18.449785 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.449790 22831 net.cpp:156] Memory required for data: 338693120
I0413 17:41:18.449796 22831 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:41:18.449805 22831 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:41:18.449808 22831 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:41:18.449815 22831 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:41:18.450410 22831 net.cpp:141] Setting up conv2_2a_relu
I0413 17:41:18.450423 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.450428 22831 net.cpp:156] Memory required for data: 355470336
I0413 17:41:18.450433 22831 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:41:18.450445 22831 net.cpp:91] Creating Layer conv2_2b
I0413 17:41:18.450450 22831 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:41:18.450458 22831 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:41:18.452828 22831 net.cpp:141] Setting up conv2_2b
I0413 17:41:18.452842 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.452847 22831 net.cpp:156] Memory required for data: 372247552
I0413 17:41:18.452855 22831 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:41:18.452864 22831 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:41:18.452869 22831 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:41:18.452877 22831 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:41:18.453039 22831 net.cpp:141] Setting up bn_conv2_2b
I0413 17:41:18.453047 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.453052 22831 net.cpp:156] Memory required for data: 389024768
I0413 17:41:18.453078 22831 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:41:18.453085 22831 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:41:18.453089 22831 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:41:18.453095 22831 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:41:18.453161 22831 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:41:18.453270 22831 net.cpp:141] Setting up scale_conv2_2b
I0413 17:41:18.453279 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.453284 22831 net.cpp:156] Memory required for data: 405801984
I0413 17:41:18.453290 22831 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:41:18.453297 22831 net.cpp:91] Creating Layer conv2_2
I0413 17:41:18.453302 22831 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:41:18.453307 22831 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:41:18.453315 22831 net.cpp:399] conv2_2 -> conv2_2
I0413 17:41:18.453337 22831 net.cpp:141] Setting up conv2_2
I0413 17:41:18.453346 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.453354 22831 net.cpp:156] Memory required for data: 422579200
I0413 17:41:18.453359 22831 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:41:18.453367 22831 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:41:18.453372 22831 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:41:18.453377 22831 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:41:18.453670 22831 net.cpp:141] Setting up conv2_2_relu
I0413 17:41:18.453683 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.453688 22831 net.cpp:156] Memory required for data: 439356416
I0413 17:41:18.453692 22831 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:41:18.453701 22831 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:41:18.453706 22831 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:41:18.453713 22831 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:41:18.453721 22831 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:41:18.453760 22831 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:41:18.453768 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.453774 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.453778 22831 net.cpp:156] Memory required for data: 472910848
I0413 17:41:18.453783 22831 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:41:18.453794 22831 net.cpp:91] Creating Layer conv2_3a
I0413 17:41:18.453797 22831 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:41:18.453804 22831 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:41:18.456508 22831 net.cpp:141] Setting up conv2_3a
I0413 17:41:18.456523 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.456527 22831 net.cpp:156] Memory required for data: 489688064
I0413 17:41:18.456535 22831 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:41:18.456542 22831 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:41:18.456547 22831 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:41:18.456555 22831 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:41:18.456723 22831 net.cpp:141] Setting up bn_conv2_3a
I0413 17:41:18.456732 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.456735 22831 net.cpp:156] Memory required for data: 506465280
I0413 17:41:18.456743 22831 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:41:18.456750 22831 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:41:18.456754 22831 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:41:18.456759 22831 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:41:18.456792 22831 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:41:18.456890 22831 net.cpp:141] Setting up scale_conv2_3a
I0413 17:41:18.456898 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.456902 22831 net.cpp:156] Memory required for data: 523242496
I0413 17:41:18.456909 22831 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:41:18.456914 22831 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:41:18.456919 22831 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:41:18.456925 22831 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:41:18.457571 22831 net.cpp:141] Setting up conv2_3a_relu
I0413 17:41:18.457583 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.457587 22831 net.cpp:156] Memory required for data: 540019712
I0413 17:41:18.457592 22831 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:41:18.457604 22831 net.cpp:91] Creating Layer conv2_3b
I0413 17:41:18.457609 22831 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:41:18.457617 22831 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:41:18.475071 22831 net.cpp:141] Setting up conv2_3b
I0413 17:41:18.475087 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.475091 22831 net.cpp:156] Memory required for data: 556796928
I0413 17:41:18.475098 22831 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:41:18.475111 22831 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:41:18.475122 22831 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:41:18.475131 22831 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:41:18.475291 22831 net.cpp:141] Setting up bn_conv2_3b
I0413 17:41:18.475299 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.475303 22831 net.cpp:156] Memory required for data: 573574144
I0413 17:41:18.475311 22831 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:41:18.475318 22831 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:41:18.475322 22831 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:41:18.475327 22831 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:41:18.475361 22831 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:41:18.475458 22831 net.cpp:141] Setting up scale_conv2_3b
I0413 17:41:18.475466 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.475469 22831 net.cpp:156] Memory required for data: 590351360
I0413 17:41:18.475476 22831 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:41:18.475481 22831 net.cpp:91] Creating Layer conv2_3
I0413 17:41:18.475486 22831 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:41:18.475491 22831 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:41:18.475497 22831 net.cpp:399] conv2_3 -> conv2_3
I0413 17:41:18.475518 22831 net.cpp:141] Setting up conv2_3
I0413 17:41:18.475527 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.475530 22831 net.cpp:156] Memory required for data: 607128576
I0413 17:41:18.475533 22831 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:41:18.475539 22831 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:41:18.475543 22831 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:41:18.475548 22831 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:41:18.483326 22831 net.cpp:141] Setting up conv2_3_relu
I0413 17:41:18.483340 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.483345 22831 net.cpp:156] Memory required for data: 623905792
I0413 17:41:18.483350 22831 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 17:41:18.483356 22831 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 17:41:18.483361 22831 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 17:41:18.483368 22831 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 17:41:18.483376 22831 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 17:41:18.483414 22831 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 17:41:18.483422 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.483428 22831 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:41:18.483430 22831 net.cpp:156] Memory required for data: 657460224
I0413 17:41:18.483434 22831 layer_factory.hpp:77] Creating layer conv2_sub
I0413 17:41:18.483446 22831 net.cpp:91] Creating Layer conv2_sub
I0413 17:41:18.483451 22831 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 17:41:18.483458 22831 net.cpp:399] conv2_sub -> conv2_sub
I0413 17:41:18.484390 22831 net.cpp:141] Setting up conv2_sub
I0413 17:41:18.484403 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.484410 22831 net.cpp:156] Memory required for data: 665848832
I0413 17:41:18.484417 22831 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 17:41:18.484424 22831 net.cpp:91] Creating Layer bn_conv2_sub
I0413 17:41:18.484429 22831 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 17:41:18.484436 22831 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 17:41:18.484599 22831 net.cpp:141] Setting up bn_conv2_sub
I0413 17:41:18.484607 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.484611 22831 net.cpp:156] Memory required for data: 674237440
I0413 17:41:18.484618 22831 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:41:18.484624 22831 net.cpp:91] Creating Layer scale_conv2_sub
I0413 17:41:18.484628 22831 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 17:41:18.484634 22831 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 17:41:18.484671 22831 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:41:18.484766 22831 net.cpp:141] Setting up scale_conv2_sub
I0413 17:41:18.484773 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.484777 22831 net.cpp:156] Memory required for data: 682626048
I0413 17:41:18.484783 22831 layer_factory.hpp:77] Creating layer conv3_1a
I0413 17:41:18.484793 22831 net.cpp:91] Creating Layer conv3_1a
I0413 17:41:18.484798 22831 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 17:41:18.484808 22831 net.cpp:399] conv3_1a -> conv3_1a
I0413 17:41:18.493983 22831 net.cpp:141] Setting up conv3_1a
I0413 17:41:18.494032 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.494038 22831 net.cpp:156] Memory required for data: 691014656
I0413 17:41:18.494051 22831 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 17:41:18.494067 22831 net.cpp:91] Creating Layer bn_conv3_1a
I0413 17:41:18.494073 22831 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 17:41:18.494081 22831 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 17:41:18.494251 22831 net.cpp:141] Setting up bn_conv3_1a
I0413 17:41:18.494258 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.494262 22831 net.cpp:156] Memory required for data: 699403264
I0413 17:41:18.494271 22831 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:41:18.494280 22831 net.cpp:91] Creating Layer scale_conv3_1a
I0413 17:41:18.494284 22831 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 17:41:18.494289 22831 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 17:41:18.494325 22831 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:41:18.494424 22831 net.cpp:141] Setting up scale_conv3_1a
I0413 17:41:18.494432 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.494436 22831 net.cpp:156] Memory required for data: 707791872
I0413 17:41:18.494443 22831 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 17:41:18.494453 22831 net.cpp:91] Creating Layer conv3_1a_relu
I0413 17:41:18.494458 22831 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 17:41:18.494462 22831 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 17:41:18.494969 22831 net.cpp:141] Setting up conv3_1a_relu
I0413 17:41:18.494983 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.494987 22831 net.cpp:156] Memory required for data: 716180480
I0413 17:41:18.494992 22831 layer_factory.hpp:77] Creating layer conv3_1b
I0413 17:41:18.495007 22831 net.cpp:91] Creating Layer conv3_1b
I0413 17:41:18.495012 22831 net.cpp:425] conv3_1b <- conv3_1a
I0413 17:41:18.495019 22831 net.cpp:399] conv3_1b -> conv3_1b
I0413 17:41:18.498587 22831 net.cpp:141] Setting up conv3_1b
I0413 17:41:18.498602 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.498607 22831 net.cpp:156] Memory required for data: 724569088
I0413 17:41:18.498630 22831 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 17:41:18.498639 22831 net.cpp:91] Creating Layer bn_conv3_1b
I0413 17:41:18.498644 22831 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 17:41:18.498651 22831 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 17:41:18.498811 22831 net.cpp:141] Setting up bn_conv3_1b
I0413 17:41:18.498818 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.498822 22831 net.cpp:156] Memory required for data: 732957696
I0413 17:41:18.498831 22831 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:41:18.498836 22831 net.cpp:91] Creating Layer scale_conv3_1b
I0413 17:41:18.498841 22831 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 17:41:18.498849 22831 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 17:41:18.498881 22831 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:41:18.498976 22831 net.cpp:141] Setting up scale_conv3_1b
I0413 17:41:18.498986 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.498989 22831 net.cpp:156] Memory required for data: 741346304
I0413 17:41:18.498996 22831 layer_factory.hpp:77] Creating layer conv3_1
I0413 17:41:18.499002 22831 net.cpp:91] Creating Layer conv3_1
I0413 17:41:18.499017 22831 net.cpp:425] conv3_1 <- conv3_1b
I0413 17:41:18.499022 22831 net.cpp:425] conv3_1 <- conv2_sub
I0413 17:41:18.499027 22831 net.cpp:399] conv3_1 -> conv3_1
I0413 17:41:18.499049 22831 net.cpp:141] Setting up conv3_1
I0413 17:41:18.499056 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.499059 22831 net.cpp:156] Memory required for data: 749734912
I0413 17:41:18.499063 22831 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 17:41:18.499069 22831 net.cpp:91] Creating Layer conv3_1_relu
I0413 17:41:18.499073 22831 net.cpp:425] conv3_1_relu <- conv3_1
I0413 17:41:18.499079 22831 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 17:41:18.499390 22831 net.cpp:141] Setting up conv3_1_relu
I0413 17:41:18.499400 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.499404 22831 net.cpp:156] Memory required for data: 758123520
I0413 17:41:18.499408 22831 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 17:41:18.499416 22831 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 17:41:18.499420 22831 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 17:41:18.499425 22831 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 17:41:18.499433 22831 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 17:41:18.499470 22831 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 17:41:18.499476 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.499481 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.499485 22831 net.cpp:156] Memory required for data: 774900736
I0413 17:41:18.499488 22831 layer_factory.hpp:77] Creating layer conv3_2a
I0413 17:41:18.499500 22831 net.cpp:91] Creating Layer conv3_2a
I0413 17:41:18.499503 22831 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 17:41:18.499511 22831 net.cpp:399] conv3_2a -> conv3_2a
I0413 17:41:18.506345 22831 net.cpp:141] Setting up conv3_2a
I0413 17:41:18.506361 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.506366 22831 net.cpp:156] Memory required for data: 783289344
I0413 17:41:18.506373 22831 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 17:41:18.506382 22831 net.cpp:91] Creating Layer bn_conv3_2a
I0413 17:41:18.506387 22831 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 17:41:18.506393 22831 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 17:41:18.506564 22831 net.cpp:141] Setting up bn_conv3_2a
I0413 17:41:18.506572 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.506577 22831 net.cpp:156] Memory required for data: 791677952
I0413 17:41:18.506584 22831 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:41:18.506592 22831 net.cpp:91] Creating Layer scale_conv3_2a
I0413 17:41:18.506595 22831 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 17:41:18.506602 22831 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 17:41:18.506644 22831 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:41:18.506738 22831 net.cpp:141] Setting up scale_conv3_2a
I0413 17:41:18.506745 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.506749 22831 net.cpp:156] Memory required for data: 800066560
I0413 17:41:18.506755 22831 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 17:41:18.506762 22831 net.cpp:91] Creating Layer conv3_2a_relu
I0413 17:41:18.506767 22831 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 17:41:18.506772 22831 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 17:41:18.507376 22831 net.cpp:141] Setting up conv3_2a_relu
I0413 17:41:18.507386 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.507390 22831 net.cpp:156] Memory required for data: 808455168
I0413 17:41:18.507395 22831 layer_factory.hpp:77] Creating layer conv3_2b
I0413 17:41:18.507407 22831 net.cpp:91] Creating Layer conv3_2b
I0413 17:41:18.507411 22831 net.cpp:425] conv3_2b <- conv3_2a
I0413 17:41:18.507418 22831 net.cpp:399] conv3_2b -> conv3_2b
I0413 17:41:18.514435 22831 net.cpp:141] Setting up conv3_2b
I0413 17:41:18.514489 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.514495 22831 net.cpp:156] Memory required for data: 816843776
I0413 17:41:18.514509 22831 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 17:41:18.514526 22831 net.cpp:91] Creating Layer bn_conv3_2b
I0413 17:41:18.514533 22831 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 17:41:18.514544 22831 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 17:41:18.514859 22831 net.cpp:141] Setting up bn_conv3_2b
I0413 17:41:18.514910 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.514945 22831 net.cpp:156] Memory required for data: 825232384
I0413 17:41:18.514962 22831 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:41:18.514981 22831 net.cpp:91] Creating Layer scale_conv3_2b
I0413 17:41:18.514986 22831 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 17:41:18.514997 22831 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 17:41:18.515100 22831 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:41:18.515264 22831 net.cpp:141] Setting up scale_conv3_2b
I0413 17:41:18.515275 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.515280 22831 net.cpp:156] Memory required for data: 833620992
I0413 17:41:18.515293 22831 layer_factory.hpp:77] Creating layer conv3_2
I0413 17:41:18.515308 22831 net.cpp:91] Creating Layer conv3_2
I0413 17:41:18.515316 22831 net.cpp:425] conv3_2 <- conv3_2b
I0413 17:41:18.515324 22831 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 17:41:18.515336 22831 net.cpp:399] conv3_2 -> conv3_2
I0413 17:41:18.515400 22831 net.cpp:141] Setting up conv3_2
I0413 17:41:18.515436 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.515444 22831 net.cpp:156] Memory required for data: 842009600
I0413 17:41:18.515449 22831 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 17:41:18.515461 22831 net.cpp:91] Creating Layer conv3_2_relu
I0413 17:41:18.515466 22831 net.cpp:425] conv3_2_relu <- conv3_2
I0413 17:41:18.515475 22831 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 17:41:18.516721 22831 net.cpp:141] Setting up conv3_2_relu
I0413 17:41:18.516765 22831 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:41:18.516770 22831 net.cpp:156] Memory required for data: 850398208
I0413 17:41:18.516778 22831 layer_factory.hpp:77] Creating layer global_pool
I0413 17:41:18.516793 22831 net.cpp:91] Creating Layer global_pool
I0413 17:41:18.516799 22831 net.cpp:425] global_pool <- conv3_2
I0413 17:41:18.516810 22831 net.cpp:399] global_pool -> global_pool
I0413 17:41:18.517782 22831 net.cpp:141] Setting up global_pool
I0413 17:41:18.517796 22831 net.cpp:148] Top shape: 256 32 2 2 (32768)
I0413 17:41:18.517799 22831 net.cpp:156] Memory required for data: 850529280
I0413 17:41:18.517803 22831 layer_factory.hpp:77] Creating layer ip
I0413 17:41:18.517813 22831 net.cpp:91] Creating Layer ip
I0413 17:41:18.517817 22831 net.cpp:425] ip <- global_pool
I0413 17:41:18.517823 22831 net.cpp:399] ip -> ip
I0413 17:41:18.517953 22831 net.cpp:141] Setting up ip
I0413 17:41:18.517962 22831 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:41:18.517966 22831 net.cpp:156] Memory required for data: 850539520
I0413 17:41:18.517974 22831 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:41:18.517982 22831 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:41:18.517985 22831 net.cpp:425] ip_ip_0_split <- ip
I0413 17:41:18.517990 22831 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:41:18.517998 22831 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:41:18.518029 22831 net.cpp:141] Setting up ip_ip_0_split
I0413 17:41:18.518036 22831 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:41:18.518040 22831 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:41:18.518044 22831 net.cpp:156] Memory required for data: 850560000
I0413 17:41:18.518049 22831 layer_factory.hpp:77] Creating layer accuracy
I0413 17:41:18.518059 22831 net.cpp:91] Creating Layer accuracy
I0413 17:41:18.518062 22831 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:41:18.518074 22831 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:41:18.518080 22831 net.cpp:399] accuracy -> accuracy
I0413 17:41:18.518088 22831 net.cpp:141] Setting up accuracy
I0413 17:41:18.518093 22831 net.cpp:148] Top shape: (1)
I0413 17:41:18.518097 22831 net.cpp:156] Memory required for data: 850560004
I0413 17:41:18.518100 22831 layer_factory.hpp:77] Creating layer loss
I0413 17:41:18.518106 22831 net.cpp:91] Creating Layer loss
I0413 17:41:18.518110 22831 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:41:18.518115 22831 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:41:18.518122 22831 net.cpp:399] loss -> loss
I0413 17:41:18.518134 22831 layer_factory.hpp:77] Creating layer loss
I0413 17:41:18.519057 22831 net.cpp:141] Setting up loss
I0413 17:41:18.519070 22831 net.cpp:148] Top shape: (1)
I0413 17:41:18.519074 22831 net.cpp:151]     with loss weight 1
I0413 17:41:18.519086 22831 net.cpp:156] Memory required for data: 850560008
I0413 17:41:18.519090 22831 net.cpp:217] loss needs backward computation.
I0413 17:41:18.519094 22831 net.cpp:219] accuracy does not need backward computation.
I0413 17:41:18.519099 22831 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:41:18.519103 22831 net.cpp:217] ip needs backward computation.
I0413 17:41:18.519106 22831 net.cpp:217] global_pool needs backward computation.
I0413 17:41:18.519109 22831 net.cpp:217] conv3_2_relu needs backward computation.
I0413 17:41:18.519114 22831 net.cpp:217] conv3_2 needs backward computation.
I0413 17:41:18.519117 22831 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 17:41:18.519121 22831 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 17:41:18.519124 22831 net.cpp:217] conv3_2b needs backward computation.
I0413 17:41:18.519129 22831 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 17:41:18.519132 22831 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 17:41:18.519136 22831 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 17:41:18.519140 22831 net.cpp:217] conv3_2a needs backward computation.
I0413 17:41:18.519143 22831 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 17:41:18.519147 22831 net.cpp:217] conv3_1_relu needs backward computation.
I0413 17:41:18.519151 22831 net.cpp:217] conv3_1 needs backward computation.
I0413 17:41:18.519155 22831 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 17:41:18.519160 22831 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 17:41:18.519162 22831 net.cpp:217] conv3_1b needs backward computation.
I0413 17:41:18.519167 22831 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 17:41:18.519170 22831 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 17:41:18.519175 22831 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 17:41:18.519178 22831 net.cpp:217] conv3_1a needs backward computation.
I0413 17:41:18.519182 22831 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 17:41:18.519186 22831 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 17:41:18.519189 22831 net.cpp:217] conv2_sub needs backward computation.
I0413 17:41:18.519193 22831 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 17:41:18.519197 22831 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:41:18.519201 22831 net.cpp:217] conv2_3 needs backward computation.
I0413 17:41:18.519206 22831 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:41:18.519209 22831 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:41:18.519213 22831 net.cpp:217] conv2_3b needs backward computation.
I0413 17:41:18.519217 22831 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:41:18.519220 22831 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:41:18.519224 22831 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:41:18.519228 22831 net.cpp:217] conv2_3a needs backward computation.
I0413 17:41:18.519232 22831 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:41:18.519242 22831 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:41:18.519245 22831 net.cpp:217] conv2_2 needs backward computation.
I0413 17:41:18.519249 22831 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:41:18.519253 22831 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:41:18.519258 22831 net.cpp:217] conv2_2b needs backward computation.
I0413 17:41:18.519260 22831 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:41:18.519264 22831 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:41:18.519268 22831 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:41:18.519273 22831 net.cpp:217] conv2_2a needs backward computation.
I0413 17:41:18.519276 22831 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:41:18.519280 22831 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:41:18.519284 22831 net.cpp:217] conv2_1 needs backward computation.
I0413 17:41:18.519289 22831 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:41:18.519292 22831 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:41:18.519295 22831 net.cpp:217] conv2_1b needs backward computation.
I0413 17:41:18.519299 22831 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:41:18.519304 22831 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:41:18.519307 22831 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:41:18.519311 22831 net.cpp:217] conv2_1a needs backward computation.
I0413 17:41:18.519315 22831 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:41:18.519320 22831 net.cpp:217] conv1_relu needs backward computation.
I0413 17:41:18.519325 22831 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:41:18.519327 22831 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:41:18.519331 22831 net.cpp:217] conv1 needs backward computation.
I0413 17:41:18.519335 22831 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:41:18.519340 22831 net.cpp:219] cifar does not need backward computation.
I0413 17:41:18.519345 22831 net.cpp:261] This network produces output accuracy
I0413 17:41:18.519348 22831 net.cpp:261] This network produces output loss
I0413 17:41:18.519384 22831 net.cpp:274] Network initialization done.
I0413 17:41:18.520577 22831 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar4.prototxt
I0413 17:41:18.520653 22831 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 17:41:18.520948 22831 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv3_2"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:41:18.521206 22831 layer_factory.hpp:77] Creating layer cifar
I0413 17:41:18.521330 22831 net.cpp:91] Creating Layer cifar
I0413 17:41:18.521343 22831 net.cpp:399] cifar -> data
I0413 17:41:18.521354 22831 net.cpp:399] cifar -> label
I0413 17:41:18.521364 22831 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:41:18.522384 22909 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 17:41:18.522502 22831 data_layer.cpp:41] output data size: 100,3,32,32
I0413 17:41:18.528450 22831 net.cpp:141] Setting up cifar
I0413 17:41:18.528472 22831 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 17:41:18.528478 22831 net.cpp:148] Top shape: 100 (100)
I0413 17:41:18.528483 22831 net.cpp:156] Memory required for data: 1229200
I0413 17:41:18.528501 22831 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:41:18.528509 22831 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:41:18.528513 22831 net.cpp:425] label_cifar_1_split <- label
I0413 17:41:18.528522 22831 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:41:18.528529 22831 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:41:18.528630 22831 net.cpp:141] Setting up label_cifar_1_split
I0413 17:41:18.528643 22831 net.cpp:148] Top shape: 100 (100)
I0413 17:41:18.528652 22831 net.cpp:148] Top shape: 100 (100)
I0413 17:41:18.528656 22831 net.cpp:156] Memory required for data: 1230000
I0413 17:41:18.528661 22831 layer_factory.hpp:77] Creating layer conv1
I0413 17:41:18.528681 22831 net.cpp:91] Creating Layer conv1
I0413 17:41:18.528686 22831 net.cpp:425] conv1 <- data
I0413 17:41:18.528698 22831 net.cpp:399] conv1 -> conv1
I0413 17:41:18.531891 22831 net.cpp:141] Setting up conv1
I0413 17:41:18.531908 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.531913 22831 net.cpp:156] Memory required for data: 7783600
I0413 17:41:18.531924 22831 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:41:18.531932 22831 net.cpp:91] Creating Layer bn_conv1
I0413 17:41:18.531937 22831 net.cpp:425] bn_conv1 <- conv1
I0413 17:41:18.531944 22831 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:41:18.532171 22831 net.cpp:141] Setting up bn_conv1
I0413 17:41:18.532192 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.532196 22831 net.cpp:156] Memory required for data: 14337200
I0413 17:41:18.532217 22831 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:41:18.532234 22831 net.cpp:91] Creating Layer scale_conv1
I0413 17:41:18.532238 22831 net.cpp:425] scale_conv1 <- conv1
I0413 17:41:18.532263 22831 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:41:18.532307 22831 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:41:18.532439 22831 net.cpp:141] Setting up scale_conv1
I0413 17:41:18.532452 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.532456 22831 net.cpp:156] Memory required for data: 20890800
I0413 17:41:18.532462 22831 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:41:18.532495 22831 net.cpp:91] Creating Layer conv1_relu
I0413 17:41:18.532500 22831 net.cpp:425] conv1_relu <- conv1
I0413 17:41:18.532505 22831 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:41:18.533088 22831 net.cpp:141] Setting up conv1_relu
I0413 17:41:18.533130 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.533143 22831 net.cpp:156] Memory required for data: 27444400
I0413 17:41:18.533149 22831 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:41:18.533154 22831 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:41:18.533169 22831 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:41:18.533188 22831 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:41:18.533196 22831 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:41:18.533275 22831 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:41:18.533285 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.533296 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.533299 22831 net.cpp:156] Memory required for data: 40551600
I0413 17:41:18.533303 22831 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:41:18.533329 22831 net.cpp:91] Creating Layer conv2_1a
I0413 17:41:18.533339 22831 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:41:18.533344 22831 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:41:18.536602 22831 net.cpp:141] Setting up conv2_1a
I0413 17:41:18.536624 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.536628 22831 net.cpp:156] Memory required for data: 47105200
I0413 17:41:18.536643 22831 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:41:18.536653 22831 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:41:18.536665 22831 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:41:18.536670 22831 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:41:18.537935 22831 net.cpp:141] Setting up bn_conv2_1a
I0413 17:41:18.537950 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.537955 22831 net.cpp:156] Memory required for data: 53658800
I0413 17:41:18.537966 22831 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:41:18.537973 22831 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:41:18.537977 22831 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:41:18.537983 22831 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:41:18.538043 22831 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:41:18.538180 22831 net.cpp:141] Setting up scale_conv2_1a
I0413 17:41:18.538194 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.538198 22831 net.cpp:156] Memory required for data: 60212400
I0413 17:41:18.538210 22831 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:41:18.538218 22831 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:41:18.538221 22831 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:41:18.538233 22831 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:41:18.538863 22831 net.cpp:141] Setting up conv2_1a_relu
I0413 17:41:18.538885 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.538904 22831 net.cpp:156] Memory required for data: 66766000
I0413 17:41:18.538908 22831 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:41:18.538925 22831 net.cpp:91] Creating Layer conv2_1b
I0413 17:41:18.538938 22831 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:41:18.538947 22831 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:41:18.542263 22831 net.cpp:141] Setting up conv2_1b
I0413 17:41:18.542279 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.542284 22831 net.cpp:156] Memory required for data: 73319600
I0413 17:41:18.542290 22831 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:41:18.542299 22831 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:41:18.542304 22831 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:41:18.542309 22831 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:41:18.542511 22831 net.cpp:141] Setting up bn_conv2_1b
I0413 17:41:18.542520 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.542525 22831 net.cpp:156] Memory required for data: 79873200
I0413 17:41:18.542534 22831 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:41:18.542541 22831 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:41:18.542544 22831 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:41:18.542551 22831 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:41:18.543486 22831 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:41:18.543736 22831 net.cpp:141] Setting up scale_conv2_1b
I0413 17:41:18.543748 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.543756 22831 net.cpp:156] Memory required for data: 86426800
I0413 17:41:18.543766 22831 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:41:18.543772 22831 net.cpp:91] Creating Layer conv2_1
I0413 17:41:18.543776 22831 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:41:18.543781 22831 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:41:18.543787 22831 net.cpp:399] conv2_1 -> conv2_1
I0413 17:41:18.543831 22831 net.cpp:141] Setting up conv2_1
I0413 17:41:18.543839 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.543843 22831 net.cpp:156] Memory required for data: 92980400
I0413 17:41:18.543848 22831 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:41:18.543853 22831 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:41:18.543856 22831 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:41:18.543864 22831 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:41:18.544137 22831 net.cpp:141] Setting up conv2_1_relu
I0413 17:41:18.544150 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.544157 22831 net.cpp:156] Memory required for data: 99534000
I0413 17:41:18.544160 22831 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:41:18.544167 22831 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:41:18.544173 22831 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:41:18.544178 22831 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:41:18.544195 22831 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:41:18.544239 22831 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:41:18.544251 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.544258 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.544263 22831 net.cpp:156] Memory required for data: 112641200
I0413 17:41:18.544267 22831 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:41:18.544277 22831 net.cpp:91] Creating Layer conv2_2a
I0413 17:41:18.544282 22831 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:41:18.544289 22831 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:41:18.546838 22831 net.cpp:141] Setting up conv2_2a
I0413 17:41:18.546855 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.546859 22831 net.cpp:156] Memory required for data: 119194800
I0413 17:41:18.546867 22831 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:41:18.546876 22831 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:41:18.546882 22831 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:41:18.546890 22831 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:41:18.547075 22831 net.cpp:141] Setting up bn_conv2_2a
I0413 17:41:18.547085 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.547088 22831 net.cpp:156] Memory required for data: 125748400
I0413 17:41:18.547096 22831 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:41:18.547104 22831 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:41:18.547108 22831 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:41:18.547114 22831 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:41:18.547154 22831 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:41:18.547262 22831 net.cpp:141] Setting up scale_conv2_2a
I0413 17:41:18.547271 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.547274 22831 net.cpp:156] Memory required for data: 132302000
I0413 17:41:18.547281 22831 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:41:18.547288 22831 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:41:18.547292 22831 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:41:18.547297 22831 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:41:18.547834 22831 net.cpp:141] Setting up conv2_2a_relu
I0413 17:41:18.547847 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.547850 22831 net.cpp:156] Memory required for data: 138855600
I0413 17:41:18.547854 22831 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:41:18.547870 22831 net.cpp:91] Creating Layer conv2_2b
I0413 17:41:18.547875 22831 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:41:18.547883 22831 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:41:18.550503 22831 net.cpp:141] Setting up conv2_2b
I0413 17:41:18.550518 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.550523 22831 net.cpp:156] Memory required for data: 145409200
I0413 17:41:18.550530 22831 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:41:18.550542 22831 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:41:18.550547 22831 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:41:18.550554 22831 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:41:18.550743 22831 net.cpp:141] Setting up bn_conv2_2b
I0413 17:41:18.550751 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.550755 22831 net.cpp:156] Memory required for data: 151962800
I0413 17:41:18.550770 22831 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:41:18.550776 22831 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:41:18.550779 22831 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:41:18.550786 22831 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:41:18.550827 22831 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:41:18.550936 22831 net.cpp:141] Setting up scale_conv2_2b
I0413 17:41:18.550945 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.550948 22831 net.cpp:156] Memory required for data: 158516400
I0413 17:41:18.550956 22831 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:41:18.550962 22831 net.cpp:91] Creating Layer conv2_2
I0413 17:41:18.550966 22831 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:41:18.550971 22831 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:41:18.550978 22831 net.cpp:399] conv2_2 -> conv2_2
I0413 17:41:18.551002 22831 net.cpp:141] Setting up conv2_2
I0413 17:41:18.551010 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.551014 22831 net.cpp:156] Memory required for data: 165070000
I0413 17:41:18.551018 22831 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:41:18.551025 22831 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:41:18.551029 22831 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:41:18.551034 22831 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:41:18.551575 22831 net.cpp:141] Setting up conv2_2_relu
I0413 17:41:18.551589 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.551594 22831 net.cpp:156] Memory required for data: 171623600
I0413 17:41:18.551597 22831 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:41:18.551605 22831 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:41:18.551610 22831 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:41:18.551615 22831 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:41:18.551625 22831 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:41:18.551669 22831 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:41:18.551678 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.551683 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.551687 22831 net.cpp:156] Memory required for data: 184730800
I0413 17:41:18.551692 22831 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:41:18.551702 22831 net.cpp:91] Creating Layer conv2_3a
I0413 17:41:18.551707 22831 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:41:18.551713 22831 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:41:18.555074 22831 net.cpp:141] Setting up conv2_3a
I0413 17:41:18.555089 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.555094 22831 net.cpp:156] Memory required for data: 191284400
I0413 17:41:18.555101 22831 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:41:18.555110 22831 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:41:18.555115 22831 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:41:18.555121 22831 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:41:18.555322 22831 net.cpp:141] Setting up bn_conv2_3a
I0413 17:41:18.555331 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.555335 22831 net.cpp:156] Memory required for data: 197838000
I0413 17:41:18.555343 22831 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:41:18.555349 22831 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:41:18.555354 22831 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:41:18.555359 22831 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:41:18.555402 22831 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:41:18.555510 22831 net.cpp:141] Setting up scale_conv2_3a
I0413 17:41:18.555517 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.555521 22831 net.cpp:156] Memory required for data: 204391600
I0413 17:41:18.555528 22831 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:41:18.555533 22831 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:41:18.555537 22831 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:41:18.555544 22831 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:41:18.556126 22831 net.cpp:141] Setting up conv2_3a_relu
I0413 17:41:18.556140 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.556145 22831 net.cpp:156] Memory required for data: 210945200
I0413 17:41:18.556149 22831 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:41:18.556161 22831 net.cpp:91] Creating Layer conv2_3b
I0413 17:41:18.556166 22831 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:41:18.556174 22831 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:41:18.559700 22831 net.cpp:141] Setting up conv2_3b
I0413 17:41:18.559716 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.559721 22831 net.cpp:156] Memory required for data: 217498800
I0413 17:41:18.559728 22831 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:41:18.559739 22831 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:41:18.559744 22831 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:41:18.559752 22831 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:41:18.559947 22831 net.cpp:141] Setting up bn_conv2_3b
I0413 17:41:18.559957 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.559960 22831 net.cpp:156] Memory required for data: 224052400
I0413 17:41:18.559968 22831 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:41:18.559974 22831 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:41:18.559978 22831 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:41:18.559988 22831 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:41:18.560029 22831 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:41:18.560137 22831 net.cpp:141] Setting up scale_conv2_3b
I0413 17:41:18.560148 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.560151 22831 net.cpp:156] Memory required for data: 230606000
I0413 17:41:18.560158 22831 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:41:18.560163 22831 net.cpp:91] Creating Layer conv2_3
I0413 17:41:18.560168 22831 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:41:18.560173 22831 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:41:18.560178 22831 net.cpp:399] conv2_3 -> conv2_3
I0413 17:41:18.560204 22831 net.cpp:141] Setting up conv2_3
I0413 17:41:18.560211 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.560215 22831 net.cpp:156] Memory required for data: 237159600
I0413 17:41:18.560219 22831 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:41:18.560225 22831 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:41:18.560230 22831 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:41:18.560235 22831 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:41:18.560739 22831 net.cpp:141] Setting up conv2_3_relu
I0413 17:41:18.560751 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.560756 22831 net.cpp:156] Memory required for data: 243713200
I0413 17:41:18.560760 22831 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 17:41:18.560766 22831 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 17:41:18.560775 22831 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 17:41:18.560781 22831 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 17:41:18.560789 22831 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 17:41:18.560830 22831 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 17:41:18.560837 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.560844 22831 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:41:18.560848 22831 net.cpp:156] Memory required for data: 256820400
I0413 17:41:18.560853 22831 layer_factory.hpp:77] Creating layer conv2_sub
I0413 17:41:18.560860 22831 net.cpp:91] Creating Layer conv2_sub
I0413 17:41:18.560865 22831 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 17:41:18.560873 22831 net.cpp:399] conv2_sub -> conv2_sub
I0413 17:41:18.564314 22831 net.cpp:141] Setting up conv2_sub
I0413 17:41:18.564329 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.564333 22831 net.cpp:156] Memory required for data: 260097200
I0413 17:41:18.564342 22831 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 17:41:18.564349 22831 net.cpp:91] Creating Layer bn_conv2_sub
I0413 17:41:18.564354 22831 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 17:41:18.564360 22831 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 17:41:18.564554 22831 net.cpp:141] Setting up bn_conv2_sub
I0413 17:41:18.564563 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.564566 22831 net.cpp:156] Memory required for data: 263374000
I0413 17:41:18.564574 22831 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:41:18.564580 22831 net.cpp:91] Creating Layer scale_conv2_sub
I0413 17:41:18.564584 22831 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 17:41:18.564590 22831 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 17:41:18.564632 22831 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:41:18.564744 22831 net.cpp:141] Setting up scale_conv2_sub
I0413 17:41:18.564752 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.564756 22831 net.cpp:156] Memory required for data: 266650800
I0413 17:41:18.564764 22831 layer_factory.hpp:77] Creating layer conv3_1a
I0413 17:41:18.564774 22831 net.cpp:91] Creating Layer conv3_1a
I0413 17:41:18.564777 22831 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 17:41:18.564785 22831 net.cpp:399] conv3_1a -> conv3_1a
I0413 17:41:18.566792 22831 net.cpp:141] Setting up conv3_1a
I0413 17:41:18.566809 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.566814 22831 net.cpp:156] Memory required for data: 269927600
I0413 17:41:18.566822 22831 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 17:41:18.566828 22831 net.cpp:91] Creating Layer bn_conv3_1a
I0413 17:41:18.566833 22831 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 17:41:18.566841 22831 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 17:41:18.567029 22831 net.cpp:141] Setting up bn_conv3_1a
I0413 17:41:18.567037 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.567041 22831 net.cpp:156] Memory required for data: 273204400
I0413 17:41:18.567049 22831 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:41:18.567055 22831 net.cpp:91] Creating Layer scale_conv3_1a
I0413 17:41:18.567059 22831 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 17:41:18.567065 22831 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 17:41:18.567106 22831 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:41:18.567215 22831 net.cpp:141] Setting up scale_conv3_1a
I0413 17:41:18.567224 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.567227 22831 net.cpp:156] Memory required for data: 276481200
I0413 17:41:18.567234 22831 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 17:41:18.567241 22831 net.cpp:91] Creating Layer conv3_1a_relu
I0413 17:41:18.567246 22831 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 17:41:18.567255 22831 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 17:41:18.567847 22831 net.cpp:141] Setting up conv3_1a_relu
I0413 17:41:18.567858 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.567862 22831 net.cpp:156] Memory required for data: 279758000
I0413 17:41:18.567867 22831 layer_factory.hpp:77] Creating layer conv3_1b
I0413 17:41:18.567878 22831 net.cpp:91] Creating Layer conv3_1b
I0413 17:41:18.567881 22831 net.cpp:425] conv3_1b <- conv3_1a
I0413 17:41:18.567888 22831 net.cpp:399] conv3_1b -> conv3_1b
I0413 17:41:18.571620 22831 net.cpp:141] Setting up conv3_1b
I0413 17:41:18.571635 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.571640 22831 net.cpp:156] Memory required for data: 283034800
I0413 17:41:18.571657 22831 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 17:41:18.571666 22831 net.cpp:91] Creating Layer bn_conv3_1b
I0413 17:41:18.571671 22831 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 17:41:18.571677 22831 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 17:41:18.571864 22831 net.cpp:141] Setting up bn_conv3_1b
I0413 17:41:18.571872 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.571877 22831 net.cpp:156] Memory required for data: 286311600
I0413 17:41:18.571884 22831 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:41:18.571894 22831 net.cpp:91] Creating Layer scale_conv3_1b
I0413 17:41:18.571899 22831 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 17:41:18.571904 22831 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 17:41:18.571946 22831 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:41:18.572057 22831 net.cpp:141] Setting up scale_conv3_1b
I0413 17:41:18.572065 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.572069 22831 net.cpp:156] Memory required for data: 289588400
I0413 17:41:18.572075 22831 layer_factory.hpp:77] Creating layer conv3_1
I0413 17:41:18.572083 22831 net.cpp:91] Creating Layer conv3_1
I0413 17:41:18.572088 22831 net.cpp:425] conv3_1 <- conv3_1b
I0413 17:41:18.572093 22831 net.cpp:425] conv3_1 <- conv2_sub
I0413 17:41:18.572098 22831 net.cpp:399] conv3_1 -> conv3_1
I0413 17:41:18.572119 22831 net.cpp:141] Setting up conv3_1
I0413 17:41:18.572126 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.572130 22831 net.cpp:156] Memory required for data: 292865200
I0413 17:41:18.572134 22831 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 17:41:18.572139 22831 net.cpp:91] Creating Layer conv3_1_relu
I0413 17:41:18.572144 22831 net.cpp:425] conv3_1_relu <- conv3_1
I0413 17:41:18.572149 22831 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 17:41:18.572666 22831 net.cpp:141] Setting up conv3_1_relu
I0413 17:41:18.572679 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.572684 22831 net.cpp:156] Memory required for data: 296142000
I0413 17:41:18.572687 22831 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 17:41:18.572695 22831 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 17:41:18.572698 22831 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 17:41:18.572706 22831 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 17:41:18.572715 22831 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 17:41:18.572757 22831 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 17:41:18.572763 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.572768 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.572772 22831 net.cpp:156] Memory required for data: 302695600
I0413 17:41:18.572777 22831 layer_factory.hpp:77] Creating layer conv3_2a
I0413 17:41:18.572789 22831 net.cpp:91] Creating Layer conv3_2a
I0413 17:41:18.572793 22831 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 17:41:18.572800 22831 net.cpp:399] conv3_2a -> conv3_2a
I0413 17:41:18.576179 22831 net.cpp:141] Setting up conv3_2a
I0413 17:41:18.576195 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.576200 22831 net.cpp:156] Memory required for data: 305972400
I0413 17:41:18.576215 22831 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 17:41:18.576222 22831 net.cpp:91] Creating Layer bn_conv3_2a
I0413 17:41:18.576227 22831 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 17:41:18.576236 22831 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 17:41:18.576424 22831 net.cpp:141] Setting up bn_conv3_2a
I0413 17:41:18.576433 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.576436 22831 net.cpp:156] Memory required for data: 309249200
I0413 17:41:18.576444 22831 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:41:18.576452 22831 net.cpp:91] Creating Layer scale_conv3_2a
I0413 17:41:18.576455 22831 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 17:41:18.576462 22831 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 17:41:18.576501 22831 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:41:18.576613 22831 net.cpp:141] Setting up scale_conv3_2a
I0413 17:41:18.576620 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.576624 22831 net.cpp:156] Memory required for data: 312526000
I0413 17:41:18.576632 22831 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 17:41:18.576638 22831 net.cpp:91] Creating Layer conv3_2a_relu
I0413 17:41:18.576642 22831 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 17:41:18.576648 22831 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 17:41:18.577236 22831 net.cpp:141] Setting up conv3_2a_relu
I0413 17:41:18.577250 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.577255 22831 net.cpp:156] Memory required for data: 315802800
I0413 17:41:18.577258 22831 layer_factory.hpp:77] Creating layer conv3_2b
I0413 17:41:18.577272 22831 net.cpp:91] Creating Layer conv3_2b
I0413 17:41:18.577277 22831 net.cpp:425] conv3_2b <- conv3_2a
I0413 17:41:18.577286 22831 net.cpp:399] conv3_2b -> conv3_2b
I0413 17:41:18.580483 22831 net.cpp:141] Setting up conv3_2b
I0413 17:41:18.580497 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.580503 22831 net.cpp:156] Memory required for data: 319079600
I0413 17:41:18.580512 22831 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 17:41:18.580518 22831 net.cpp:91] Creating Layer bn_conv3_2b
I0413 17:41:18.580523 22831 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 17:41:18.580530 22831 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 17:41:18.580725 22831 net.cpp:141] Setting up bn_conv3_2b
I0413 17:41:18.580734 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.580739 22831 net.cpp:156] Memory required for data: 322356400
I0413 17:41:18.580746 22831 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:41:18.580752 22831 net.cpp:91] Creating Layer scale_conv3_2b
I0413 17:41:18.580757 22831 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 17:41:18.580762 22831 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 17:41:18.580803 22831 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:41:18.580917 22831 net.cpp:141] Setting up scale_conv3_2b
I0413 17:41:18.580925 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.580929 22831 net.cpp:156] Memory required for data: 325633200
I0413 17:41:18.580935 22831 layer_factory.hpp:77] Creating layer conv3_2
I0413 17:41:18.580942 22831 net.cpp:91] Creating Layer conv3_2
I0413 17:41:18.580947 22831 net.cpp:425] conv3_2 <- conv3_2b
I0413 17:41:18.580952 22831 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 17:41:18.580957 22831 net.cpp:399] conv3_2 -> conv3_2
I0413 17:41:18.580978 22831 net.cpp:141] Setting up conv3_2
I0413 17:41:18.580984 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.580988 22831 net.cpp:156] Memory required for data: 328910000
I0413 17:41:18.580992 22831 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 17:41:18.580999 22831 net.cpp:91] Creating Layer conv3_2_relu
I0413 17:41:18.581003 22831 net.cpp:425] conv3_2_relu <- conv3_2
I0413 17:41:18.581008 22831 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 17:41:18.581199 22831 net.cpp:141] Setting up conv3_2_relu
I0413 17:41:18.581214 22831 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:41:18.581219 22831 net.cpp:156] Memory required for data: 332186800
I0413 17:41:18.581223 22831 layer_factory.hpp:77] Creating layer global_pool
I0413 17:41:18.581230 22831 net.cpp:91] Creating Layer global_pool
I0413 17:41:18.581234 22831 net.cpp:425] global_pool <- conv3_2
I0413 17:41:18.581243 22831 net.cpp:399] global_pool -> global_pool
I0413 17:41:18.581812 22831 net.cpp:141] Setting up global_pool
I0413 17:41:18.581826 22831 net.cpp:148] Top shape: 100 32 2 2 (12800)
I0413 17:41:18.581830 22831 net.cpp:156] Memory required for data: 332238000
I0413 17:41:18.581835 22831 layer_factory.hpp:77] Creating layer ip
I0413 17:41:18.581845 22831 net.cpp:91] Creating Layer ip
I0413 17:41:18.581850 22831 net.cpp:425] ip <- global_pool
I0413 17:41:18.581856 22831 net.cpp:399] ip -> ip
I0413 17:41:18.581976 22831 net.cpp:141] Setting up ip
I0413 17:41:18.581986 22831 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:41:18.581990 22831 net.cpp:156] Memory required for data: 332242000
I0413 17:41:18.581996 22831 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:41:18.582005 22831 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:41:18.582008 22831 net.cpp:425] ip_ip_0_split <- ip
I0413 17:41:18.582015 22831 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:41:18.582021 22831 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:41:18.582062 22831 net.cpp:141] Setting up ip_ip_0_split
I0413 17:41:18.582068 22831 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:41:18.582073 22831 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:41:18.582077 22831 net.cpp:156] Memory required for data: 332250000
I0413 17:41:18.582082 22831 layer_factory.hpp:77] Creating layer accuracy
I0413 17:41:18.582087 22831 net.cpp:91] Creating Layer accuracy
I0413 17:41:18.582092 22831 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:41:18.582095 22831 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:41:18.582103 22831 net.cpp:399] accuracy -> accuracy
I0413 17:41:18.582110 22831 net.cpp:141] Setting up accuracy
I0413 17:41:18.582115 22831 net.cpp:148] Top shape: (1)
I0413 17:41:18.582119 22831 net.cpp:156] Memory required for data: 332250004
I0413 17:41:18.582123 22831 layer_factory.hpp:77] Creating layer loss
I0413 17:41:18.582129 22831 net.cpp:91] Creating Layer loss
I0413 17:41:18.582132 22831 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:41:18.582137 22831 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:41:18.582144 22831 net.cpp:399] loss -> loss
I0413 17:41:18.582152 22831 layer_factory.hpp:77] Creating layer loss
I0413 17:41:18.583027 22831 net.cpp:141] Setting up loss
I0413 17:41:18.583039 22831 net.cpp:148] Top shape: (1)
I0413 17:41:18.583042 22831 net.cpp:151]     with loss weight 1
I0413 17:41:18.583050 22831 net.cpp:156] Memory required for data: 332250008
I0413 17:41:18.583055 22831 net.cpp:217] loss needs backward computation.
I0413 17:41:18.583060 22831 net.cpp:219] accuracy does not need backward computation.
I0413 17:41:18.583063 22831 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:41:18.583067 22831 net.cpp:217] ip needs backward computation.
I0413 17:41:18.583071 22831 net.cpp:217] global_pool needs backward computation.
I0413 17:41:18.583076 22831 net.cpp:217] conv3_2_relu needs backward computation.
I0413 17:41:18.583078 22831 net.cpp:217] conv3_2 needs backward computation.
I0413 17:41:18.583083 22831 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 17:41:18.583086 22831 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 17:41:18.583091 22831 net.cpp:217] conv3_2b needs backward computation.
I0413 17:41:18.583094 22831 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 17:41:18.583098 22831 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 17:41:18.583101 22831 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 17:41:18.583106 22831 net.cpp:217] conv3_2a needs backward computation.
I0413 17:41:18.583108 22831 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 17:41:18.583117 22831 net.cpp:217] conv3_1_relu needs backward computation.
I0413 17:41:18.583120 22831 net.cpp:217] conv3_1 needs backward computation.
I0413 17:41:18.583125 22831 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 17:41:18.583128 22831 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 17:41:18.583132 22831 net.cpp:217] conv3_1b needs backward computation.
I0413 17:41:18.583137 22831 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 17:41:18.583139 22831 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 17:41:18.583143 22831 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 17:41:18.583148 22831 net.cpp:217] conv3_1a needs backward computation.
I0413 17:41:18.583151 22831 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 17:41:18.583154 22831 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 17:41:18.583158 22831 net.cpp:217] conv2_sub needs backward computation.
I0413 17:41:18.583163 22831 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 17:41:18.583166 22831 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:41:18.583169 22831 net.cpp:217] conv2_3 needs backward computation.
I0413 17:41:18.583174 22831 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:41:18.583179 22831 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:41:18.583184 22831 net.cpp:217] conv2_3b needs backward computation.
I0413 17:41:18.583186 22831 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:41:18.583190 22831 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:41:18.583194 22831 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:41:18.583197 22831 net.cpp:217] conv2_3a needs backward computation.
I0413 17:41:18.583201 22831 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:41:18.583205 22831 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:41:18.583209 22831 net.cpp:217] conv2_2 needs backward computation.
I0413 17:41:18.583214 22831 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:41:18.583217 22831 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:41:18.583220 22831 net.cpp:217] conv2_2b needs backward computation.
I0413 17:41:18.583225 22831 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:41:18.583228 22831 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:41:18.583232 22831 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:41:18.583235 22831 net.cpp:217] conv2_2a needs backward computation.
I0413 17:41:18.583240 22831 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:41:18.583243 22831 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:41:18.583247 22831 net.cpp:217] conv2_1 needs backward computation.
I0413 17:41:18.583251 22831 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:41:18.583256 22831 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:41:18.583258 22831 net.cpp:217] conv2_1b needs backward computation.
I0413 17:41:18.583262 22831 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:41:18.583266 22831 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:41:18.583269 22831 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:41:18.583273 22831 net.cpp:217] conv2_1a needs backward computation.
I0413 17:41:18.583277 22831 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:41:18.583281 22831 net.cpp:217] conv1_relu needs backward computation.
I0413 17:41:18.583284 22831 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:41:18.583288 22831 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:41:18.583292 22831 net.cpp:217] conv1 needs backward computation.
I0413 17:41:18.583297 22831 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:41:18.583302 22831 net.cpp:219] cifar does not need backward computation.
I0413 17:41:18.583307 22831 net.cpp:261] This network produces output accuracy
I0413 17:41:18.583312 22831 net.cpp:261] This network produces output loss
I0413 17:41:18.583348 22831 net.cpp:274] Network initialization done.
I0413 17:41:18.583515 22831 solver.cpp:60] Solver scaffolding done.
I0413 17:41:18.874384 22831 solver.cpp:228] Iteration 0, loss = 0.968345
I0413 17:41:18.874465 22831 solver.cpp:244]     Train net output #0: accuracy = 0.683594
I0413 17:41:18.874478 22831 solver.cpp:244]     Train net output #1: loss = 0.968345 (* 1 = 0.968345 loss)
I0413 17:41:18.874488 22831 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 17:41:23.532516 22831 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 17:41:26.088634 22831 solver.cpp:404]     Test net output #0: accuracy = 0.2771
I0413 17:41:26.088706 22831 solver.cpp:404]     Test net output #1: loss = 6.62563 (* 1 = 6.62563 loss)
I0413 17:41:26.264791 22831 solver.cpp:228] Iteration 20, loss = 0.683722
I0413 17:41:26.264842 22831 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:41:26.264854 22831 solver.cpp:244]     Train net output #1: loss = 0.683722 (* 1 = 0.683722 loss)
I0413 17:41:26.264865 22831 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 17:41:30.917346 22831 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 17:41:33.312743 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5141
I0413 17:41:33.312816 22831 solver.cpp:404]     Test net output #1: loss = 2.19482 (* 1 = 2.19482 loss)
I0413 17:41:33.470235 22831 solver.cpp:228] Iteration 40, loss = 0.680766
I0413 17:41:33.470276 22831 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:41:33.470289 22831 solver.cpp:244]     Train net output #1: loss = 0.680766 (* 1 = 0.680766 loss)
I0413 17:41:33.470299 22831 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 17:41:38.475041 22831 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 17:41:40.702152 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5836
I0413 17:41:40.702208 22831 solver.cpp:404]     Test net output #1: loss = 1.49041 (* 1 = 1.49041 loss)
I0413 17:41:40.853957 22831 solver.cpp:228] Iteration 60, loss = 0.618443
I0413 17:41:40.854006 22831 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:41:40.854018 22831 solver.cpp:244]     Train net output #1: loss = 0.618443 (* 1 = 0.618443 loss)
I0413 17:41:40.854030 22831 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 17:41:45.682935 22831 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 17:41:48.147377 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4
I0413 17:41:48.147424 22831 solver.cpp:404]     Test net output #1: loss = 2.89297 (* 1 = 2.89297 loss)
I0413 17:41:48.334002 22831 solver.cpp:228] Iteration 80, loss = 0.638169
I0413 17:41:48.334056 22831 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 17:41:48.334069 22831 solver.cpp:244]     Train net output #1: loss = 0.638169 (* 1 = 0.638169 loss)
I0413 17:41:48.334081 22831 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 17:41:52.904486 22831 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 17:41:55.385066 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4719
I0413 17:41:55.385107 22831 solver.cpp:404]     Test net output #1: loss = 2.31769 (* 1 = 2.31769 loss)
I0413 17:41:55.537377 22831 solver.cpp:228] Iteration 100, loss = 0.700137
I0413 17:41:55.537420 22831 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:41:55.537432 22831 solver.cpp:244]     Train net output #1: loss = 0.700137 (* 1 = 0.700137 loss)
I0413 17:41:55.537444 22831 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 17:42:00.504364 22831 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 17:42:02.686058 22831 solver.cpp:404]     Test net output #0: accuracy = 0.551
I0413 17:42:02.686115 22831 solver.cpp:404]     Test net output #1: loss = 1.6977 (* 1 = 1.6977 loss)
I0413 17:42:02.840122 22831 solver.cpp:228] Iteration 120, loss = 0.72486
I0413 17:42:02.840168 22831 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:42:02.840180 22831 solver.cpp:244]     Train net output #1: loss = 0.72486 (* 1 = 0.72486 loss)
I0413 17:42:02.840199 22831 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 17:42:07.779338 22831 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 17:42:10.269826 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6513
I0413 17:42:10.269876 22831 solver.cpp:404]     Test net output #1: loss = 1.16478 (* 1 = 1.16478 loss)
I0413 17:42:10.425230 22831 solver.cpp:228] Iteration 140, loss = 0.547805
I0413 17:42:10.425271 22831 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:42:10.425284 22831 solver.cpp:244]     Train net output #1: loss = 0.547805 (* 1 = 0.547805 loss)
I0413 17:42:10.425293 22831 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 17:42:14.951669 22831 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 17:42:17.457609 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6727
I0413 17:42:17.457669 22831 solver.cpp:404]     Test net output #1: loss = 1.0115 (* 1 = 1.0115 loss)
I0413 17:42:17.649246 22831 solver.cpp:228] Iteration 160, loss = 0.623064
I0413 17:42:17.649288 22831 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:42:17.649302 22831 solver.cpp:244]     Train net output #1: loss = 0.623064 (* 1 = 0.623064 loss)
I0413 17:42:17.649310 22831 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 17:42:22.501193 22831 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 17:42:24.683979 22831 solver.cpp:404]     Test net output #0: accuracy = 0.698
I0413 17:42:24.684016 22831 solver.cpp:404]     Test net output #1: loss = 0.94534 (* 1 = 0.94534 loss)
I0413 17:42:24.846456 22831 solver.cpp:228] Iteration 180, loss = 0.724069
I0413 17:42:24.846520 22831 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 17:42:24.846532 22831 solver.cpp:244]     Train net output #1: loss = 0.724069 (* 1 = 0.724069 loss)
I0413 17:42:24.846550 22831 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 17:42:29.847962 22831 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 17:42:32.279692 22831 solver.cpp:404]     Test net output #0: accuracy = 0.624
I0413 17:42:32.279742 22831 solver.cpp:404]     Test net output #1: loss = 1.41863 (* 1 = 1.41863 loss)
I0413 17:42:32.431588 22831 solver.cpp:228] Iteration 200, loss = 0.626786
I0413 17:42:32.431629 22831 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:42:32.431640 22831 solver.cpp:244]     Train net output #1: loss = 0.626786 (* 1 = 0.626786 loss)
I0413 17:42:32.431649 22831 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 17:42:37.034893 22831 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 17:42:39.501484 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5667
I0413 17:42:39.501546 22831 solver.cpp:404]     Test net output #1: loss = 1.80381 (* 1 = 1.80381 loss)
I0413 17:42:39.691341 22831 solver.cpp:228] Iteration 220, loss = 0.534073
I0413 17:42:39.691383 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:42:39.691395 22831 solver.cpp:244]     Train net output #1: loss = 0.534073 (* 1 = 0.534073 loss)
I0413 17:42:39.691406 22831 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 17:42:44.474758 22831 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 17:42:46.742913 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6339
I0413 17:42:46.742952 22831 solver.cpp:404]     Test net output #1: loss = 1.39587 (* 1 = 1.39587 loss)
I0413 17:42:46.886111 22831 solver.cpp:228] Iteration 240, loss = 0.543175
I0413 17:42:46.886158 22831 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 17:42:46.886169 22831 solver.cpp:244]     Train net output #1: loss = 0.543175 (* 1 = 0.543175 loss)
I0413 17:42:46.886178 22831 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 17:42:51.881790 22831 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 17:42:54.245893 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6286
I0413 17:42:54.245957 22831 solver.cpp:404]     Test net output #1: loss = 1.19244 (* 1 = 1.19244 loss)
I0413 17:42:54.400873 22831 solver.cpp:228] Iteration 260, loss = 0.635287
I0413 17:42:54.400921 22831 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 17:42:54.400934 22831 solver.cpp:244]     Train net output #1: loss = 0.635287 (* 1 = 0.635287 loss)
I0413 17:42:54.400941 22831 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 17:42:59.089941 22831 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 17:43:01.564604 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6505
I0413 17:43:01.564652 22831 solver.cpp:404]     Test net output #1: loss = 1.19014 (* 1 = 1.19014 loss)
I0413 17:43:01.756878 22831 solver.cpp:228] Iteration 280, loss = 0.755116
I0413 17:43:01.756919 22831 solver.cpp:244]     Train net output #0: accuracy = 0.730469
I0413 17:43:01.756930 22831 solver.cpp:244]     Train net output #1: loss = 0.755116 (* 1 = 0.755116 loss)
I0413 17:43:01.756939 22831 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 17:43:06.408234 22831 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 17:43:08.764672 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5018
I0413 17:43:08.764716 22831 solver.cpp:404]     Test net output #1: loss = 2.38729 (* 1 = 2.38729 loss)
I0413 17:43:08.922183 22831 solver.cpp:228] Iteration 300, loss = 0.674586
I0413 17:43:08.922225 22831 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:43:08.922236 22831 solver.cpp:244]     Train net output #1: loss = 0.674586 (* 1 = 0.674586 loss)
I0413 17:43:08.922246 22831 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 17:43:13.915398 22831 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 17:43:16.203449 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6608
I0413 17:43:16.203491 22831 solver.cpp:404]     Test net output #1: loss = 1.0565 (* 1 = 1.0565 loss)
I0413 17:43:16.355123 22831 solver.cpp:228] Iteration 320, loss = 0.685332
I0413 17:43:16.355160 22831 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:43:16.355171 22831 solver.cpp:244]     Train net output #1: loss = 0.685332 (* 1 = 0.685332 loss)
I0413 17:43:16.355180 22831 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 17:43:21.142390 22831 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 17:43:23.601799 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4299
I0413 17:43:23.601841 22831 solver.cpp:404]     Test net output #1: loss = 2.54608 (* 1 = 2.54608 loss)
I0413 17:43:23.788777 22831 solver.cpp:228] Iteration 340, loss = 0.629497
I0413 17:43:23.788817 22831 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:43:23.788830 22831 solver.cpp:244]     Train net output #1: loss = 0.629497 (* 1 = 0.629497 loss)
I0413 17:43:23.788839 22831 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 17:43:28.436650 22831 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 17:43:30.857365 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4872
I0413 17:43:30.857419 22831 solver.cpp:404]     Test net output #1: loss = 1.91102 (* 1 = 1.91102 loss)
I0413 17:43:31.027421 22831 solver.cpp:228] Iteration 360, loss = 0.459386
I0413 17:43:31.027468 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:43:31.027480 22831 solver.cpp:244]     Train net output #1: loss = 0.459386 (* 1 = 0.459386 loss)
I0413 17:43:31.027489 22831 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 17:43:36.022657 22831 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 17:43:38.185475 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5848
I0413 17:43:38.185536 22831 solver.cpp:404]     Test net output #1: loss = 1.63129 (* 1 = 1.63129 loss)
I0413 17:43:38.339263 22831 solver.cpp:228] Iteration 380, loss = 0.667406
I0413 17:43:38.339304 22831 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:43:38.339318 22831 solver.cpp:244]     Train net output #1: loss = 0.667406 (* 1 = 0.667406 loss)
I0413 17:43:38.339328 22831 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 17:43:43.236121 22831 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 17:43:45.741704 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6124
I0413 17:43:45.741752 22831 solver.cpp:404]     Test net output #1: loss = 1.35295 (* 1 = 1.35295 loss)
I0413 17:43:45.893960 22831 solver.cpp:228] Iteration 400, loss = 0.479931
I0413 17:43:45.894003 22831 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:43:45.894016 22831 solver.cpp:244]     Train net output #1: loss = 0.479931 (* 1 = 0.479931 loss)
I0413 17:43:45.894024 22831 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 17:43:50.451623 22831 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 17:43:52.924166 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6252
I0413 17:43:52.924211 22831 solver.cpp:404]     Test net output #1: loss = 1.33342 (* 1 = 1.33342 loss)
I0413 17:43:53.112763 22831 solver.cpp:228] Iteration 420, loss = 0.558161
I0413 17:43:53.112808 22831 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:43:53.112821 22831 solver.cpp:244]     Train net output #1: loss = 0.558161 (* 1 = 0.558161 loss)
I0413 17:43:53.112833 22831 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 17:43:58.016475 22831 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 17:44:00.209422 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5936
I0413 17:44:00.209462 22831 solver.cpp:404]     Test net output #1: loss = 1.49021 (* 1 = 1.49021 loss)
I0413 17:44:00.364806 22831 solver.cpp:228] Iteration 440, loss = 0.49288
I0413 17:44:00.364892 22831 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:44:00.364928 22831 solver.cpp:244]     Train net output #1: loss = 0.49288 (* 1 = 0.49288 loss)
I0413 17:44:00.364961 22831 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 17:44:05.321570 22831 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 17:44:07.796375 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6778
I0413 17:44:07.796427 22831 solver.cpp:404]     Test net output #1: loss = 1.04313 (* 1 = 1.04313 loss)
I0413 17:44:07.932045 22831 solver.cpp:228] Iteration 460, loss = 0.534944
I0413 17:44:07.932085 22831 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:44:07.932096 22831 solver.cpp:244]     Train net output #1: loss = 0.534944 (* 1 = 0.534944 loss)
I0413 17:44:07.932106 22831 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 17:44:12.505105 22831 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 17:44:14.983355 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6509
I0413 17:44:14.983395 22831 solver.cpp:404]     Test net output #1: loss = 1.14541 (* 1 = 1.14541 loss)
I0413 17:44:15.164443 22831 solver.cpp:228] Iteration 480, loss = 0.574542
I0413 17:44:15.164480 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:44:15.164491 22831 solver.cpp:244]     Train net output #1: loss = 0.574542 (* 1 = 0.574542 loss)
I0413 17:44:15.164499 22831 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 17:44:19.979477 22831 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 17:44:22.211942 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6008
I0413 17:44:22.211984 22831 solver.cpp:404]     Test net output #1: loss = 1.49832 (* 1 = 1.49832 loss)
I0413 17:44:22.400614 22831 solver.cpp:228] Iteration 500, loss = 0.510998
I0413 17:44:22.400683 22831 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:44:22.400698 22831 solver.cpp:244]     Train net output #1: loss = 0.510998 (* 1 = 0.510998 loss)
I0413 17:44:22.400709 22831 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 17:44:27.398416 22831 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 17:44:29.756594 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6845
I0413 17:44:29.756645 22831 solver.cpp:404]     Test net output #1: loss = 1.01313 (* 1 = 1.01313 loss)
I0413 17:44:29.909970 22831 solver.cpp:228] Iteration 520, loss = 0.724514
I0413 17:44:29.910034 22831 solver.cpp:244]     Train net output #0: accuracy = 0.738281
I0413 17:44:29.910048 22831 solver.cpp:244]     Train net output #1: loss = 0.724514 (* 1 = 0.724514 loss)
I0413 17:44:29.910059 22831 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 17:44:34.568688 22831 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 17:44:37.070492 22831 solver.cpp:404]     Test net output #0: accuracy = 0.3732
I0413 17:44:37.070551 22831 solver.cpp:404]     Test net output #1: loss = 3.82026 (* 1 = 3.82026 loss)
I0413 17:44:37.217923 22831 solver.cpp:228] Iteration 540, loss = 0.589231
I0413 17:44:37.217958 22831 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:44:37.217968 22831 solver.cpp:244]     Train net output #1: loss = 0.589231 (* 1 = 0.589231 loss)
I0413 17:44:37.217977 22831 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 17:44:41.942396 22831 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 17:44:44.273406 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6312
I0413 17:44:44.273450 22831 solver.cpp:404]     Test net output #1: loss = 1.18442 (* 1 = 1.18442 loss)
I0413 17:44:44.454794 22831 solver.cpp:228] Iteration 560, loss = 0.600608
I0413 17:44:44.454843 22831 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:44:44.454854 22831 solver.cpp:244]     Train net output #1: loss = 0.600608 (* 1 = 0.600608 loss)
I0413 17:44:44.454866 22831 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 17:44:49.439851 22831 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 17:44:51.700703 22831 solver.cpp:404]     Test net output #0: accuracy = 0.508
I0413 17:44:51.700747 22831 solver.cpp:404]     Test net output #1: loss = 2.41253 (* 1 = 2.41253 loss)
I0413 17:44:51.852468 22831 solver.cpp:228] Iteration 580, loss = 0.570834
I0413 17:44:51.852526 22831 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:44:51.852538 22831 solver.cpp:244]     Train net output #1: loss = 0.570834 (* 1 = 0.570834 loss)
I0413 17:44:51.852552 22831 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 17:44:56.608104 22831 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 17:44:59.096285 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5973
I0413 17:44:59.096330 22831 solver.cpp:404]     Test net output #1: loss = 1.39129 (* 1 = 1.39129 loss)
I0413 17:44:59.271050 22831 solver.cpp:228] Iteration 600, loss = 0.544928
I0413 17:44:59.271090 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:44:59.271100 22831 solver.cpp:244]     Train net output #1: loss = 0.544928 (* 1 = 0.544928 loss)
I0413 17:44:59.271109 22831 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 17:45:03.901767 22831 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 17:45:06.321779 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6474
I0413 17:45:06.321817 22831 solver.cpp:404]     Test net output #1: loss = 1.32273 (* 1 = 1.32273 loss)
I0413 17:45:06.485116 22831 solver.cpp:228] Iteration 620, loss = 0.566431
I0413 17:45:06.485172 22831 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:45:06.485184 22831 solver.cpp:244]     Train net output #1: loss = 0.566431 (* 1 = 0.566431 loss)
I0413 17:45:06.485194 22831 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 17:45:11.472802 22831 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 17:45:13.646999 22831 solver.cpp:404]     Test net output #0: accuracy = 0.528
I0413 17:45:13.647112 22831 solver.cpp:404]     Test net output #1: loss = 1.7018 (* 1 = 1.7018 loss)
I0413 17:45:13.801265 22831 solver.cpp:228] Iteration 640, loss = 0.600671
I0413 17:45:13.801300 22831 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:45:13.801311 22831 solver.cpp:244]     Train net output #1: loss = 0.600671 (* 1 = 0.600671 loss)
I0413 17:45:13.801322 22831 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 17:45:18.629897 22831 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 17:45:21.123648 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5906
I0413 17:45:21.123685 22831 solver.cpp:404]     Test net output #1: loss = 1.37352 (* 1 = 1.37352 loss)
I0413 17:45:21.299849 22831 solver.cpp:228] Iteration 660, loss = 0.643337
I0413 17:45:21.299892 22831 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:45:21.299914 22831 solver.cpp:244]     Train net output #1: loss = 0.643337 (* 1 = 0.643337 loss)
I0413 17:45:21.299924 22831 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 17:45:25.832280 22831 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 17:45:28.332864 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5739
I0413 17:45:28.332902 22831 solver.cpp:404]     Test net output #1: loss = 1.59992 (* 1 = 1.59992 loss)
I0413 17:45:28.495067 22831 solver.cpp:228] Iteration 680, loss = 0.510274
I0413 17:45:28.495103 22831 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:45:28.495115 22831 solver.cpp:244]     Train net output #1: loss = 0.510274 (* 1 = 0.510274 loss)
I0413 17:45:28.495122 22831 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 17:45:33.415588 22831 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 17:45:35.611367 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6439
I0413 17:45:35.611415 22831 solver.cpp:404]     Test net output #1: loss = 1.19907 (* 1 = 1.19907 loss)
I0413 17:45:35.763602 22831 solver.cpp:228] Iteration 700, loss = 0.426892
I0413 17:45:35.763645 22831 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:45:35.763658 22831 solver.cpp:244]     Train net output #1: loss = 0.426892 (* 1 = 0.426892 loss)
I0413 17:45:35.763666 22831 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 17:45:40.707660 22831 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 17:45:43.185745 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4709
I0413 17:45:43.185782 22831 solver.cpp:404]     Test net output #1: loss = 1.8974 (* 1 = 1.8974 loss)
I0413 17:45:43.378027 22831 solver.cpp:228] Iteration 720, loss = 0.583472
I0413 17:45:43.378080 22831 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:45:43.378093 22831 solver.cpp:244]     Train net output #1: loss = 0.583472 (* 1 = 0.583472 loss)
I0413 17:45:43.378100 22831 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 17:45:47.912351 22831 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 17:45:50.420750 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5017
I0413 17:45:50.420791 22831 solver.cpp:404]     Test net output #1: loss = 1.85767 (* 1 = 1.85767 loss)
I0413 17:45:50.595616 22831 solver.cpp:228] Iteration 740, loss = 0.5712
I0413 17:45:50.595664 22831 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:45:50.595675 22831 solver.cpp:244]     Train net output #1: loss = 0.5712 (* 1 = 0.5712 loss)
I0413 17:45:50.595685 22831 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 17:45:55.407101 22831 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 17:45:57.661499 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6748
I0413 17:45:57.661531 22831 solver.cpp:404]     Test net output #1: loss = 1.09647 (* 1 = 1.09647 loss)
I0413 17:45:57.807953 22831 solver.cpp:228] Iteration 760, loss = 0.50868
I0413 17:45:57.808012 22831 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:45:57.808023 22831 solver.cpp:244]     Train net output #1: loss = 0.50868 (* 1 = 0.50868 loss)
I0413 17:45:57.808033 22831 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 17:46:02.807538 22831 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 17:46:05.190899 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6007
I0413 17:46:05.190964 22831 solver.cpp:404]     Test net output #1: loss = 1.71029 (* 1 = 1.71029 loss)
I0413 17:46:05.342555 22831 solver.cpp:228] Iteration 780, loss = 0.499148
I0413 17:46:05.342574 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:46:05.342582 22831 solver.cpp:244]     Train net output #1: loss = 0.499148 (* 1 = 0.499148 loss)
I0413 17:46:05.342592 22831 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 17:46:10.042886 22831 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 17:46:12.541463 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6813
I0413 17:46:12.541504 22831 solver.cpp:404]     Test net output #1: loss = 1.03949 (* 1 = 1.03949 loss)
I0413 17:46:12.697638 22831 solver.cpp:228] Iteration 800, loss = 0.614351
I0413 17:46:12.697693 22831 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:46:12.697705 22831 solver.cpp:244]     Train net output #1: loss = 0.614351 (* 1 = 0.614351 loss)
I0413 17:46:12.697718 22831 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 17:46:17.386088 22831 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 17:46:19.689108 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5767
I0413 17:46:19.689188 22831 solver.cpp:404]     Test net output #1: loss = 1.76247 (* 1 = 1.76247 loss)
I0413 17:46:19.867794 22831 solver.cpp:228] Iteration 820, loss = 0.553394
I0413 17:46:19.867866 22831 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:46:19.867882 22831 solver.cpp:244]     Train net output #1: loss = 0.553394 (* 1 = 0.553394 loss)
I0413 17:46:19.867893 22831 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 17:46:24.852100 22831 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 17:46:27.148207 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6596
I0413 17:46:27.148248 22831 solver.cpp:404]     Test net output #1: loss = 1.09718 (* 1 = 1.09718 loss)
I0413 17:46:27.300258 22831 solver.cpp:228] Iteration 840, loss = 0.53826
I0413 17:46:27.300298 22831 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:46:27.300310 22831 solver.cpp:244]     Train net output #1: loss = 0.53826 (* 1 = 0.53826 loss)
I0413 17:46:27.300319 22831 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 17:46:32.060245 22831 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 17:46:34.565995 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6403
I0413 17:46:34.566038 22831 solver.cpp:404]     Test net output #1: loss = 1.17034 (* 1 = 1.17034 loss)
I0413 17:46:34.711285 22831 solver.cpp:228] Iteration 860, loss = 0.616784
I0413 17:46:34.711347 22831 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:46:34.711361 22831 solver.cpp:244]     Train net output #1: loss = 0.616784 (* 1 = 0.616784 loss)
I0413 17:46:34.711372 22831 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 17:46:39.353009 22831 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 17:46:41.758005 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5559
I0413 17:46:41.758074 22831 solver.cpp:404]     Test net output #1: loss = 1.94856 (* 1 = 1.94856 loss)
I0413 17:46:41.949431 22831 solver.cpp:228] Iteration 880, loss = 0.580639
I0413 17:46:41.949476 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:46:41.949488 22831 solver.cpp:244]     Train net output #1: loss = 0.580639 (* 1 = 0.580639 loss)
I0413 17:46:41.949497 22831 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 17:46:46.932693 22831 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 17:46:49.131574 22831 solver.cpp:404]     Test net output #0: accuracy = 0.491
I0413 17:46:49.131615 22831 solver.cpp:404]     Test net output #1: loss = 2.50114 (* 1 = 2.50114 loss)
I0413 17:46:49.281093 22831 solver.cpp:228] Iteration 900, loss = 0.568303
I0413 17:46:49.281153 22831 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:46:49.281167 22831 solver.cpp:244]     Train net output #1: loss = 0.568303 (* 1 = 0.568303 loss)
I0413 17:46:49.281175 22831 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 17:46:54.126004 22831 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 17:46:56.595713 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5968
I0413 17:46:56.595757 22831 solver.cpp:404]     Test net output #1: loss = 1.49572 (* 1 = 1.49572 loss)
I0413 17:46:56.779983 22831 solver.cpp:228] Iteration 920, loss = 0.550197
I0413 17:46:56.780022 22831 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:46:56.780033 22831 solver.cpp:244]     Train net output #1: loss = 0.550197 (* 1 = 0.550197 loss)
I0413 17:46:56.780042 22831 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 17:47:01.305999 22831 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 17:47:03.801043 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4405
I0413 17:47:03.801090 22831 solver.cpp:404]     Test net output #1: loss = 2.41872 (* 1 = 2.41872 loss)
I0413 17:47:03.966020 22831 solver.cpp:228] Iteration 940, loss = 0.491639
I0413 17:47:03.966060 22831 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:47:03.966071 22831 solver.cpp:244]     Train net output #1: loss = 0.491639 (* 1 = 0.491639 loss)
I0413 17:47:03.966080 22831 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 17:47:08.893170 22831 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 17:47:11.073336 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6141
I0413 17:47:11.073388 22831 solver.cpp:404]     Test net output #1: loss = 1.39514 (* 1 = 1.39514 loss)
I0413 17:47:11.224632 22831 solver.cpp:228] Iteration 960, loss = 0.472512
I0413 17:47:11.224671 22831 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 17:47:11.224684 22831 solver.cpp:244]     Train net output #1: loss = 0.472512 (* 1 = 0.472512 loss)
I0413 17:47:11.224694 22831 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 17:47:16.156182 22831 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 17:47:18.632261 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4942
I0413 17:47:18.632302 22831 solver.cpp:404]     Test net output #1: loss = 2.2877 (* 1 = 2.2877 loss)
I0413 17:47:18.816436 22831 solver.cpp:228] Iteration 980, loss = 0.470129
I0413 17:47:18.816478 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:47:18.816489 22831 solver.cpp:244]     Train net output #1: loss = 0.470129 (* 1 = 0.470129 loss)
I0413 17:47:18.816498 22831 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 17:47:23.360252 22831 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 17:47:25.875805 22831 solver.cpp:404]     Test net output #0: accuracy = 0.652
I0413 17:47:25.875849 22831 solver.cpp:404]     Test net output #1: loss = 1.21359 (* 1 = 1.21359 loss)
I0413 17:47:26.024222 22831 solver.cpp:228] Iteration 1000, loss = 0.508827
I0413 17:47:26.024260 22831 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:47:26.024271 22831 solver.cpp:244]     Train net output #1: loss = 0.508827 (* 1 = 0.508827 loss)
I0413 17:47:26.024281 22831 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 17:47:30.890836 22831 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 17:47:33.112836 22831 solver.cpp:404]     Test net output #0: accuracy = 0.641
I0413 17:47:33.112890 22831 solver.cpp:404]     Test net output #1: loss = 1.2935 (* 1 = 1.2935 loss)
I0413 17:47:33.277401 22831 solver.cpp:228] Iteration 1020, loss = 0.531005
I0413 17:47:33.277447 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:47:33.277470 22831 solver.cpp:244]     Train net output #1: loss = 0.531005 (* 1 = 0.531005 loss)
I0413 17:47:33.277478 22831 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 17:47:38.270900 22831 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 17:47:40.658516 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6696
I0413 17:47:40.658556 22831 solver.cpp:404]     Test net output #1: loss = 1.03916 (* 1 = 1.03916 loss)
I0413 17:47:40.814800 22831 solver.cpp:228] Iteration 1040, loss = 0.556246
I0413 17:47:40.814877 22831 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:47:40.814914 22831 solver.cpp:244]     Train net output #1: loss = 0.556246 (* 1 = 0.556246 loss)
I0413 17:47:40.814929 22831 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 17:47:45.454159 22831 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 17:47:47.941891 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6425
I0413 17:47:47.941934 22831 solver.cpp:404]     Test net output #1: loss = 1.18987 (* 1 = 1.18987 loss)
I0413 17:47:48.124374 22831 solver.cpp:228] Iteration 1060, loss = 0.609907
I0413 17:47:48.124428 22831 solver.cpp:244]     Train net output #0: accuracy = 0.773438
I0413 17:47:48.124440 22831 solver.cpp:244]     Train net output #1: loss = 0.609907 (* 1 = 0.609907 loss)
I0413 17:47:48.124456 22831 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 17:47:52.874495 22831 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 17:47:55.192773 22831 solver.cpp:404]     Test net output #0: accuracy = 0.3363
I0413 17:47:55.192819 22831 solver.cpp:404]     Test net output #1: loss = 4.31224 (* 1 = 4.31224 loss)
I0413 17:47:55.352381 22831 solver.cpp:228] Iteration 1080, loss = 0.482706
I0413 17:47:55.352423 22831 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 17:47:55.352434 22831 solver.cpp:244]     Train net output #1: loss = 0.482706 (* 1 = 0.482706 loss)
I0413 17:47:55.352443 22831 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 17:48:00.341033 22831 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 17:48:02.650825 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6545
I0413 17:48:02.650924 22831 solver.cpp:404]     Test net output #1: loss = 1.1484 (* 1 = 1.1484 loss)
I0413 17:48:02.800273 22831 solver.cpp:228] Iteration 1100, loss = 0.497613
I0413 17:48:02.800313 22831 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:48:02.800323 22831 solver.cpp:244]     Train net output #1: loss = 0.497613 (* 1 = 0.497613 loss)
I0413 17:48:02.800333 22831 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 17:48:07.554538 22831 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 17:48:10.027391 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4177
I0413 17:48:10.027452 22831 solver.cpp:404]     Test net output #1: loss = 3.59201 (* 1 = 3.59201 loss)
I0413 17:48:10.206007 22831 solver.cpp:228] Iteration 1120, loss = 0.636602
I0413 17:48:10.206043 22831 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:48:10.206053 22831 solver.cpp:244]     Train net output #1: loss = 0.636602 (* 1 = 0.636602 loss)
I0413 17:48:10.206061 22831 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 17:48:14.829084 22831 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 17:48:17.218696 22831 solver.cpp:404]     Test net output #0: accuracy = 0.469
I0413 17:48:17.218741 22831 solver.cpp:404]     Test net output #1: loss = 2.42023 (* 1 = 2.42023 loss)
I0413 17:48:17.389226 22831 solver.cpp:228] Iteration 1140, loss = 0.582624
I0413 17:48:17.389303 22831 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:48:17.389322 22831 solver.cpp:244]     Train net output #1: loss = 0.582624 (* 1 = 0.582624 loss)
I0413 17:48:17.389336 22831 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 17:48:22.348839 22831 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 17:48:24.575438 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6777
I0413 17:48:24.575477 22831 solver.cpp:404]     Test net output #1: loss = 1.11934 (* 1 = 1.11934 loss)
I0413 17:48:24.729491 22831 solver.cpp:228] Iteration 1160, loss = 0.527993
I0413 17:48:24.729529 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:48:24.729542 22831 solver.cpp:244]     Train net output #1: loss = 0.527993 (* 1 = 0.527993 loss)
I0413 17:48:24.729552 22831 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 17:48:29.582720 22831 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 17:48:32.073500 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6488
I0413 17:48:32.073585 22831 solver.cpp:404]     Test net output #1: loss = 1.11296 (* 1 = 1.11296 loss)
I0413 17:48:32.237820 22831 solver.cpp:228] Iteration 1180, loss = 0.524101
I0413 17:48:32.237862 22831 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:48:32.237874 22831 solver.cpp:244]     Train net output #1: loss = 0.524101 (* 1 = 0.524101 loss)
I0413 17:48:32.237882 22831 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 17:48:36.798825 22831 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 17:48:39.258363 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6057
I0413 17:48:39.258409 22831 solver.cpp:404]     Test net output #1: loss = 1.43925 (* 1 = 1.43925 loss)
I0413 17:48:39.445927 22831 solver.cpp:228] Iteration 1200, loss = 0.471348
I0413 17:48:39.445976 22831 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 17:48:39.445987 22831 solver.cpp:244]     Train net output #1: loss = 0.471348 (* 1 = 0.471348 loss)
I0413 17:48:39.445996 22831 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 17:48:44.372519 22831 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 17:48:46.558063 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5694
I0413 17:48:46.558104 22831 solver.cpp:404]     Test net output #1: loss = 1.56528 (* 1 = 1.56528 loss)
I0413 17:48:46.708737 22831 solver.cpp:228] Iteration 1220, loss = 0.580221
I0413 17:48:46.708787 22831 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:48:46.708798 22831 solver.cpp:244]     Train net output #1: loss = 0.580221 (* 1 = 0.580221 loss)
I0413 17:48:46.708807 22831 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 17:48:51.611304 22831 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 17:48:54.131155 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5591
I0413 17:48:54.131252 22831 solver.cpp:404]     Test net output #1: loss = 1.45864 (* 1 = 1.45864 loss)
I0413 17:48:54.279980 22831 solver.cpp:228] Iteration 1240, loss = 0.545583
I0413 17:48:54.280015 22831 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:48:54.280025 22831 solver.cpp:244]     Train net output #1: loss = 0.545583 (* 1 = 0.545583 loss)
I0413 17:48:54.280033 22831 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 17:48:58.826355 22831 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 17:49:01.317761 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6235
I0413 17:49:01.317798 22831 solver.cpp:404]     Test net output #1: loss = 1.28722 (* 1 = 1.28722 loss)
I0413 17:49:01.507377 22831 solver.cpp:228] Iteration 1260, loss = 0.53952
I0413 17:49:01.507418 22831 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:49:01.507431 22831 solver.cpp:244]     Train net output #1: loss = 0.53952 (* 1 = 0.53952 loss)
I0413 17:49:01.507441 22831 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 17:49:06.338273 22831 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 17:49:08.531112 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6091
I0413 17:49:08.531162 22831 solver.cpp:404]     Test net output #1: loss = 1.53566 (* 1 = 1.53566 loss)
I0413 17:49:08.704620 22831 solver.cpp:228] Iteration 1280, loss = 0.503672
I0413 17:49:08.704660 22831 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 17:49:08.704673 22831 solver.cpp:244]     Train net output #1: loss = 0.503672 (* 1 = 0.503672 loss)
I0413 17:49:08.704682 22831 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 17:49:13.696130 22831 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 17:49:16.105840 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6038
I0413 17:49:16.105890 22831 solver.cpp:404]     Test net output #1: loss = 1.42206 (* 1 = 1.42206 loss)
I0413 17:49:16.257254 22831 solver.cpp:228] Iteration 1300, loss = 0.623773
I0413 17:49:16.257294 22831 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 17:49:16.257307 22831 solver.cpp:244]     Train net output #1: loss = 0.623773 (* 1 = 0.623773 loss)
I0413 17:49:16.257315 22831 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 17:49:20.870360 22831 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 17:49:23.334621 22831 solver.cpp:404]     Test net output #0: accuracy = 0.4196
I0413 17:49:23.334682 22831 solver.cpp:404]     Test net output #1: loss = 3.1628 (* 1 = 3.1628 loss)
I0413 17:49:23.524866 22831 solver.cpp:228] Iteration 1320, loss = 0.559583
I0413 17:49:23.524906 22831 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:49:23.524919 22831 solver.cpp:244]     Train net output #1: loss = 0.559583 (* 1 = 0.559583 loss)
I0413 17:49:23.524926 22831 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 17:49:28.254122 22831 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 17:49:30.522236 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6391
I0413 17:49:30.522291 22831 solver.cpp:404]     Test net output #1: loss = 1.27801 (* 1 = 1.27801 loss)
I0413 17:49:30.676748 22831 solver.cpp:228] Iteration 1340, loss = 0.581196
I0413 17:49:30.676810 22831 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 17:49:30.676821 22831 solver.cpp:244]     Train net output #1: loss = 0.581196 (* 1 = 0.581196 loss)
I0413 17:49:30.676832 22831 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 17:49:35.687988 22831 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 17:49:38.041823 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5996
I0413 17:49:38.041860 22831 solver.cpp:404]     Test net output #1: loss = 1.76924 (* 1 = 1.76924 loss)
I0413 17:49:38.194823 22831 solver.cpp:228] Iteration 1360, loss = 0.494275
I0413 17:49:38.194866 22831 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 17:49:38.194877 22831 solver.cpp:244]     Train net output #1: loss = 0.494275 (* 1 = 0.494275 loss)
I0413 17:49:38.194886 22831 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 17:49:42.946250 22831 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 17:49:45.415565 22831 solver.cpp:404]     Test net output #0: accuracy = 0.7024
I0413 17:49:45.415618 22831 solver.cpp:404]     Test net output #1: loss = 0.914501 (* 1 = 0.914501 loss)
I0413 17:49:45.585222 22831 solver.cpp:228] Iteration 1380, loss = 0.539785
I0413 17:49:45.585261 22831 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:49:45.585273 22831 solver.cpp:244]     Train net output #1: loss = 0.539785 (* 1 = 0.539785 loss)
I0413 17:49:45.585284 22831 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 17:49:50.286404 22831 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 17:49:52.640588 22831 solver.cpp:404]     Test net output #0: accuracy = 0.655
I0413 17:49:52.640635 22831 solver.cpp:404]     Test net output #1: loss = 1.34171 (* 1 = 1.34171 loss)
I0413 17:49:52.829742 22831 solver.cpp:228] Iteration 1400, loss = 0.547622
I0413 17:49:52.829787 22831 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:49:52.829798 22831 solver.cpp:244]     Train net output #1: loss = 0.547622 (* 1 = 0.547622 loss)
I0413 17:49:52.829807 22831 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 17:49:57.821621 22831 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 17:50:00.072252 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6638
I0413 17:50:00.072304 22831 solver.cpp:404]     Test net output #1: loss = 1.1277 (* 1 = 1.1277 loss)
I0413 17:50:00.226603 22831 solver.cpp:228] Iteration 1420, loss = 0.619721
I0413 17:50:00.226665 22831 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:50:00.226680 22831 solver.cpp:244]     Train net output #1: loss = 0.619721 (* 1 = 0.619721 loss)
I0413 17:50:00.226721 22831 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 17:50:05.032554 22831 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 17:50:07.515527 22831 solver.cpp:404]     Test net output #0: accuracy = 0.7226
I0413 17:50:07.515573 22831 solver.cpp:404]     Test net output #1: loss = 0.807576 (* 1 = 0.807576 loss)
I0413 17:50:07.687566 22831 solver.cpp:228] Iteration 1440, loss = 0.510196
I0413 17:50:07.687608 22831 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 17:50:07.687620 22831 solver.cpp:244]     Train net output #1: loss = 0.510196 (* 1 = 0.510196 loss)
I0413 17:50:07.687629 22831 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 17:50:12.268519 22831 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 17:50:14.705988 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6151
I0413 17:50:14.706033 22831 solver.cpp:404]     Test net output #1: loss = 1.26009 (* 1 = 1.26009 loss)
I0413 17:50:14.885329 22831 solver.cpp:228] Iteration 1460, loss = 0.533595
I0413 17:50:14.885385 22831 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:50:14.885402 22831 solver.cpp:244]     Train net output #1: loss = 0.533595 (* 1 = 0.533595 loss)
I0413 17:50:14.885423 22831 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 17:50:19.882693 22831 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 17:50:22.039680 22831 solver.cpp:404]     Test net output #0: accuracy = 0.712
I0413 17:50:22.039718 22831 solver.cpp:404]     Test net output #1: loss = 0.930321 (* 1 = 0.930321 loss)
I0413 17:50:22.194582 22831 solver.cpp:228] Iteration 1480, loss = 0.470018
I0413 17:50:22.194646 22831 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 17:50:22.194665 22831 solver.cpp:244]     Train net output #1: loss = 0.470018 (* 1 = 0.470018 loss)
I0413 17:50:22.194679 22831 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 17:50:27.118264 22831 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 17:50:29.595360 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6483
I0413 17:50:29.595405 22831 solver.cpp:404]     Test net output #1: loss = 1.1976 (* 1 = 1.1976 loss)
I0413 17:50:29.784693 22831 solver.cpp:228] Iteration 1500, loss = 0.485206
I0413 17:50:29.784734 22831 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 17:50:29.784746 22831 solver.cpp:244]     Train net output #1: loss = 0.485206 (* 1 = 0.485206 loss)
I0413 17:50:29.784756 22831 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 17:50:34.302853 22831 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 17:50:36.800088 22831 solver.cpp:404]     Test net output #0: accuracy = 0.572
I0413 17:50:36.800132 22831 solver.cpp:404]     Test net output #1: loss = 1.52128 (* 1 = 1.52128 loss)
I0413 17:50:36.965160 22831 solver.cpp:228] Iteration 1520, loss = 0.492449
I0413 17:50:36.965204 22831 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:50:36.965215 22831 solver.cpp:244]     Train net output #1: loss = 0.492449 (* 1 = 0.492449 loss)
I0413 17:50:36.965224 22831 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 17:50:41.843850 22831 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 17:50:44.018304 22831 solver.cpp:404]     Test net output #0: accuracy = 0.7553
I0413 17:50:44.018347 22831 solver.cpp:404]     Test net output #1: loss = 0.729487 (* 1 = 0.729487 loss)
I0413 17:50:44.170429 22831 solver.cpp:228] Iteration 1540, loss = 0.543445
I0413 17:50:44.170476 22831 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 17:50:44.170490 22831 solver.cpp:244]     Train net output #1: loss = 0.543445 (* 1 = 0.543445 loss)
I0413 17:50:44.170502 22831 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 17:50:49.172251 22831 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 17:50:51.599387 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6647
I0413 17:50:51.599426 22831 solver.cpp:404]     Test net output #1: loss = 1.13429 (* 1 = 1.13429 loss)
I0413 17:50:51.749554 22831 solver.cpp:228] Iteration 1560, loss = 0.585997
I0413 17:50:51.749601 22831 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 17:50:51.749613 22831 solver.cpp:244]     Train net output #1: loss = 0.585997 (* 1 = 0.585997 loss)
I0413 17:50:51.749621 22831 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 17:50:56.340699 22831 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 17:50:58.851864 22831 solver.cpp:404]     Test net output #0: accuracy = 0.7243
I0413 17:50:58.851904 22831 solver.cpp:404]     Test net output #1: loss = 0.816265 (* 1 = 0.816265 loss)
I0413 17:50:59.034690 22831 solver.cpp:228] Iteration 1580, loss = 0.500045
I0413 17:50:59.034744 22831 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:50:59.034756 22831 solver.cpp:244]     Train net output #1: loss = 0.500045 (* 1 = 0.500045 loss)
I0413 17:50:59.034767 22831 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 17:51:03.816433 22831 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 17:51:06.104558 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6248
I0413 17:51:06.104604 22831 solver.cpp:404]     Test net output #1: loss = 1.23546 (* 1 = 1.23546 loss)
I0413 17:51:06.249294 22831 solver.cpp:228] Iteration 1600, loss = 0.461483
I0413 17:51:06.249341 22831 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:51:06.249367 22831 solver.cpp:244]     Train net output #1: loss = 0.461483 (* 1 = 0.461483 loss)
I0413 17:51:06.249377 22831 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 17:51:11.227727 22831 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 17:51:13.582384 22831 solver.cpp:404]     Test net output #0: accuracy = 0.7186
I0413 17:51:13.582429 22831 solver.cpp:404]     Test net output #1: loss = 0.882834 (* 1 = 0.882834 loss)
I0413 17:51:13.735898 22831 solver.cpp:228] Iteration 1620, loss = 0.498696
I0413 17:51:13.735952 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:51:13.735965 22831 solver.cpp:244]     Train net output #1: loss = 0.498696 (* 1 = 0.498696 loss)
I0413 17:51:13.735975 22831 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 17:51:18.434255 22831 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 17:51:20.895251 22831 solver.cpp:404]     Test net output #0: accuracy = 0.641
I0413 17:51:20.895292 22831 solver.cpp:404]     Test net output #1: loss = 1.28685 (* 1 = 1.28685 loss)
I0413 17:51:21.086805 22831 solver.cpp:228] Iteration 1640, loss = 0.53537
I0413 17:51:21.086846 22831 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:51:21.086858 22831 solver.cpp:244]     Train net output #1: loss = 0.53537 (* 1 = 0.53537 loss)
I0413 17:51:21.086868 22831 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 17:51:25.739723 22831 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 17:51:28.082747 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6163
I0413 17:51:28.082809 22831 solver.cpp:404]     Test net output #1: loss = 1.44887 (* 1 = 1.44887 loss)
I0413 17:51:28.240380 22831 solver.cpp:228] Iteration 1660, loss = 0.438142
I0413 17:51:28.240418 22831 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 17:51:28.240429 22831 solver.cpp:244]     Train net output #1: loss = 0.438142 (* 1 = 0.438142 loss)
I0413 17:51:28.240439 22831 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 17:51:33.206710 22831 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 17:51:35.494403 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6211
I0413 17:51:35.494442 22831 solver.cpp:404]     Test net output #1: loss = 1.28055 (* 1 = 1.28055 loss)
I0413 17:51:35.648725 22831 solver.cpp:228] Iteration 1680, loss = 0.51839
I0413 17:51:35.648771 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:51:35.648783 22831 solver.cpp:244]     Train net output #1: loss = 0.51839 (* 1 = 0.51839 loss)
I0413 17:51:35.648793 22831 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 17:51:40.444108 22831 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 17:51:42.933065 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6635
I0413 17:51:42.933181 22831 solver.cpp:404]     Test net output #1: loss = 1.08023 (* 1 = 1.08023 loss)
I0413 17:51:43.124229 22831 solver.cpp:228] Iteration 1700, loss = 0.478874
I0413 17:51:43.124274 22831 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:51:43.124287 22831 solver.cpp:244]     Train net output #1: loss = 0.478874 (* 1 = 0.478874 loss)
I0413 17:51:43.124296 22831 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 17:51:47.725306 22831 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 17:51:50.156942 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6355
I0413 17:51:50.157003 22831 solver.cpp:404]     Test net output #1: loss = 1.10583 (* 1 = 1.10583 loss)
I0413 17:51:50.334393 22831 solver.cpp:228] Iteration 1720, loss = 0.599909
I0413 17:51:50.334437 22831 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:51:50.334449 22831 solver.cpp:244]     Train net output #1: loss = 0.599909 (* 1 = 0.599909 loss)
I0413 17:51:50.334457 22831 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 17:51:55.347360 22831 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 17:51:57.510459 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6382
I0413 17:51:57.510504 22831 solver.cpp:404]     Test net output #1: loss = 1.1274 (* 1 = 1.1274 loss)
I0413 17:51:57.662781 22831 solver.cpp:228] Iteration 1740, loss = 0.529265
I0413 17:51:57.662827 22831 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:51:57.662837 22831 solver.cpp:244]     Train net output #1: loss = 0.529265 (* 1 = 0.529265 loss)
I0413 17:51:57.662847 22831 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 17:52:02.559249 22831 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 17:52:05.074079 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6629
I0413 17:52:05.074116 22831 solver.cpp:404]     Test net output #1: loss = 1.08817 (* 1 = 1.08817 loss)
I0413 17:52:05.247835 22831 solver.cpp:228] Iteration 1760, loss = 0.655882
I0413 17:52:05.247876 22831 solver.cpp:244]     Train net output #0: accuracy = 0.761719
I0413 17:52:05.247889 22831 solver.cpp:244]     Train net output #1: loss = 0.655882 (* 1 = 0.655882 loss)
I0413 17:52:05.247897 22831 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 17:52:09.794384 22831 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 17:52:12.256753 22831 solver.cpp:404]     Test net output #0: accuracy = 0.7354
I0413 17:52:12.256815 22831 solver.cpp:404]     Test net output #1: loss = 0.819336 (* 1 = 0.819336 loss)
I0413 17:52:12.449589 22831 solver.cpp:228] Iteration 1780, loss = 0.500457
I0413 17:52:12.449635 22831 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:52:12.449645 22831 solver.cpp:244]     Train net output #1: loss = 0.500457 (* 1 = 0.500457 loss)
I0413 17:52:12.449654 22831 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 17:52:17.330984 22831 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 17:52:19.535480 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6214
I0413 17:52:19.535528 22831 solver.cpp:404]     Test net output #1: loss = 1.39335 (* 1 = 1.39335 loss)
I0413 17:52:19.690270 22831 solver.cpp:228] Iteration 1800, loss = 0.530824
I0413 17:52:19.690310 22831 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:52:19.690322 22831 solver.cpp:244]     Train net output #1: loss = 0.530824 (* 1 = 0.530824 loss)
I0413 17:52:19.690330 22831 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 17:52:24.686729 22831 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 17:52:27.119338 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6449
I0413 17:52:27.119420 22831 solver.cpp:404]     Test net output #1: loss = 1.27339 (* 1 = 1.27339 loss)
I0413 17:52:27.272349 22831 solver.cpp:228] Iteration 1820, loss = 0.436965
I0413 17:52:27.272388 22831 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 17:52:27.272400 22831 solver.cpp:244]     Train net output #1: loss = 0.436965 (* 1 = 0.436965 loss)
I0413 17:52:27.272408 22831 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 17:52:31.869933 22831 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 17:52:34.385705 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6987
I0413 17:52:34.385751 22831 solver.cpp:404]     Test net output #1: loss = 0.98 (* 1 = 0.98 loss)
I0413 17:52:34.557508 22831 solver.cpp:228] Iteration 1840, loss = 0.494889
I0413 17:52:34.557548 22831 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:52:34.557559 22831 solver.cpp:244]     Train net output #1: loss = 0.494889 (* 1 = 0.494889 loss)
I0413 17:52:34.557566 22831 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 17:52:39.350226 22831 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 17:52:41.621217 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5229
I0413 17:52:41.621279 22831 solver.cpp:404]     Test net output #1: loss = 2.24019 (* 1 = 2.24019 loss)
I0413 17:52:41.777452 22831 solver.cpp:228] Iteration 1860, loss = 0.508718
I0413 17:52:41.777472 22831 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:52:41.777482 22831 solver.cpp:244]     Train net output #1: loss = 0.508718 (* 1 = 0.508718 loss)
I0413 17:52:41.777500 22831 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 17:52:46.747061 22831 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 17:52:49.101483 22831 solver.cpp:404]     Test net output #0: accuracy = 0.7208
I0413 17:52:49.101537 22831 solver.cpp:404]     Test net output #1: loss = 0.870685 (* 1 = 0.870685 loss)
I0413 17:52:49.253954 22831 solver.cpp:228] Iteration 1880, loss = 0.52217
I0413 17:52:49.253995 22831 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:52:49.254006 22831 solver.cpp:244]     Train net output #1: loss = 0.52217 (* 1 = 0.52217 loss)
I0413 17:52:49.254015 22831 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 17:52:53.986166 22831 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 17:52:56.451030 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5854
I0413 17:52:56.451078 22831 solver.cpp:404]     Test net output #1: loss = 1.60313 (* 1 = 1.60313 loss)
I0413 17:52:56.643023 22831 solver.cpp:228] Iteration 1900, loss = 0.549953
I0413 17:52:56.643064 22831 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:52:56.643075 22831 solver.cpp:244]     Train net output #1: loss = 0.549953 (* 1 = 0.549953 loss)
I0413 17:52:56.643085 22831 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 17:53:01.317144 22831 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 17:53:03.678447 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5968
I0413 17:53:03.678488 22831 solver.cpp:404]     Test net output #1: loss = 1.34557 (* 1 = 1.34557 loss)
I0413 17:53:03.825515 22831 solver.cpp:228] Iteration 1920, loss = 0.640053
I0413 17:53:03.825575 22831 solver.cpp:244]     Train net output #0: accuracy = 0.734375
I0413 17:53:03.825590 22831 solver.cpp:244]     Train net output #1: loss = 0.640053 (* 1 = 0.640053 loss)
I0413 17:53:03.825600 22831 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 17:53:08.816628 22831 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 17:53:11.080860 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6326
I0413 17:53:11.080924 22831 solver.cpp:404]     Test net output #1: loss = 1.43577 (* 1 = 1.43577 loss)
I0413 17:53:11.235976 22831 solver.cpp:228] Iteration 1940, loss = 0.431705
I0413 17:53:11.236016 22831 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 17:53:11.236027 22831 solver.cpp:244]     Train net output #1: loss = 0.431705 (* 1 = 0.431705 loss)
I0413 17:53:11.236035 22831 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 17:53:16.010579 22831 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 17:53:18.464756 22831 solver.cpp:404]     Test net output #0: accuracy = 0.5779
I0413 17:53:18.464817 22831 solver.cpp:404]     Test net output #1: loss = 1.70117 (* 1 = 1.70117 loss)
I0413 17:53:18.654809 22831 solver.cpp:228] Iteration 1960, loss = 0.437247
I0413 17:53:18.654858 22831 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:53:18.654870 22831 solver.cpp:244]     Train net output #1: loss = 0.437247 (* 1 = 0.437247 loss)
I0413 17:53:18.654880 22831 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 17:53:23.240728 22831 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 17:53:25.665278 22831 solver.cpp:404]     Test net output #0: accuracy = 0.6507
I0413 17:53:25.665318 22831 solver.cpp:404]     Test net output #1: loss = 1.22531 (* 1 = 1.22531 loss)
I0413 17:53:25.821159 22831 solver.cpp:228] Iteration 1980, loss = 0.494506
I0413 17:53:25.821204 22831 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 17:53:25.821218 22831 solver.cpp:244]     Train net output #1: loss = 0.494506 (* 1 = 0.494506 loss)
I0413 17:53:25.821228 22831 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 17:53:30.810329 22831 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar4/ResNet-cifar4_iter_2000.caffemodel
I0413 17:53:30.815237 22831 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar4/ResNet-cifar4_iter_2000.solverstate
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 17:53:33.282683 26605 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar5/ResNet-cifar5"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar5.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 17:53:33.282724 26605 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar5.prototxt
I0413 17:53:33.283926 26605 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 17:53:33.284287 26605 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv3_3"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:53:33.284577 26605 layer_factory.hpp:77] Creating layer cifar
I0413 17:53:33.285567 26605 net.cpp:91] Creating Layer cifar
I0413 17:53:33.285579 26605 net.cpp:399] cifar -> data
I0413 17:53:33.285605 26605 net.cpp:399] cifar -> label
I0413 17:53:33.285621 26605 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:53:33.319037 26667 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 17:53:33.349052 26605 data_layer.cpp:41] output data size: 256,3,32,32
I0413 17:53:33.366901 26605 net.cpp:141] Setting up cifar
I0413 17:53:33.366946 26605 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 17:53:33.366952 26605 net.cpp:148] Top shape: 256 (256)
I0413 17:53:33.366957 26605 net.cpp:156] Memory required for data: 3146752
I0413 17:53:33.366966 26605 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:53:33.366986 26605 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:53:33.366992 26605 net.cpp:425] label_cifar_1_split <- label
I0413 17:53:33.367002 26605 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:53:33.367017 26605 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:53:33.367126 26605 net.cpp:141] Setting up label_cifar_1_split
I0413 17:53:33.367136 26605 net.cpp:148] Top shape: 256 (256)
I0413 17:53:33.367141 26605 net.cpp:148] Top shape: 256 (256)
I0413 17:53:33.367144 26605 net.cpp:156] Memory required for data: 3148800
I0413 17:53:33.367148 26605 layer_factory.hpp:77] Creating layer conv1
I0413 17:53:33.367163 26605 net.cpp:91] Creating Layer conv1
I0413 17:53:33.367168 26605 net.cpp:425] conv1 <- data
I0413 17:53:33.367177 26605 net.cpp:399] conv1 -> conv1
I0413 17:53:33.581262 26605 net.cpp:141] Setting up conv1
I0413 17:53:33.581302 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.581308 26605 net.cpp:156] Memory required for data: 19926016
I0413 17:53:33.581326 26605 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:53:33.581341 26605 net.cpp:91] Creating Layer bn_conv1
I0413 17:53:33.581346 26605 net.cpp:425] bn_conv1 <- conv1
I0413 17:53:33.581356 26605 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:53:33.581537 26605 net.cpp:141] Setting up bn_conv1
I0413 17:53:33.581545 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.581550 26605 net.cpp:156] Memory required for data: 36703232
I0413 17:53:33.581562 26605 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:53:33.581570 26605 net.cpp:91] Creating Layer scale_conv1
I0413 17:53:33.581574 26605 net.cpp:425] scale_conv1 <- conv1
I0413 17:53:33.581580 26605 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:53:33.581614 26605 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:53:33.581699 26605 net.cpp:141] Setting up scale_conv1
I0413 17:53:33.581707 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.581712 26605 net.cpp:156] Memory required for data: 53480448
I0413 17:53:33.581718 26605 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:53:33.581725 26605 net.cpp:91] Creating Layer conv1_relu
I0413 17:53:33.581729 26605 net.cpp:425] conv1_relu <- conv1
I0413 17:53:33.581735 26605 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:53:33.582335 26605 net.cpp:141] Setting up conv1_relu
I0413 17:53:33.582356 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.582361 26605 net.cpp:156] Memory required for data: 70257664
I0413 17:53:33.582366 26605 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:53:33.582373 26605 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:53:33.582377 26605 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:53:33.582383 26605 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:53:33.582391 26605 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:53:33.582425 26605 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:53:33.582432 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.582437 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.582440 26605 net.cpp:156] Memory required for data: 103812096
I0413 17:53:33.582444 26605 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:53:33.582455 26605 net.cpp:91] Creating Layer conv2_1a
I0413 17:53:33.582459 26605 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:53:33.582466 26605 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:53:33.586822 26605 net.cpp:141] Setting up conv2_1a
I0413 17:53:33.586841 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.586845 26605 net.cpp:156] Memory required for data: 120589312
I0413 17:53:33.586856 26605 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:53:33.586866 26605 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:53:33.586871 26605 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:53:33.586879 26605 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:53:33.587034 26605 net.cpp:141] Setting up bn_conv2_1a
I0413 17:53:33.587043 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.587045 26605 net.cpp:156] Memory required for data: 137366528
I0413 17:53:33.587054 26605 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:53:33.587061 26605 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:53:33.587065 26605 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:53:33.587070 26605 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:53:33.587101 26605 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:53:33.587194 26605 net.cpp:141] Setting up scale_conv2_1a
I0413 17:53:33.587201 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.587205 26605 net.cpp:156] Memory required for data: 154143744
I0413 17:53:33.587211 26605 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:53:33.587218 26605 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:53:33.587220 26605 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:53:33.587227 26605 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:53:33.587875 26605 net.cpp:141] Setting up conv2_1a_relu
I0413 17:53:33.587888 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.587893 26605 net.cpp:156] Memory required for data: 170920960
I0413 17:53:33.587896 26605 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:53:33.587909 26605 net.cpp:91] Creating Layer conv2_1b
I0413 17:53:33.587913 26605 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:53:33.587920 26605 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:53:33.591366 26605 net.cpp:141] Setting up conv2_1b
I0413 17:53:33.591380 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.591385 26605 net.cpp:156] Memory required for data: 187698176
I0413 17:53:33.591392 26605 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:53:33.591401 26605 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:53:33.591405 26605 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:53:33.591411 26605 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:53:33.591569 26605 net.cpp:141] Setting up bn_conv2_1b
I0413 17:53:33.591577 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.591580 26605 net.cpp:156] Memory required for data: 204475392
I0413 17:53:33.591590 26605 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:53:33.591598 26605 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:53:33.591609 26605 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:53:33.591614 26605 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:53:33.591648 26605 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:53:33.591745 26605 net.cpp:141] Setting up scale_conv2_1b
I0413 17:53:33.591753 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.591756 26605 net.cpp:156] Memory required for data: 221252608
I0413 17:53:33.591763 26605 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:53:33.591778 26605 net.cpp:91] Creating Layer conv2_1
I0413 17:53:33.591781 26605 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:53:33.591786 26605 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:53:33.591792 26605 net.cpp:399] conv2_1 -> conv2_1
I0413 17:53:33.591814 26605 net.cpp:141] Setting up conv2_1
I0413 17:53:33.591821 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.591825 26605 net.cpp:156] Memory required for data: 238029824
I0413 17:53:33.591828 26605 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:53:33.591836 26605 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:53:33.591840 26605 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:53:33.591845 26605 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:53:33.592430 26605 net.cpp:141] Setting up conv2_1_relu
I0413 17:53:33.592440 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.592444 26605 net.cpp:156] Memory required for data: 254807040
I0413 17:53:33.592447 26605 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:53:33.592456 26605 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:53:33.592460 26605 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:53:33.592466 26605 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:53:33.592473 26605 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:53:33.592509 26605 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:53:33.592515 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.592519 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.592524 26605 net.cpp:156] Memory required for data: 288361472
I0413 17:53:33.592526 26605 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:53:33.592537 26605 net.cpp:91] Creating Layer conv2_2a
I0413 17:53:33.592541 26605 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:53:33.592550 26605 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:53:33.597316 26605 net.cpp:141] Setting up conv2_2a
I0413 17:53:33.597333 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.597339 26605 net.cpp:156] Memory required for data: 305138688
I0413 17:53:33.597347 26605 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:53:33.597360 26605 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:53:33.597365 26605 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:53:33.597373 26605 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:53:33.597606 26605 net.cpp:141] Setting up bn_conv2_2a
I0413 17:53:33.597615 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.597618 26605 net.cpp:156] Memory required for data: 321915904
I0413 17:53:33.597625 26605 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:53:33.597631 26605 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:53:33.597635 26605 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:53:33.597640 26605 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:53:33.597671 26605 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:53:33.597764 26605 net.cpp:141] Setting up scale_conv2_2a
I0413 17:53:33.597770 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.597774 26605 net.cpp:156] Memory required for data: 338693120
I0413 17:53:33.597780 26605 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:53:33.597789 26605 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:53:33.597791 26605 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:53:33.597800 26605 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:53:33.610783 26605 net.cpp:141] Setting up conv2_2a_relu
I0413 17:53:33.610798 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.610802 26605 net.cpp:156] Memory required for data: 355470336
I0413 17:53:33.610806 26605 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:53:33.610821 26605 net.cpp:91] Creating Layer conv2_2b
I0413 17:53:33.610826 26605 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:53:33.610832 26605 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:53:33.613356 26605 net.cpp:141] Setting up conv2_2b
I0413 17:53:33.613373 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.613378 26605 net.cpp:156] Memory required for data: 372247552
I0413 17:53:33.613384 26605 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:53:33.613394 26605 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:53:33.613399 26605 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:53:33.613406 26605 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:53:33.613590 26605 net.cpp:141] Setting up bn_conv2_2b
I0413 17:53:33.613597 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.613600 26605 net.cpp:156] Memory required for data: 389024768
I0413 17:53:33.613612 26605 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:53:33.613620 26605 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:53:33.613623 26605 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:53:33.613628 26605 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:53:33.613662 26605 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:53:33.613754 26605 net.cpp:141] Setting up scale_conv2_2b
I0413 17:53:33.613761 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.613765 26605 net.cpp:156] Memory required for data: 405801984
I0413 17:53:33.613770 26605 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:53:33.613776 26605 net.cpp:91] Creating Layer conv2_2
I0413 17:53:33.613780 26605 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:53:33.613785 26605 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:53:33.613792 26605 net.cpp:399] conv2_2 -> conv2_2
I0413 17:53:33.613812 26605 net.cpp:141] Setting up conv2_2
I0413 17:53:33.613818 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.613822 26605 net.cpp:156] Memory required for data: 422579200
I0413 17:53:33.613826 26605 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:53:33.613832 26605 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:53:33.613837 26605 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:53:33.613842 26605 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:53:33.616742 26605 net.cpp:141] Setting up conv2_2_relu
I0413 17:53:33.616760 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.616765 26605 net.cpp:156] Memory required for data: 439356416
I0413 17:53:33.616770 26605 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:53:33.616775 26605 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:53:33.616780 26605 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:53:33.616787 26605 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:53:33.616796 26605 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:53:33.616833 26605 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:53:33.616853 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.616858 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.616861 26605 net.cpp:156] Memory required for data: 472910848
I0413 17:53:33.616865 26605 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:53:33.616876 26605 net.cpp:91] Creating Layer conv2_3a
I0413 17:53:33.616880 26605 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:53:33.616886 26605 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:53:33.625072 26605 net.cpp:141] Setting up conv2_3a
I0413 17:53:33.625147 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.625164 26605 net.cpp:156] Memory required for data: 489688064
I0413 17:53:33.625179 26605 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:53:33.625193 26605 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:53:33.625200 26605 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:53:33.625213 26605 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:53:33.625421 26605 net.cpp:141] Setting up bn_conv2_3a
I0413 17:53:33.625440 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.625445 26605 net.cpp:156] Memory required for data: 506465280
I0413 17:53:33.625454 26605 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:53:33.625463 26605 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:53:33.625468 26605 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:53:33.625474 26605 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:53:33.625515 26605 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:53:33.625632 26605 net.cpp:141] Setting up scale_conv2_3a
I0413 17:53:33.625643 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.625648 26605 net.cpp:156] Memory required for data: 523242496
I0413 17:53:33.625658 26605 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:53:33.625669 26605 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:53:33.625674 26605 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:53:33.625684 26605 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:53:33.626127 26605 net.cpp:141] Setting up conv2_3a_relu
I0413 17:53:33.626185 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.626245 26605 net.cpp:156] Memory required for data: 540019712
I0413 17:53:33.626258 26605 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:53:33.626286 26605 net.cpp:91] Creating Layer conv2_3b
I0413 17:53:33.626297 26605 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:53:33.626322 26605 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:53:33.632864 26605 net.cpp:141] Setting up conv2_3b
I0413 17:53:33.632915 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.632920 26605 net.cpp:156] Memory required for data: 556796928
I0413 17:53:33.632932 26605 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:53:33.632953 26605 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:53:33.632961 26605 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:53:33.632969 26605 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:53:33.633177 26605 net.cpp:141] Setting up bn_conv2_3b
I0413 17:53:33.633186 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.633190 26605 net.cpp:156] Memory required for data: 573574144
I0413 17:53:33.633199 26605 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:53:33.633210 26605 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:53:33.633215 26605 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:53:33.633221 26605 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:53:33.633263 26605 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:53:33.633373 26605 net.cpp:141] Setting up scale_conv2_3b
I0413 17:53:33.633381 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.633385 26605 net.cpp:156] Memory required for data: 590351360
I0413 17:53:33.633394 26605 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:53:33.633400 26605 net.cpp:91] Creating Layer conv2_3
I0413 17:53:33.633404 26605 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:53:33.633410 26605 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:53:33.633419 26605 net.cpp:399] conv2_3 -> conv2_3
I0413 17:53:33.633452 26605 net.cpp:141] Setting up conv2_3
I0413 17:53:33.633460 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.633465 26605 net.cpp:156] Memory required for data: 607128576
I0413 17:53:33.633468 26605 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:53:33.633476 26605 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:53:33.633479 26605 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:53:33.633484 26605 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:53:33.633815 26605 net.cpp:141] Setting up conv2_3_relu
I0413 17:53:33.633827 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.633832 26605 net.cpp:156] Memory required for data: 623905792
I0413 17:53:33.633836 26605 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 17:53:33.633843 26605 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 17:53:33.633847 26605 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 17:53:33.633854 26605 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 17:53:33.633862 26605 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 17:53:33.633900 26605 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 17:53:33.633908 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.633913 26605 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 17:53:33.633915 26605 net.cpp:156] Memory required for data: 657460224
I0413 17:53:33.633919 26605 layer_factory.hpp:77] Creating layer conv2_sub
I0413 17:53:33.633934 26605 net.cpp:91] Creating Layer conv2_sub
I0413 17:53:33.633939 26605 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 17:53:33.633944 26605 net.cpp:399] conv2_sub -> conv2_sub
I0413 17:53:33.637549 26605 net.cpp:141] Setting up conv2_sub
I0413 17:53:33.637564 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.637570 26605 net.cpp:156] Memory required for data: 665848832
I0413 17:53:33.637578 26605 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 17:53:33.637584 26605 net.cpp:91] Creating Layer bn_conv2_sub
I0413 17:53:33.637589 26605 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 17:53:33.637596 26605 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 17:53:33.637758 26605 net.cpp:141] Setting up bn_conv2_sub
I0413 17:53:33.637765 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.637768 26605 net.cpp:156] Memory required for data: 674237440
I0413 17:53:33.637776 26605 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:53:33.637783 26605 net.cpp:91] Creating Layer scale_conv2_sub
I0413 17:53:33.637786 26605 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 17:53:33.637791 26605 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 17:53:33.637822 26605 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:53:33.637917 26605 net.cpp:141] Setting up scale_conv2_sub
I0413 17:53:33.637924 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.637928 26605 net.cpp:156] Memory required for data: 682626048
I0413 17:53:33.637934 26605 layer_factory.hpp:77] Creating layer conv3_1a
I0413 17:53:33.637944 26605 net.cpp:91] Creating Layer conv3_1a
I0413 17:53:33.637949 26605 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 17:53:33.637959 26605 net.cpp:399] conv3_1a -> conv3_1a
I0413 17:53:33.644129 26605 net.cpp:141] Setting up conv3_1a
I0413 17:53:33.644142 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.644147 26605 net.cpp:156] Memory required for data: 691014656
I0413 17:53:33.644155 26605 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 17:53:33.644165 26605 net.cpp:91] Creating Layer bn_conv3_1a
I0413 17:53:33.644170 26605 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 17:53:33.644176 26605 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 17:53:33.644338 26605 net.cpp:141] Setting up bn_conv3_1a
I0413 17:53:33.644346 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.644350 26605 net.cpp:156] Memory required for data: 699403264
I0413 17:53:33.644356 26605 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:53:33.644363 26605 net.cpp:91] Creating Layer scale_conv3_1a
I0413 17:53:33.644367 26605 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 17:53:33.644372 26605 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 17:53:33.644403 26605 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:53:33.644500 26605 net.cpp:141] Setting up scale_conv3_1a
I0413 17:53:33.644506 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.644515 26605 net.cpp:156] Memory required for data: 707791872
I0413 17:53:33.644521 26605 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 17:53:33.644528 26605 net.cpp:91] Creating Layer conv3_1a_relu
I0413 17:53:33.644532 26605 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 17:53:33.644537 26605 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 17:53:33.645226 26605 net.cpp:141] Setting up conv3_1a_relu
I0413 17:53:33.645241 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.645246 26605 net.cpp:156] Memory required for data: 716180480
I0413 17:53:33.645249 26605 layer_factory.hpp:77] Creating layer conv3_1b
I0413 17:53:33.645263 26605 net.cpp:91] Creating Layer conv3_1b
I0413 17:53:33.645268 26605 net.cpp:425] conv3_1b <- conv3_1a
I0413 17:53:33.645275 26605 net.cpp:399] conv3_1b -> conv3_1b
I0413 17:53:33.647807 26605 net.cpp:141] Setting up conv3_1b
I0413 17:53:33.647822 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.647826 26605 net.cpp:156] Memory required for data: 724569088
I0413 17:53:33.647846 26605 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 17:53:33.647855 26605 net.cpp:91] Creating Layer bn_conv3_1b
I0413 17:53:33.647860 26605 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 17:53:33.647866 26605 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 17:53:33.648025 26605 net.cpp:141] Setting up bn_conv3_1b
I0413 17:53:33.648033 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.648036 26605 net.cpp:156] Memory required for data: 732957696
I0413 17:53:33.648044 26605 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:53:33.648051 26605 net.cpp:91] Creating Layer scale_conv3_1b
I0413 17:53:33.648054 26605 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 17:53:33.648063 26605 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 17:53:33.648094 26605 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:53:33.648195 26605 net.cpp:141] Setting up scale_conv3_1b
I0413 17:53:33.648205 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.648207 26605 net.cpp:156] Memory required for data: 741346304
I0413 17:53:33.648214 26605 layer_factory.hpp:77] Creating layer conv3_1
I0413 17:53:33.648221 26605 net.cpp:91] Creating Layer conv3_1
I0413 17:53:33.648224 26605 net.cpp:425] conv3_1 <- conv3_1b
I0413 17:53:33.648228 26605 net.cpp:425] conv3_1 <- conv2_sub
I0413 17:53:33.648233 26605 net.cpp:399] conv3_1 -> conv3_1
I0413 17:53:33.648253 26605 net.cpp:141] Setting up conv3_1
I0413 17:53:33.648259 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.648263 26605 net.cpp:156] Memory required for data: 749734912
I0413 17:53:33.648267 26605 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 17:53:33.648272 26605 net.cpp:91] Creating Layer conv3_1_relu
I0413 17:53:33.648277 26605 net.cpp:425] conv3_1_relu <- conv3_1
I0413 17:53:33.648283 26605 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 17:53:33.648433 26605 net.cpp:141] Setting up conv3_1_relu
I0413 17:53:33.648445 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.648464 26605 net.cpp:156] Memory required for data: 758123520
I0413 17:53:33.648481 26605 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 17:53:33.648490 26605 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 17:53:33.648495 26605 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 17:53:33.649857 26605 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 17:53:33.649932 26605 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 17:53:33.650063 26605 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 17:53:33.650079 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.650085 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.650089 26605 net.cpp:156] Memory required for data: 774900736
I0413 17:53:33.650096 26605 layer_factory.hpp:77] Creating layer conv3_2a
I0413 17:53:33.650128 26605 net.cpp:91] Creating Layer conv3_2a
I0413 17:53:33.650135 26605 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 17:53:33.650146 26605 net.cpp:399] conv3_2a -> conv3_2a
I0413 17:53:33.657208 26605 net.cpp:141] Setting up conv3_2a
I0413 17:53:33.657258 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.657263 26605 net.cpp:156] Memory required for data: 783289344
I0413 17:53:33.657277 26605 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 17:53:33.657294 26605 net.cpp:91] Creating Layer bn_conv3_2a
I0413 17:53:33.657300 26605 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 17:53:33.657310 26605 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 17:53:33.657516 26605 net.cpp:141] Setting up bn_conv3_2a
I0413 17:53:33.657524 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.657527 26605 net.cpp:156] Memory required for data: 791677952
I0413 17:53:33.657536 26605 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:53:33.657543 26605 net.cpp:91] Creating Layer scale_conv3_2a
I0413 17:53:33.657547 26605 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 17:53:33.657552 26605 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 17:53:33.657589 26605 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:53:33.657688 26605 net.cpp:141] Setting up scale_conv3_2a
I0413 17:53:33.657696 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.657699 26605 net.cpp:156] Memory required for data: 800066560
I0413 17:53:33.657706 26605 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 17:53:33.657714 26605 net.cpp:91] Creating Layer conv3_2a_relu
I0413 17:53:33.657718 26605 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 17:53:33.657723 26605 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 17:53:33.657883 26605 net.cpp:141] Setting up conv3_2a_relu
I0413 17:53:33.657896 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.657899 26605 net.cpp:156] Memory required for data: 808455168
I0413 17:53:33.657903 26605 layer_factory.hpp:77] Creating layer conv3_2b
I0413 17:53:33.657917 26605 net.cpp:91] Creating Layer conv3_2b
I0413 17:53:33.657920 26605 net.cpp:425] conv3_2b <- conv3_2a
I0413 17:53:33.657927 26605 net.cpp:399] conv3_2b -> conv3_2b
I0413 17:53:33.659982 26605 net.cpp:141] Setting up conv3_2b
I0413 17:53:33.659996 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.660001 26605 net.cpp:156] Memory required for data: 816843776
I0413 17:53:33.660007 26605 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 17:53:33.660019 26605 net.cpp:91] Creating Layer bn_conv3_2b
I0413 17:53:33.660024 26605 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 17:53:33.660029 26605 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 17:53:33.660192 26605 net.cpp:141] Setting up bn_conv3_2b
I0413 17:53:33.660200 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.660203 26605 net.cpp:156] Memory required for data: 825232384
I0413 17:53:33.660212 26605 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:53:33.660219 26605 net.cpp:91] Creating Layer scale_conv3_2b
I0413 17:53:33.660223 26605 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 17:53:33.660228 26605 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 17:53:33.660260 26605 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:53:33.660357 26605 net.cpp:141] Setting up scale_conv3_2b
I0413 17:53:33.660365 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.660368 26605 net.cpp:156] Memory required for data: 833620992
I0413 17:53:33.660374 26605 layer_factory.hpp:77] Creating layer conv3_2
I0413 17:53:33.660382 26605 net.cpp:91] Creating Layer conv3_2
I0413 17:53:33.660387 26605 net.cpp:425] conv3_2 <- conv3_2b
I0413 17:53:33.660392 26605 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 17:53:33.660398 26605 net.cpp:399] conv3_2 -> conv3_2
I0413 17:53:33.660418 26605 net.cpp:141] Setting up conv3_2
I0413 17:53:33.660425 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.660429 26605 net.cpp:156] Memory required for data: 842009600
I0413 17:53:33.660439 26605 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 17:53:33.660446 26605 net.cpp:91] Creating Layer conv3_2_relu
I0413 17:53:33.660449 26605 net.cpp:425] conv3_2_relu <- conv3_2
I0413 17:53:33.660454 26605 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 17:53:33.661037 26605 net.cpp:141] Setting up conv3_2_relu
I0413 17:53:33.661051 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.661054 26605 net.cpp:156] Memory required for data: 850398208
I0413 17:53:33.661058 26605 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 17:53:33.661064 26605 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 17:53:33.661069 26605 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 17:53:33.661077 26605 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 17:53:33.661083 26605 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 17:53:33.661164 26605 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 17:53:33.661173 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.661180 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.661183 26605 net.cpp:156] Memory required for data: 867175424
I0413 17:53:33.661187 26605 layer_factory.hpp:77] Creating layer conv3_3a
I0413 17:53:33.661200 26605 net.cpp:91] Creating Layer conv3_3a
I0413 17:53:33.661204 26605 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 17:53:33.661213 26605 net.cpp:399] conv3_3a -> conv3_3a
I0413 17:53:33.664130 26605 net.cpp:141] Setting up conv3_3a
I0413 17:53:33.664144 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.664149 26605 net.cpp:156] Memory required for data: 875564032
I0413 17:53:33.664155 26605 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 17:53:33.664165 26605 net.cpp:91] Creating Layer bn_conv3_3a
I0413 17:53:33.664170 26605 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 17:53:33.664176 26605 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 17:53:33.664342 26605 net.cpp:141] Setting up bn_conv3_3a
I0413 17:53:33.664350 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.664353 26605 net.cpp:156] Memory required for data: 883952640
I0413 17:53:33.664361 26605 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 17:53:33.664367 26605 net.cpp:91] Creating Layer scale_conv3_3a
I0413 17:53:33.664371 26605 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 17:53:33.664376 26605 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 17:53:33.664414 26605 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 17:53:33.664547 26605 net.cpp:141] Setting up scale_conv3_3a
I0413 17:53:33.664563 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.664566 26605 net.cpp:156] Memory required for data: 892341248
I0413 17:53:33.664572 26605 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 17:53:33.664587 26605 net.cpp:91] Creating Layer conv3_3a_relu
I0413 17:53:33.664592 26605 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 17:53:33.664602 26605 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 17:53:33.664782 26605 net.cpp:141] Setting up conv3_3a_relu
I0413 17:53:33.664798 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.664801 26605 net.cpp:156] Memory required for data: 900729856
I0413 17:53:33.664810 26605 layer_factory.hpp:77] Creating layer conv3_3b
I0413 17:53:33.664835 26605 net.cpp:91] Creating Layer conv3_3b
I0413 17:53:33.664840 26605 net.cpp:425] conv3_3b <- conv3_3a
I0413 17:53:33.664847 26605 net.cpp:399] conv3_3b -> conv3_3b
I0413 17:53:33.666724 26605 net.cpp:141] Setting up conv3_3b
I0413 17:53:33.666744 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.666749 26605 net.cpp:156] Memory required for data: 909118464
I0413 17:53:33.666759 26605 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 17:53:33.666767 26605 net.cpp:91] Creating Layer bn_conv3_3b
I0413 17:53:33.666777 26605 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 17:53:33.666787 26605 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 17:53:33.667021 26605 net.cpp:141] Setting up bn_conv3_3b
I0413 17:53:33.667029 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.667033 26605 net.cpp:156] Memory required for data: 917507072
I0413 17:53:33.667040 26605 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 17:53:33.667047 26605 net.cpp:91] Creating Layer scale_conv3_3b
I0413 17:53:33.667052 26605 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 17:53:33.667057 26605 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 17:53:33.667094 26605 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 17:53:33.667214 26605 net.cpp:141] Setting up scale_conv3_3b
I0413 17:53:33.667227 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.667230 26605 net.cpp:156] Memory required for data: 925895680
I0413 17:53:33.667237 26605 layer_factory.hpp:77] Creating layer conv3_3
I0413 17:53:33.667250 26605 net.cpp:91] Creating Layer conv3_3
I0413 17:53:33.667254 26605 net.cpp:425] conv3_3 <- conv3_3b
I0413 17:53:33.667259 26605 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 17:53:33.667273 26605 net.cpp:399] conv3_3 -> conv3_3
I0413 17:53:33.667295 26605 net.cpp:141] Setting up conv3_3
I0413 17:53:33.667302 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.667315 26605 net.cpp:156] Memory required for data: 934284288
I0413 17:53:33.667318 26605 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 17:53:33.667325 26605 net.cpp:91] Creating Layer conv3_3_relu
I0413 17:53:33.667333 26605 net.cpp:425] conv3_3_relu <- conv3_3
I0413 17:53:33.667337 26605 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 17:53:33.667556 26605 net.cpp:141] Setting up conv3_3_relu
I0413 17:53:33.667570 26605 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 17:53:33.667574 26605 net.cpp:156] Memory required for data: 942672896
I0413 17:53:33.667578 26605 layer_factory.hpp:77] Creating layer global_pool
I0413 17:53:33.667590 26605 net.cpp:91] Creating Layer global_pool
I0413 17:53:33.667594 26605 net.cpp:425] global_pool <- conv3_3
I0413 17:53:33.667606 26605 net.cpp:399] global_pool -> global_pool
I0413 17:53:33.668509 26605 net.cpp:141] Setting up global_pool
I0413 17:53:33.668532 26605 net.cpp:148] Top shape: 256 32 2 2 (32768)
I0413 17:53:33.668536 26605 net.cpp:156] Memory required for data: 942803968
I0413 17:53:33.668546 26605 layer_factory.hpp:77] Creating layer ip
I0413 17:53:33.668562 26605 net.cpp:91] Creating Layer ip
I0413 17:53:33.668567 26605 net.cpp:425] ip <- global_pool
I0413 17:53:33.668572 26605 net.cpp:399] ip -> ip
I0413 17:53:33.668715 26605 net.cpp:141] Setting up ip
I0413 17:53:33.668723 26605 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:53:33.668726 26605 net.cpp:156] Memory required for data: 942814208
I0413 17:53:33.668737 26605 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:53:33.668743 26605 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:53:33.668747 26605 net.cpp:425] ip_ip_0_split <- ip
I0413 17:53:33.668766 26605 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:53:33.668776 26605 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:53:33.668812 26605 net.cpp:141] Setting up ip_ip_0_split
I0413 17:53:33.668829 26605 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:53:33.668834 26605 net.cpp:148] Top shape: 256 10 (2560)
I0413 17:53:33.668844 26605 net.cpp:156] Memory required for data: 942834688
I0413 17:53:33.668848 26605 layer_factory.hpp:77] Creating layer accuracy
I0413 17:53:33.668877 26605 net.cpp:91] Creating Layer accuracy
I0413 17:53:33.668897 26605 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:53:33.668901 26605 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:53:33.668913 26605 net.cpp:399] accuracy -> accuracy
I0413 17:53:33.668920 26605 net.cpp:141] Setting up accuracy
I0413 17:53:33.668931 26605 net.cpp:148] Top shape: (1)
I0413 17:53:33.668934 26605 net.cpp:156] Memory required for data: 942834692
I0413 17:53:33.668938 26605 layer_factory.hpp:77] Creating layer loss
I0413 17:53:33.668951 26605 net.cpp:91] Creating Layer loss
I0413 17:53:33.668956 26605 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:53:33.668961 26605 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:53:33.668967 26605 net.cpp:399] loss -> loss
I0413 17:53:33.668974 26605 layer_factory.hpp:77] Creating layer loss
I0413 17:53:33.669678 26605 net.cpp:141] Setting up loss
I0413 17:53:33.669699 26605 net.cpp:148] Top shape: (1)
I0413 17:53:33.669703 26605 net.cpp:151]     with loss weight 1
I0413 17:53:33.669715 26605 net.cpp:156] Memory required for data: 942834696
I0413 17:53:33.669719 26605 net.cpp:217] loss needs backward computation.
I0413 17:53:33.669723 26605 net.cpp:219] accuracy does not need backward computation.
I0413 17:53:33.669728 26605 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:53:33.669731 26605 net.cpp:217] ip needs backward computation.
I0413 17:53:33.669735 26605 net.cpp:217] global_pool needs backward computation.
I0413 17:53:33.669739 26605 net.cpp:217] conv3_3_relu needs backward computation.
I0413 17:53:33.669742 26605 net.cpp:217] conv3_3 needs backward computation.
I0413 17:53:33.669746 26605 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 17:53:33.669749 26605 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 17:53:33.669752 26605 net.cpp:217] conv3_3b needs backward computation.
I0413 17:53:33.669756 26605 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 17:53:33.669760 26605 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 17:53:33.669764 26605 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 17:53:33.669766 26605 net.cpp:217] conv3_3a needs backward computation.
I0413 17:53:33.669773 26605 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 17:53:33.669777 26605 net.cpp:217] conv3_2_relu needs backward computation.
I0413 17:53:33.669780 26605 net.cpp:217] conv3_2 needs backward computation.
I0413 17:53:33.669785 26605 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 17:53:33.669788 26605 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 17:53:33.669795 26605 net.cpp:217] conv3_2b needs backward computation.
I0413 17:53:33.669800 26605 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 17:53:33.669802 26605 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 17:53:33.669806 26605 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 17:53:33.669809 26605 net.cpp:217] conv3_2a needs backward computation.
I0413 17:53:33.669818 26605 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 17:53:33.669822 26605 net.cpp:217] conv3_1_relu needs backward computation.
I0413 17:53:33.669826 26605 net.cpp:217] conv3_1 needs backward computation.
I0413 17:53:33.669831 26605 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 17:53:33.669837 26605 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 17:53:33.669841 26605 net.cpp:217] conv3_1b needs backward computation.
I0413 17:53:33.669844 26605 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 17:53:33.669847 26605 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 17:53:33.669852 26605 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 17:53:33.669859 26605 net.cpp:217] conv3_1a needs backward computation.
I0413 17:53:33.669863 26605 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 17:53:33.669867 26605 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 17:53:33.669872 26605 net.cpp:217] conv2_sub needs backward computation.
I0413 17:53:33.669874 26605 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 17:53:33.669890 26605 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:53:33.669893 26605 net.cpp:217] conv2_3 needs backward computation.
I0413 17:53:33.669898 26605 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:53:33.669903 26605 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:53:33.669906 26605 net.cpp:217] conv2_3b needs backward computation.
I0413 17:53:33.669914 26605 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:53:33.669919 26605 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:53:33.669940 26605 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:53:33.669947 26605 net.cpp:217] conv2_3a needs backward computation.
I0413 17:53:33.669951 26605 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:53:33.669955 26605 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:53:33.669960 26605 net.cpp:217] conv2_2 needs backward computation.
I0413 17:53:33.669970 26605 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:53:33.669973 26605 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:53:33.669977 26605 net.cpp:217] conv2_2b needs backward computation.
I0413 17:53:33.669981 26605 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:53:33.669984 26605 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:53:33.670006 26605 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:53:33.670012 26605 net.cpp:217] conv2_2a needs backward computation.
I0413 17:53:33.670016 26605 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:53:33.670019 26605 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:53:33.670023 26605 net.cpp:217] conv2_1 needs backward computation.
I0413 17:53:33.670027 26605 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:53:33.670034 26605 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:53:33.670037 26605 net.cpp:217] conv2_1b needs backward computation.
I0413 17:53:33.670042 26605 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:53:33.670045 26605 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:53:33.670048 26605 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:53:33.670055 26605 net.cpp:217] conv2_1a needs backward computation.
I0413 17:53:33.670076 26605 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:53:33.670080 26605 net.cpp:217] conv1_relu needs backward computation.
I0413 17:53:33.670084 26605 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:53:33.670088 26605 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:53:33.670091 26605 net.cpp:217] conv1 needs backward computation.
I0413 17:53:33.670095 26605 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:53:33.670099 26605 net.cpp:219] cifar does not need backward computation.
I0413 17:53:33.670104 26605 net.cpp:261] This network produces output accuracy
I0413 17:53:33.670109 26605 net.cpp:261] This network produces output loss
I0413 17:53:33.670146 26605 net.cpp:274] Network initialization done.
I0413 17:53:33.671684 26605 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar5.prototxt
I0413 17:53:33.671788 26605 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 17:53:33.672176 26605 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv3_3"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 17:53:33.672479 26605 layer_factory.hpp:77] Creating layer cifar
I0413 17:53:33.672632 26605 net.cpp:91] Creating Layer cifar
I0413 17:53:33.672641 26605 net.cpp:399] cifar -> data
I0413 17:53:33.672657 26605 net.cpp:399] cifar -> label
I0413 17:53:33.672664 26605 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 17:53:33.674561 26679 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 17:53:33.674715 26605 data_layer.cpp:41] output data size: 100,3,32,32
I0413 17:53:33.679533 26605 net.cpp:141] Setting up cifar
I0413 17:53:33.679555 26605 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 17:53:33.679577 26605 net.cpp:148] Top shape: 100 (100)
I0413 17:53:33.679582 26605 net.cpp:156] Memory required for data: 1229200
I0413 17:53:33.679594 26605 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 17:53:33.679601 26605 net.cpp:91] Creating Layer label_cifar_1_split
I0413 17:53:33.679606 26605 net.cpp:425] label_cifar_1_split <- label
I0413 17:53:33.679612 26605 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 17:53:33.679630 26605 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 17:53:33.679690 26605 net.cpp:141] Setting up label_cifar_1_split
I0413 17:53:33.679698 26605 net.cpp:148] Top shape: 100 (100)
I0413 17:53:33.679702 26605 net.cpp:148] Top shape: 100 (100)
I0413 17:53:33.679705 26605 net.cpp:156] Memory required for data: 1230000
I0413 17:53:33.679713 26605 layer_factory.hpp:77] Creating layer conv1
I0413 17:53:33.679723 26605 net.cpp:91] Creating Layer conv1
I0413 17:53:33.679733 26605 net.cpp:425] conv1 <- data
I0413 17:53:33.679746 26605 net.cpp:399] conv1 -> conv1
I0413 17:53:33.681550 26605 net.cpp:141] Setting up conv1
I0413 17:53:33.681566 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.681571 26605 net.cpp:156] Memory required for data: 7783600
I0413 17:53:33.681581 26605 layer_factory.hpp:77] Creating layer bn_conv1
I0413 17:53:33.681593 26605 net.cpp:91] Creating Layer bn_conv1
I0413 17:53:33.681597 26605 net.cpp:425] bn_conv1 <- conv1
I0413 17:53:33.681605 26605 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 17:53:33.681977 26605 net.cpp:141] Setting up bn_conv1
I0413 17:53:33.681993 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.681998 26605 net.cpp:156] Memory required for data: 14337200
I0413 17:53:33.682014 26605 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:53:33.682021 26605 net.cpp:91] Creating Layer scale_conv1
I0413 17:53:33.682025 26605 net.cpp:425] scale_conv1 <- conv1
I0413 17:53:33.682037 26605 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 17:53:33.682240 26605 layer_factory.hpp:77] Creating layer scale_conv1
I0413 17:53:33.682382 26605 net.cpp:141] Setting up scale_conv1
I0413 17:53:33.682399 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.682402 26605 net.cpp:156] Memory required for data: 20890800
I0413 17:53:33.682415 26605 layer_factory.hpp:77] Creating layer conv1_relu
I0413 17:53:33.682438 26605 net.cpp:91] Creating Layer conv1_relu
I0413 17:53:33.682442 26605 net.cpp:425] conv1_relu <- conv1
I0413 17:53:33.682447 26605 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 17:53:33.682879 26605 net.cpp:141] Setting up conv1_relu
I0413 17:53:33.682898 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.682910 26605 net.cpp:156] Memory required for data: 27444400
I0413 17:53:33.682914 26605 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 17:53:33.682921 26605 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 17:53:33.682925 26605 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 17:53:33.682932 26605 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 17:53:33.682950 26605 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 17:53:33.683002 26605 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 17:53:33.683017 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.683022 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.683024 26605 net.cpp:156] Memory required for data: 40551600
I0413 17:53:33.683028 26605 layer_factory.hpp:77] Creating layer conv2_1a
I0413 17:53:33.683039 26605 net.cpp:91] Creating Layer conv2_1a
I0413 17:53:33.683044 26605 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 17:53:33.683051 26605 net.cpp:399] conv2_1a -> conv2_1a
I0413 17:53:33.686293 26605 net.cpp:141] Setting up conv2_1a
I0413 17:53:33.686322 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.686328 26605 net.cpp:156] Memory required for data: 47105200
I0413 17:53:33.686378 26605 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 17:53:33.686408 26605 net.cpp:91] Creating Layer bn_conv2_1a
I0413 17:53:33.686414 26605 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 17:53:33.686420 26605 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 17:53:33.686672 26605 net.cpp:141] Setting up bn_conv2_1a
I0413 17:53:33.686681 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.686686 26605 net.cpp:156] Memory required for data: 53658800
I0413 17:53:33.686693 26605 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:53:33.686702 26605 net.cpp:91] Creating Layer scale_conv2_1a
I0413 17:53:33.686707 26605 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 17:53:33.686712 26605 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 17:53:33.686754 26605 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 17:53:33.686882 26605 net.cpp:141] Setting up scale_conv2_1a
I0413 17:53:33.686892 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.686895 26605 net.cpp:156] Memory required for data: 60212400
I0413 17:53:33.686907 26605 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 17:53:33.686914 26605 net.cpp:91] Creating Layer conv2_1a_relu
I0413 17:53:33.686918 26605 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 17:53:33.686923 26605 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 17:53:33.687574 26605 net.cpp:141] Setting up conv2_1a_relu
I0413 17:53:33.687587 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.687592 26605 net.cpp:156] Memory required for data: 66766000
I0413 17:53:33.687600 26605 layer_factory.hpp:77] Creating layer conv2_1b
I0413 17:53:33.687611 26605 net.cpp:91] Creating Layer conv2_1b
I0413 17:53:33.687616 26605 net.cpp:425] conv2_1b <- conv2_1a
I0413 17:53:33.687624 26605 net.cpp:399] conv2_1b -> conv2_1b
I0413 17:53:33.690819 26605 net.cpp:141] Setting up conv2_1b
I0413 17:53:33.690837 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.690842 26605 net.cpp:156] Memory required for data: 73319600
I0413 17:53:33.690850 26605 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 17:53:33.690861 26605 net.cpp:91] Creating Layer bn_conv2_1b
I0413 17:53:33.690866 26605 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 17:53:33.690891 26605 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 17:53:33.691083 26605 net.cpp:141] Setting up bn_conv2_1b
I0413 17:53:33.691092 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.691095 26605 net.cpp:156] Memory required for data: 79873200
I0413 17:53:33.691108 26605 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:53:33.691124 26605 net.cpp:91] Creating Layer scale_conv2_1b
I0413 17:53:33.691128 26605 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 17:53:33.691133 26605 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 17:53:33.691175 26605 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 17:53:33.691292 26605 net.cpp:141] Setting up scale_conv2_1b
I0413 17:53:33.691300 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.691309 26605 net.cpp:156] Memory required for data: 86426800
I0413 17:53:33.691316 26605 layer_factory.hpp:77] Creating layer conv2_1
I0413 17:53:33.691324 26605 net.cpp:91] Creating Layer conv2_1
I0413 17:53:33.691329 26605 net.cpp:425] conv2_1 <- conv2_1b
I0413 17:53:33.691334 26605 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 17:53:33.691339 26605 net.cpp:399] conv2_1 -> conv2_1
I0413 17:53:33.691365 26605 net.cpp:141] Setting up conv2_1
I0413 17:53:33.691372 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.691375 26605 net.cpp:156] Memory required for data: 92980400
I0413 17:53:33.691380 26605 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 17:53:33.691385 26605 net.cpp:91] Creating Layer conv2_1_relu
I0413 17:53:33.691404 26605 net.cpp:425] conv2_1_relu <- conv2_1
I0413 17:53:33.691411 26605 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 17:53:33.691879 26605 net.cpp:141] Setting up conv2_1_relu
I0413 17:53:33.691891 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.691896 26605 net.cpp:156] Memory required for data: 99534000
I0413 17:53:33.691900 26605 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 17:53:33.691910 26605 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 17:53:33.691915 26605 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 17:53:33.691920 26605 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 17:53:33.691929 26605 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 17:53:33.691972 26605 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 17:53:33.691980 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.691984 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.691988 26605 net.cpp:156] Memory required for data: 112641200
I0413 17:53:33.691992 26605 layer_factory.hpp:77] Creating layer conv2_2a
I0413 17:53:33.692003 26605 net.cpp:91] Creating Layer conv2_2a
I0413 17:53:33.692013 26605 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 17:53:33.692023 26605 net.cpp:399] conv2_2a -> conv2_2a
I0413 17:53:33.695353 26605 net.cpp:141] Setting up conv2_2a
I0413 17:53:33.695369 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.695374 26605 net.cpp:156] Memory required for data: 119194800
I0413 17:53:33.695381 26605 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 17:53:33.695389 26605 net.cpp:91] Creating Layer bn_conv2_2a
I0413 17:53:33.695394 26605 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 17:53:33.695410 26605 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 17:53:33.695613 26605 net.cpp:141] Setting up bn_conv2_2a
I0413 17:53:33.695634 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.695647 26605 net.cpp:156] Memory required for data: 125748400
I0413 17:53:33.695654 26605 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:53:33.695660 26605 net.cpp:91] Creating Layer scale_conv2_2a
I0413 17:53:33.695665 26605 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 17:53:33.695672 26605 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 17:53:33.695724 26605 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 17:53:33.695839 26605 net.cpp:141] Setting up scale_conv2_2a
I0413 17:53:33.695849 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.695864 26605 net.cpp:156] Memory required for data: 132302000
I0413 17:53:33.695878 26605 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 17:53:33.695883 26605 net.cpp:91] Creating Layer conv2_2a_relu
I0413 17:53:33.695888 26605 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 17:53:33.695894 26605 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 17:53:33.696677 26605 net.cpp:141] Setting up conv2_2a_relu
I0413 17:53:33.696691 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.696701 26605 net.cpp:156] Memory required for data: 138855600
I0413 17:53:33.696704 26605 layer_factory.hpp:77] Creating layer conv2_2b
I0413 17:53:33.696717 26605 net.cpp:91] Creating Layer conv2_2b
I0413 17:53:33.696722 26605 net.cpp:425] conv2_2b <- conv2_2a
I0413 17:53:33.696730 26605 net.cpp:399] conv2_2b -> conv2_2b
I0413 17:53:33.700165 26605 net.cpp:141] Setting up conv2_2b
I0413 17:53:33.700181 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.700186 26605 net.cpp:156] Memory required for data: 145409200
I0413 17:53:33.700192 26605 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 17:53:33.700201 26605 net.cpp:91] Creating Layer bn_conv2_2b
I0413 17:53:33.700206 26605 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 17:53:33.700212 26605 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 17:53:33.700407 26605 net.cpp:141] Setting up bn_conv2_2b
I0413 17:53:33.700415 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.700419 26605 net.cpp:156] Memory required for data: 151962800
I0413 17:53:33.700430 26605 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:53:33.700439 26605 net.cpp:91] Creating Layer scale_conv2_2b
I0413 17:53:33.700443 26605 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 17:53:33.700448 26605 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 17:53:33.700490 26605 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 17:53:33.700603 26605 net.cpp:141] Setting up scale_conv2_2b
I0413 17:53:33.700610 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.700614 26605 net.cpp:156] Memory required for data: 158516400
I0413 17:53:33.700620 26605 layer_factory.hpp:77] Creating layer conv2_2
I0413 17:53:33.700626 26605 net.cpp:91] Creating Layer conv2_2
I0413 17:53:33.700630 26605 net.cpp:425] conv2_2 <- conv2_2b
I0413 17:53:33.700635 26605 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 17:53:33.700640 26605 net.cpp:399] conv2_2 -> conv2_2
I0413 17:53:33.700666 26605 net.cpp:141] Setting up conv2_2
I0413 17:53:33.700673 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.700678 26605 net.cpp:156] Memory required for data: 165070000
I0413 17:53:33.700686 26605 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 17:53:33.700692 26605 net.cpp:91] Creating Layer conv2_2_relu
I0413 17:53:33.700696 26605 net.cpp:425] conv2_2_relu <- conv2_2
I0413 17:53:33.700701 26605 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 17:53:33.701217 26605 net.cpp:141] Setting up conv2_2_relu
I0413 17:53:33.701231 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.701234 26605 net.cpp:156] Memory required for data: 171623600
I0413 17:53:33.701238 26605 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 17:53:33.701246 26605 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 17:53:33.701249 26605 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 17:53:33.701257 26605 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 17:53:33.701264 26605 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 17:53:33.701311 26605 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 17:53:33.701318 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.701324 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.701328 26605 net.cpp:156] Memory required for data: 184730800
I0413 17:53:33.701333 26605 layer_factory.hpp:77] Creating layer conv2_3a
I0413 17:53:33.701344 26605 net.cpp:91] Creating Layer conv2_3a
I0413 17:53:33.701349 26605 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 17:53:33.701356 26605 net.cpp:399] conv2_3a -> conv2_3a
I0413 17:53:33.704882 26605 net.cpp:141] Setting up conv2_3a
I0413 17:53:33.704896 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.704901 26605 net.cpp:156] Memory required for data: 191284400
I0413 17:53:33.704908 26605 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 17:53:33.704917 26605 net.cpp:91] Creating Layer bn_conv2_3a
I0413 17:53:33.704922 26605 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 17:53:33.704929 26605 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 17:53:33.705173 26605 net.cpp:141] Setting up bn_conv2_3a
I0413 17:53:33.705184 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.705200 26605 net.cpp:156] Memory required for data: 197838000
I0413 17:53:33.705209 26605 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:53:33.705219 26605 net.cpp:91] Creating Layer scale_conv2_3a
I0413 17:53:33.705224 26605 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 17:53:33.705229 26605 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 17:53:33.705277 26605 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 17:53:33.705406 26605 net.cpp:141] Setting up scale_conv2_3a
I0413 17:53:33.705415 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.705420 26605 net.cpp:156] Memory required for data: 204391600
I0413 17:53:33.705426 26605 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 17:53:33.705432 26605 net.cpp:91] Creating Layer conv2_3a_relu
I0413 17:53:33.705437 26605 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 17:53:33.705445 26605 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 17:53:33.706001 26605 net.cpp:141] Setting up conv2_3a_relu
I0413 17:53:33.706014 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.706019 26605 net.cpp:156] Memory required for data: 210945200
I0413 17:53:33.706023 26605 layer_factory.hpp:77] Creating layer conv2_3b
I0413 17:53:33.706034 26605 net.cpp:91] Creating Layer conv2_3b
I0413 17:53:33.706039 26605 net.cpp:425] conv2_3b <- conv2_3a
I0413 17:53:33.706048 26605 net.cpp:399] conv2_3b -> conv2_3b
I0413 17:53:33.709434 26605 net.cpp:141] Setting up conv2_3b
I0413 17:53:33.709450 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.709453 26605 net.cpp:156] Memory required for data: 217498800
I0413 17:53:33.709461 26605 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 17:53:33.709472 26605 net.cpp:91] Creating Layer bn_conv2_3b
I0413 17:53:33.709487 26605 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 17:53:33.709493 26605 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 17:53:33.709695 26605 net.cpp:141] Setting up bn_conv2_3b
I0413 17:53:33.709703 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.709707 26605 net.cpp:156] Memory required for data: 224052400
I0413 17:53:33.709715 26605 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:53:33.709722 26605 net.cpp:91] Creating Layer scale_conv2_3b
I0413 17:53:33.709725 26605 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 17:53:33.709730 26605 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 17:53:33.709779 26605 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 17:53:33.709895 26605 net.cpp:141] Setting up scale_conv2_3b
I0413 17:53:33.709903 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.709906 26605 net.cpp:156] Memory required for data: 230606000
I0413 17:53:33.709913 26605 layer_factory.hpp:77] Creating layer conv2_3
I0413 17:53:33.709919 26605 net.cpp:91] Creating Layer conv2_3
I0413 17:53:33.709923 26605 net.cpp:425] conv2_3 <- conv2_3b
I0413 17:53:33.709928 26605 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 17:53:33.709935 26605 net.cpp:399] conv2_3 -> conv2_3
I0413 17:53:33.709959 26605 net.cpp:141] Setting up conv2_3
I0413 17:53:33.709966 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.709969 26605 net.cpp:156] Memory required for data: 237159600
I0413 17:53:33.709974 26605 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 17:53:33.709980 26605 net.cpp:91] Creating Layer conv2_3_relu
I0413 17:53:33.709985 26605 net.cpp:425] conv2_3_relu <- conv2_3
I0413 17:53:33.709990 26605 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 17:53:33.710448 26605 net.cpp:141] Setting up conv2_3_relu
I0413 17:53:33.710463 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.710466 26605 net.cpp:156] Memory required for data: 243713200
I0413 17:53:33.710470 26605 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 17:53:33.710477 26605 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 17:53:33.710481 26605 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 17:53:33.710489 26605 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 17:53:33.710497 26605 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 17:53:33.710541 26605 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 17:53:33.710551 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.710556 26605 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 17:53:33.710561 26605 net.cpp:156] Memory required for data: 256820400
I0413 17:53:33.710564 26605 layer_factory.hpp:77] Creating layer conv2_sub
I0413 17:53:33.710574 26605 net.cpp:91] Creating Layer conv2_sub
I0413 17:53:33.710579 26605 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 17:53:33.710585 26605 net.cpp:399] conv2_sub -> conv2_sub
I0413 17:53:33.714323 26605 net.cpp:141] Setting up conv2_sub
I0413 17:53:33.714337 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.714342 26605 net.cpp:156] Memory required for data: 260097200
I0413 17:53:33.714349 26605 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 17:53:33.714359 26605 net.cpp:91] Creating Layer bn_conv2_sub
I0413 17:53:33.714364 26605 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 17:53:33.714370 26605 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 17:53:33.714563 26605 net.cpp:141] Setting up bn_conv2_sub
I0413 17:53:33.714571 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.714576 26605 net.cpp:156] Memory required for data: 263374000
I0413 17:53:33.714583 26605 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:53:33.714589 26605 net.cpp:91] Creating Layer scale_conv2_sub
I0413 17:53:33.714593 26605 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 17:53:33.714601 26605 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 17:53:33.714640 26605 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 17:53:33.714756 26605 net.cpp:141] Setting up scale_conv2_sub
I0413 17:53:33.714769 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.714773 26605 net.cpp:156] Memory required for data: 266650800
I0413 17:53:33.714779 26605 layer_factory.hpp:77] Creating layer conv3_1a
I0413 17:53:33.714790 26605 net.cpp:91] Creating Layer conv3_1a
I0413 17:53:33.714795 26605 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 17:53:33.714803 26605 net.cpp:399] conv3_1a -> conv3_1a
I0413 17:53:33.717743 26605 net.cpp:141] Setting up conv3_1a
I0413 17:53:33.717759 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.717763 26605 net.cpp:156] Memory required for data: 269927600
I0413 17:53:33.717770 26605 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 17:53:33.717779 26605 net.cpp:91] Creating Layer bn_conv3_1a
I0413 17:53:33.717784 26605 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 17:53:33.717792 26605 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 17:53:33.717983 26605 net.cpp:141] Setting up bn_conv3_1a
I0413 17:53:33.717993 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.717995 26605 net.cpp:156] Memory required for data: 273204400
I0413 17:53:33.718003 26605 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:53:33.718011 26605 net.cpp:91] Creating Layer scale_conv3_1a
I0413 17:53:33.718015 26605 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 17:53:33.718020 26605 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 17:53:33.718063 26605 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 17:53:33.718179 26605 net.cpp:141] Setting up scale_conv3_1a
I0413 17:53:33.718188 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.718191 26605 net.cpp:156] Memory required for data: 276481200
I0413 17:53:33.718199 26605 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 17:53:33.718204 26605 net.cpp:91] Creating Layer conv3_1a_relu
I0413 17:53:33.718207 26605 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 17:53:33.718214 26605 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 17:53:33.719166 26605 net.cpp:141] Setting up conv3_1a_relu
I0413 17:53:33.719177 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.719182 26605 net.cpp:156] Memory required for data: 279758000
I0413 17:53:33.719185 26605 layer_factory.hpp:77] Creating layer conv3_1b
I0413 17:53:33.719195 26605 net.cpp:91] Creating Layer conv3_1b
I0413 17:53:33.719200 26605 net.cpp:425] conv3_1b <- conv3_1a
I0413 17:53:33.719208 26605 net.cpp:399] conv3_1b -> conv3_1b
I0413 17:53:33.722681 26605 net.cpp:141] Setting up conv3_1b
I0413 17:53:33.722697 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.722702 26605 net.cpp:156] Memory required for data: 283034800
I0413 17:53:33.722718 26605 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 17:53:33.722726 26605 net.cpp:91] Creating Layer bn_conv3_1b
I0413 17:53:33.722731 26605 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 17:53:33.722738 26605 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 17:53:33.722931 26605 net.cpp:141] Setting up bn_conv3_1b
I0413 17:53:33.722939 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.722944 26605 net.cpp:156] Memory required for data: 286311600
I0413 17:53:33.722951 26605 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:53:33.722957 26605 net.cpp:91] Creating Layer scale_conv3_1b
I0413 17:53:33.722961 26605 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 17:53:33.722970 26605 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 17:53:33.723012 26605 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 17:53:33.723129 26605 net.cpp:141] Setting up scale_conv3_1b
I0413 17:53:33.723136 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.723140 26605 net.cpp:156] Memory required for data: 289588400
I0413 17:53:33.723146 26605 layer_factory.hpp:77] Creating layer conv3_1
I0413 17:53:33.723152 26605 net.cpp:91] Creating Layer conv3_1
I0413 17:53:33.723156 26605 net.cpp:425] conv3_1 <- conv3_1b
I0413 17:53:33.723161 26605 net.cpp:425] conv3_1 <- conv2_sub
I0413 17:53:33.723171 26605 net.cpp:399] conv3_1 -> conv3_1
I0413 17:53:33.723196 26605 net.cpp:141] Setting up conv3_1
I0413 17:53:33.723202 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.723206 26605 net.cpp:156] Memory required for data: 292865200
I0413 17:53:33.723211 26605 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 17:53:33.723217 26605 net.cpp:91] Creating Layer conv3_1_relu
I0413 17:53:33.723220 26605 net.cpp:425] conv3_1_relu <- conv3_1
I0413 17:53:33.723225 26605 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 17:53:33.723700 26605 net.cpp:141] Setting up conv3_1_relu
I0413 17:53:33.723709 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.723713 26605 net.cpp:156] Memory required for data: 296142000
I0413 17:53:33.723717 26605 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 17:53:33.723724 26605 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 17:53:33.723728 26605 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 17:53:33.723734 26605 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 17:53:33.723743 26605 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 17:53:33.723785 26605 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 17:53:33.723793 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.723798 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.723800 26605 net.cpp:156] Memory required for data: 302695600
I0413 17:53:33.723804 26605 layer_factory.hpp:77] Creating layer conv3_2a
I0413 17:53:33.723814 26605 net.cpp:91] Creating Layer conv3_2a
I0413 17:53:33.723819 26605 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 17:53:33.723827 26605 net.cpp:399] conv3_2a -> conv3_2a
I0413 17:53:33.727349 26605 net.cpp:141] Setting up conv3_2a
I0413 17:53:33.727365 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.727370 26605 net.cpp:156] Memory required for data: 305972400
I0413 17:53:33.727376 26605 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 17:53:33.727383 26605 net.cpp:91] Creating Layer bn_conv3_2a
I0413 17:53:33.727387 26605 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 17:53:33.727396 26605 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 17:53:33.727593 26605 net.cpp:141] Setting up bn_conv3_2a
I0413 17:53:33.727602 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.727605 26605 net.cpp:156] Memory required for data: 309249200
I0413 17:53:33.727612 26605 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:53:33.727618 26605 net.cpp:91] Creating Layer scale_conv3_2a
I0413 17:53:33.727622 26605 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 17:53:33.727628 26605 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 17:53:33.727670 26605 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 17:53:33.727787 26605 net.cpp:141] Setting up scale_conv3_2a
I0413 17:53:33.727797 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.727799 26605 net.cpp:156] Memory required for data: 312526000
I0413 17:53:33.727807 26605 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 17:53:33.727812 26605 net.cpp:91] Creating Layer conv3_2a_relu
I0413 17:53:33.727815 26605 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 17:53:33.727820 26605 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 17:53:33.728377 26605 net.cpp:141] Setting up conv3_2a_relu
I0413 17:53:33.728392 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.728396 26605 net.cpp:156] Memory required for data: 315802800
I0413 17:53:33.728401 26605 layer_factory.hpp:77] Creating layer conv3_2b
I0413 17:53:33.728412 26605 net.cpp:91] Creating Layer conv3_2b
I0413 17:53:33.728417 26605 net.cpp:425] conv3_2b <- conv3_2a
I0413 17:53:33.728425 26605 net.cpp:399] conv3_2b -> conv3_2b
I0413 17:53:33.732101 26605 net.cpp:141] Setting up conv3_2b
I0413 17:53:33.732116 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.732120 26605 net.cpp:156] Memory required for data: 319079600
I0413 17:53:33.732131 26605 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 17:53:33.732141 26605 net.cpp:91] Creating Layer bn_conv3_2b
I0413 17:53:33.732146 26605 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 17:53:33.732156 26605 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 17:53:33.732352 26605 net.cpp:141] Setting up bn_conv3_2b
I0413 17:53:33.732362 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.732364 26605 net.cpp:156] Memory required for data: 322356400
I0413 17:53:33.732372 26605 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:53:33.732378 26605 net.cpp:91] Creating Layer scale_conv3_2b
I0413 17:53:33.732383 26605 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 17:53:33.732389 26605 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 17:53:33.732431 26605 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 17:53:33.732549 26605 net.cpp:141] Setting up scale_conv3_2b
I0413 17:53:33.732558 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.732561 26605 net.cpp:156] Memory required for data: 325633200
I0413 17:53:33.732568 26605 layer_factory.hpp:77] Creating layer conv3_2
I0413 17:53:33.732573 26605 net.cpp:91] Creating Layer conv3_2
I0413 17:53:33.732578 26605 net.cpp:425] conv3_2 <- conv3_2b
I0413 17:53:33.732583 26605 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 17:53:33.732589 26605 net.cpp:399] conv3_2 -> conv3_2
I0413 17:53:33.732610 26605 net.cpp:141] Setting up conv3_2
I0413 17:53:33.732617 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.732621 26605 net.cpp:156] Memory required for data: 328910000
I0413 17:53:33.732625 26605 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 17:53:33.732631 26605 net.cpp:91] Creating Layer conv3_2_relu
I0413 17:53:33.732635 26605 net.cpp:425] conv3_2_relu <- conv3_2
I0413 17:53:33.732640 26605 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 17:53:33.733152 26605 net.cpp:141] Setting up conv3_2_relu
I0413 17:53:33.733165 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.733170 26605 net.cpp:156] Memory required for data: 332186800
I0413 17:53:33.733175 26605 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 17:53:33.733180 26605 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 17:53:33.733185 26605 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 17:53:33.733192 26605 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 17:53:33.733201 26605 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 17:53:33.733249 26605 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 17:53:33.733258 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.733263 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.733266 26605 net.cpp:156] Memory required for data: 338740400
I0413 17:53:33.733271 26605 layer_factory.hpp:77] Creating layer conv3_3a
I0413 17:53:33.733283 26605 net.cpp:91] Creating Layer conv3_3a
I0413 17:53:33.733286 26605 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 17:53:33.733294 26605 net.cpp:399] conv3_3a -> conv3_3a
I0413 17:53:33.736681 26605 net.cpp:141] Setting up conv3_3a
I0413 17:53:33.736696 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.736701 26605 net.cpp:156] Memory required for data: 342017200
I0413 17:53:33.736708 26605 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 17:53:33.736716 26605 net.cpp:91] Creating Layer bn_conv3_3a
I0413 17:53:33.736721 26605 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 17:53:33.736728 26605 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 17:53:33.736928 26605 net.cpp:141] Setting up bn_conv3_3a
I0413 17:53:33.736937 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.736942 26605 net.cpp:156] Memory required for data: 345294000
I0413 17:53:33.736948 26605 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 17:53:33.736954 26605 net.cpp:91] Creating Layer scale_conv3_3a
I0413 17:53:33.736963 26605 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 17:53:33.736970 26605 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 17:53:33.737015 26605 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 17:53:33.737166 26605 net.cpp:141] Setting up scale_conv3_3a
I0413 17:53:33.737187 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.737191 26605 net.cpp:156] Memory required for data: 348570800
I0413 17:53:33.737200 26605 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 17:53:33.737205 26605 net.cpp:91] Creating Layer conv3_3a_relu
I0413 17:53:33.737210 26605 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 17:53:33.737216 26605 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 17:53:33.738065 26605 net.cpp:141] Setting up conv3_3a_relu
I0413 17:53:33.738076 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.738081 26605 net.cpp:156] Memory required for data: 351847600
I0413 17:53:33.738085 26605 layer_factory.hpp:77] Creating layer conv3_3b
I0413 17:53:33.738101 26605 net.cpp:91] Creating Layer conv3_3b
I0413 17:53:33.738106 26605 net.cpp:425] conv3_3b <- conv3_3a
I0413 17:53:33.738113 26605 net.cpp:399] conv3_3b -> conv3_3b
I0413 17:53:33.741590 26605 net.cpp:141] Setting up conv3_3b
I0413 17:53:33.741605 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.741610 26605 net.cpp:156] Memory required for data: 355124400
I0413 17:53:33.741617 26605 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 17:53:33.741626 26605 net.cpp:91] Creating Layer bn_conv3_3b
I0413 17:53:33.741631 26605 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 17:53:33.741636 26605 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 17:53:33.741835 26605 net.cpp:141] Setting up bn_conv3_3b
I0413 17:53:33.741843 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.741847 26605 net.cpp:156] Memory required for data: 358401200
I0413 17:53:33.741854 26605 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 17:53:33.741863 26605 net.cpp:91] Creating Layer scale_conv3_3b
I0413 17:53:33.741866 26605 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 17:53:33.741873 26605 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 17:53:33.741915 26605 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 17:53:33.742033 26605 net.cpp:141] Setting up scale_conv3_3b
I0413 17:53:33.742041 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.742044 26605 net.cpp:156] Memory required for data: 361678000
I0413 17:53:33.742051 26605 layer_factory.hpp:77] Creating layer conv3_3
I0413 17:53:33.742058 26605 net.cpp:91] Creating Layer conv3_3
I0413 17:53:33.742063 26605 net.cpp:425] conv3_3 <- conv3_3b
I0413 17:53:33.742068 26605 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 17:53:33.742074 26605 net.cpp:399] conv3_3 -> conv3_3
I0413 17:53:33.742096 26605 net.cpp:141] Setting up conv3_3
I0413 17:53:33.742102 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.742106 26605 net.cpp:156] Memory required for data: 364954800
I0413 17:53:33.742110 26605 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 17:53:33.742115 26605 net.cpp:91] Creating Layer conv3_3_relu
I0413 17:53:33.742120 26605 net.cpp:425] conv3_3_relu <- conv3_3
I0413 17:53:33.742126 26605 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 17:53:33.742702 26605 net.cpp:141] Setting up conv3_3_relu
I0413 17:53:33.742715 26605 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 17:53:33.742719 26605 net.cpp:156] Memory required for data: 368231600
I0413 17:53:33.742723 26605 layer_factory.hpp:77] Creating layer global_pool
I0413 17:53:33.742733 26605 net.cpp:91] Creating Layer global_pool
I0413 17:53:33.742738 26605 net.cpp:425] global_pool <- conv3_3
I0413 17:53:33.742743 26605 net.cpp:399] global_pool -> global_pool
I0413 17:53:33.744348 26605 net.cpp:141] Setting up global_pool
I0413 17:53:33.744359 26605 net.cpp:148] Top shape: 100 32 2 2 (12800)
I0413 17:53:33.744362 26605 net.cpp:156] Memory required for data: 368282800
I0413 17:53:33.744371 26605 layer_factory.hpp:77] Creating layer ip
I0413 17:53:33.744379 26605 net.cpp:91] Creating Layer ip
I0413 17:53:33.744384 26605 net.cpp:425] ip <- global_pool
I0413 17:53:33.744390 26605 net.cpp:399] ip -> ip
I0413 17:53:33.744506 26605 net.cpp:141] Setting up ip
I0413 17:53:33.744514 26605 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:53:33.744518 26605 net.cpp:156] Memory required for data: 368286800
I0413 17:53:33.744525 26605 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 17:53:33.744535 26605 net.cpp:91] Creating Layer ip_ip_0_split
I0413 17:53:33.744539 26605 net.cpp:425] ip_ip_0_split <- ip
I0413 17:53:33.744545 26605 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 17:53:33.744551 26605 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 17:53:33.744593 26605 net.cpp:141] Setting up ip_ip_0_split
I0413 17:53:33.744601 26605 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:53:33.744606 26605 net.cpp:148] Top shape: 100 10 (1000)
I0413 17:53:33.744608 26605 net.cpp:156] Memory required for data: 368294800
I0413 17:53:33.744612 26605 layer_factory.hpp:77] Creating layer accuracy
I0413 17:53:33.744618 26605 net.cpp:91] Creating Layer accuracy
I0413 17:53:33.744622 26605 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 17:53:33.744627 26605 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 17:53:33.744634 26605 net.cpp:399] accuracy -> accuracy
I0413 17:53:33.744642 26605 net.cpp:141] Setting up accuracy
I0413 17:53:33.744647 26605 net.cpp:148] Top shape: (1)
I0413 17:53:33.744650 26605 net.cpp:156] Memory required for data: 368294804
I0413 17:53:33.744654 26605 layer_factory.hpp:77] Creating layer loss
I0413 17:53:33.744659 26605 net.cpp:91] Creating Layer loss
I0413 17:53:33.744663 26605 net.cpp:425] loss <- ip_ip_0_split_1
I0413 17:53:33.744668 26605 net.cpp:425] loss <- label_cifar_1_split_1
I0413 17:53:33.744675 26605 net.cpp:399] loss -> loss
I0413 17:53:33.744683 26605 layer_factory.hpp:77] Creating layer loss
I0413 17:53:33.745590 26605 net.cpp:141] Setting up loss
I0413 17:53:33.745605 26605 net.cpp:148] Top shape: (1)
I0413 17:53:33.745609 26605 net.cpp:151]     with loss weight 1
I0413 17:53:33.745616 26605 net.cpp:156] Memory required for data: 368294808
I0413 17:53:33.745621 26605 net.cpp:217] loss needs backward computation.
I0413 17:53:33.745625 26605 net.cpp:219] accuracy does not need backward computation.
I0413 17:53:33.745630 26605 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 17:53:33.745633 26605 net.cpp:217] ip needs backward computation.
I0413 17:53:33.745637 26605 net.cpp:217] global_pool needs backward computation.
I0413 17:53:33.745641 26605 net.cpp:217] conv3_3_relu needs backward computation.
I0413 17:53:33.745645 26605 net.cpp:217] conv3_3 needs backward computation.
I0413 17:53:33.745650 26605 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 17:53:33.745652 26605 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 17:53:33.745656 26605 net.cpp:217] conv3_3b needs backward computation.
I0413 17:53:33.745661 26605 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 17:53:33.745664 26605 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 17:53:33.745667 26605 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 17:53:33.745671 26605 net.cpp:217] conv3_3a needs backward computation.
I0413 17:53:33.745676 26605 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 17:53:33.745679 26605 net.cpp:217] conv3_2_relu needs backward computation.
I0413 17:53:33.745682 26605 net.cpp:217] conv3_2 needs backward computation.
I0413 17:53:33.745687 26605 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 17:53:33.745690 26605 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 17:53:33.745694 26605 net.cpp:217] conv3_2b needs backward computation.
I0413 17:53:33.745698 26605 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 17:53:33.745702 26605 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 17:53:33.745705 26605 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 17:53:33.745712 26605 net.cpp:217] conv3_2a needs backward computation.
I0413 17:53:33.745718 26605 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 17:53:33.745720 26605 net.cpp:217] conv3_1_relu needs backward computation.
I0413 17:53:33.745724 26605 net.cpp:217] conv3_1 needs backward computation.
I0413 17:53:33.745728 26605 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 17:53:33.745733 26605 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 17:53:33.745736 26605 net.cpp:217] conv3_1b needs backward computation.
I0413 17:53:33.745739 26605 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 17:53:33.745743 26605 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 17:53:33.745746 26605 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 17:53:33.745750 26605 net.cpp:217] conv3_1a needs backward computation.
I0413 17:53:33.745754 26605 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 17:53:33.745759 26605 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 17:53:33.745761 26605 net.cpp:217] conv2_sub needs backward computation.
I0413 17:53:33.745765 26605 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 17:53:33.745769 26605 net.cpp:217] conv2_3_relu needs backward computation.
I0413 17:53:33.745772 26605 net.cpp:217] conv2_3 needs backward computation.
I0413 17:53:33.745777 26605 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 17:53:33.745780 26605 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 17:53:33.745784 26605 net.cpp:217] conv2_3b needs backward computation.
I0413 17:53:33.745789 26605 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 17:53:33.745791 26605 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 17:53:33.745795 26605 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 17:53:33.745798 26605 net.cpp:217] conv2_3a needs backward computation.
I0413 17:53:33.745802 26605 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 17:53:33.745806 26605 net.cpp:217] conv2_2_relu needs backward computation.
I0413 17:53:33.745810 26605 net.cpp:217] conv2_2 needs backward computation.
I0413 17:53:33.745815 26605 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 17:53:33.745817 26605 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 17:53:33.745821 26605 net.cpp:217] conv2_2b needs backward computation.
I0413 17:53:33.745826 26605 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 17:53:33.745828 26605 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 17:53:33.745832 26605 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 17:53:33.745836 26605 net.cpp:217] conv2_2a needs backward computation.
I0413 17:53:33.745839 26605 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 17:53:33.745843 26605 net.cpp:217] conv2_1_relu needs backward computation.
I0413 17:53:33.745846 26605 net.cpp:217] conv2_1 needs backward computation.
I0413 17:53:33.745851 26605 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 17:53:33.745854 26605 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 17:53:33.745858 26605 net.cpp:217] conv2_1b needs backward computation.
I0413 17:53:33.745862 26605 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 17:53:33.745865 26605 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 17:53:33.745869 26605 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 17:53:33.745872 26605 net.cpp:217] conv2_1a needs backward computation.
I0413 17:53:33.745877 26605 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 17:53:33.745880 26605 net.cpp:217] conv1_relu needs backward computation.
I0413 17:53:33.745884 26605 net.cpp:217] scale_conv1 needs backward computation.
I0413 17:53:33.745887 26605 net.cpp:217] bn_conv1 needs backward computation.
I0413 17:53:33.745892 26605 net.cpp:217] conv1 needs backward computation.
I0413 17:53:33.745895 26605 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 17:53:33.745903 26605 net.cpp:219] cifar does not need backward computation.
I0413 17:53:33.745906 26605 net.cpp:261] This network produces output accuracy
I0413 17:53:33.745913 26605 net.cpp:261] This network produces output loss
I0413 17:53:33.745954 26605 net.cpp:274] Network initialization done.
I0413 17:53:33.746146 26605 solver.cpp:60] Solver scaffolding done.
I0413 17:53:34.128363 26605 solver.cpp:228] Iteration 0, loss = 0.725647
I0413 17:53:34.128450 26605 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:53:34.128464 26605 solver.cpp:244]     Train net output #1: loss = 0.725647 (* 1 = 0.725647 loss)
I0413 17:53:34.128475 26605 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 17:53:39.538187 26605 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 17:53:42.124501 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5672
I0413 17:53:42.124564 26605 solver.cpp:404]     Test net output #1: loss = 1.85635 (* 1 = 1.85635 loss)
I0413 17:53:42.298094 26605 solver.cpp:228] Iteration 20, loss = 0.613778
I0413 17:53:42.298164 26605 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:53:42.298182 26605 solver.cpp:244]     Train net output #1: loss = 0.613778 (* 1 = 0.613778 loss)
I0413 17:53:42.298197 26605 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 17:53:47.931037 26605 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 17:53:50.487416 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6288
I0413 17:53:50.487480 26605 solver.cpp:404]     Test net output #1: loss = 1.4719 (* 1 = 1.4719 loss)
I0413 17:53:50.665343 26605 solver.cpp:228] Iteration 40, loss = 0.529283
I0413 17:53:50.665391 26605 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 17:53:50.665405 26605 solver.cpp:244]     Train net output #1: loss = 0.529283 (* 1 = 0.529283 loss)
I0413 17:53:50.665416 26605 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 17:53:56.055569 26605 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 17:53:58.767189 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6
I0413 17:53:58.767244 26605 solver.cpp:404]     Test net output #1: loss = 1.55704 (* 1 = 1.55704 loss)
I0413 17:53:58.989673 26605 solver.cpp:228] Iteration 60, loss = 0.514602
I0413 17:53:58.989763 26605 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 17:53:58.989776 26605 solver.cpp:244]     Train net output #1: loss = 0.514602 (* 1 = 0.514602 loss)
I0413 17:53:58.989787 26605 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 17:54:04.140408 26605 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 17:54:06.867835 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6489
I0413 17:54:06.867895 26605 solver.cpp:404]     Test net output #1: loss = 1.25364 (* 1 = 1.25364 loss)
I0413 17:54:07.073767 26605 solver.cpp:228] Iteration 80, loss = 0.504846
I0413 17:54:07.073820 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:54:07.073837 26605 solver.cpp:244]     Train net output #1: loss = 0.504846 (* 1 = 0.504846 loss)
I0413 17:54:07.073849 26605 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 17:54:12.432379 26605 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 17:54:14.996330 26605 solver.cpp:404]     Test net output #0: accuracy = 0.4739
I0413 17:54:14.996384 26605 solver.cpp:404]     Test net output #1: loss = 2.49549 (* 1 = 2.49549 loss)
I0413 17:54:15.204726 26605 solver.cpp:228] Iteration 100, loss = 0.575619
I0413 17:54:15.204777 26605 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:54:15.204792 26605 solver.cpp:244]     Train net output #1: loss = 0.575619 (* 1 = 0.575619 loss)
I0413 17:54:15.204803 26605 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 17:54:20.782284 26605 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 17:54:23.254218 26605 solver.cpp:404]     Test net output #0: accuracy = 0.581
I0413 17:54:23.254279 26605 solver.cpp:404]     Test net output #1: loss = 1.76964 (* 1 = 1.76964 loss)
I0413 17:54:23.438207 26605 solver.cpp:228] Iteration 120, loss = 0.647416
I0413 17:54:23.438269 26605 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 17:54:23.438285 26605 solver.cpp:244]     Train net output #1: loss = 0.647416 (* 1 = 0.647416 loss)
I0413 17:54:23.438299 26605 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 17:54:28.847476 26605 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 17:54:31.580749 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6595
I0413 17:54:31.580801 26605 solver.cpp:404]     Test net output #1: loss = 1.27327 (* 1 = 1.27327 loss)
I0413 17:54:31.800544 26605 solver.cpp:228] Iteration 140, loss = 0.44717
I0413 17:54:31.800596 26605 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 17:54:31.800612 26605 solver.cpp:244]     Train net output #1: loss = 0.44717 (* 1 = 0.44717 loss)
I0413 17:54:31.800623 26605 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 17:54:36.858489 26605 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 17:54:39.618795 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6161
I0413 17:54:39.618860 26605 solver.cpp:404]     Test net output #1: loss = 1.37903 (* 1 = 1.37903 loss)
I0413 17:54:39.804129 26605 solver.cpp:228] Iteration 160, loss = 0.55867
I0413 17:54:39.804177 26605 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 17:54:39.804189 26605 solver.cpp:244]     Train net output #1: loss = 0.55867 (* 1 = 0.55867 loss)
I0413 17:54:39.804199 26605 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 17:54:45.056145 26605 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 17:54:47.693312 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7338
I0413 17:54:47.693377 26605 solver.cpp:404]     Test net output #1: loss = 0.863828 (* 1 = 0.863828 loss)
I0413 17:54:47.873775 26605 solver.cpp:228] Iteration 180, loss = 0.593355
I0413 17:54:47.873831 26605 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:54:47.873852 26605 solver.cpp:244]     Train net output #1: loss = 0.593355 (* 1 = 0.593355 loss)
I0413 17:54:47.873864 26605 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 17:54:53.477464 26605 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 17:54:55.868849 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6104
I0413 17:54:55.868891 26605 solver.cpp:404]     Test net output #1: loss = 1.40268 (* 1 = 1.40268 loss)
I0413 17:54:56.047534 26605 solver.cpp:228] Iteration 200, loss = 0.490929
I0413 17:54:56.047585 26605 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:54:56.047600 26605 solver.cpp:244]     Train net output #1: loss = 0.490929 (* 1 = 0.490929 loss)
I0413 17:54:56.047612 26605 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 17:55:01.555495 26605 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 17:55:04.228023 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6945
I0413 17:55:04.228070 26605 solver.cpp:404]     Test net output #1: loss = 1.02128 (* 1 = 1.02128 loss)
I0413 17:55:04.406468 26605 solver.cpp:228] Iteration 220, loss = 0.420566
I0413 17:55:04.406491 26605 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 17:55:04.406502 26605 solver.cpp:244]     Train net output #1: loss = 0.420566 (* 1 = 0.420566 loss)
I0413 17:55:04.406512 26605 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 17:55:09.652705 26605 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 17:55:12.418189 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6251
I0413 17:55:12.418254 26605 solver.cpp:404]     Test net output #1: loss = 1.38548 (* 1 = 1.38548 loss)
I0413 17:55:12.595875 26605 solver.cpp:228] Iteration 240, loss = 0.507233
I0413 17:55:12.595898 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:55:12.595909 26605 solver.cpp:244]     Train net output #1: loss = 0.507233 (* 1 = 0.507233 loss)
I0413 17:55:12.595921 26605 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 17:55:17.806468 26605 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 17:55:20.530925 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6148
I0413 17:55:20.530987 26605 solver.cpp:404]     Test net output #1: loss = 1.38247 (* 1 = 1.38247 loss)
I0413 17:55:20.701664 26605 solver.cpp:228] Iteration 260, loss = 0.587048
I0413 17:55:20.701719 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:55:20.701731 26605 solver.cpp:244]     Train net output #1: loss = 0.587048 (* 1 = 0.587048 loss)
I0413 17:55:20.701745 26605 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 17:55:26.193320 26605 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 17:55:28.619218 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7003
I0413 17:55:28.619282 26605 solver.cpp:404]     Test net output #1: loss = 1.04876 (* 1 = 1.04876 loss)
I0413 17:55:28.810665 26605 solver.cpp:228] Iteration 280, loss = 0.613251
I0413 17:55:28.810722 26605 solver.cpp:244]     Train net output #0: accuracy = 0.777344
I0413 17:55:28.810739 26605 solver.cpp:244]     Train net output #1: loss = 0.613251 (* 1 = 0.613251 loss)
I0413 17:55:28.810752 26605 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 17:55:34.420538 26605 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 17:55:36.985940 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5534
I0413 17:55:36.985986 26605 solver.cpp:404]     Test net output #1: loss = 2.12607 (* 1 = 2.12607 loss)
I0413 17:55:37.168915 26605 solver.cpp:228] Iteration 300, loss = 0.672075
I0413 17:55:37.168962 26605 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 17:55:37.168975 26605 solver.cpp:244]     Train net output #1: loss = 0.672075 (* 1 = 0.672075 loss)
I0413 17:55:37.168985 26605 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 17:55:42.535771 26605 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 17:55:45.250942 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6975
I0413 17:55:45.251004 26605 solver.cpp:404]     Test net output #1: loss = 0.980213 (* 1 = 0.980213 loss)
I0413 17:55:45.450696 26605 solver.cpp:228] Iteration 320, loss = 0.585197
I0413 17:55:45.450738 26605 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:55:45.450755 26605 solver.cpp:244]     Train net output #1: loss = 0.585197 (* 1 = 0.585197 loss)
I0413 17:55:45.450772 26605 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 17:55:50.627357 26605 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 17:55:53.376585 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5507
I0413 17:55:53.376631 26605 solver.cpp:404]     Test net output #1: loss = 1.86938 (* 1 = 1.86938 loss)
I0413 17:55:53.576982 26605 solver.cpp:228] Iteration 340, loss = 0.492451
I0413 17:55:53.577020 26605 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:55:53.577033 26605 solver.cpp:244]     Train net output #1: loss = 0.492451 (* 1 = 0.492451 loss)
I0413 17:55:53.577042 26605 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 17:55:58.940945 26605 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 17:56:01.462208 26605 solver.cpp:404]     Test net output #0: accuracy = 0.695
I0413 17:56:01.462281 26605 solver.cpp:404]     Test net output #1: loss = 0.94782 (* 1 = 0.94782 loss)
I0413 17:56:01.646452 26605 solver.cpp:228] Iteration 360, loss = 0.32675
I0413 17:56:01.646486 26605 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 17:56:01.646502 26605 solver.cpp:244]     Train net output #1: loss = 0.32675 (* 1 = 0.32675 loss)
I0413 17:56:01.646517 26605 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 17:56:07.214813 26605 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 17:56:09.702651 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6156
I0413 17:56:09.702718 26605 solver.cpp:404]     Test net output #1: loss = 1.64681 (* 1 = 1.64681 loss)
I0413 17:56:09.883054 26605 solver.cpp:228] Iteration 380, loss = 0.525063
I0413 17:56:09.883096 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:56:09.883108 26605 solver.cpp:244]     Train net output #1: loss = 0.525063 (* 1 = 0.525063 loss)
I0413 17:56:09.883117 26605 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 17:56:15.293514 26605 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 17:56:18.017226 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6213
I0413 17:56:18.017290 26605 solver.cpp:404]     Test net output #1: loss = 1.40187 (* 1 = 1.40187 loss)
I0413 17:56:18.227162 26605 solver.cpp:228] Iteration 400, loss = 0.327354
I0413 17:56:18.227188 26605 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 17:56:18.227202 26605 solver.cpp:244]     Train net output #1: loss = 0.327354 (* 1 = 0.327354 loss)
I0413 17:56:18.227216 26605 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 17:56:23.345974 26605 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 17:56:26.096941 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6198
I0413 17:56:26.096992 26605 solver.cpp:404]     Test net output #1: loss = 1.58192 (* 1 = 1.58192 loss)
I0413 17:56:26.274256 26605 solver.cpp:228] Iteration 420, loss = 0.558216
I0413 17:56:26.274307 26605 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:56:26.274323 26605 solver.cpp:244]     Train net output #1: loss = 0.558216 (* 1 = 0.558216 loss)
I0413 17:56:26.274335 26605 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 17:56:31.609477 26605 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 17:56:34.224535 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6122
I0413 17:56:34.224594 26605 solver.cpp:404]     Test net output #1: loss = 1.50926 (* 1 = 1.50926 loss)
I0413 17:56:34.414696 26605 solver.cpp:228] Iteration 440, loss = 0.402907
I0413 17:56:34.414744 26605 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 17:56:34.414759 26605 solver.cpp:244]     Train net output #1: loss = 0.402907 (* 1 = 0.402907 loss)
I0413 17:56:34.414772 26605 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 17:56:40.004508 26605 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 17:56:42.437269 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6789
I0413 17:56:42.437338 26605 solver.cpp:404]     Test net output #1: loss = 0.992236 (* 1 = 0.992236 loss)
I0413 17:56:42.614487 26605 solver.cpp:228] Iteration 460, loss = 0.448821
I0413 17:56:42.614526 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:56:42.614542 26605 solver.cpp:244]     Train net output #1: loss = 0.448821 (* 1 = 0.448821 loss)
I0413 17:56:42.614553 26605 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 17:56:48.103281 26605 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 17:56:50.795492 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7314
I0413 17:56:50.795547 26605 solver.cpp:404]     Test net output #1: loss = 0.781288 (* 1 = 0.781288 loss)
I0413 17:56:50.972873 26605 solver.cpp:228] Iteration 480, loss = 0.481719
I0413 17:56:50.972918 26605 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 17:56:50.972930 26605 solver.cpp:244]     Train net output #1: loss = 0.481719 (* 1 = 0.481719 loss)
I0413 17:56:50.972944 26605 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 17:56:56.203843 26605 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 17:56:58.942749 26605 solver.cpp:404]     Test net output #0: accuracy = 0.617
I0413 17:56:58.942806 26605 solver.cpp:404]     Test net output #1: loss = 1.39751 (* 1 = 1.39751 loss)
I0413 17:56:59.162310 26605 solver.cpp:228] Iteration 500, loss = 0.363379
I0413 17:56:59.162360 26605 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 17:56:59.162374 26605 solver.cpp:244]     Train net output #1: loss = 0.363379 (* 1 = 0.363379 loss)
I0413 17:56:59.162386 26605 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 17:57:04.378912 26605 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 17:57:07.060693 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6419
I0413 17:57:07.060747 26605 solver.cpp:404]     Test net output #1: loss = 1.1332 (* 1 = 1.1332 loss)
I0413 17:57:07.273339 26605 solver.cpp:228] Iteration 520, loss = 0.601563
I0413 17:57:07.273408 26605 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 17:57:07.273442 26605 solver.cpp:244]     Train net output #1: loss = 0.601563 (* 1 = 0.601563 loss)
I0413 17:57:07.273458 26605 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 17:57:12.769743 26605 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 17:57:15.197298 26605 solver.cpp:404]     Test net output #0: accuracy = 0.4746
I0413 17:57:15.197336 26605 solver.cpp:404]     Test net output #1: loss = 2.3403 (* 1 = 2.3403 loss)
I0413 17:57:15.379935 26605 solver.cpp:228] Iteration 540, loss = 0.423284
I0413 17:57:15.380046 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:57:15.380071 26605 solver.cpp:244]     Train net output #1: loss = 0.423284 (* 1 = 0.423284 loss)
I0413 17:57:15.380084 26605 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 17:57:20.982285 26605 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 17:57:23.582821 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6948
I0413 17:57:23.582885 26605 solver.cpp:404]     Test net output #1: loss = 0.951967 (* 1 = 0.951967 loss)
I0413 17:57:23.767282 26605 solver.cpp:228] Iteration 560, loss = 0.50523
I0413 17:57:23.767320 26605 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:57:23.767333 26605 solver.cpp:244]     Train net output #1: loss = 0.50523 (* 1 = 0.50523 loss)
I0413 17:57:23.767345 26605 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 17:57:29.082830 26605 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 17:57:31.851889 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6387
I0413 17:57:31.851933 26605 solver.cpp:404]     Test net output #1: loss = 1.38981 (* 1 = 1.38981 loss)
I0413 17:57:32.027351 26605 solver.cpp:228] Iteration 580, loss = 0.418661
I0413 17:57:32.027385 26605 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 17:57:32.027398 26605 solver.cpp:244]     Train net output #1: loss = 0.418661 (* 1 = 0.418661 loss)
I0413 17:57:32.027407 26605 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 17:57:37.169423 26605 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 17:57:39.937453 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5946
I0413 17:57:39.937505 26605 solver.cpp:404]     Test net output #1: loss = 1.3915 (* 1 = 1.3915 loss)
I0413 17:57:40.117292 26605 solver.cpp:228] Iteration 600, loss = 0.460819
I0413 17:57:40.117343 26605 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 17:57:40.117357 26605 solver.cpp:244]     Train net output #1: loss = 0.460819 (* 1 = 0.460819 loss)
I0413 17:57:40.117370 26605 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 17:57:45.525611 26605 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 17:57:48.023510 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7074
I0413 17:57:48.023553 26605 solver.cpp:404]     Test net output #1: loss = 0.855573 (* 1 = 0.855573 loss)
I0413 17:57:48.213105 26605 solver.cpp:228] Iteration 620, loss = 0.522111
I0413 17:57:48.213146 26605 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 17:57:48.213157 26605 solver.cpp:244]     Train net output #1: loss = 0.522111 (* 1 = 0.522111 loss)
I0413 17:57:48.213166 26605 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 17:57:53.800456 26605 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 17:57:56.325876 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6731
I0413 17:57:56.325929 26605 solver.cpp:404]     Test net output #1: loss = 1.07014 (* 1 = 1.07014 loss)
I0413 17:57:56.501443 26605 solver.cpp:228] Iteration 640, loss = 0.471688
I0413 17:57:56.501507 26605 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 17:57:56.501523 26605 solver.cpp:244]     Train net output #1: loss = 0.471688 (* 1 = 0.471688 loss)
I0413 17:57:56.501538 26605 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 17:58:01.914229 26605 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 17:58:04.644739 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6143
I0413 17:58:04.644805 26605 solver.cpp:404]     Test net output #1: loss = 1.3255 (* 1 = 1.3255 loss)
I0413 17:58:04.856317 26605 solver.cpp:228] Iteration 660, loss = 0.534898
I0413 17:58:04.856355 26605 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 17:58:04.856367 26605 solver.cpp:244]     Train net output #1: loss = 0.534898 (* 1 = 0.534898 loss)
I0413 17:58:04.856377 26605 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 17:58:09.990010 26605 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 17:58:12.746238 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5309
I0413 17:58:12.746294 26605 solver.cpp:404]     Test net output #1: loss = 1.71549 (* 1 = 1.71549 loss)
I0413 17:58:12.935237 26605 solver.cpp:228] Iteration 680, loss = 0.420006
I0413 17:58:12.935266 26605 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 17:58:12.935281 26605 solver.cpp:244]     Train net output #1: loss = 0.420006 (* 1 = 0.420006 loss)
I0413 17:58:12.935295 26605 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 17:58:18.241858 26605 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 17:58:20.838901 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5667
I0413 17:58:20.838963 26605 solver.cpp:404]     Test net output #1: loss = 1.73583 (* 1 = 1.73583 loss)
I0413 17:58:21.024310 26605 solver.cpp:228] Iteration 700, loss = 0.396485
I0413 17:58:21.024358 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:58:21.024372 26605 solver.cpp:244]     Train net output #1: loss = 0.396485 (* 1 = 0.396485 loss)
I0413 17:58:21.024384 26605 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 17:58:26.600148 26605 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 17:58:29.054373 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5365
I0413 17:58:29.054427 26605 solver.cpp:404]     Test net output #1: loss = 1.8302 (* 1 = 1.8302 loss)
I0413 17:58:29.229423 26605 solver.cpp:228] Iteration 720, loss = 0.483753
I0413 17:58:29.229471 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:58:29.229483 26605 solver.cpp:244]     Train net output #1: loss = 0.483753 (* 1 = 0.483753 loss)
I0413 17:58:29.229496 26605 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 17:58:34.773005 26605 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 17:58:37.472877 26605 solver.cpp:404]     Test net output #0: accuracy = 0.4379
I0413 17:58:37.472920 26605 solver.cpp:404]     Test net output #1: loss = 2.54343 (* 1 = 2.54343 loss)
I0413 17:58:37.653143 26605 solver.cpp:228] Iteration 740, loss = 0.474731
I0413 17:58:37.653187 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:58:37.653199 26605 solver.cpp:244]     Train net output #1: loss = 0.474731 (* 1 = 0.474731 loss)
I0413 17:58:37.653213 26605 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 17:58:42.850888 26605 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 17:58:45.579929 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6575
I0413 17:58:45.579978 26605 solver.cpp:404]     Test net output #1: loss = 1.05607 (* 1 = 1.05607 loss)
I0413 17:58:45.785441 26605 solver.cpp:228] Iteration 760, loss = 0.477238
I0413 17:58:45.785491 26605 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:58:45.785507 26605 solver.cpp:244]     Train net output #1: loss = 0.477238 (* 1 = 0.477238 loss)
I0413 17:58:45.785521 26605 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 17:58:50.992280 26605 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 17:58:53.666530 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6228
I0413 17:58:53.666584 26605 solver.cpp:404]     Test net output #1: loss = 1.308 (* 1 = 1.308 loss)
I0413 17:58:53.850469 26605 solver.cpp:228] Iteration 780, loss = 0.414052
I0413 17:58:53.850508 26605 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 17:58:53.850519 26605 solver.cpp:244]     Train net output #1: loss = 0.414052 (* 1 = 0.414052 loss)
I0413 17:58:53.850529 26605 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 17:58:59.282057 26605 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 17:59:01.704368 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6411
I0413 17:59:01.704408 26605 solver.cpp:404]     Test net output #1: loss = 1.11164 (* 1 = 1.11164 loss)
I0413 17:59:01.889405 26605 solver.cpp:228] Iteration 800, loss = 0.507831
I0413 17:59:01.889457 26605 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 17:59:01.889469 26605 solver.cpp:244]     Train net output #1: loss = 0.507831 (* 1 = 0.507831 loss)
I0413 17:59:01.889479 26605 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 17:59:07.433220 26605 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 17:59:10.060963 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7128
I0413 17:59:10.061012 26605 solver.cpp:404]     Test net output #1: loss = 0.859828 (* 1 = 0.859828 loss)
I0413 17:59:10.242457 26605 solver.cpp:228] Iteration 820, loss = 0.491667
I0413 17:59:10.242488 26605 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 17:59:10.242501 26605 solver.cpp:244]     Train net output #1: loss = 0.491667 (* 1 = 0.491667 loss)
I0413 17:59:10.242509 26605 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 17:59:15.519984 26605 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 17:59:18.291857 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6517
I0413 17:59:18.291895 26605 solver.cpp:404]     Test net output #1: loss = 1.06663 (* 1 = 1.06663 loss)
I0413 17:59:18.468463 26605 solver.cpp:228] Iteration 840, loss = 0.537967
I0413 17:59:18.468525 26605 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 17:59:18.468538 26605 solver.cpp:244]     Train net output #1: loss = 0.537967 (* 1 = 0.537967 loss)
I0413 17:59:18.468550 26605 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 17:59:23.640427 26605 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 17:59:26.366436 26605 solver.cpp:404]     Test net output #0: accuracy = 0.581
I0413 17:59:26.366489 26605 solver.cpp:404]     Test net output #1: loss = 1.3975 (* 1 = 1.3975 loss)
I0413 17:59:26.560879 26605 solver.cpp:228] Iteration 860, loss = 0.510583
I0413 17:59:26.560904 26605 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 17:59:26.560916 26605 solver.cpp:244]     Train net output #1: loss = 0.510583 (* 1 = 0.510583 loss)
I0413 17:59:26.560925 26605 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 17:59:32.038381 26605 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 17:59:34.509517 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5688
I0413 17:59:34.509564 26605 solver.cpp:404]     Test net output #1: loss = 1.70277 (* 1 = 1.70277 loss)
I0413 17:59:34.700538 26605 solver.cpp:228] Iteration 880, loss = 0.469266
I0413 17:59:34.700587 26605 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 17:59:34.700600 26605 solver.cpp:244]     Train net output #1: loss = 0.469266 (* 1 = 0.469266 loss)
I0413 17:59:34.700610 26605 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 17:59:40.316647 26605 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 17:59:42.867873 26605 solver.cpp:404]     Test net output #0: accuracy = 0.66
I0413 17:59:42.867913 26605 solver.cpp:404]     Test net output #1: loss = 1.19124 (* 1 = 1.19124 loss)
I0413 17:59:43.049078 26605 solver.cpp:228] Iteration 900, loss = 0.447278
I0413 17:59:43.049166 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 17:59:43.049182 26605 solver.cpp:244]     Train net output #1: loss = 0.447278 (* 1 = 0.447278 loss)
I0413 17:59:43.049193 26605 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 17:59:48.439417 26605 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 17:59:51.154906 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6547
I0413 17:59:51.154978 26605 solver.cpp:404]     Test net output #1: loss = 1.19397 (* 1 = 1.19397 loss)
I0413 17:59:51.348209 26605 solver.cpp:228] Iteration 920, loss = 0.448336
I0413 17:59:51.348273 26605 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 17:59:51.348291 26605 solver.cpp:244]     Train net output #1: loss = 0.448336 (* 1 = 0.448336 loss)
I0413 17:59:51.348316 26605 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 17:59:56.501775 26605 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 17:59:59.274628 26605 solver.cpp:404]     Test net output #0: accuracy = 0.496
I0413 17:59:59.274699 26605 solver.cpp:404]     Test net output #1: loss = 2.04871 (* 1 = 2.04871 loss)
I0413 17:59:59.453632 26605 solver.cpp:228] Iteration 940, loss = 0.457935
I0413 17:59:59.453680 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 17:59:59.453693 26605 solver.cpp:244]     Train net output #1: loss = 0.457935 (* 1 = 0.457935 loss)
I0413 17:59:59.453703 26605 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 18:00:04.864506 26605 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 18:00:07.423992 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6261
I0413 18:00:07.424044 26605 solver.cpp:404]     Test net output #1: loss = 1.19452 (* 1 = 1.19452 loss)
I0413 18:00:07.601958 26605 solver.cpp:228] Iteration 960, loss = 0.425196
I0413 18:00:07.602008 26605 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:00:07.602021 26605 solver.cpp:244]     Train net output #1: loss = 0.425196 (* 1 = 0.425196 loss)
I0413 18:00:07.602031 26605 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 18:00:13.200803 26605 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 18:00:15.686333 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5662
I0413 18:00:15.686377 26605 solver.cpp:404]     Test net output #1: loss = 1.63827 (* 1 = 1.63827 loss)
I0413 18:00:15.860684 26605 solver.cpp:228] Iteration 980, loss = 0.38082
I0413 18:00:15.860725 26605 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:00:15.860738 26605 solver.cpp:244]     Train net output #1: loss = 0.38082 (* 1 = 0.38082 loss)
I0413 18:00:15.860748 26605 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 18:00:21.308656 26605 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 18:00:24.023115 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6689
I0413 18:00:24.023167 26605 solver.cpp:404]     Test net output #1: loss = 1.01776 (* 1 = 1.01776 loss)
I0413 18:00:24.227012 26605 solver.cpp:228] Iteration 1000, loss = 0.433472
I0413 18:00:24.227056 26605 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:00:24.227067 26605 solver.cpp:244]     Train net output #1: loss = 0.433472 (* 1 = 0.433472 loss)
I0413 18:00:24.227077 26605 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 18:00:29.379597 26605 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 18:00:32.126727 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5194
I0413 18:00:32.126772 26605 solver.cpp:404]     Test net output #1: loss = 1.76525 (* 1 = 1.76525 loss)
I0413 18:00:32.318012 26605 solver.cpp:228] Iteration 1020, loss = 0.523329
I0413 18:00:32.318049 26605 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 18:00:32.318061 26605 solver.cpp:244]     Train net output #1: loss = 0.523329 (* 1 = 0.523329 loss)
I0413 18:00:32.318070 26605 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 18:00:37.590739 26605 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 18:00:40.240546 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6224
I0413 18:00:40.240597 26605 solver.cpp:404]     Test net output #1: loss = 1.22194 (* 1 = 1.22194 loss)
I0413 18:00:40.431957 26605 solver.cpp:228] Iteration 1040, loss = 0.437527
I0413 18:00:40.431984 26605 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:00:40.431996 26605 solver.cpp:244]     Train net output #1: loss = 0.437527 (* 1 = 0.437527 loss)
I0413 18:00:40.432006 26605 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 18:00:46.042855 26605 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 18:00:48.399055 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7163
I0413 18:00:48.399109 26605 solver.cpp:404]     Test net output #1: loss = 0.889336 (* 1 = 0.889336 loss)
I0413 18:00:48.580337 26605 solver.cpp:228] Iteration 1060, loss = 0.531935
I0413 18:00:48.580359 26605 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 18:00:48.580379 26605 solver.cpp:244]     Train net output #1: loss = 0.531935 (* 1 = 0.531935 loss)
I0413 18:00:48.580389 26605 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 18:00:54.143806 26605 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 18:00:56.819818 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5373
I0413 18:00:56.819869 26605 solver.cpp:404]     Test net output #1: loss = 2.20657 (* 1 = 2.20657 loss)
I0413 18:00:56.999032 26605 solver.cpp:228] Iteration 1080, loss = 0.460694
I0413 18:00:56.999073 26605 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:00:56.999086 26605 solver.cpp:244]     Train net output #1: loss = 0.460694 (* 1 = 0.460694 loss)
I0413 18:00:56.999099 26605 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 18:01:02.225075 26605 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 18:01:04.978685 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7377
I0413 18:01:04.978739 26605 solver.cpp:404]     Test net output #1: loss = 0.814837 (* 1 = 0.814837 loss)
I0413 18:01:05.168678 26605 solver.cpp:228] Iteration 1100, loss = 0.452731
I0413 18:01:05.168731 26605 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:01:05.168745 26605 solver.cpp:244]     Train net output #1: loss = 0.452731 (* 1 = 0.452731 loss)
I0413 18:01:05.168763 26605 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 18:01:10.382879 26605 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 18:01:13.086917 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6737
I0413 18:01:13.086977 26605 solver.cpp:404]     Test net output #1: loss = 1.07364 (* 1 = 1.07364 loss)
I0413 18:01:13.264384 26605 solver.cpp:228] Iteration 1120, loss = 0.536963
I0413 18:01:13.264405 26605 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 18:01:13.264415 26605 solver.cpp:244]     Train net output #1: loss = 0.536963 (* 1 = 0.536963 loss)
I0413 18:01:13.264425 26605 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 18:01:18.761433 26605 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 18:01:21.204054 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5847
I0413 18:01:21.204102 26605 solver.cpp:404]     Test net output #1: loss = 1.47707 (* 1 = 1.47707 loss)
I0413 18:01:21.389077 26605 solver.cpp:228] Iteration 1140, loss = 0.5359
I0413 18:01:21.389183 26605 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 18:01:21.389209 26605 solver.cpp:244]     Train net output #1: loss = 0.5359 (* 1 = 0.5359 loss)
I0413 18:01:21.389230 26605 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 18:01:26.992735 26605 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 18:01:29.579480 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6701
I0413 18:01:29.579540 26605 solver.cpp:404]     Test net output #1: loss = 1.13897 (* 1 = 1.13897 loss)
I0413 18:01:29.756916 26605 solver.cpp:228] Iteration 1160, loss = 0.466313
I0413 18:01:29.756959 26605 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:01:29.756974 26605 solver.cpp:244]     Train net output #1: loss = 0.466313 (* 1 = 0.466313 loss)
I0413 18:01:29.756985 26605 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 18:01:35.055585 26605 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 18:01:37.801296 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5811
I0413 18:01:37.801349 26605 solver.cpp:404]     Test net output #1: loss = 1.84557 (* 1 = 1.84557 loss)
I0413 18:01:37.988278 26605 solver.cpp:228] Iteration 1180, loss = 0.447738
I0413 18:01:37.988329 26605 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:01:37.988343 26605 solver.cpp:244]     Train net output #1: loss = 0.447738 (* 1 = 0.447738 loss)
I0413 18:01:37.988354 26605 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 18:01:43.147972 26605 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 18:01:45.922350 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6921
I0413 18:01:45.922417 26605 solver.cpp:404]     Test net output #1: loss = 0.973881 (* 1 = 0.973881 loss)
I0413 18:01:46.100363 26605 solver.cpp:228] Iteration 1200, loss = 0.385924
I0413 18:01:46.100407 26605 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:01:46.100422 26605 solver.cpp:244]     Train net output #1: loss = 0.385924 (* 1 = 0.385924 loss)
I0413 18:01:46.100433 26605 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 18:01:51.547349 26605 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 18:01:54.073752 26605 solver.cpp:404]     Test net output #0: accuracy = 0.712
I0413 18:01:54.073810 26605 solver.cpp:404]     Test net output #1: loss = 0.911748 (* 1 = 0.911748 loss)
I0413 18:01:54.276041 26605 solver.cpp:228] Iteration 1220, loss = 0.534182
I0413 18:01:54.276064 26605 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:01:54.276077 26605 solver.cpp:244]     Train net output #1: loss = 0.534182 (* 1 = 0.534182 loss)
I0413 18:01:54.276089 26605 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 18:01:59.834092 26605 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 18:02:02.345717 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7052
I0413 18:02:02.345769 26605 solver.cpp:404]     Test net output #1: loss = 0.902702 (* 1 = 0.902702 loss)
I0413 18:02:02.520548 26605 solver.cpp:228] Iteration 1240, loss = 0.42482
I0413 18:02:02.520604 26605 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:02:02.520618 26605 solver.cpp:244]     Train net output #1: loss = 0.42482 (* 1 = 0.42482 loss)
I0413 18:02:02.520629 26605 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 18:02:07.908808 26605 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 18:02:10.649674 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7145
I0413 18:02:10.649726 26605 solver.cpp:404]     Test net output #1: loss = 0.890208 (* 1 = 0.890208 loss)
I0413 18:02:10.868413 26605 solver.cpp:228] Iteration 1260, loss = 0.413495
I0413 18:02:10.868463 26605 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:02:10.868479 26605 solver.cpp:244]     Train net output #1: loss = 0.413495 (* 1 = 0.413495 loss)
I0413 18:02:10.868494 26605 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 18:02:16.016649 26605 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 18:02:18.744745 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6281
I0413 18:02:18.744815 26605 solver.cpp:404]     Test net output #1: loss = 1.51076 (* 1 = 1.51076 loss)
I0413 18:02:18.951364 26605 solver.cpp:228] Iteration 1280, loss = 0.46539
I0413 18:02:18.951406 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:02:18.951419 26605 solver.cpp:244]     Train net output #1: loss = 0.46539 (* 1 = 0.46539 loss)
I0413 18:02:18.951431 26605 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 18:02:24.227561 26605 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 18:02:26.843686 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7113
I0413 18:02:26.843756 26605 solver.cpp:404]     Test net output #1: loss = 0.917357 (* 1 = 0.917357 loss)
I0413 18:02:27.024638 26605 solver.cpp:228] Iteration 1300, loss = 0.618708
I0413 18:02:27.024685 26605 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 18:02:27.024699 26605 solver.cpp:244]     Train net output #1: loss = 0.618708 (* 1 = 0.618708 loss)
I0413 18:02:27.024713 26605 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 18:02:32.605104 26605 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 18:02:35.038353 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6729
I0413 18:02:35.038404 26605 solver.cpp:404]     Test net output #1: loss = 1.13008 (* 1 = 1.13008 loss)
I0413 18:02:35.220281 26605 solver.cpp:228] Iteration 1320, loss = 0.50544
I0413 18:02:35.220319 26605 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 18:02:35.220334 26605 solver.cpp:244]     Train net output #1: loss = 0.50544 (* 1 = 0.50544 loss)
I0413 18:02:35.220342 26605 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 18:02:40.693292 26605 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 18:02:43.404220 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6817
I0413 18:02:43.404291 26605 solver.cpp:404]     Test net output #1: loss = 1.10463 (* 1 = 1.10463 loss)
I0413 18:02:43.566864 26605 solver.cpp:228] Iteration 1340, loss = 0.508111
I0413 18:02:43.566910 26605 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:02:43.566922 26605 solver.cpp:244]     Train net output #1: loss = 0.508111 (* 1 = 0.508111 loss)
I0413 18:02:43.566936 26605 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 18:02:48.734087 26605 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 18:02:51.499403 26605 solver.cpp:404]     Test net output #0: accuracy = 0.644
I0413 18:02:51.499460 26605 solver.cpp:404]     Test net output #1: loss = 1.34099 (* 1 = 1.34099 loss)
I0413 18:02:51.675272 26605 solver.cpp:228] Iteration 1360, loss = 0.432087
I0413 18:02:51.675320 26605 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:02:51.675335 26605 solver.cpp:244]     Train net output #1: loss = 0.432087 (* 1 = 0.432087 loss)
I0413 18:02:51.675348 26605 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 18:02:56.898165 26605 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 18:02:59.585352 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6746
I0413 18:02:59.585403 26605 solver.cpp:404]     Test net output #1: loss = 1.07985 (* 1 = 1.07985 loss)
I0413 18:02:59.768105 26605 solver.cpp:228] Iteration 1380, loss = 0.509298
I0413 18:02:59.768164 26605 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 18:02:59.768187 26605 solver.cpp:244]     Train net output #1: loss = 0.509298 (* 1 = 0.509298 loss)
I0413 18:02:59.768208 26605 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 18:03:05.274168 26605 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 18:03:07.711046 26605 solver.cpp:404]     Test net output #0: accuracy = 0.691
I0413 18:03:07.711089 26605 solver.cpp:404]     Test net output #1: loss = 1.06206 (* 1 = 1.06206 loss)
I0413 18:03:07.886276 26605 solver.cpp:228] Iteration 1400, loss = 0.471195
I0413 18:03:07.886348 26605 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:03:07.886364 26605 solver.cpp:244]     Train net output #1: loss = 0.471195 (* 1 = 0.471195 loss)
I0413 18:03:07.886376 26605 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 18:03:13.462586 26605 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 18:03:16.076133 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6422
I0413 18:03:16.076194 26605 solver.cpp:404]     Test net output #1: loss = 1.25099 (* 1 = 1.25099 loss)
I0413 18:03:16.257948 26605 solver.cpp:228] Iteration 1420, loss = 0.612435
I0413 18:03:16.257999 26605 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 18:03:16.258016 26605 solver.cpp:244]     Train net output #1: loss = 0.612435 (* 1 = 0.612435 loss)
I0413 18:03:16.258033 26605 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 18:03:21.506534 26605 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 18:03:24.263449 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6152
I0413 18:03:24.263495 26605 solver.cpp:404]     Test net output #1: loss = 1.28296 (* 1 = 1.28296 loss)
I0413 18:03:24.466912 26605 solver.cpp:228] Iteration 1440, loss = 0.392833
I0413 18:03:24.466979 26605 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:03:24.466996 26605 solver.cpp:244]     Train net output #1: loss = 0.392833 (* 1 = 0.392833 loss)
I0413 18:03:24.467008 26605 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 18:03:29.586422 26605 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 18:03:32.329331 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7569
I0413 18:03:32.329409 26605 solver.cpp:404]     Test net output #1: loss = 0.712695 (* 1 = 0.712695 loss)
I0413 18:03:32.515910 26605 solver.cpp:228] Iteration 1460, loss = 0.433509
I0413 18:03:32.515971 26605 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:03:32.516005 26605 solver.cpp:244]     Train net output #1: loss = 0.433509 (* 1 = 0.433509 loss)
I0413 18:03:32.516021 26605 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 18:03:37.959722 26605 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 18:03:40.414615 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7375
I0413 18:03:40.414680 26605 solver.cpp:404]     Test net output #1: loss = 0.803136 (* 1 = 0.803136 loss)
I0413 18:03:40.606914 26605 solver.cpp:228] Iteration 1480, loss = 0.419032
I0413 18:03:40.606961 26605 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:03:40.606976 26605 solver.cpp:244]     Train net output #1: loss = 0.419032 (* 1 = 0.419032 loss)
I0413 18:03:40.606986 26605 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 18:03:46.155799 26605 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 18:03:48.714531 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6359
I0413 18:03:48.714642 26605 solver.cpp:404]     Test net output #1: loss = 1.21733 (* 1 = 1.21733 loss)
I0413 18:03:48.895054 26605 solver.cpp:228] Iteration 1500, loss = 0.362444
I0413 18:03:48.895112 26605 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:03:48.895128 26605 solver.cpp:244]     Train net output #1: loss = 0.362444 (* 1 = 0.362444 loss)
I0413 18:03:48.895143 26605 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 18:03:54.202745 26605 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 18:03:56.965014 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6567
I0413 18:03:56.965064 26605 solver.cpp:404]     Test net output #1: loss = 1.18779 (* 1 = 1.18779 loss)
I0413 18:03:57.154630 26605 solver.cpp:228] Iteration 1520, loss = 0.475601
I0413 18:03:57.154687 26605 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:03:57.154703 26605 solver.cpp:244]     Train net output #1: loss = 0.475601 (* 1 = 0.475601 loss)
I0413 18:03:57.154716 26605 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 18:04:02.307454 26605 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 18:04:05.044387 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7512
I0413 18:04:05.044442 26605 solver.cpp:404]     Test net output #1: loss = 0.727547 (* 1 = 0.727547 loss)
I0413 18:04:05.243033 26605 solver.cpp:228] Iteration 1540, loss = 0.434322
I0413 18:04:05.243090 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:04:05.243110 26605 solver.cpp:244]     Train net output #1: loss = 0.434322 (* 1 = 0.434322 loss)
I0413 18:04:05.243127 26605 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 18:04:10.607609 26605 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 18:04:13.148119 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7266
I0413 18:04:13.148166 26605 solver.cpp:404]     Test net output #1: loss = 0.784652 (* 1 = 0.784652 loss)
I0413 18:04:13.361901 26605 solver.cpp:228] Iteration 1560, loss = 0.482692
I0413 18:04:13.361954 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 18:04:13.361969 26605 solver.cpp:244]     Train net output #1: loss = 0.482692 (* 1 = 0.482692 loss)
I0413 18:04:13.361981 26605 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 18:04:18.948385 26605 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 18:04:21.433436 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7658
I0413 18:04:21.433491 26605 solver.cpp:404]     Test net output #1: loss = 0.68847 (* 1 = 0.68847 loss)
I0413 18:04:21.610149 26605 solver.cpp:228] Iteration 1580, loss = 0.427114
I0413 18:04:21.610201 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:04:21.610218 26605 solver.cpp:244]     Train net output #1: loss = 0.427114 (* 1 = 0.427114 loss)
I0413 18:04:21.610234 26605 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 18:04:27.072840 26605 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 18:04:29.846413 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7405
I0413 18:04:29.846462 26605 solver.cpp:404]     Test net output #1: loss = 0.797055 (* 1 = 0.797055 loss)
I0413 18:04:30.030252 26605 solver.cpp:228] Iteration 1600, loss = 0.400538
I0413 18:04:30.030308 26605 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:04:30.030323 26605 solver.cpp:244]     Train net output #1: loss = 0.400538 (* 1 = 0.400538 loss)
I0413 18:04:30.030334 26605 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 18:04:35.194257 26605 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 18:04:37.966528 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7108
I0413 18:04:37.966590 26605 solver.cpp:404]     Test net output #1: loss = 0.883392 (* 1 = 0.883392 loss)
I0413 18:04:38.141894 26605 solver.cpp:228] Iteration 1620, loss = 0.429441
I0413 18:04:38.141947 26605 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:04:38.141963 26605 solver.cpp:244]     Train net output #1: loss = 0.429441 (* 1 = 0.429441 loss)
I0413 18:04:38.141981 26605 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 18:04:43.473434 26605 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 18:04:46.091274 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6906
I0413 18:04:46.091328 26605 solver.cpp:404]     Test net output #1: loss = 1.03579 (* 1 = 1.03579 loss)
I0413 18:04:46.283084 26605 solver.cpp:228] Iteration 1640, loss = 0.478819
I0413 18:04:46.283165 26605 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:04:46.283188 26605 solver.cpp:244]     Train net output #1: loss = 0.478819 (* 1 = 0.478819 loss)
I0413 18:04:46.283203 26605 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 18:04:51.875460 26605 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 18:04:54.275789 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7639
I0413 18:04:54.275846 26605 solver.cpp:404]     Test net output #1: loss = 0.724558 (* 1 = 0.724558 loss)
I0413 18:04:54.457612 26605 solver.cpp:228] Iteration 1660, loss = 0.356382
I0413 18:04:54.457659 26605 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:04:54.457674 26605 solver.cpp:244]     Train net output #1: loss = 0.356382 (* 1 = 0.356382 loss)
I0413 18:04:54.457691 26605 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 18:04:59.981365 26605 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 18:05:02.618937 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6999
I0413 18:05:02.618990 26605 solver.cpp:404]     Test net output #1: loss = 0.981993 (* 1 = 0.981993 loss)
I0413 18:05:02.800220 26605 solver.cpp:228] Iteration 1680, loss = 0.410573
I0413 18:05:02.800263 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:05:02.800276 26605 solver.cpp:244]     Train net output #1: loss = 0.410573 (* 1 = 0.410573 loss)
I0413 18:05:02.800285 26605 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 18:05:07.977337 26605 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 18:05:10.729558 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7083
I0413 18:05:10.729614 26605 solver.cpp:404]     Test net output #1: loss = 0.959882 (* 1 = 0.959882 loss)
I0413 18:05:10.934672 26605 solver.cpp:228] Iteration 1700, loss = 0.386169
I0413 18:05:10.934716 26605 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:05:10.934733 26605 solver.cpp:244]     Train net output #1: loss = 0.386169 (* 1 = 0.386169 loss)
I0413 18:05:10.934751 26605 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 18:05:16.106163 26605 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 18:05:18.783566 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5537
I0413 18:05:18.783610 26605 solver.cpp:404]     Test net output #1: loss = 1.7423 (* 1 = 1.7423 loss)
I0413 18:05:18.971632 26605 solver.cpp:228] Iteration 1720, loss = 0.499979
I0413 18:05:18.971669 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 18:05:18.971680 26605 solver.cpp:244]     Train net output #1: loss = 0.499979 (* 1 = 0.499979 loss)
I0413 18:05:18.971689 26605 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 18:05:24.457533 26605 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 18:05:26.877172 26605 solver.cpp:404]     Test net output #0: accuracy = 0.669
I0413 18:05:26.877220 26605 solver.cpp:404]     Test net output #1: loss = 1.06648 (* 1 = 1.06648 loss)
I0413 18:05:27.057715 26605 solver.cpp:228] Iteration 1740, loss = 0.482359
I0413 18:05:27.057752 26605 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 18:05:27.057763 26605 solver.cpp:244]     Train net output #1: loss = 0.482359 (* 1 = 0.482359 loss)
I0413 18:05:27.057775 26605 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 18:05:32.638015 26605 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 18:05:35.228698 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6214
I0413 18:05:35.228751 26605 solver.cpp:404]     Test net output #1: loss = 1.45909 (* 1 = 1.45909 loss)
I0413 18:05:35.412346 26605 solver.cpp:228] Iteration 1760, loss = 0.599106
I0413 18:05:35.412381 26605 solver.cpp:244]     Train net output #0: accuracy = 0.757812
I0413 18:05:35.412394 26605 solver.cpp:244]     Train net output #1: loss = 0.599106 (* 1 = 0.599106 loss)
I0413 18:05:35.412401 26605 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 18:05:40.694161 26605 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 18:05:43.454412 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7178
I0413 18:05:43.454454 26605 solver.cpp:404]     Test net output #1: loss = 0.903032 (* 1 = 0.903032 loss)
I0413 18:05:43.641695 26605 solver.cpp:228] Iteration 1780, loss = 0.410319
I0413 18:05:43.641741 26605 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:05:43.641754 26605 solver.cpp:244]     Train net output #1: loss = 0.410319 (* 1 = 0.410319 loss)
I0413 18:05:43.641767 26605 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 18:05:48.748481 26605 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 18:05:51.486228 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6986
I0413 18:05:51.486266 26605 solver.cpp:404]     Test net output #1: loss = 0.969066 (* 1 = 0.969066 loss)
I0413 18:05:51.704531 26605 solver.cpp:228] Iteration 1800, loss = 0.427055
I0413 18:05:51.704573 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:05:51.704586 26605 solver.cpp:244]     Train net output #1: loss = 0.427055 (* 1 = 0.427055 loss)
I0413 18:05:51.704596 26605 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 18:05:57.098296 26605 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 18:05:59.566692 26605 solver.cpp:404]     Test net output #0: accuracy = 0.5419
I0413 18:05:59.566748 26605 solver.cpp:404]     Test net output #1: loss = 1.61391 (* 1 = 1.61391 loss)
I0413 18:05:59.776561 26605 solver.cpp:228] Iteration 1820, loss = 0.486754
I0413 18:05:59.776597 26605 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:05:59.776609 26605 solver.cpp:244]     Train net output #1: loss = 0.486754 (* 1 = 0.486754 loss)
I0413 18:05:59.776618 26605 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 18:06:05.364193 26605 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 18:06:07.910984 26605 solver.cpp:404]     Test net output #0: accuracy = 0.66
I0413 18:06:07.911041 26605 solver.cpp:404]     Test net output #1: loss = 1.07784 (* 1 = 1.07784 loss)
I0413 18:06:08.090788 26605 solver.cpp:228] Iteration 1840, loss = 0.404244
I0413 18:06:08.090837 26605 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:06:08.090850 26605 solver.cpp:244]     Train net output #1: loss = 0.404244 (* 1 = 0.404244 loss)
I0413 18:06:08.090860 26605 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 18:06:13.444542 26605 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 18:06:16.195884 26605 solver.cpp:404]     Test net output #0: accuracy = 0.675
I0413 18:06:16.195924 26605 solver.cpp:404]     Test net output #1: loss = 1.04313 (* 1 = 1.04313 loss)
I0413 18:06:16.407353 26605 solver.cpp:228] Iteration 1860, loss = 0.363815
I0413 18:06:16.407400 26605 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:06:16.407414 26605 solver.cpp:244]     Train net output #1: loss = 0.363815 (* 1 = 0.363815 loss)
I0413 18:06:16.407433 26605 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 18:06:21.530442 26605 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 18:06:24.258477 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7336
I0413 18:06:24.258515 26605 solver.cpp:404]     Test net output #1: loss = 0.855792 (* 1 = 0.855792 loss)
I0413 18:06:24.471369 26605 solver.cpp:228] Iteration 1880, loss = 0.4781
I0413 18:06:24.471411 26605 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:06:24.471423 26605 solver.cpp:244]     Train net output #1: loss = 0.4781 (* 1 = 0.4781 loss)
I0413 18:06:24.471432 26605 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 18:06:29.799638 26605 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 18:06:32.355823 26605 solver.cpp:404]     Test net output #0: accuracy = 0.6712
I0413 18:06:32.355875 26605 solver.cpp:404]     Test net output #1: loss = 1.18458 (* 1 = 1.18458 loss)
I0413 18:06:32.545313 26605 solver.cpp:228] Iteration 1900, loss = 0.468556
I0413 18:06:32.545375 26605 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:06:32.545389 26605 solver.cpp:244]     Train net output #1: loss = 0.468556 (* 1 = 0.468556 loss)
I0413 18:06:32.545402 26605 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 18:06:38.153165 26605 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 18:06:40.627362 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7078
I0413 18:06:40.627398 26605 solver.cpp:404]     Test net output #1: loss = 0.897728 (* 1 = 0.897728 loss)
I0413 18:06:40.810786 26605 solver.cpp:228] Iteration 1920, loss = 0.526377
I0413 18:06:40.810842 26605 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 18:06:40.810854 26605 solver.cpp:244]     Train net output #1: loss = 0.526377 (* 1 = 0.526377 loss)
I0413 18:06:40.810864 26605 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 18:06:46.284596 26605 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 18:06:49.021430 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7014
I0413 18:06:49.021481 26605 solver.cpp:404]     Test net output #1: loss = 0.977273 (* 1 = 0.977273 loss)
I0413 18:06:49.240386 26605 solver.cpp:228] Iteration 1940, loss = 0.410664
I0413 18:06:49.240433 26605 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:06:49.240444 26605 solver.cpp:244]     Train net output #1: loss = 0.410664 (* 1 = 0.410664 loss)
I0413 18:06:49.240453 26605 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 18:06:54.303086 26605 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 18:06:57.064116 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7014
I0413 18:06:57.064153 26605 solver.cpp:404]     Test net output #1: loss = 0.981336 (* 1 = 0.981336 loss)
I0413 18:06:57.239742 26605 solver.cpp:228] Iteration 1960, loss = 0.387955
I0413 18:06:57.239804 26605 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:06:57.239816 26605 solver.cpp:244]     Train net output #1: loss = 0.387955 (* 1 = 0.387955 loss)
I0413 18:06:57.239827 26605 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 18:07:02.499467 26605 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 18:07:05.112233 26605 solver.cpp:404]     Test net output #0: accuracy = 0.7399
I0413 18:07:05.112277 26605 solver.cpp:404]     Test net output #1: loss = 0.764755 (* 1 = 0.764755 loss)
I0413 18:07:05.307322 26605 solver.cpp:228] Iteration 1980, loss = 0.472541
I0413 18:07:05.307364 26605 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:07:05.307375 26605 solver.cpp:244]     Train net output #1: loss = 0.472541 (* 1 = 0.472541 loss)
I0413 18:07:05.307384 26605 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 18:07:10.882540 26605 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar5/ResNet-cifar5_iter_2000.caffemodel
I0413 18:07:10.889600 26605 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar5/ResNet-cifar5_iter_2000.solverstate
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 18:07:13.198457  1537 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar6/ResNet-cifar6"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar6.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 18:07:13.198498  1537 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar6.prototxt
I0413 18:07:13.200392  1537 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 18:07:13.200876  1537 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_sub"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_sub"
  type: "BatchNorm"
  bottom: "conv3_sub"
  top: "conv3_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_sub"
  type: "Scale"
  bottom: "conv3_sub"
  top: "conv3_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv4_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1a"
  type: "BatchNorm"
  bottom: "conv4_1a"
  top: "conv4_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1a"
  type: "Scale"
  bottom: "conv4_1a"
  top: "conv4_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a_relu"
  type: "ReLU"
  bottom: "conv4_1a"
  top: "conv4_1a"
}
layer {
  name: "conv4_1b"
  type: "Convolution"
  bottom: "conv4_1a"
  top: "conv4_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1b"
  type: "BatchNorm"
  bottom: "conv4_1b"
  top: "conv4_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1b"
  type: "Scale"
  bottom: "conv4_1b"
  top: "conv4_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv3_sub"
  bottom: "conv4_1b"
  top: "conv4_1"
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv4_1"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 18:07:13.201275  1537 layer_factory.hpp:77] Creating layer cifar
I0413 18:07:13.201895  1537 net.cpp:91] Creating Layer cifar
I0413 18:07:13.201912  1537 net.cpp:399] cifar -> data
I0413 18:07:13.201927  1537 net.cpp:399] cifar -> label
I0413 18:07:13.201941  1537 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 18:07:13.222039  1597 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 18:07:13.249747  1537 data_layer.cpp:41] output data size: 256,3,32,32
I0413 18:07:13.260462  1537 net.cpp:141] Setting up cifar
I0413 18:07:13.260489  1537 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 18:07:13.260499  1537 net.cpp:148] Top shape: 256 (256)
I0413 18:07:13.260505  1537 net.cpp:156] Memory required for data: 3146752
I0413 18:07:13.260514  1537 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 18:07:13.260535  1537 net.cpp:91] Creating Layer label_cifar_1_split
I0413 18:07:13.260551  1537 net.cpp:425] label_cifar_1_split <- label
I0413 18:07:13.260563  1537 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 18:07:13.260576  1537 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 18:07:13.260648  1537 net.cpp:141] Setting up label_cifar_1_split
I0413 18:07:13.260659  1537 net.cpp:148] Top shape: 256 (256)
I0413 18:07:13.260665  1537 net.cpp:148] Top shape: 256 (256)
I0413 18:07:13.260670  1537 net.cpp:156] Memory required for data: 3148800
I0413 18:07:13.260675  1537 layer_factory.hpp:77] Creating layer conv1
I0413 18:07:13.260692  1537 net.cpp:91] Creating Layer conv1
I0413 18:07:13.260699  1537 net.cpp:425] conv1 <- data
I0413 18:07:13.260707  1537 net.cpp:399] conv1 -> conv1
I0413 18:07:13.552949  1537 net.cpp:141] Setting up conv1
I0413 18:07:13.552999  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.553006  1537 net.cpp:156] Memory required for data: 19926016
I0413 18:07:13.553026  1537 layer_factory.hpp:77] Creating layer bn_conv1
I0413 18:07:13.553045  1537 net.cpp:91] Creating Layer bn_conv1
I0413 18:07:13.553051  1537 net.cpp:425] bn_conv1 <- conv1
I0413 18:07:13.553061  1537 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 18:07:13.553303  1537 net.cpp:141] Setting up bn_conv1
I0413 18:07:13.553315  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.553320  1537 net.cpp:156] Memory required for data: 36703232
I0413 18:07:13.553336  1537 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:07:13.553349  1537 net.cpp:91] Creating Layer scale_conv1
I0413 18:07:13.553354  1537 net.cpp:425] scale_conv1 <- conv1
I0413 18:07:13.553361  1537 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 18:07:13.553406  1537 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:07:13.553549  1537 net.cpp:141] Setting up scale_conv1
I0413 18:07:13.553560  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.553565  1537 net.cpp:156] Memory required for data: 53480448
I0413 18:07:13.553575  1537 layer_factory.hpp:77] Creating layer conv1_relu
I0413 18:07:13.553586  1537 net.cpp:91] Creating Layer conv1_relu
I0413 18:07:13.553591  1537 net.cpp:425] conv1_relu <- conv1
I0413 18:07:13.553597  1537 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 18:07:13.553952  1537 net.cpp:141] Setting up conv1_relu
I0413 18:07:13.553971  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.553977  1537 net.cpp:156] Memory required for data: 70257664
I0413 18:07:13.553982  1537 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 18:07:13.553992  1537 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 18:07:13.553997  1537 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 18:07:13.554008  1537 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 18:07:13.554018  1537 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 18:07:13.554066  1537 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 18:07:13.554077  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.554085  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.554090  1537 net.cpp:156] Memory required for data: 103812096
I0413 18:07:13.554095  1537 layer_factory.hpp:77] Creating layer conv2_1a
I0413 18:07:13.554111  1537 net.cpp:91] Creating Layer conv2_1a
I0413 18:07:13.554116  1537 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 18:07:13.554126  1537 net.cpp:399] conv2_1a -> conv2_1a
I0413 18:07:13.557507  1537 net.cpp:141] Setting up conv2_1a
I0413 18:07:13.557526  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.557533  1537 net.cpp:156] Memory required for data: 120589312
I0413 18:07:13.557546  1537 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 18:07:13.557560  1537 net.cpp:91] Creating Layer bn_conv2_1a
I0413 18:07:13.557566  1537 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 18:07:13.557576  1537 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 18:07:13.557796  1537 net.cpp:141] Setting up bn_conv2_1a
I0413 18:07:13.557816  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.557821  1537 net.cpp:156] Memory required for data: 137366528
I0413 18:07:13.557832  1537 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:07:13.557842  1537 net.cpp:91] Creating Layer scale_conv2_1a
I0413 18:07:13.557848  1537 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 18:07:13.557855  1537 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 18:07:13.557898  1537 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:07:13.558022  1537 net.cpp:141] Setting up scale_conv2_1a
I0413 18:07:13.558032  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.558037  1537 net.cpp:156] Memory required for data: 154143744
I0413 18:07:13.558045  1537 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 18:07:13.558053  1537 net.cpp:91] Creating Layer conv2_1a_relu
I0413 18:07:13.558058  1537 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 18:07:13.558066  1537 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 18:07:13.558531  1537 net.cpp:141] Setting up conv2_1a_relu
I0413 18:07:13.558547  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.558553  1537 net.cpp:156] Memory required for data: 170920960
I0413 18:07:13.558559  1537 layer_factory.hpp:77] Creating layer conv2_1b
I0413 18:07:13.558576  1537 net.cpp:91] Creating Layer conv2_1b
I0413 18:07:13.558583  1537 net.cpp:425] conv2_1b <- conv2_1a
I0413 18:07:13.558591  1537 net.cpp:399] conv2_1b -> conv2_1b
I0413 18:07:13.562052  1537 net.cpp:141] Setting up conv2_1b
I0413 18:07:13.562072  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.562077  1537 net.cpp:156] Memory required for data: 187698176
I0413 18:07:13.562086  1537 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 18:07:13.562098  1537 net.cpp:91] Creating Layer bn_conv2_1b
I0413 18:07:13.562103  1537 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 18:07:13.562111  1537 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 18:07:13.562322  1537 net.cpp:141] Setting up bn_conv2_1b
I0413 18:07:13.562331  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.562336  1537 net.cpp:156] Memory required for data: 204475392
I0413 18:07:13.562350  1537 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:07:13.562360  1537 net.cpp:91] Creating Layer scale_conv2_1b
I0413 18:07:13.562364  1537 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 18:07:13.562371  1537 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 18:07:13.562417  1537 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:07:13.562541  1537 net.cpp:141] Setting up scale_conv2_1b
I0413 18:07:13.562551  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.562556  1537 net.cpp:156] Memory required for data: 221252608
I0413 18:07:13.562563  1537 layer_factory.hpp:77] Creating layer conv2_1
I0413 18:07:13.562572  1537 net.cpp:91] Creating Layer conv2_1
I0413 18:07:13.562577  1537 net.cpp:425] conv2_1 <- conv2_1b
I0413 18:07:13.562582  1537 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 18:07:13.562592  1537 net.cpp:399] conv2_1 -> conv2_1
I0413 18:07:13.562619  1537 net.cpp:141] Setting up conv2_1
I0413 18:07:13.562628  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.562633  1537 net.cpp:156] Memory required for data: 238029824
I0413 18:07:13.562638  1537 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 18:07:13.562646  1537 net.cpp:91] Creating Layer conv2_1_relu
I0413 18:07:13.562652  1537 net.cpp:425] conv2_1_relu <- conv2_1
I0413 18:07:13.562659  1537 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 18:07:13.563073  1537 net.cpp:141] Setting up conv2_1_relu
I0413 18:07:13.563086  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.563091  1537 net.cpp:156] Memory required for data: 254807040
I0413 18:07:13.563096  1537 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 18:07:13.563110  1537 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 18:07:13.563123  1537 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 18:07:13.563132  1537 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 18:07:13.563140  1537 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 18:07:13.563189  1537 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 18:07:13.563197  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.563204  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.563208  1537 net.cpp:156] Memory required for data: 288361472
I0413 18:07:13.563213  1537 layer_factory.hpp:77] Creating layer conv2_2a
I0413 18:07:13.563227  1537 net.cpp:91] Creating Layer conv2_2a
I0413 18:07:13.563232  1537 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 18:07:13.563242  1537 net.cpp:399] conv2_2a -> conv2_2a
I0413 18:07:13.566606  1537 net.cpp:141] Setting up conv2_2a
I0413 18:07:13.566624  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.566630  1537 net.cpp:156] Memory required for data: 305138688
I0413 18:07:13.566639  1537 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 18:07:13.566651  1537 net.cpp:91] Creating Layer bn_conv2_2a
I0413 18:07:13.566658  1537 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 18:07:13.566665  1537 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 18:07:13.566875  1537 net.cpp:141] Setting up bn_conv2_2a
I0413 18:07:13.566885  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.566890  1537 net.cpp:156] Memory required for data: 321915904
I0413 18:07:13.566900  1537 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:07:13.566908  1537 net.cpp:91] Creating Layer scale_conv2_2a
I0413 18:07:13.566915  1537 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 18:07:13.566920  1537 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 18:07:13.566962  1537 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:07:13.567086  1537 net.cpp:141] Setting up scale_conv2_2a
I0413 18:07:13.567095  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.567101  1537 net.cpp:156] Memory required for data: 338693120
I0413 18:07:13.567108  1537 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 18:07:13.567118  1537 net.cpp:91] Creating Layer conv2_2a_relu
I0413 18:07:13.567123  1537 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 18:07:13.567129  1537 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 18:07:13.567638  1537 net.cpp:141] Setting up conv2_2a_relu
I0413 18:07:13.567654  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.567661  1537 net.cpp:156] Memory required for data: 355470336
I0413 18:07:13.567665  1537 layer_factory.hpp:77] Creating layer conv2_2b
I0413 18:07:13.567682  1537 net.cpp:91] Creating Layer conv2_2b
I0413 18:07:13.567688  1537 net.cpp:425] conv2_2b <- conv2_2a
I0413 18:07:13.567697  1537 net.cpp:399] conv2_2b -> conv2_2b
I0413 18:07:13.571202  1537 net.cpp:141] Setting up conv2_2b
I0413 18:07:13.571219  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.571225  1537 net.cpp:156] Memory required for data: 372247552
I0413 18:07:13.571234  1537 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 18:07:13.571246  1537 net.cpp:91] Creating Layer bn_conv2_2b
I0413 18:07:13.571251  1537 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 18:07:13.571261  1537 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 18:07:13.571472  1537 net.cpp:141] Setting up bn_conv2_2b
I0413 18:07:13.571482  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.571487  1537 net.cpp:156] Memory required for data: 389024768
I0413 18:07:13.571504  1537 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:07:13.571513  1537 net.cpp:91] Creating Layer scale_conv2_2b
I0413 18:07:13.571518  1537 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 18:07:13.571526  1537 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 18:07:13.571568  1537 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:07:13.571691  1537 net.cpp:141] Setting up scale_conv2_2b
I0413 18:07:13.571704  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.571709  1537 net.cpp:156] Memory required for data: 405801984
I0413 18:07:13.571718  1537 layer_factory.hpp:77] Creating layer conv2_2
I0413 18:07:13.571727  1537 net.cpp:91] Creating Layer conv2_2
I0413 18:07:13.571732  1537 net.cpp:425] conv2_2 <- conv2_2b
I0413 18:07:13.571738  1537 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 18:07:13.571748  1537 net.cpp:399] conv2_2 -> conv2_2
I0413 18:07:13.571774  1537 net.cpp:141] Setting up conv2_2
I0413 18:07:13.571784  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.571789  1537 net.cpp:156] Memory required for data: 422579200
I0413 18:07:13.571792  1537 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 18:07:13.571802  1537 net.cpp:91] Creating Layer conv2_2_relu
I0413 18:07:13.571807  1537 net.cpp:425] conv2_2_relu <- conv2_2
I0413 18:07:13.571815  1537 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 18:07:13.572228  1537 net.cpp:141] Setting up conv2_2_relu
I0413 18:07:13.572245  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.572250  1537 net.cpp:156] Memory required for data: 439356416
I0413 18:07:13.572257  1537 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 18:07:13.572264  1537 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 18:07:13.572269  1537 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 18:07:13.572279  1537 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 18:07:13.572289  1537 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 18:07:13.572341  1537 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 18:07:13.572350  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.572356  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.572361  1537 net.cpp:156] Memory required for data: 472910848
I0413 18:07:13.572366  1537 layer_factory.hpp:77] Creating layer conv2_3a
I0413 18:07:13.572381  1537 net.cpp:91] Creating Layer conv2_3a
I0413 18:07:13.572386  1537 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 18:07:13.572399  1537 net.cpp:399] conv2_3a -> conv2_3a
I0413 18:07:13.576705  1537 net.cpp:141] Setting up conv2_3a
I0413 18:07:13.576724  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.576728  1537 net.cpp:156] Memory required for data: 489688064
I0413 18:07:13.576738  1537 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 18:07:13.576747  1537 net.cpp:91] Creating Layer bn_conv2_3a
I0413 18:07:13.576752  1537 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 18:07:13.576762  1537 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 18:07:13.576972  1537 net.cpp:141] Setting up bn_conv2_3a
I0413 18:07:13.576982  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.576987  1537 net.cpp:156] Memory required for data: 506465280
I0413 18:07:13.576997  1537 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:07:13.577004  1537 net.cpp:91] Creating Layer scale_conv2_3a
I0413 18:07:13.577009  1537 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 18:07:13.577018  1537 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 18:07:13.577055  1537 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:07:13.577181  1537 net.cpp:141] Setting up scale_conv2_3a
I0413 18:07:13.577193  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.577196  1537 net.cpp:156] Memory required for data: 523242496
I0413 18:07:13.577205  1537 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 18:07:13.577214  1537 net.cpp:91] Creating Layer conv2_3a_relu
I0413 18:07:13.577219  1537 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 18:07:13.577225  1537 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 18:07:13.577728  1537 net.cpp:141] Setting up conv2_3a_relu
I0413 18:07:13.577739  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.577744  1537 net.cpp:156] Memory required for data: 540019712
I0413 18:07:13.577754  1537 layer_factory.hpp:77] Creating layer conv2_3b
I0413 18:07:13.577769  1537 net.cpp:91] Creating Layer conv2_3b
I0413 18:07:13.577774  1537 net.cpp:425] conv2_3b <- conv2_3a
I0413 18:07:13.577783  1537 net.cpp:399] conv2_3b -> conv2_3b
I0413 18:07:13.581231  1537 net.cpp:141] Setting up conv2_3b
I0413 18:07:13.581249  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.581254  1537 net.cpp:156] Memory required for data: 556796928
I0413 18:07:13.581264  1537 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 18:07:13.581279  1537 net.cpp:91] Creating Layer bn_conv2_3b
I0413 18:07:13.581285  1537 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 18:07:13.581295  1537 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 18:07:13.581511  1537 net.cpp:141] Setting up bn_conv2_3b
I0413 18:07:13.581519  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.581524  1537 net.cpp:156] Memory required for data: 573574144
I0413 18:07:13.581534  1537 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:07:13.581544  1537 net.cpp:91] Creating Layer scale_conv2_3b
I0413 18:07:13.581550  1537 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 18:07:13.581557  1537 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 18:07:13.581599  1537 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:07:13.581727  1537 net.cpp:141] Setting up scale_conv2_3b
I0413 18:07:13.581735  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.581740  1537 net.cpp:156] Memory required for data: 590351360
I0413 18:07:13.581748  1537 layer_factory.hpp:77] Creating layer conv2_3
I0413 18:07:13.581755  1537 net.cpp:91] Creating Layer conv2_3
I0413 18:07:13.581760  1537 net.cpp:425] conv2_3 <- conv2_3b
I0413 18:07:13.581766  1537 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 18:07:13.581774  1537 net.cpp:399] conv2_3 -> conv2_3
I0413 18:07:13.581800  1537 net.cpp:141] Setting up conv2_3
I0413 18:07:13.581810  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.581815  1537 net.cpp:156] Memory required for data: 607128576
I0413 18:07:13.581820  1537 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 18:07:13.581827  1537 net.cpp:91] Creating Layer conv2_3_relu
I0413 18:07:13.581832  1537 net.cpp:425] conv2_3_relu <- conv2_3
I0413 18:07:13.581838  1537 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 18:07:13.582262  1537 net.cpp:141] Setting up conv2_3_relu
I0413 18:07:13.582278  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.582283  1537 net.cpp:156] Memory required for data: 623905792
I0413 18:07:13.582288  1537 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 18:07:13.582295  1537 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 18:07:13.582300  1537 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 18:07:13.582310  1537 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 18:07:13.582319  1537 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 18:07:13.582366  1537 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 18:07:13.582375  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.582396  1537 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:07:13.582401  1537 net.cpp:156] Memory required for data: 657460224
I0413 18:07:13.582404  1537 layer_factory.hpp:77] Creating layer conv2_sub
I0413 18:07:13.582419  1537 net.cpp:91] Creating Layer conv2_sub
I0413 18:07:13.582425  1537 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 18:07:13.582433  1537 net.cpp:399] conv2_sub -> conv2_sub
I0413 18:07:13.586273  1537 net.cpp:141] Setting up conv2_sub
I0413 18:07:13.586292  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.586295  1537 net.cpp:156] Memory required for data: 665848832
I0413 18:07:13.586303  1537 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 18:07:13.586310  1537 net.cpp:91] Creating Layer bn_conv2_sub
I0413 18:07:13.586318  1537 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 18:07:13.586326  1537 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 18:07:13.586486  1537 net.cpp:141] Setting up bn_conv2_sub
I0413 18:07:13.586493  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.586498  1537 net.cpp:156] Memory required for data: 674237440
I0413 18:07:13.586504  1537 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:07:13.586511  1537 net.cpp:91] Creating Layer scale_conv2_sub
I0413 18:07:13.586515  1537 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 18:07:13.586520  1537 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 18:07:13.586550  1537 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:07:13.586644  1537 net.cpp:141] Setting up scale_conv2_sub
I0413 18:07:13.586652  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.586654  1537 net.cpp:156] Memory required for data: 682626048
I0413 18:07:13.586661  1537 layer_factory.hpp:77] Creating layer conv3_1a
I0413 18:07:13.586673  1537 net.cpp:91] Creating Layer conv3_1a
I0413 18:07:13.586676  1537 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 18:07:13.586686  1537 net.cpp:399] conv3_1a -> conv3_1a
I0413 18:07:13.590234  1537 net.cpp:141] Setting up conv3_1a
I0413 18:07:13.590247  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.590251  1537 net.cpp:156] Memory required for data: 691014656
I0413 18:07:13.590258  1537 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 18:07:13.590267  1537 net.cpp:91] Creating Layer bn_conv3_1a
I0413 18:07:13.590271  1537 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 18:07:13.590277  1537 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 18:07:13.590440  1537 net.cpp:141] Setting up bn_conv3_1a
I0413 18:07:13.590446  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.590450  1537 net.cpp:156] Memory required for data: 699403264
I0413 18:07:13.590456  1537 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:07:13.590464  1537 net.cpp:91] Creating Layer scale_conv3_1a
I0413 18:07:13.590467  1537 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 18:07:13.590473  1537 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 18:07:13.590504  1537 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:07:13.590602  1537 net.cpp:141] Setting up scale_conv3_1a
I0413 18:07:13.590610  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.590612  1537 net.cpp:156] Memory required for data: 707791872
I0413 18:07:13.590618  1537 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 18:07:13.590626  1537 net.cpp:91] Creating Layer conv3_1a_relu
I0413 18:07:13.590631  1537 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 18:07:13.590634  1537 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 18:07:13.591281  1537 net.cpp:141] Setting up conv3_1a_relu
I0413 18:07:13.591294  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.591297  1537 net.cpp:156] Memory required for data: 716180480
I0413 18:07:13.591301  1537 layer_factory.hpp:77] Creating layer conv3_1b
I0413 18:07:13.591315  1537 net.cpp:91] Creating Layer conv3_1b
I0413 18:07:13.591320  1537 net.cpp:425] conv3_1b <- conv3_1a
I0413 18:07:13.591325  1537 net.cpp:399] conv3_1b -> conv3_1b
I0413 18:07:13.594774  1537 net.cpp:141] Setting up conv3_1b
I0413 18:07:13.594789  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.594792  1537 net.cpp:156] Memory required for data: 724569088
I0413 18:07:13.594808  1537 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 18:07:13.594817  1537 net.cpp:91] Creating Layer bn_conv3_1b
I0413 18:07:13.594822  1537 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 18:07:13.594830  1537 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 18:07:13.594995  1537 net.cpp:141] Setting up bn_conv3_1b
I0413 18:07:13.595002  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.595006  1537 net.cpp:156] Memory required for data: 732957696
I0413 18:07:13.595013  1537 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:07:13.595023  1537 net.cpp:91] Creating Layer scale_conv3_1b
I0413 18:07:13.595027  1537 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 18:07:13.595036  1537 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 18:07:13.595068  1537 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:07:13.595166  1537 net.cpp:141] Setting up scale_conv3_1b
I0413 18:07:13.595175  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.595177  1537 net.cpp:156] Memory required for data: 741346304
I0413 18:07:13.595185  1537 layer_factory.hpp:77] Creating layer conv3_1
I0413 18:07:13.595191  1537 net.cpp:91] Creating Layer conv3_1
I0413 18:07:13.595193  1537 net.cpp:425] conv3_1 <- conv3_1b
I0413 18:07:13.595198  1537 net.cpp:425] conv3_1 <- conv2_sub
I0413 18:07:13.595203  1537 net.cpp:399] conv3_1 -> conv3_1
I0413 18:07:13.595222  1537 net.cpp:141] Setting up conv3_1
I0413 18:07:13.595228  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.595232  1537 net.cpp:156] Memory required for data: 749734912
I0413 18:07:13.595237  1537 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 18:07:13.595242  1537 net.cpp:91] Creating Layer conv3_1_relu
I0413 18:07:13.595245  1537 net.cpp:425] conv3_1_relu <- conv3_1
I0413 18:07:13.595252  1537 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 18:07:13.595854  1537 net.cpp:141] Setting up conv3_1_relu
I0413 18:07:13.595863  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.595866  1537 net.cpp:156] Memory required for data: 758123520
I0413 18:07:13.595870  1537 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 18:07:13.595878  1537 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 18:07:13.595882  1537 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 18:07:13.595887  1537 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 18:07:13.595895  1537 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 18:07:13.595932  1537 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 18:07:13.595938  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.595942  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.595947  1537 net.cpp:156] Memory required for data: 774900736
I0413 18:07:13.595949  1537 layer_factory.hpp:77] Creating layer conv3_2a
I0413 18:07:13.595960  1537 net.cpp:91] Creating Layer conv3_2a
I0413 18:07:13.595964  1537 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 18:07:13.595973  1537 net.cpp:399] conv3_2a -> conv3_2a
I0413 18:07:13.600350  1537 net.cpp:141] Setting up conv3_2a
I0413 18:07:13.600364  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.600369  1537 net.cpp:156] Memory required for data: 783289344
I0413 18:07:13.600376  1537 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 18:07:13.600385  1537 net.cpp:91] Creating Layer bn_conv3_2a
I0413 18:07:13.600389  1537 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 18:07:13.600395  1537 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 18:07:13.600559  1537 net.cpp:141] Setting up bn_conv3_2a
I0413 18:07:13.600567  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.600570  1537 net.cpp:156] Memory required for data: 791677952
I0413 18:07:13.600579  1537 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:07:13.600584  1537 net.cpp:91] Creating Layer scale_conv3_2a
I0413 18:07:13.600589  1537 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 18:07:13.600596  1537 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 18:07:13.600626  1537 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:07:13.600721  1537 net.cpp:141] Setting up scale_conv3_2a
I0413 18:07:13.600728  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.600733  1537 net.cpp:156] Memory required for data: 800066560
I0413 18:07:13.600739  1537 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 18:07:13.600745  1537 net.cpp:91] Creating Layer conv3_2a_relu
I0413 18:07:13.600754  1537 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 18:07:13.600759  1537 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 18:07:13.601409  1537 net.cpp:141] Setting up conv3_2a_relu
I0413 18:07:13.601430  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.601434  1537 net.cpp:156] Memory required for data: 808455168
I0413 18:07:13.601438  1537 layer_factory.hpp:77] Creating layer conv3_2b
I0413 18:07:13.601450  1537 net.cpp:91] Creating Layer conv3_2b
I0413 18:07:13.601454  1537 net.cpp:425] conv3_2b <- conv3_2a
I0413 18:07:13.601462  1537 net.cpp:399] conv3_2b -> conv3_2b
I0413 18:07:13.604905  1537 net.cpp:141] Setting up conv3_2b
I0413 18:07:13.604919  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.604923  1537 net.cpp:156] Memory required for data: 816843776
I0413 18:07:13.604930  1537 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 18:07:13.604939  1537 net.cpp:91] Creating Layer bn_conv3_2b
I0413 18:07:13.604943  1537 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 18:07:13.604949  1537 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 18:07:13.605120  1537 net.cpp:141] Setting up bn_conv3_2b
I0413 18:07:13.605141  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.605145  1537 net.cpp:156] Memory required for data: 825232384
I0413 18:07:13.605152  1537 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:07:13.605173  1537 net.cpp:91] Creating Layer scale_conv3_2b
I0413 18:07:13.605177  1537 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 18:07:13.605183  1537 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 18:07:13.605234  1537 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:07:13.605346  1537 net.cpp:141] Setting up scale_conv3_2b
I0413 18:07:13.605355  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.605358  1537 net.cpp:156] Memory required for data: 833620992
I0413 18:07:13.605365  1537 layer_factory.hpp:77] Creating layer conv3_2
I0413 18:07:13.605373  1537 net.cpp:91] Creating Layer conv3_2
I0413 18:07:13.605377  1537 net.cpp:425] conv3_2 <- conv3_2b
I0413 18:07:13.605382  1537 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 18:07:13.605388  1537 net.cpp:399] conv3_2 -> conv3_2
I0413 18:07:13.605409  1537 net.cpp:141] Setting up conv3_2
I0413 18:07:13.605417  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.605420  1537 net.cpp:156] Memory required for data: 842009600
I0413 18:07:13.605424  1537 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 18:07:13.605430  1537 net.cpp:91] Creating Layer conv3_2_relu
I0413 18:07:13.605434  1537 net.cpp:425] conv3_2_relu <- conv3_2
I0413 18:07:13.605445  1537 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 18:07:13.605947  1537 net.cpp:141] Setting up conv3_2_relu
I0413 18:07:13.605960  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.605964  1537 net.cpp:156] Memory required for data: 850398208
I0413 18:07:13.605968  1537 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 18:07:13.605974  1537 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 18:07:13.605978  1537 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 18:07:13.605985  1537 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 18:07:13.605993  1537 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 18:07:13.606034  1537 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 18:07:13.606041  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.606046  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.606050  1537 net.cpp:156] Memory required for data: 867175424
I0413 18:07:13.606053  1537 layer_factory.hpp:77] Creating layer conv3_3a
I0413 18:07:13.606065  1537 net.cpp:91] Creating Layer conv3_3a
I0413 18:07:13.606070  1537 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 18:07:13.606078  1537 net.cpp:399] conv3_3a -> conv3_3a
I0413 18:07:13.609468  1537 net.cpp:141] Setting up conv3_3a
I0413 18:07:13.609486  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.609491  1537 net.cpp:156] Memory required for data: 875564032
I0413 18:07:13.609498  1537 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 18:07:13.609508  1537 net.cpp:91] Creating Layer bn_conv3_3a
I0413 18:07:13.609511  1537 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 18:07:13.609518  1537 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 18:07:13.609685  1537 net.cpp:141] Setting up bn_conv3_3a
I0413 18:07:13.609694  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.609697  1537 net.cpp:156] Memory required for data: 883952640
I0413 18:07:13.609704  1537 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:07:13.609711  1537 net.cpp:91] Creating Layer scale_conv3_3a
I0413 18:07:13.609715  1537 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 18:07:13.609721  1537 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 18:07:13.609752  1537 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:07:13.609853  1537 net.cpp:141] Setting up scale_conv3_3a
I0413 18:07:13.609860  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.609864  1537 net.cpp:156] Memory required for data: 892341248
I0413 18:07:13.609870  1537 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 18:07:13.609876  1537 net.cpp:91] Creating Layer conv3_3a_relu
I0413 18:07:13.609880  1537 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 18:07:13.609885  1537 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 18:07:13.610755  1537 net.cpp:141] Setting up conv3_3a_relu
I0413 18:07:13.610764  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.610769  1537 net.cpp:156] Memory required for data: 900729856
I0413 18:07:13.610772  1537 layer_factory.hpp:77] Creating layer conv3_3b
I0413 18:07:13.610788  1537 net.cpp:91] Creating Layer conv3_3b
I0413 18:07:13.610793  1537 net.cpp:425] conv3_3b <- conv3_3a
I0413 18:07:13.610801  1537 net.cpp:399] conv3_3b -> conv3_3b
I0413 18:07:13.614810  1537 net.cpp:141] Setting up conv3_3b
I0413 18:07:13.614825  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.614828  1537 net.cpp:156] Memory required for data: 909118464
I0413 18:07:13.614835  1537 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 18:07:13.614845  1537 net.cpp:91] Creating Layer bn_conv3_3b
I0413 18:07:13.614850  1537 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 18:07:13.614855  1537 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 18:07:13.615022  1537 net.cpp:141] Setting up bn_conv3_3b
I0413 18:07:13.615030  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.615033  1537 net.cpp:156] Memory required for data: 917507072
I0413 18:07:13.615041  1537 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:07:13.615047  1537 net.cpp:91] Creating Layer scale_conv3_3b
I0413 18:07:13.615051  1537 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 18:07:13.615056  1537 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 18:07:13.615087  1537 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:07:13.615185  1537 net.cpp:141] Setting up scale_conv3_3b
I0413 18:07:13.615192  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.615195  1537 net.cpp:156] Memory required for data: 925895680
I0413 18:07:13.615202  1537 layer_factory.hpp:77] Creating layer conv3_3
I0413 18:07:13.615209  1537 net.cpp:91] Creating Layer conv3_3
I0413 18:07:13.615213  1537 net.cpp:425] conv3_3 <- conv3_3b
I0413 18:07:13.615217  1537 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 18:07:13.615222  1537 net.cpp:399] conv3_3 -> conv3_3
I0413 18:07:13.615241  1537 net.cpp:141] Setting up conv3_3
I0413 18:07:13.615247  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.615249  1537 net.cpp:156] Memory required for data: 934284288
I0413 18:07:13.615253  1537 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 18:07:13.615260  1537 net.cpp:91] Creating Layer conv3_3_relu
I0413 18:07:13.615264  1537 net.cpp:425] conv3_3_relu <- conv3_3
I0413 18:07:13.615275  1537 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 18:07:13.615851  1537 net.cpp:141] Setting up conv3_3_relu
I0413 18:07:13.615861  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.615865  1537 net.cpp:156] Memory required for data: 942672896
I0413 18:07:13.615869  1537 layer_factory.hpp:77] Creating layer conv3_3_conv3_3_relu_0_split
I0413 18:07:13.615875  1537 net.cpp:91] Creating Layer conv3_3_conv3_3_relu_0_split
I0413 18:07:13.615880  1537 net.cpp:425] conv3_3_conv3_3_relu_0_split <- conv3_3
I0413 18:07:13.615886  1537 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_0
I0413 18:07:13.615893  1537 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_1
I0413 18:07:13.615929  1537 net.cpp:141] Setting up conv3_3_conv3_3_relu_0_split
I0413 18:07:13.615937  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.615942  1537 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:07:13.615945  1537 net.cpp:156] Memory required for data: 959450112
I0413 18:07:13.615949  1537 layer_factory.hpp:77] Creating layer conv3_sub
I0413 18:07:13.615960  1537 net.cpp:91] Creating Layer conv3_sub
I0413 18:07:13.615964  1537 net.cpp:425] conv3_sub <- conv3_3_conv3_3_relu_0_split_0
I0413 18:07:13.615970  1537 net.cpp:399] conv3_sub -> conv3_sub
I0413 18:07:13.619354  1537 net.cpp:141] Setting up conv3_sub
I0413 18:07:13.619367  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.619372  1537 net.cpp:156] Memory required for data: 963644416
I0413 18:07:13.619379  1537 layer_factory.hpp:77] Creating layer bn_conv3_sub
I0413 18:07:13.619387  1537 net.cpp:91] Creating Layer bn_conv3_sub
I0413 18:07:13.619391  1537 net.cpp:425] bn_conv3_sub <- conv3_sub
I0413 18:07:13.619398  1537 net.cpp:386] bn_conv3_sub -> conv3_sub (in-place)
I0413 18:07:13.619570  1537 net.cpp:141] Setting up bn_conv3_sub
I0413 18:07:13.619576  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.619580  1537 net.cpp:156] Memory required for data: 967838720
I0413 18:07:13.619587  1537 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:07:13.619595  1537 net.cpp:91] Creating Layer scale_conv3_sub
I0413 18:07:13.619598  1537 net.cpp:425] scale_conv3_sub <- conv3_sub
I0413 18:07:13.619603  1537 net.cpp:386] scale_conv3_sub -> conv3_sub (in-place)
I0413 18:07:13.619637  1537 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:07:13.619742  1537 net.cpp:141] Setting up scale_conv3_sub
I0413 18:07:13.619750  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.619752  1537 net.cpp:156] Memory required for data: 972033024
I0413 18:07:13.619758  1537 layer_factory.hpp:77] Creating layer conv4_1a
I0413 18:07:13.619770  1537 net.cpp:91] Creating Layer conv4_1a
I0413 18:07:13.619773  1537 net.cpp:425] conv4_1a <- conv3_3_conv3_3_relu_0_split_1
I0413 18:07:13.619781  1537 net.cpp:399] conv4_1a -> conv4_1a
I0413 18:07:13.624172  1537 net.cpp:141] Setting up conv4_1a
I0413 18:07:13.624188  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.624192  1537 net.cpp:156] Memory required for data: 976227328
I0413 18:07:13.624199  1537 layer_factory.hpp:77] Creating layer bn_conv4_1a
I0413 18:07:13.624207  1537 net.cpp:91] Creating Layer bn_conv4_1a
I0413 18:07:13.624212  1537 net.cpp:425] bn_conv4_1a <- conv4_1a
I0413 18:07:13.624218  1537 net.cpp:386] bn_conv4_1a -> conv4_1a (in-place)
I0413 18:07:13.624394  1537 net.cpp:141] Setting up bn_conv4_1a
I0413 18:07:13.624402  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.624404  1537 net.cpp:156] Memory required for data: 980421632
I0413 18:07:13.624411  1537 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:07:13.624418  1537 net.cpp:91] Creating Layer scale_conv4_1a
I0413 18:07:13.624421  1537 net.cpp:425] scale_conv4_1a <- conv4_1a
I0413 18:07:13.624430  1537 net.cpp:386] scale_conv4_1a -> conv4_1a (in-place)
I0413 18:07:13.624464  1537 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:07:13.624568  1537 net.cpp:141] Setting up scale_conv4_1a
I0413 18:07:13.624579  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.624583  1537 net.cpp:156] Memory required for data: 984615936
I0413 18:07:13.624589  1537 layer_factory.hpp:77] Creating layer conv4_1a_relu
I0413 18:07:13.624595  1537 net.cpp:91] Creating Layer conv4_1a_relu
I0413 18:07:13.624599  1537 net.cpp:425] conv4_1a_relu <- conv4_1a
I0413 18:07:13.624603  1537 net.cpp:386] conv4_1a_relu -> conv4_1a (in-place)
I0413 18:07:13.625218  1537 net.cpp:141] Setting up conv4_1a_relu
I0413 18:07:13.625232  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.625236  1537 net.cpp:156] Memory required for data: 988810240
I0413 18:07:13.625241  1537 layer_factory.hpp:77] Creating layer conv4_1b
I0413 18:07:13.625254  1537 net.cpp:91] Creating Layer conv4_1b
I0413 18:07:13.625258  1537 net.cpp:425] conv4_1b <- conv4_1a
I0413 18:07:13.625267  1537 net.cpp:399] conv4_1b -> conv4_1b
I0413 18:07:13.628720  1537 net.cpp:141] Setting up conv4_1b
I0413 18:07:13.628733  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.628737  1537 net.cpp:156] Memory required for data: 993004544
I0413 18:07:13.628744  1537 layer_factory.hpp:77] Creating layer bn_conv4_1b
I0413 18:07:13.628753  1537 net.cpp:91] Creating Layer bn_conv4_1b
I0413 18:07:13.628758  1537 net.cpp:425] bn_conv4_1b <- conv4_1b
I0413 18:07:13.628765  1537 net.cpp:386] bn_conv4_1b -> conv4_1b (in-place)
I0413 18:07:13.628938  1537 net.cpp:141] Setting up bn_conv4_1b
I0413 18:07:13.628947  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.628949  1537 net.cpp:156] Memory required for data: 997198848
I0413 18:07:13.628957  1537 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:07:13.628964  1537 net.cpp:91] Creating Layer scale_conv4_1b
I0413 18:07:13.628968  1537 net.cpp:425] scale_conv4_1b <- conv4_1b
I0413 18:07:13.628973  1537 net.cpp:386] scale_conv4_1b -> conv4_1b (in-place)
I0413 18:07:13.629007  1537 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:07:13.629115  1537 net.cpp:141] Setting up scale_conv4_1b
I0413 18:07:13.629135  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.629139  1537 net.cpp:156] Memory required for data: 1001393152
I0413 18:07:13.629147  1537 layer_factory.hpp:77] Creating layer conv4_1
I0413 18:07:13.629165  1537 net.cpp:91] Creating Layer conv4_1
I0413 18:07:13.629170  1537 net.cpp:425] conv4_1 <- conv3_sub
I0413 18:07:13.629175  1537 net.cpp:425] conv4_1 <- conv4_1b
I0413 18:07:13.629182  1537 net.cpp:399] conv4_1 -> conv4_1
I0413 18:07:13.629215  1537 net.cpp:141] Setting up conv4_1
I0413 18:07:13.629223  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.629227  1537 net.cpp:156] Memory required for data: 1005587456
I0413 18:07:13.629231  1537 layer_factory.hpp:77] Creating layer conv4_1_relu
I0413 18:07:13.629237  1537 net.cpp:91] Creating Layer conv4_1_relu
I0413 18:07:13.629241  1537 net.cpp:425] conv4_1_relu <- conv4_1
I0413 18:07:13.629248  1537 net.cpp:386] conv4_1_relu -> conv4_1 (in-place)
I0413 18:07:13.629768  1537 net.cpp:141] Setting up conv4_1_relu
I0413 18:07:13.629781  1537 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:07:13.629786  1537 net.cpp:156] Memory required for data: 1009781760
I0413 18:07:13.629789  1537 layer_factory.hpp:77] Creating layer global_pool
I0413 18:07:13.629798  1537 net.cpp:91] Creating Layer global_pool
I0413 18:07:13.629803  1537 net.cpp:425] global_pool <- conv4_1
I0413 18:07:13.629808  1537 net.cpp:399] global_pool -> global_pool
I0413 18:07:13.630915  1537 net.cpp:141] Setting up global_pool
I0413 18:07:13.630926  1537 net.cpp:148] Top shape: 256 64 1 1 (16384)
I0413 18:07:13.630929  1537 net.cpp:156] Memory required for data: 1009847296
I0413 18:07:13.630934  1537 layer_factory.hpp:77] Creating layer ip
I0413 18:07:13.630940  1537 net.cpp:91] Creating Layer ip
I0413 18:07:13.630944  1537 net.cpp:425] ip <- global_pool
I0413 18:07:13.630951  1537 net.cpp:399] ip -> ip
I0413 18:07:13.631053  1537 net.cpp:141] Setting up ip
I0413 18:07:13.631062  1537 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:07:13.631069  1537 net.cpp:156] Memory required for data: 1009857536
I0413 18:07:13.631077  1537 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 18:07:13.631083  1537 net.cpp:91] Creating Layer ip_ip_0_split
I0413 18:07:13.631086  1537 net.cpp:425] ip_ip_0_split <- ip
I0413 18:07:13.631091  1537 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 18:07:13.631098  1537 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 18:07:13.631129  1537 net.cpp:141] Setting up ip_ip_0_split
I0413 18:07:13.631134  1537 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:07:13.631139  1537 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:07:13.631142  1537 net.cpp:156] Memory required for data: 1009878016
I0413 18:07:13.631146  1537 layer_factory.hpp:77] Creating layer accuracy
I0413 18:07:13.631155  1537 net.cpp:91] Creating Layer accuracy
I0413 18:07:13.631158  1537 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 18:07:13.631163  1537 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 18:07:13.631170  1537 net.cpp:399] accuracy -> accuracy
I0413 18:07:13.631177  1537 net.cpp:141] Setting up accuracy
I0413 18:07:13.631181  1537 net.cpp:148] Top shape: (1)
I0413 18:07:13.631186  1537 net.cpp:156] Memory required for data: 1009878020
I0413 18:07:13.631188  1537 layer_factory.hpp:77] Creating layer loss
I0413 18:07:13.631194  1537 net.cpp:91] Creating Layer loss
I0413 18:07:13.631197  1537 net.cpp:425] loss <- ip_ip_0_split_1
I0413 18:07:13.631202  1537 net.cpp:425] loss <- label_cifar_1_split_1
I0413 18:07:13.631208  1537 net.cpp:399] loss -> loss
I0413 18:07:13.631219  1537 layer_factory.hpp:77] Creating layer loss
I0413 18:07:13.632174  1537 net.cpp:141] Setting up loss
I0413 18:07:13.632186  1537 net.cpp:148] Top shape: (1)
I0413 18:07:13.632190  1537 net.cpp:151]     with loss weight 1
I0413 18:07:13.632201  1537 net.cpp:156] Memory required for data: 1009878024
I0413 18:07:13.632205  1537 net.cpp:217] loss needs backward computation.
I0413 18:07:13.632210  1537 net.cpp:219] accuracy does not need backward computation.
I0413 18:07:13.632215  1537 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 18:07:13.632220  1537 net.cpp:217] ip needs backward computation.
I0413 18:07:13.632223  1537 net.cpp:217] global_pool needs backward computation.
I0413 18:07:13.632227  1537 net.cpp:217] conv4_1_relu needs backward computation.
I0413 18:07:13.632230  1537 net.cpp:217] conv4_1 needs backward computation.
I0413 18:07:13.632235  1537 net.cpp:217] scale_conv4_1b needs backward computation.
I0413 18:07:13.632237  1537 net.cpp:217] bn_conv4_1b needs backward computation.
I0413 18:07:13.632241  1537 net.cpp:217] conv4_1b needs backward computation.
I0413 18:07:13.632244  1537 net.cpp:217] conv4_1a_relu needs backward computation.
I0413 18:07:13.632248  1537 net.cpp:217] scale_conv4_1a needs backward computation.
I0413 18:07:13.632251  1537 net.cpp:217] bn_conv4_1a needs backward computation.
I0413 18:07:13.632254  1537 net.cpp:217] conv4_1a needs backward computation.
I0413 18:07:13.632258  1537 net.cpp:217] scale_conv3_sub needs backward computation.
I0413 18:07:13.632261  1537 net.cpp:217] bn_conv3_sub needs backward computation.
I0413 18:07:13.632266  1537 net.cpp:217] conv3_sub needs backward computation.
I0413 18:07:13.632268  1537 net.cpp:217] conv3_3_conv3_3_relu_0_split needs backward computation.
I0413 18:07:13.632272  1537 net.cpp:217] conv3_3_relu needs backward computation.
I0413 18:07:13.632275  1537 net.cpp:217] conv3_3 needs backward computation.
I0413 18:07:13.632279  1537 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 18:07:13.632283  1537 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 18:07:13.632287  1537 net.cpp:217] conv3_3b needs backward computation.
I0413 18:07:13.632290  1537 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 18:07:13.632293  1537 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 18:07:13.632297  1537 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 18:07:13.632300  1537 net.cpp:217] conv3_3a needs backward computation.
I0413 18:07:13.632309  1537 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 18:07:13.632313  1537 net.cpp:217] conv3_2_relu needs backward computation.
I0413 18:07:13.632318  1537 net.cpp:217] conv3_2 needs backward computation.
I0413 18:07:13.632321  1537 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 18:07:13.632324  1537 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 18:07:13.632328  1537 net.cpp:217] conv3_2b needs backward computation.
I0413 18:07:13.632331  1537 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 18:07:13.632334  1537 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 18:07:13.632339  1537 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 18:07:13.632341  1537 net.cpp:217] conv3_2a needs backward computation.
I0413 18:07:13.632345  1537 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 18:07:13.632349  1537 net.cpp:217] conv3_1_relu needs backward computation.
I0413 18:07:13.632352  1537 net.cpp:217] conv3_1 needs backward computation.
I0413 18:07:13.632356  1537 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 18:07:13.632359  1537 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 18:07:13.632362  1537 net.cpp:217] conv3_1b needs backward computation.
I0413 18:07:13.632366  1537 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 18:07:13.632369  1537 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 18:07:13.632374  1537 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 18:07:13.632376  1537 net.cpp:217] conv3_1a needs backward computation.
I0413 18:07:13.632380  1537 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 18:07:13.632383  1537 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 18:07:13.632386  1537 net.cpp:217] conv2_sub needs backward computation.
I0413 18:07:13.632390  1537 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 18:07:13.632395  1537 net.cpp:217] conv2_3_relu needs backward computation.
I0413 18:07:13.632397  1537 net.cpp:217] conv2_3 needs backward computation.
I0413 18:07:13.632401  1537 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 18:07:13.632405  1537 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 18:07:13.632408  1537 net.cpp:217] conv2_3b needs backward computation.
I0413 18:07:13.632411  1537 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 18:07:13.632414  1537 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 18:07:13.632418  1537 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 18:07:13.632421  1537 net.cpp:217] conv2_3a needs backward computation.
I0413 18:07:13.632426  1537 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 18:07:13.632428  1537 net.cpp:217] conv2_2_relu needs backward computation.
I0413 18:07:13.632432  1537 net.cpp:217] conv2_2 needs backward computation.
I0413 18:07:13.632436  1537 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 18:07:13.632439  1537 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 18:07:13.632442  1537 net.cpp:217] conv2_2b needs backward computation.
I0413 18:07:13.632447  1537 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 18:07:13.632449  1537 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 18:07:13.632452  1537 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 18:07:13.632457  1537 net.cpp:217] conv2_2a needs backward computation.
I0413 18:07:13.632459  1537 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 18:07:13.632464  1537 net.cpp:217] conv2_1_relu needs backward computation.
I0413 18:07:13.632468  1537 net.cpp:217] conv2_1 needs backward computation.
I0413 18:07:13.632472  1537 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 18:07:13.632475  1537 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 18:07:13.632478  1537 net.cpp:217] conv2_1b needs backward computation.
I0413 18:07:13.632483  1537 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 18:07:13.632488  1537 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 18:07:13.632491  1537 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 18:07:13.632494  1537 net.cpp:217] conv2_1a needs backward computation.
I0413 18:07:13.632498  1537 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 18:07:13.632503  1537 net.cpp:217] conv1_relu needs backward computation.
I0413 18:07:13.632505  1537 net.cpp:217] scale_conv1 needs backward computation.
I0413 18:07:13.632509  1537 net.cpp:217] bn_conv1 needs backward computation.
I0413 18:07:13.632513  1537 net.cpp:217] conv1 needs backward computation.
I0413 18:07:13.632516  1537 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 18:07:13.632521  1537 net.cpp:219] cifar does not need backward computation.
I0413 18:07:13.632524  1537 net.cpp:261] This network produces output accuracy
I0413 18:07:13.632529  1537 net.cpp:261] This network produces output loss
I0413 18:07:13.632571  1537 net.cpp:274] Network initialization done.
I0413 18:07:13.634198  1537 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar6.prototxt
I0413 18:07:13.634289  1537 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 18:07:13.634652  1537 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_sub"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_sub"
  type: "BatchNorm"
  bottom: "conv3_sub"
  top: "conv3_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_sub"
  type: "Scale"
  bottom: "conv3_sub"
  top: "conv3_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv4_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1a"
  type: "BatchNorm"
  bottom: "conv4_1a"
  top: "conv4_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1a"
  type: "Scale"
  bottom: "conv4_1a"
  top: "conv4_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a_relu"
  type: "ReLU"
  bottom: "conv4_1a"
  top: "conv4_1a"
}
layer {
  name: "conv4_1b"
  type: "Convolution"
  bottom: "conv4_1a"
  top: "conv4_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1b"
  type: "BatchNorm"
  bottom: "conv4_1b"
  top: "conv4_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1b"
  type: "Scale"
  bottom: "conv4_1b"
  top: "conv4_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv3_sub"
  bottom: "conv4_1b"
  top: "conv4_1"
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv4_1"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 18:07:13.634932  1537 layer_factory.hpp:77] Creating layer cifar
I0413 18:07:13.635397  1537 net.cpp:91] Creating Layer cifar
I0413 18:07:13.635407  1537 net.cpp:399] cifar -> data
I0413 18:07:13.635416  1537 net.cpp:399] cifar -> label
I0413 18:07:13.635423  1537 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 18:07:13.636251  1622 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 18:07:13.636380  1537 data_layer.cpp:41] output data size: 100,3,32,32
I0413 18:07:13.641055  1537 net.cpp:141] Setting up cifar
I0413 18:07:13.641070  1537 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 18:07:13.641077  1537 net.cpp:148] Top shape: 100 (100)
I0413 18:07:13.641080  1537 net.cpp:156] Memory required for data: 1229200
I0413 18:07:13.641084  1537 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 18:07:13.641093  1537 net.cpp:91] Creating Layer label_cifar_1_split
I0413 18:07:13.641098  1537 net.cpp:425] label_cifar_1_split <- label
I0413 18:07:13.641104  1537 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 18:07:13.641134  1537 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 18:07:13.641253  1537 net.cpp:141] Setting up label_cifar_1_split
I0413 18:07:13.641264  1537 net.cpp:148] Top shape: 100 (100)
I0413 18:07:13.641270  1537 net.cpp:148] Top shape: 100 (100)
I0413 18:07:13.641274  1537 net.cpp:156] Memory required for data: 1230000
I0413 18:07:13.641278  1537 layer_factory.hpp:77] Creating layer conv1
I0413 18:07:13.641290  1537 net.cpp:91] Creating Layer conv1
I0413 18:07:13.641295  1537 net.cpp:425] conv1 <- data
I0413 18:07:13.641304  1537 net.cpp:399] conv1 -> conv1
I0413 18:07:13.644287  1537 net.cpp:141] Setting up conv1
I0413 18:07:13.644304  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.644309  1537 net.cpp:156] Memory required for data: 7783600
I0413 18:07:13.644318  1537 layer_factory.hpp:77] Creating layer bn_conv1
I0413 18:07:13.644331  1537 net.cpp:91] Creating Layer bn_conv1
I0413 18:07:13.644336  1537 net.cpp:425] bn_conv1 <- conv1
I0413 18:07:13.644341  1537 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 18:07:13.644541  1537 net.cpp:141] Setting up bn_conv1
I0413 18:07:13.644548  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.644556  1537 net.cpp:156] Memory required for data: 14337200
I0413 18:07:13.644572  1537 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:07:13.644582  1537 net.cpp:91] Creating Layer scale_conv1
I0413 18:07:13.644585  1537 net.cpp:425] scale_conv1 <- conv1
I0413 18:07:13.644590  1537 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 18:07:13.644634  1537 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:07:13.644743  1537 net.cpp:141] Setting up scale_conv1
I0413 18:07:13.644750  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.644757  1537 net.cpp:156] Memory required for data: 20890800
I0413 18:07:13.644763  1537 layer_factory.hpp:77] Creating layer conv1_relu
I0413 18:07:13.644769  1537 net.cpp:91] Creating Layer conv1_relu
I0413 18:07:13.644773  1537 net.cpp:425] conv1_relu <- conv1
I0413 18:07:13.644778  1537 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 18:07:13.644938  1537 net.cpp:141] Setting up conv1_relu
I0413 18:07:13.644956  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.644960  1537 net.cpp:156] Memory required for data: 27444400
I0413 18:07:13.644973  1537 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 18:07:13.644979  1537 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 18:07:13.644982  1537 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 18:07:13.644989  1537 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 18:07:13.644999  1537 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 18:07:13.645041  1537 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 18:07:13.645048  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.645052  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.645056  1537 net.cpp:156] Memory required for data: 40551600
I0413 18:07:13.645069  1537 layer_factory.hpp:77] Creating layer conv2_1a
I0413 18:07:13.645081  1537 net.cpp:91] Creating Layer conv2_1a
I0413 18:07:13.645090  1537 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 18:07:13.645102  1537 net.cpp:399] conv2_1a -> conv2_1a
I0413 18:07:13.646430  1537 net.cpp:141] Setting up conv2_1a
I0413 18:07:13.646445  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.646459  1537 net.cpp:156] Memory required for data: 47105200
I0413 18:07:13.646471  1537 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 18:07:13.646479  1537 net.cpp:91] Creating Layer bn_conv2_1a
I0413 18:07:13.646484  1537 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 18:07:13.646491  1537 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 18:07:13.646694  1537 net.cpp:141] Setting up bn_conv2_1a
I0413 18:07:13.646704  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.646708  1537 net.cpp:156] Memory required for data: 53658800
I0413 18:07:13.646715  1537 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:07:13.646725  1537 net.cpp:91] Creating Layer scale_conv2_1a
I0413 18:07:13.646730  1537 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 18:07:13.646736  1537 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 18:07:13.646848  1537 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:07:13.646963  1537 net.cpp:141] Setting up scale_conv2_1a
I0413 18:07:13.646971  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.646975  1537 net.cpp:156] Memory required for data: 60212400
I0413 18:07:13.646981  1537 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 18:07:13.646986  1537 net.cpp:91] Creating Layer conv2_1a_relu
I0413 18:07:13.646991  1537 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 18:07:13.646998  1537 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 18:07:13.647266  1537 net.cpp:141] Setting up conv2_1a_relu
I0413 18:07:13.647279  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.647284  1537 net.cpp:156] Memory required for data: 66766000
I0413 18:07:13.647287  1537 layer_factory.hpp:77] Creating layer conv2_1b
I0413 18:07:13.647297  1537 net.cpp:91] Creating Layer conv2_1b
I0413 18:07:13.647302  1537 net.cpp:425] conv2_1b <- conv2_1a
I0413 18:07:13.647317  1537 net.cpp:399] conv2_1b -> conv2_1b
I0413 18:07:13.649737  1537 net.cpp:141] Setting up conv2_1b
I0413 18:07:13.649752  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.649757  1537 net.cpp:156] Memory required for data: 73319600
I0413 18:07:13.649765  1537 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 18:07:13.649772  1537 net.cpp:91] Creating Layer bn_conv2_1b
I0413 18:07:13.649776  1537 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 18:07:13.649785  1537 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 18:07:13.651070  1537 net.cpp:141] Setting up bn_conv2_1b
I0413 18:07:13.651080  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.651084  1537 net.cpp:156] Memory required for data: 79873200
I0413 18:07:13.651096  1537 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:07:13.651103  1537 net.cpp:91] Creating Layer scale_conv2_1b
I0413 18:07:13.651108  1537 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 18:07:13.651113  1537 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 18:07:13.651156  1537 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:07:13.651268  1537 net.cpp:141] Setting up scale_conv2_1b
I0413 18:07:13.651274  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.651279  1537 net.cpp:156] Memory required for data: 86426800
I0413 18:07:13.651288  1537 layer_factory.hpp:77] Creating layer conv2_1
I0413 18:07:13.651293  1537 net.cpp:91] Creating Layer conv2_1
I0413 18:07:13.651298  1537 net.cpp:425] conv2_1 <- conv2_1b
I0413 18:07:13.651301  1537 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 18:07:13.651312  1537 net.cpp:399] conv2_1 -> conv2_1
I0413 18:07:13.651336  1537 net.cpp:141] Setting up conv2_1
I0413 18:07:13.651342  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.651346  1537 net.cpp:156] Memory required for data: 92980400
I0413 18:07:13.651350  1537 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 18:07:13.651366  1537 net.cpp:91] Creating Layer conv2_1_relu
I0413 18:07:13.651371  1537 net.cpp:425] conv2_1_relu <- conv2_1
I0413 18:07:13.651376  1537 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 18:07:13.651543  1537 net.cpp:141] Setting up conv2_1_relu
I0413 18:07:13.651552  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.651556  1537 net.cpp:156] Memory required for data: 99534000
I0413 18:07:13.651561  1537 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 18:07:13.651569  1537 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 18:07:13.651572  1537 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 18:07:13.651578  1537 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 18:07:13.651595  1537 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 18:07:13.651643  1537 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 18:07:13.651649  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.651654  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.651659  1537 net.cpp:156] Memory required for data: 112641200
I0413 18:07:13.651662  1537 layer_factory.hpp:77] Creating layer conv2_2a
I0413 18:07:13.651671  1537 net.cpp:91] Creating Layer conv2_2a
I0413 18:07:13.651676  1537 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 18:07:13.651684  1537 net.cpp:399] conv2_2a -> conv2_2a
I0413 18:07:13.654009  1537 net.cpp:141] Setting up conv2_2a
I0413 18:07:13.654026  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.654031  1537 net.cpp:156] Memory required for data: 119194800
I0413 18:07:13.654037  1537 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 18:07:13.654047  1537 net.cpp:91] Creating Layer bn_conv2_2a
I0413 18:07:13.654050  1537 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 18:07:13.654058  1537 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 18:07:13.654265  1537 net.cpp:141] Setting up bn_conv2_2a
I0413 18:07:13.654274  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.654278  1537 net.cpp:156] Memory required for data: 125748400
I0413 18:07:13.654285  1537 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:07:13.654294  1537 net.cpp:91] Creating Layer scale_conv2_2a
I0413 18:07:13.654299  1537 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 18:07:13.654304  1537 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 18:07:13.654346  1537 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:07:13.654465  1537 net.cpp:141] Setting up scale_conv2_2a
I0413 18:07:13.654474  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.654477  1537 net.cpp:156] Memory required for data: 132302000
I0413 18:07:13.654484  1537 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 18:07:13.654489  1537 net.cpp:91] Creating Layer conv2_2a_relu
I0413 18:07:13.654494  1537 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 18:07:13.654500  1537 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 18:07:13.654953  1537 net.cpp:141] Setting up conv2_2a_relu
I0413 18:07:13.654965  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.654969  1537 net.cpp:156] Memory required for data: 138855600
I0413 18:07:13.654973  1537 layer_factory.hpp:77] Creating layer conv2_2b
I0413 18:07:13.654984  1537 net.cpp:91] Creating Layer conv2_2b
I0413 18:07:13.654989  1537 net.cpp:425] conv2_2b <- conv2_2a
I0413 18:07:13.654995  1537 net.cpp:399] conv2_2b -> conv2_2b
I0413 18:07:13.658102  1537 net.cpp:141] Setting up conv2_2b
I0413 18:07:13.658118  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.658123  1537 net.cpp:156] Memory required for data: 145409200
I0413 18:07:13.658130  1537 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 18:07:13.658138  1537 net.cpp:91] Creating Layer bn_conv2_2b
I0413 18:07:13.658143  1537 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 18:07:13.658150  1537 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 18:07:13.658347  1537 net.cpp:141] Setting up bn_conv2_2b
I0413 18:07:13.658355  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.658359  1537 net.cpp:156] Memory required for data: 151962800
I0413 18:07:13.658373  1537 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:07:13.658380  1537 net.cpp:91] Creating Layer scale_conv2_2b
I0413 18:07:13.658385  1537 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 18:07:13.658390  1537 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 18:07:13.658430  1537 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:07:13.658545  1537 net.cpp:141] Setting up scale_conv2_2b
I0413 18:07:13.658552  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.658556  1537 net.cpp:156] Memory required for data: 158516400
I0413 18:07:13.658563  1537 layer_factory.hpp:77] Creating layer conv2_2
I0413 18:07:13.658576  1537 net.cpp:91] Creating Layer conv2_2
I0413 18:07:13.658579  1537 net.cpp:425] conv2_2 <- conv2_2b
I0413 18:07:13.658584  1537 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 18:07:13.658591  1537 net.cpp:399] conv2_2 -> conv2_2
I0413 18:07:13.658617  1537 net.cpp:141] Setting up conv2_2
I0413 18:07:13.658622  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.658627  1537 net.cpp:156] Memory required for data: 165070000
I0413 18:07:13.658630  1537 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 18:07:13.658635  1537 net.cpp:91] Creating Layer conv2_2_relu
I0413 18:07:13.658639  1537 net.cpp:425] conv2_2_relu <- conv2_2
I0413 18:07:13.658653  1537 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 18:07:13.659148  1537 net.cpp:141] Setting up conv2_2_relu
I0413 18:07:13.659162  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.659165  1537 net.cpp:156] Memory required for data: 171623600
I0413 18:07:13.659169  1537 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 18:07:13.659176  1537 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 18:07:13.659180  1537 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 18:07:13.659188  1537 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 18:07:13.659195  1537 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 18:07:13.659242  1537 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 18:07:13.659250  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.659255  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.659260  1537 net.cpp:156] Memory required for data: 184730800
I0413 18:07:13.659262  1537 layer_factory.hpp:77] Creating layer conv2_3a
I0413 18:07:13.659274  1537 net.cpp:91] Creating Layer conv2_3a
I0413 18:07:13.659279  1537 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 18:07:13.659287  1537 net.cpp:399] conv2_3a -> conv2_3a
I0413 18:07:13.662031  1537 net.cpp:141] Setting up conv2_3a
I0413 18:07:13.662048  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.662053  1537 net.cpp:156] Memory required for data: 191284400
I0413 18:07:13.662060  1537 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 18:07:13.662068  1537 net.cpp:91] Creating Layer bn_conv2_3a
I0413 18:07:13.662072  1537 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 18:07:13.662081  1537 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 18:07:13.662282  1537 net.cpp:141] Setting up bn_conv2_3a
I0413 18:07:13.662291  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.662293  1537 net.cpp:156] Memory required for data: 197838000
I0413 18:07:13.662302  1537 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:07:13.662308  1537 net.cpp:91] Creating Layer scale_conv2_3a
I0413 18:07:13.662312  1537 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 18:07:13.662317  1537 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 18:07:13.662358  1537 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:07:13.662469  1537 net.cpp:141] Setting up scale_conv2_3a
I0413 18:07:13.662477  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.662480  1537 net.cpp:156] Memory required for data: 204391600
I0413 18:07:13.662487  1537 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 18:07:13.662494  1537 net.cpp:91] Creating Layer conv2_3a_relu
I0413 18:07:13.662498  1537 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 18:07:13.662503  1537 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 18:07:13.662678  1537 net.cpp:141] Setting up conv2_3a_relu
I0413 18:07:13.662688  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.662693  1537 net.cpp:156] Memory required for data: 210945200
I0413 18:07:13.662696  1537 layer_factory.hpp:77] Creating layer conv2_3b
I0413 18:07:13.662708  1537 net.cpp:91] Creating Layer conv2_3b
I0413 18:07:13.662713  1537 net.cpp:425] conv2_3b <- conv2_3a
I0413 18:07:13.662729  1537 net.cpp:399] conv2_3b -> conv2_3b
I0413 18:07:13.665565  1537 net.cpp:141] Setting up conv2_3b
I0413 18:07:13.665580  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.665585  1537 net.cpp:156] Memory required for data: 217498800
I0413 18:07:13.665593  1537 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 18:07:13.665604  1537 net.cpp:91] Creating Layer bn_conv2_3b
I0413 18:07:13.665608  1537 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 18:07:13.665617  1537 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 18:07:13.665820  1537 net.cpp:141] Setting up bn_conv2_3b
I0413 18:07:13.665828  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.665832  1537 net.cpp:156] Memory required for data: 224052400
I0413 18:07:13.665840  1537 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:07:13.665848  1537 net.cpp:91] Creating Layer scale_conv2_3b
I0413 18:07:13.665851  1537 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 18:07:13.665858  1537 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 18:07:13.665895  1537 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:07:13.666008  1537 net.cpp:141] Setting up scale_conv2_3b
I0413 18:07:13.666018  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.666021  1537 net.cpp:156] Memory required for data: 230606000
I0413 18:07:13.666028  1537 layer_factory.hpp:77] Creating layer conv2_3
I0413 18:07:13.666034  1537 net.cpp:91] Creating Layer conv2_3
I0413 18:07:13.666038  1537 net.cpp:425] conv2_3 <- conv2_3b
I0413 18:07:13.666043  1537 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 18:07:13.666049  1537 net.cpp:399] conv2_3 -> conv2_3
I0413 18:07:13.666075  1537 net.cpp:141] Setting up conv2_3
I0413 18:07:13.666081  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.666085  1537 net.cpp:156] Memory required for data: 237159600
I0413 18:07:13.666090  1537 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 18:07:13.666096  1537 net.cpp:91] Creating Layer conv2_3_relu
I0413 18:07:13.666100  1537 net.cpp:425] conv2_3_relu <- conv2_3
I0413 18:07:13.666106  1537 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 18:07:13.666599  1537 net.cpp:141] Setting up conv2_3_relu
I0413 18:07:13.666609  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.666612  1537 net.cpp:156] Memory required for data: 243713200
I0413 18:07:13.666617  1537 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 18:07:13.666623  1537 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 18:07:13.666627  1537 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 18:07:13.666635  1537 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 18:07:13.666642  1537 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 18:07:13.666683  1537 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 18:07:13.666692  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.666697  1537 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:07:13.666700  1537 net.cpp:156] Memory required for data: 256820400
I0413 18:07:13.666704  1537 layer_factory.hpp:77] Creating layer conv2_sub
I0413 18:07:13.666715  1537 net.cpp:91] Creating Layer conv2_sub
I0413 18:07:13.666719  1537 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 18:07:13.666726  1537 net.cpp:399] conv2_sub -> conv2_sub
I0413 18:07:13.669687  1537 net.cpp:141] Setting up conv2_sub
I0413 18:07:13.669702  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.669705  1537 net.cpp:156] Memory required for data: 260097200
I0413 18:07:13.669713  1537 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 18:07:13.669723  1537 net.cpp:91] Creating Layer bn_conv2_sub
I0413 18:07:13.669728  1537 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 18:07:13.669734  1537 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 18:07:13.669931  1537 net.cpp:141] Setting up bn_conv2_sub
I0413 18:07:13.669939  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.669947  1537 net.cpp:156] Memory required for data: 263374000
I0413 18:07:13.669956  1537 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:07:13.669963  1537 net.cpp:91] Creating Layer scale_conv2_sub
I0413 18:07:13.669967  1537 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 18:07:13.669972  1537 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 18:07:13.670017  1537 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:07:13.670132  1537 net.cpp:141] Setting up scale_conv2_sub
I0413 18:07:13.670140  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.670143  1537 net.cpp:156] Memory required for data: 266650800
I0413 18:07:13.670150  1537 layer_factory.hpp:77] Creating layer conv3_1a
I0413 18:07:13.670161  1537 net.cpp:91] Creating Layer conv3_1a
I0413 18:07:13.670166  1537 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 18:07:13.670174  1537 net.cpp:399] conv3_1a -> conv3_1a
I0413 18:07:13.671659  1537 net.cpp:141] Setting up conv3_1a
I0413 18:07:13.671674  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.671679  1537 net.cpp:156] Memory required for data: 269927600
I0413 18:07:13.671685  1537 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 18:07:13.671694  1537 net.cpp:91] Creating Layer bn_conv3_1a
I0413 18:07:13.671700  1537 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 18:07:13.671706  1537 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 18:07:13.671902  1537 net.cpp:141] Setting up bn_conv3_1a
I0413 18:07:13.671911  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.671914  1537 net.cpp:156] Memory required for data: 273204400
I0413 18:07:13.671922  1537 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:07:13.671928  1537 net.cpp:91] Creating Layer scale_conv3_1a
I0413 18:07:13.671932  1537 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 18:07:13.671939  1537 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 18:07:13.671980  1537 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:07:13.672098  1537 net.cpp:141] Setting up scale_conv3_1a
I0413 18:07:13.672106  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.672109  1537 net.cpp:156] Memory required for data: 276481200
I0413 18:07:13.672116  1537 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 18:07:13.672122  1537 net.cpp:91] Creating Layer conv3_1a_relu
I0413 18:07:13.672127  1537 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 18:07:13.672132  1537 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 18:07:13.672714  1537 net.cpp:141] Setting up conv3_1a_relu
I0413 18:07:13.672727  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.672731  1537 net.cpp:156] Memory required for data: 279758000
I0413 18:07:13.672736  1537 layer_factory.hpp:77] Creating layer conv3_1b
I0413 18:07:13.672749  1537 net.cpp:91] Creating Layer conv3_1b
I0413 18:07:13.672754  1537 net.cpp:425] conv3_1b <- conv3_1a
I0413 18:07:13.672761  1537 net.cpp:399] conv3_1b -> conv3_1b
I0413 18:07:13.674793  1537 net.cpp:141] Setting up conv3_1b
I0413 18:07:13.674808  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.674813  1537 net.cpp:156] Memory required for data: 283034800
I0413 18:07:13.674831  1537 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 18:07:13.674839  1537 net.cpp:91] Creating Layer bn_conv3_1b
I0413 18:07:13.674844  1537 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 18:07:13.674851  1537 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 18:07:13.675048  1537 net.cpp:141] Setting up bn_conv3_1b
I0413 18:07:13.675056  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.675060  1537 net.cpp:156] Memory required for data: 286311600
I0413 18:07:13.675068  1537 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:07:13.675076  1537 net.cpp:91] Creating Layer scale_conv3_1b
I0413 18:07:13.675079  1537 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 18:07:13.675084  1537 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 18:07:13.675132  1537 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:07:13.675251  1537 net.cpp:141] Setting up scale_conv3_1b
I0413 18:07:13.675258  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.675261  1537 net.cpp:156] Memory required for data: 289588400
I0413 18:07:13.675268  1537 layer_factory.hpp:77] Creating layer conv3_1
I0413 18:07:13.675276  1537 net.cpp:91] Creating Layer conv3_1
I0413 18:07:13.675281  1537 net.cpp:425] conv3_1 <- conv3_1b
I0413 18:07:13.675285  1537 net.cpp:425] conv3_1 <- conv2_sub
I0413 18:07:13.675290  1537 net.cpp:399] conv3_1 -> conv3_1
I0413 18:07:13.675312  1537 net.cpp:141] Setting up conv3_1
I0413 18:07:13.675318  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.675321  1537 net.cpp:156] Memory required for data: 292865200
I0413 18:07:13.675325  1537 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 18:07:13.675333  1537 net.cpp:91] Creating Layer conv3_1_relu
I0413 18:07:13.675338  1537 net.cpp:425] conv3_1_relu <- conv3_1
I0413 18:07:13.675343  1537 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 18:07:13.675859  1537 net.cpp:141] Setting up conv3_1_relu
I0413 18:07:13.675873  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.675878  1537 net.cpp:156] Memory required for data: 296142000
I0413 18:07:13.675881  1537 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 18:07:13.675889  1537 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 18:07:13.675894  1537 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 18:07:13.675901  1537 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 18:07:13.675909  1537 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 18:07:13.675952  1537 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 18:07:13.675959  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.675964  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.675968  1537 net.cpp:156] Memory required for data: 302695600
I0413 18:07:13.675972  1537 layer_factory.hpp:77] Creating layer conv3_2a
I0413 18:07:13.675983  1537 net.cpp:91] Creating Layer conv3_2a
I0413 18:07:13.675988  1537 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 18:07:13.675997  1537 net.cpp:399] conv3_2a -> conv3_2a
I0413 18:07:13.678038  1537 net.cpp:141] Setting up conv3_2a
I0413 18:07:13.678053  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.678058  1537 net.cpp:156] Memory required for data: 305972400
I0413 18:07:13.678066  1537 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 18:07:13.678074  1537 net.cpp:91] Creating Layer bn_conv3_2a
I0413 18:07:13.678079  1537 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 18:07:13.678086  1537 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 18:07:13.678287  1537 net.cpp:141] Setting up bn_conv3_2a
I0413 18:07:13.678297  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.678299  1537 net.cpp:156] Memory required for data: 309249200
I0413 18:07:13.678308  1537 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:07:13.678314  1537 net.cpp:91] Creating Layer scale_conv3_2a
I0413 18:07:13.678318  1537 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 18:07:13.678326  1537 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 18:07:13.678366  1537 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:07:13.678485  1537 net.cpp:141] Setting up scale_conv3_2a
I0413 18:07:13.678493  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.678496  1537 net.cpp:156] Memory required for data: 312526000
I0413 18:07:13.678503  1537 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 18:07:13.678509  1537 net.cpp:91] Creating Layer conv3_2a_relu
I0413 18:07:13.678514  1537 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 18:07:13.678520  1537 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 18:07:13.679020  1537 net.cpp:141] Setting up conv3_2a_relu
I0413 18:07:13.679033  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.679041  1537 net.cpp:156] Memory required for data: 315802800
I0413 18:07:13.679046  1537 layer_factory.hpp:77] Creating layer conv3_2b
I0413 18:07:13.679060  1537 net.cpp:91] Creating Layer conv3_2b
I0413 18:07:13.679065  1537 net.cpp:425] conv3_2b <- conv3_2a
I0413 18:07:13.679072  1537 net.cpp:399] conv3_2b -> conv3_2b
I0413 18:07:13.682050  1537 net.cpp:141] Setting up conv3_2b
I0413 18:07:13.682070  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.682075  1537 net.cpp:156] Memory required for data: 319079600
I0413 18:07:13.682082  1537 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 18:07:13.682092  1537 net.cpp:91] Creating Layer bn_conv3_2b
I0413 18:07:13.682097  1537 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 18:07:13.682103  1537 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 18:07:13.682306  1537 net.cpp:141] Setting up bn_conv3_2b
I0413 18:07:13.682312  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.682317  1537 net.cpp:156] Memory required for data: 322356400
I0413 18:07:13.682324  1537 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:07:13.682333  1537 net.cpp:91] Creating Layer scale_conv3_2b
I0413 18:07:13.682337  1537 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 18:07:13.682343  1537 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 18:07:13.682386  1537 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:07:13.682505  1537 net.cpp:141] Setting up scale_conv3_2b
I0413 18:07:13.682512  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.682517  1537 net.cpp:156] Memory required for data: 325633200
I0413 18:07:13.682523  1537 layer_factory.hpp:77] Creating layer conv3_2
I0413 18:07:13.682530  1537 net.cpp:91] Creating Layer conv3_2
I0413 18:07:13.682534  1537 net.cpp:425] conv3_2 <- conv3_2b
I0413 18:07:13.682540  1537 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 18:07:13.682548  1537 net.cpp:399] conv3_2 -> conv3_2
I0413 18:07:13.682569  1537 net.cpp:141] Setting up conv3_2
I0413 18:07:13.682574  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.682579  1537 net.cpp:156] Memory required for data: 328910000
I0413 18:07:13.682582  1537 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 18:07:13.682590  1537 net.cpp:91] Creating Layer conv3_2_relu
I0413 18:07:13.682593  1537 net.cpp:425] conv3_2_relu <- conv3_2
I0413 18:07:13.682600  1537 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 18:07:13.682932  1537 net.cpp:141] Setting up conv3_2_relu
I0413 18:07:13.682946  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.682950  1537 net.cpp:156] Memory required for data: 332186800
I0413 18:07:13.682955  1537 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 18:07:13.682961  1537 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 18:07:13.682965  1537 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 18:07:13.682973  1537 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 18:07:13.682981  1537 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 18:07:13.683032  1537 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 18:07:13.683038  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.683046  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.683050  1537 net.cpp:156] Memory required for data: 338740400
I0413 18:07:13.683054  1537 layer_factory.hpp:77] Creating layer conv3_3a
I0413 18:07:13.683064  1537 net.cpp:91] Creating Layer conv3_3a
I0413 18:07:13.683069  1537 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 18:07:13.683079  1537 net.cpp:399] conv3_3a -> conv3_3a
I0413 18:07:13.685056  1537 net.cpp:141] Setting up conv3_3a
I0413 18:07:13.685072  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.685077  1537 net.cpp:156] Memory required for data: 342017200
I0413 18:07:13.685086  1537 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 18:07:13.685096  1537 net.cpp:91] Creating Layer bn_conv3_3a
I0413 18:07:13.685107  1537 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 18:07:13.685133  1537 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 18:07:13.685389  1537 net.cpp:141] Setting up bn_conv3_3a
I0413 18:07:13.685397  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.685401  1537 net.cpp:156] Memory required for data: 345294000
I0413 18:07:13.685412  1537 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:07:13.685420  1537 net.cpp:91] Creating Layer scale_conv3_3a
I0413 18:07:13.685425  1537 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 18:07:13.685431  1537 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 18:07:13.685508  1537 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:07:13.685621  1537 net.cpp:141] Setting up scale_conv3_3a
I0413 18:07:13.685628  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.685631  1537 net.cpp:156] Memory required for data: 348570800
I0413 18:07:13.685638  1537 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 18:07:13.685644  1537 net.cpp:91] Creating Layer conv3_3a_relu
I0413 18:07:13.685647  1537 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 18:07:13.685654  1537 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 18:07:13.686075  1537 net.cpp:141] Setting up conv3_3a_relu
I0413 18:07:13.686089  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.686092  1537 net.cpp:156] Memory required for data: 351847600
I0413 18:07:13.686096  1537 layer_factory.hpp:77] Creating layer conv3_3b
I0413 18:07:13.686118  1537 net.cpp:91] Creating Layer conv3_3b
I0413 18:07:13.686123  1537 net.cpp:425] conv3_3b <- conv3_3a
I0413 18:07:13.686131  1537 net.cpp:399] conv3_3b -> conv3_3b
I0413 18:07:13.689604  1537 net.cpp:141] Setting up conv3_3b
I0413 18:07:13.689617  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.689621  1537 net.cpp:156] Memory required for data: 355124400
I0413 18:07:13.689630  1537 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 18:07:13.689638  1537 net.cpp:91] Creating Layer bn_conv3_3b
I0413 18:07:13.689642  1537 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 18:07:13.689649  1537 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 18:07:13.689841  1537 net.cpp:141] Setting up bn_conv3_3b
I0413 18:07:13.689848  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.689851  1537 net.cpp:156] Memory required for data: 358401200
I0413 18:07:13.689859  1537 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:07:13.689865  1537 net.cpp:91] Creating Layer scale_conv3_3b
I0413 18:07:13.689869  1537 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 18:07:13.689877  1537 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 18:07:13.689916  1537 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:07:13.690029  1537 net.cpp:141] Setting up scale_conv3_3b
I0413 18:07:13.690037  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.690040  1537 net.cpp:156] Memory required for data: 361678000
I0413 18:07:13.690047  1537 layer_factory.hpp:77] Creating layer conv3_3
I0413 18:07:13.690052  1537 net.cpp:91] Creating Layer conv3_3
I0413 18:07:13.690057  1537 net.cpp:425] conv3_3 <- conv3_3b
I0413 18:07:13.690062  1537 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 18:07:13.690068  1537 net.cpp:399] conv3_3 -> conv3_3
I0413 18:07:13.690088  1537 net.cpp:141] Setting up conv3_3
I0413 18:07:13.690096  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.690099  1537 net.cpp:156] Memory required for data: 364954800
I0413 18:07:13.690104  1537 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 18:07:13.690109  1537 net.cpp:91] Creating Layer conv3_3_relu
I0413 18:07:13.690114  1537 net.cpp:425] conv3_3_relu <- conv3_3
I0413 18:07:13.690117  1537 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 18:07:13.690606  1537 net.cpp:141] Setting up conv3_3_relu
I0413 18:07:13.690615  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.690619  1537 net.cpp:156] Memory required for data: 368231600
I0413 18:07:13.690628  1537 layer_factory.hpp:77] Creating layer conv3_3_conv3_3_relu_0_split
I0413 18:07:13.690634  1537 net.cpp:91] Creating Layer conv3_3_conv3_3_relu_0_split
I0413 18:07:13.690637  1537 net.cpp:425] conv3_3_conv3_3_relu_0_split <- conv3_3
I0413 18:07:13.690644  1537 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_0
I0413 18:07:13.690651  1537 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_1
I0413 18:07:13.690693  1537 net.cpp:141] Setting up conv3_3_conv3_3_relu_0_split
I0413 18:07:13.690701  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.690706  1537 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:07:13.690709  1537 net.cpp:156] Memory required for data: 374785200
I0413 18:07:13.690712  1537 layer_factory.hpp:77] Creating layer conv3_sub
I0413 18:07:13.690723  1537 net.cpp:91] Creating Layer conv3_sub
I0413 18:07:13.690728  1537 net.cpp:425] conv3_sub <- conv3_3_conv3_3_relu_0_split_0
I0413 18:07:13.690734  1537 net.cpp:399] conv3_sub -> conv3_sub
I0413 18:07:13.694403  1537 net.cpp:141] Setting up conv3_sub
I0413 18:07:13.694417  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.694422  1537 net.cpp:156] Memory required for data: 376423600
I0413 18:07:13.694428  1537 layer_factory.hpp:77] Creating layer bn_conv3_sub
I0413 18:07:13.694438  1537 net.cpp:91] Creating Layer bn_conv3_sub
I0413 18:07:13.694442  1537 net.cpp:425] bn_conv3_sub <- conv3_sub
I0413 18:07:13.694449  1537 net.cpp:386] bn_conv3_sub -> conv3_sub (in-place)
I0413 18:07:13.694648  1537 net.cpp:141] Setting up bn_conv3_sub
I0413 18:07:13.694656  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.694659  1537 net.cpp:156] Memory required for data: 378062000
I0413 18:07:13.694667  1537 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:07:13.694675  1537 net.cpp:91] Creating Layer scale_conv3_sub
I0413 18:07:13.694679  1537 net.cpp:425] scale_conv3_sub <- conv3_sub
I0413 18:07:13.694684  1537 net.cpp:386] scale_conv3_sub -> conv3_sub (in-place)
I0413 18:07:13.694726  1537 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:07:13.694842  1537 net.cpp:141] Setting up scale_conv3_sub
I0413 18:07:13.694850  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.694854  1537 net.cpp:156] Memory required for data: 379700400
I0413 18:07:13.694859  1537 layer_factory.hpp:77] Creating layer conv4_1a
I0413 18:07:13.694870  1537 net.cpp:91] Creating Layer conv4_1a
I0413 18:07:13.694875  1537 net.cpp:425] conv4_1a <- conv3_3_conv3_3_relu_0_split_1
I0413 18:07:13.694882  1537 net.cpp:399] conv4_1a -> conv4_1a
I0413 18:07:13.697803  1537 net.cpp:141] Setting up conv4_1a
I0413 18:07:13.697819  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.697824  1537 net.cpp:156] Memory required for data: 381338800
I0413 18:07:13.697830  1537 layer_factory.hpp:77] Creating layer bn_conv4_1a
I0413 18:07:13.697837  1537 net.cpp:91] Creating Layer bn_conv4_1a
I0413 18:07:13.697842  1537 net.cpp:425] bn_conv4_1a <- conv4_1a
I0413 18:07:13.697849  1537 net.cpp:386] bn_conv4_1a -> conv4_1a (in-place)
I0413 18:07:13.698051  1537 net.cpp:141] Setting up bn_conv4_1a
I0413 18:07:13.698060  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.698062  1537 net.cpp:156] Memory required for data: 382977200
I0413 18:07:13.698070  1537 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:07:13.698076  1537 net.cpp:91] Creating Layer scale_conv4_1a
I0413 18:07:13.698081  1537 net.cpp:425] scale_conv4_1a <- conv4_1a
I0413 18:07:13.698086  1537 net.cpp:386] scale_conv4_1a -> conv4_1a (in-place)
I0413 18:07:13.698127  1537 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:07:13.698241  1537 net.cpp:141] Setting up scale_conv4_1a
I0413 18:07:13.698248  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.698251  1537 net.cpp:156] Memory required for data: 384615600
I0413 18:07:13.698258  1537 layer_factory.hpp:77] Creating layer conv4_1a_relu
I0413 18:07:13.698268  1537 net.cpp:91] Creating Layer conv4_1a_relu
I0413 18:07:13.698272  1537 net.cpp:425] conv4_1a_relu <- conv4_1a
I0413 18:07:13.698278  1537 net.cpp:386] conv4_1a_relu -> conv4_1a (in-place)
I0413 18:07:13.698827  1537 net.cpp:141] Setting up conv4_1a_relu
I0413 18:07:13.698838  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.698843  1537 net.cpp:156] Memory required for data: 386254000
I0413 18:07:13.698845  1537 layer_factory.hpp:77] Creating layer conv4_1b
I0413 18:07:13.698858  1537 net.cpp:91] Creating Layer conv4_1b
I0413 18:07:13.698861  1537 net.cpp:425] conv4_1b <- conv4_1a
I0413 18:07:13.698868  1537 net.cpp:399] conv4_1b -> conv4_1b
I0413 18:07:13.702472  1537 net.cpp:141] Setting up conv4_1b
I0413 18:07:13.702486  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.702491  1537 net.cpp:156] Memory required for data: 387892400
I0413 18:07:13.702498  1537 layer_factory.hpp:77] Creating layer bn_conv4_1b
I0413 18:07:13.702507  1537 net.cpp:91] Creating Layer bn_conv4_1b
I0413 18:07:13.702512  1537 net.cpp:425] bn_conv4_1b <- conv4_1b
I0413 18:07:13.702518  1537 net.cpp:386] bn_conv4_1b -> conv4_1b (in-place)
I0413 18:07:13.702726  1537 net.cpp:141] Setting up bn_conv4_1b
I0413 18:07:13.702733  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.702738  1537 net.cpp:156] Memory required for data: 389530800
I0413 18:07:13.702744  1537 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:07:13.702752  1537 net.cpp:91] Creating Layer scale_conv4_1b
I0413 18:07:13.702756  1537 net.cpp:425] scale_conv4_1b <- conv4_1b
I0413 18:07:13.702761  1537 net.cpp:386] scale_conv4_1b -> conv4_1b (in-place)
I0413 18:07:13.702805  1537 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:07:13.702920  1537 net.cpp:141] Setting up scale_conv4_1b
I0413 18:07:13.702927  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.702930  1537 net.cpp:156] Memory required for data: 391169200
I0413 18:07:13.702936  1537 layer_factory.hpp:77] Creating layer conv4_1
I0413 18:07:13.702942  1537 net.cpp:91] Creating Layer conv4_1
I0413 18:07:13.702949  1537 net.cpp:425] conv4_1 <- conv3_sub
I0413 18:07:13.702952  1537 net.cpp:425] conv4_1 <- conv4_1b
I0413 18:07:13.702958  1537 net.cpp:399] conv4_1 -> conv4_1
I0413 18:07:13.702982  1537 net.cpp:141] Setting up conv4_1
I0413 18:07:13.702988  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.702992  1537 net.cpp:156] Memory required for data: 392807600
I0413 18:07:13.702996  1537 layer_factory.hpp:77] Creating layer conv4_1_relu
I0413 18:07:13.703004  1537 net.cpp:91] Creating Layer conv4_1_relu
I0413 18:07:13.703008  1537 net.cpp:425] conv4_1_relu <- conv4_1
I0413 18:07:13.703013  1537 net.cpp:386] conv4_1_relu -> conv4_1 (in-place)
I0413 18:07:13.703502  1537 net.cpp:141] Setting up conv4_1_relu
I0413 18:07:13.703516  1537 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:07:13.703521  1537 net.cpp:156] Memory required for data: 394446000
I0413 18:07:13.703524  1537 layer_factory.hpp:77] Creating layer global_pool
I0413 18:07:13.703533  1537 net.cpp:91] Creating Layer global_pool
I0413 18:07:13.703537  1537 net.cpp:425] global_pool <- conv4_1
I0413 18:07:13.703546  1537 net.cpp:399] global_pool -> global_pool
I0413 18:07:13.704653  1537 net.cpp:141] Setting up global_pool
I0413 18:07:13.704665  1537 net.cpp:148] Top shape: 100 64 1 1 (6400)
I0413 18:07:13.704670  1537 net.cpp:156] Memory required for data: 394471600
I0413 18:07:13.704674  1537 layer_factory.hpp:77] Creating layer ip
I0413 18:07:13.704681  1537 net.cpp:91] Creating Layer ip
I0413 18:07:13.704686  1537 net.cpp:425] ip <- global_pool
I0413 18:07:13.704691  1537 net.cpp:399] ip -> ip
I0413 18:07:13.704824  1537 net.cpp:141] Setting up ip
I0413 18:07:13.704833  1537 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:07:13.704836  1537 net.cpp:156] Memory required for data: 394475600
I0413 18:07:13.704843  1537 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 18:07:13.704850  1537 net.cpp:91] Creating Layer ip_ip_0_split
I0413 18:07:13.704854  1537 net.cpp:425] ip_ip_0_split <- ip
I0413 18:07:13.704865  1537 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 18:07:13.704874  1537 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 18:07:13.704919  1537 net.cpp:141] Setting up ip_ip_0_split
I0413 18:07:13.704926  1537 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:07:13.704931  1537 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:07:13.704934  1537 net.cpp:156] Memory required for data: 394483600
I0413 18:07:13.704938  1537 layer_factory.hpp:77] Creating layer accuracy
I0413 18:07:13.704946  1537 net.cpp:91] Creating Layer accuracy
I0413 18:07:13.704949  1537 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 18:07:13.704953  1537 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 18:07:13.704960  1537 net.cpp:399] accuracy -> accuracy
I0413 18:07:13.704968  1537 net.cpp:141] Setting up accuracy
I0413 18:07:13.704973  1537 net.cpp:148] Top shape: (1)
I0413 18:07:13.704977  1537 net.cpp:156] Memory required for data: 394483604
I0413 18:07:13.704980  1537 layer_factory.hpp:77] Creating layer loss
I0413 18:07:13.704987  1537 net.cpp:91] Creating Layer loss
I0413 18:07:13.704990  1537 net.cpp:425] loss <- ip_ip_0_split_1
I0413 18:07:13.704995  1537 net.cpp:425] loss <- label_cifar_1_split_1
I0413 18:07:13.705000  1537 net.cpp:399] loss -> loss
I0413 18:07:13.705008  1537 layer_factory.hpp:77] Creating layer loss
I0413 18:07:13.705862  1537 net.cpp:141] Setting up loss
I0413 18:07:13.705878  1537 net.cpp:148] Top shape: (1)
I0413 18:07:13.705883  1537 net.cpp:151]     with loss weight 1
I0413 18:07:13.705894  1537 net.cpp:156] Memory required for data: 394483608
I0413 18:07:13.705899  1537 net.cpp:217] loss needs backward computation.
I0413 18:07:13.705904  1537 net.cpp:219] accuracy does not need backward computation.
I0413 18:07:13.705909  1537 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 18:07:13.705912  1537 net.cpp:217] ip needs backward computation.
I0413 18:07:13.705916  1537 net.cpp:217] global_pool needs backward computation.
I0413 18:07:13.705920  1537 net.cpp:217] conv4_1_relu needs backward computation.
I0413 18:07:13.705924  1537 net.cpp:217] conv4_1 needs backward computation.
I0413 18:07:13.705929  1537 net.cpp:217] scale_conv4_1b needs backward computation.
I0413 18:07:13.705931  1537 net.cpp:217] bn_conv4_1b needs backward computation.
I0413 18:07:13.705935  1537 net.cpp:217] conv4_1b needs backward computation.
I0413 18:07:13.705940  1537 net.cpp:217] conv4_1a_relu needs backward computation.
I0413 18:07:13.705943  1537 net.cpp:217] scale_conv4_1a needs backward computation.
I0413 18:07:13.705946  1537 net.cpp:217] bn_conv4_1a needs backward computation.
I0413 18:07:13.705950  1537 net.cpp:217] conv4_1a needs backward computation.
I0413 18:07:13.705953  1537 net.cpp:217] scale_conv3_sub needs backward computation.
I0413 18:07:13.705957  1537 net.cpp:217] bn_conv3_sub needs backward computation.
I0413 18:07:13.705960  1537 net.cpp:217] conv3_sub needs backward computation.
I0413 18:07:13.705965  1537 net.cpp:217] conv3_3_conv3_3_relu_0_split needs backward computation.
I0413 18:07:13.705968  1537 net.cpp:217] conv3_3_relu needs backward computation.
I0413 18:07:13.705972  1537 net.cpp:217] conv3_3 needs backward computation.
I0413 18:07:13.705976  1537 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 18:07:13.705981  1537 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 18:07:13.705983  1537 net.cpp:217] conv3_3b needs backward computation.
I0413 18:07:13.705987  1537 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 18:07:13.705991  1537 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 18:07:13.705994  1537 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 18:07:13.705997  1537 net.cpp:217] conv3_3a needs backward computation.
I0413 18:07:13.706001  1537 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 18:07:13.706007  1537 net.cpp:217] conv3_2_relu needs backward computation.
I0413 18:07:13.706009  1537 net.cpp:217] conv3_2 needs backward computation.
I0413 18:07:13.706018  1537 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 18:07:13.706023  1537 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 18:07:13.706027  1537 net.cpp:217] conv3_2b needs backward computation.
I0413 18:07:13.706030  1537 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 18:07:13.706034  1537 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 18:07:13.706038  1537 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 18:07:13.706042  1537 net.cpp:217] conv3_2a needs backward computation.
I0413 18:07:13.706045  1537 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 18:07:13.706049  1537 net.cpp:217] conv3_1_relu needs backward computation.
I0413 18:07:13.706053  1537 net.cpp:217] conv3_1 needs backward computation.
I0413 18:07:13.706058  1537 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 18:07:13.706061  1537 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 18:07:13.706065  1537 net.cpp:217] conv3_1b needs backward computation.
I0413 18:07:13.706069  1537 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 18:07:13.706073  1537 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 18:07:13.706076  1537 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 18:07:13.706080  1537 net.cpp:217] conv3_1a needs backward computation.
I0413 18:07:13.706084  1537 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 18:07:13.706089  1537 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 18:07:13.706092  1537 net.cpp:217] conv2_sub needs backward computation.
I0413 18:07:13.706096  1537 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 18:07:13.706100  1537 net.cpp:217] conv2_3_relu needs backward computation.
I0413 18:07:13.706104  1537 net.cpp:217] conv2_3 needs backward computation.
I0413 18:07:13.706109  1537 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 18:07:13.706112  1537 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 18:07:13.706116  1537 net.cpp:217] conv2_3b needs backward computation.
I0413 18:07:13.706120  1537 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 18:07:13.706123  1537 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 18:07:13.706127  1537 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 18:07:13.706131  1537 net.cpp:217] conv2_3a needs backward computation.
I0413 18:07:13.706135  1537 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 18:07:13.706140  1537 net.cpp:217] conv2_2_relu needs backward computation.
I0413 18:07:13.706143  1537 net.cpp:217] conv2_2 needs backward computation.
I0413 18:07:13.706147  1537 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 18:07:13.706151  1537 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 18:07:13.706156  1537 net.cpp:217] conv2_2b needs backward computation.
I0413 18:07:13.706159  1537 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 18:07:13.706163  1537 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 18:07:13.706166  1537 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 18:07:13.706171  1537 net.cpp:217] conv2_2a needs backward computation.
I0413 18:07:13.706174  1537 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 18:07:13.706178  1537 net.cpp:217] conv2_1_relu needs backward computation.
I0413 18:07:13.706182  1537 net.cpp:217] conv2_1 needs backward computation.
I0413 18:07:13.706187  1537 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 18:07:13.706190  1537 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 18:07:13.706194  1537 net.cpp:217] conv2_1b needs backward computation.
I0413 18:07:13.706198  1537 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 18:07:13.706202  1537 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 18:07:13.706207  1537 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 18:07:13.706210  1537 net.cpp:217] conv2_1a needs backward computation.
I0413 18:07:13.706218  1537 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 18:07:13.706221  1537 net.cpp:217] conv1_relu needs backward computation.
I0413 18:07:13.706225  1537 net.cpp:217] scale_conv1 needs backward computation.
I0413 18:07:13.706229  1537 net.cpp:217] bn_conv1 needs backward computation.
I0413 18:07:13.706233  1537 net.cpp:217] conv1 needs backward computation.
I0413 18:07:13.706238  1537 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 18:07:13.706243  1537 net.cpp:219] cifar does not need backward computation.
I0413 18:07:13.706245  1537 net.cpp:261] This network produces output accuracy
I0413 18:07:13.706250  1537 net.cpp:261] This network produces output loss
I0413 18:07:13.706298  1537 net.cpp:274] Network initialization done.
I0413 18:07:13.706696  1537 solver.cpp:60] Solver scaffolding done.
I0413 18:07:14.145664  1537 solver.cpp:228] Iteration 0, loss = 2.59664
I0413 18:07:14.145714  1537 solver.cpp:244]     Train net output #0: accuracy = 0.0820312
I0413 18:07:14.145726  1537 solver.cpp:244]     Train net output #1: loss = 2.59664 (* 1 = 2.59664 loss)
I0413 18:07:14.145748  1537 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 18:07:20.126430  1537 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 18:07:23.045168  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4755
I0413 18:07:23.045212  1537 solver.cpp:404]     Test net output #1: loss = 1.56146 (* 1 = 1.56146 loss)
I0413 18:07:23.300741  1537 solver.cpp:228] Iteration 20, loss = 1.29708
I0413 18:07:23.300787  1537 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0413 18:07:23.300801  1537 solver.cpp:244]     Train net output #1: loss = 1.29708 (* 1 = 1.29708 loss)
I0413 18:07:23.300812  1537 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 18:07:29.501368  1537 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 18:07:32.196013  1537 solver.cpp:404]     Test net output #0: accuracy = 0.3657
I0413 18:07:32.196060  1537 solver.cpp:404]     Test net output #1: loss = 1.95795 (* 1 = 1.95795 loss)
I0413 18:07:32.405601  1537 solver.cpp:228] Iteration 40, loss = 0.8674
I0413 18:07:32.405658  1537 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0413 18:07:32.405669  1537 solver.cpp:244]     Train net output #1: loss = 0.8674 (* 1 = 0.8674 loss)
I0413 18:07:32.405684  1537 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 18:07:38.617883  1537 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 18:07:41.436105  1537 solver.cpp:404]     Test net output #0: accuracy = 0.2362
I0413 18:07:41.436148  1537 solver.cpp:404]     Test net output #1: loss = 3.00224 (* 1 = 3.00224 loss)
I0413 18:07:41.640750  1537 solver.cpp:228] Iteration 60, loss = 0.729721
I0413 18:07:41.640790  1537 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 18:07:41.640802  1537 solver.cpp:244]     Train net output #1: loss = 0.729721 (* 1 = 0.729721 loss)
I0413 18:07:41.640813  1537 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 18:07:47.692811  1537 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 18:07:50.683336  1537 solver.cpp:404]     Test net output #0: accuracy = 0.3637
I0413 18:07:50.683378  1537 solver.cpp:404]     Test net output #1: loss = 2.12606 (* 1 = 2.12606 loss)
I0413 18:07:50.888620  1537 solver.cpp:228] Iteration 80, loss = 0.66255
I0413 18:07:50.888662  1537 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0413 18:07:50.888674  1537 solver.cpp:244]     Train net output #1: loss = 0.66255 (* 1 = 0.66255 loss)
I0413 18:07:50.888685  1537 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 18:07:56.766633  1537 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 18:07:59.814368  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4124
I0413 18:07:59.814417  1537 solver.cpp:404]     Test net output #1: loss = 2.2834 (* 1 = 2.2834 loss)
I0413 18:08:00.047698  1537 solver.cpp:228] Iteration 100, loss = 0.669635
I0413 18:08:00.047736  1537 solver.cpp:244]     Train net output #0: accuracy = 0.746094
I0413 18:08:00.047747  1537 solver.cpp:244]     Train net output #1: loss = 0.669635 (* 1 = 0.669635 loss)
I0413 18:08:00.047765  1537 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 18:08:05.841246  1537 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 18:08:08.891952  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4273
I0413 18:08:08.891999  1537 solver.cpp:404]     Test net output #1: loss = 1.97178 (* 1 = 1.97178 loss)
I0413 18:08:09.101869  1537 solver.cpp:228] Iteration 120, loss = 0.7805
I0413 18:08:09.101907  1537 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0413 18:08:09.101918  1537 solver.cpp:244]     Train net output #1: loss = 0.7805 (* 1 = 0.7805 loss)
I0413 18:08:09.101927  1537 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 18:08:14.968272  1537 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 18:08:17.974185  1537 solver.cpp:404]     Test net output #0: accuracy = 0.3757
I0413 18:08:17.974264  1537 solver.cpp:404]     Test net output #1: loss = 2.44294 (* 1 = 2.44294 loss)
I0413 18:08:18.204566  1537 solver.cpp:228] Iteration 140, loss = 0.662429
I0413 18:08:18.204607  1537 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 18:08:18.204618  1537 solver.cpp:244]     Train net output #1: loss = 0.662429 (* 1 = 0.662429 loss)
I0413 18:08:18.204627  1537 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 18:08:24.262471  1537 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 18:08:27.110236  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5121
I0413 18:08:27.110287  1537 solver.cpp:404]     Test net output #1: loss = 1.50011 (* 1 = 1.50011 loss)
I0413 18:08:27.359025  1537 solver.cpp:228] Iteration 160, loss = 0.622283
I0413 18:08:27.359062  1537 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 18:08:27.359074  1537 solver.cpp:244]     Train net output #1: loss = 0.622283 (* 1 = 0.622283 loss)
I0413 18:08:27.359082  1537 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 18:08:33.555687  1537 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 18:08:36.250433  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5167
I0413 18:08:36.250481  1537 solver.cpp:404]     Test net output #1: loss = 1.60312 (* 1 = 1.60312 loss)
I0413 18:08:36.456936  1537 solver.cpp:228] Iteration 180, loss = 0.715707
I0413 18:08:36.456974  1537 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 18:08:36.456986  1537 solver.cpp:244]     Train net output #1: loss = 0.715707 (* 1 = 0.715707 loss)
I0413 18:08:36.456997  1537 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 18:08:42.687539  1537 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 18:08:45.481932  1537 solver.cpp:404]     Test net output #0: accuracy = 0.362
I0413 18:08:45.482039  1537 solver.cpp:404]     Test net output #1: loss = 2.98939 (* 1 = 2.98939 loss)
I0413 18:08:45.689002  1537 solver.cpp:228] Iteration 200, loss = 0.648614
I0413 18:08:45.689046  1537 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 18:08:45.689059  1537 solver.cpp:244]     Train net output #1: loss = 0.648614 (* 1 = 0.648614 loss)
I0413 18:08:45.689070  1537 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 18:08:51.742555  1537 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 18:08:54.738462  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5294
I0413 18:08:54.738519  1537 solver.cpp:404]     Test net output #1: loss = 1.44748 (* 1 = 1.44748 loss)
I0413 18:08:54.946230  1537 solver.cpp:228] Iteration 220, loss = 0.471488
I0413 18:08:54.946269  1537 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:08:54.946280  1537 solver.cpp:244]     Train net output #1: loss = 0.471488 (* 1 = 0.471488 loss)
I0413 18:08:54.946292  1537 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 18:09:00.847290  1537 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 18:09:03.895177  1537 solver.cpp:404]     Test net output #0: accuracy = 0.3879
I0413 18:09:03.895232  1537 solver.cpp:404]     Test net output #1: loss = 2.53329 (* 1 = 2.53329 loss)
I0413 18:09:04.148674  1537 solver.cpp:228] Iteration 240, loss = 0.547352
I0413 18:09:04.148738  1537 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:09:04.148751  1537 solver.cpp:244]     Train net output #1: loss = 0.547352 (* 1 = 0.547352 loss)
I0413 18:09:04.148762  1537 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 18:09:09.923627  1537 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 18:09:12.992332  1537 solver.cpp:404]     Test net output #0: accuracy = 0.333
I0413 18:09:12.992377  1537 solver.cpp:404]     Test net output #1: loss = 2.73125 (* 1 = 2.73125 loss)
I0413 18:09:13.201445  1537 solver.cpp:228] Iteration 260, loss = 0.604279
I0413 18:09:13.201493  1537 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 18:09:13.201505  1537 solver.cpp:244]     Train net output #1: loss = 0.604279 (* 1 = 0.604279 loss)
I0413 18:09:13.201516  1537 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 18:09:19.083299  1537 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 18:09:22.077075  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4897
I0413 18:09:22.077147  1537 solver.cpp:404]     Test net output #1: loss = 1.7242 (* 1 = 1.7242 loss)
I0413 18:09:22.312760  1537 solver.cpp:228] Iteration 280, loss = 0.584629
I0413 18:09:22.312799  1537 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 18:09:22.312811  1537 solver.cpp:244]     Train net output #1: loss = 0.584629 (* 1 = 0.584629 loss)
I0413 18:09:22.312821  1537 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 18:09:28.364126  1537 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 18:09:31.211766  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4634
I0413 18:09:31.211830  1537 solver.cpp:404]     Test net output #1: loss = 2.36131 (* 1 = 2.36131 loss)
I0413 18:09:31.455133  1537 solver.cpp:228] Iteration 300, loss = 0.768812
I0413 18:09:31.455178  1537 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 18:09:31.455188  1537 solver.cpp:244]     Train net output #1: loss = 0.768812 (* 1 = 0.768812 loss)
I0413 18:09:31.455199  1537 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 18:09:37.637781  1537 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 18:09:40.340507  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4929
I0413 18:09:40.340553  1537 solver.cpp:404]     Test net output #1: loss = 1.7815 (* 1 = 1.7815 loss)
I0413 18:09:40.548683  1537 solver.cpp:228] Iteration 320, loss = 0.583471
I0413 18:09:40.548724  1537 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 18:09:40.548737  1537 solver.cpp:244]     Train net output #1: loss = 0.583471 (* 1 = 0.583471 loss)
I0413 18:09:40.548746  1537 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 18:09:46.787463  1537 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 18:09:49.613766  1537 solver.cpp:404]     Test net output #0: accuracy = 0.3781
I0413 18:09:49.613842  1537 solver.cpp:404]     Test net output #1: loss = 3.04921 (* 1 = 3.04921 loss)
I0413 18:09:49.820858  1537 solver.cpp:228] Iteration 340, loss = 0.544967
I0413 18:09:49.820899  1537 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 18:09:49.820911  1537 solver.cpp:244]     Train net output #1: loss = 0.544967 (* 1 = 0.544967 loss)
I0413 18:09:49.820920  1537 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 18:09:55.846106  1537 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 18:09:58.832020  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5479
I0413 18:09:58.832080  1537 solver.cpp:404]     Test net output #1: loss = 1.43251 (* 1 = 1.43251 loss)
I0413 18:09:59.038540  1537 solver.cpp:228] Iteration 360, loss = 0.404693
I0413 18:09:59.038580  1537 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:09:59.038592  1537 solver.cpp:244]     Train net output #1: loss = 0.404693 (* 1 = 0.404693 loss)
I0413 18:09:59.038602  1537 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 18:10:04.903340  1537 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 18:10:07.915443  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5023
I0413 18:10:07.915505  1537 solver.cpp:404]     Test net output #1: loss = 2.04355 (* 1 = 2.04355 loss)
I0413 18:10:08.154726  1537 solver.cpp:228] Iteration 380, loss = 0.585253
I0413 18:10:08.154772  1537 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 18:10:08.154784  1537 solver.cpp:244]     Train net output #1: loss = 0.585253 (* 1 = 0.585253 loss)
I0413 18:10:08.154793  1537 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 18:10:13.942870  1537 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 18:10:16.983538  1537 solver.cpp:404]     Test net output #0: accuracy = 0.3541
I0413 18:10:16.983585  1537 solver.cpp:404]     Test net output #1: loss = 3.47809 (* 1 = 3.47809 loss)
I0413 18:10:17.212795  1537 solver.cpp:228] Iteration 400, loss = 0.42745
I0413 18:10:17.212836  1537 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:10:17.212847  1537 solver.cpp:244]     Train net output #1: loss = 0.42745 (* 1 = 0.42745 loss)
I0413 18:10:17.212855  1537 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 18:10:23.093648  1537 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 18:10:26.062058  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5705
I0413 18:10:26.062098  1537 solver.cpp:404]     Test net output #1: loss = 1.44806 (* 1 = 1.44806 loss)
I0413 18:10:26.302981  1537 solver.cpp:228] Iteration 420, loss = 0.547812
I0413 18:10:26.303020  1537 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 18:10:26.303031  1537 solver.cpp:244]     Train net output #1: loss = 0.547812 (* 1 = 0.547812 loss)
I0413 18:10:26.303040  1537 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 18:10:32.348911  1537 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 18:10:35.201297  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4217
I0413 18:10:35.201340  1537 solver.cpp:404]     Test net output #1: loss = 2.47678 (* 1 = 2.47678 loss)
I0413 18:10:35.411453  1537 solver.cpp:228] Iteration 440, loss = 0.512049
I0413 18:10:35.411489  1537 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:10:35.411501  1537 solver.cpp:244]     Train net output #1: loss = 0.512049 (* 1 = 0.512049 loss)
I0413 18:10:35.411510  1537 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 18:10:41.659628  1537 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 18:10:44.332178  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5118
I0413 18:10:44.332221  1537 solver.cpp:404]     Test net output #1: loss = 1.60192 (* 1 = 1.60192 loss)
I0413 18:10:44.534817  1537 solver.cpp:228] Iteration 460, loss = 0.42302
I0413 18:10:44.534855  1537 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:10:44.534868  1537 solver.cpp:244]     Train net output #1: loss = 0.42302 (* 1 = 0.42302 loss)
I0413 18:10:44.534879  1537 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 18:10:50.721601  1537 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 18:10:53.595414  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4739
I0413 18:10:53.595485  1537 solver.cpp:404]     Test net output #1: loss = 1.82932 (* 1 = 1.82932 loss)
I0413 18:10:53.802793  1537 solver.cpp:228] Iteration 480, loss = 0.578272
I0413 18:10:53.802837  1537 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 18:10:53.802848  1537 solver.cpp:244]     Train net output #1: loss = 0.578272 (* 1 = 0.578272 loss)
I0413 18:10:53.802857  1537 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 18:10:59.833979  1537 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 18:11:02.851424  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5005
I0413 18:11:02.851481  1537 solver.cpp:404]     Test net output #1: loss = 1.96448 (* 1 = 1.96448 loss)
I0413 18:11:03.018940  1537 solver.cpp:228] Iteration 500, loss = 0.429772
I0413 18:11:03.018985  1537 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:11:03.018998  1537 solver.cpp:244]     Train net output #1: loss = 0.429772 (* 1 = 0.429772 loss)
I0413 18:11:03.019006  1537 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 18:11:08.853940  1537 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 18:11:11.903290  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4656
I0413 18:11:11.903359  1537 solver.cpp:404]     Test net output #1: loss = 2.29433 (* 1 = 2.29433 loss)
I0413 18:11:12.148749  1537 solver.cpp:228] Iteration 520, loss = 0.70954
I0413 18:11:12.148788  1537 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0413 18:11:12.148800  1537 solver.cpp:244]     Train net output #1: loss = 0.70954 (* 1 = 0.70954 loss)
I0413 18:11:12.148810  1537 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 18:11:17.916854  1537 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 18:11:20.977792  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5433
I0413 18:11:20.977855  1537 solver.cpp:404]     Test net output #1: loss = 1.55449 (* 1 = 1.55449 loss)
I0413 18:11:21.186179  1537 solver.cpp:228] Iteration 540, loss = 0.465833
I0413 18:11:21.186221  1537 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:11:21.186233  1537 solver.cpp:244]     Train net output #1: loss = 0.465833 (* 1 = 0.465833 loss)
I0413 18:11:21.186240  1537 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 18:11:27.073698  1537 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 18:11:30.008868  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6319
I0413 18:11:30.008916  1537 solver.cpp:404]     Test net output #1: loss = 1.1736 (* 1 = 1.1736 loss)
I0413 18:11:30.262960  1537 solver.cpp:228] Iteration 560, loss = 0.522288
I0413 18:11:30.263001  1537 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 18:11:30.263013  1537 solver.cpp:244]     Train net output #1: loss = 0.522288 (* 1 = 0.522288 loss)
I0413 18:11:30.263022  1537 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 18:11:36.318775  1537 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 18:11:39.083171  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5421
I0413 18:11:39.083210  1537 solver.cpp:404]     Test net output #1: loss = 1.65462 (* 1 = 1.65462 loss)
I0413 18:11:39.290748  1537 solver.cpp:228] Iteration 580, loss = 0.429781
I0413 18:11:39.290802  1537 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:11:39.290814  1537 solver.cpp:244]     Train net output #1: loss = 0.429781 (* 1 = 0.429781 loss)
I0413 18:11:39.290823  1537 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 18:11:45.534024  1537 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 18:11:48.256530  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5524
I0413 18:11:48.256575  1537 solver.cpp:404]     Test net output #1: loss = 1.61721 (* 1 = 1.61721 loss)
I0413 18:11:48.464710  1537 solver.cpp:228] Iteration 600, loss = 0.515079
I0413 18:11:48.464746  1537 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 18:11:48.464758  1537 solver.cpp:244]     Train net output #1: loss = 0.515079 (* 1 = 0.515079 loss)
I0413 18:11:48.464766  1537 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 18:11:54.617859  1537 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 18:11:57.512189  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6362
I0413 18:11:57.512238  1537 solver.cpp:404]     Test net output #1: loss = 1.2282 (* 1 = 1.2282 loss)
I0413 18:11:57.717054  1537 solver.cpp:228] Iteration 620, loss = 0.604569
I0413 18:11:57.717094  1537 solver.cpp:244]     Train net output #0: accuracy = 0.769531
I0413 18:11:57.717106  1537 solver.cpp:244]     Train net output #1: loss = 0.604569 (* 1 = 0.604569 loss)
I0413 18:11:57.717123  1537 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 18:12:03.706890  1537 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 18:12:06.769047  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4904
I0413 18:12:06.769094  1537 solver.cpp:404]     Test net output #1: loss = 2.77046 (* 1 = 2.77046 loss)
I0413 18:12:06.988029  1537 solver.cpp:228] Iteration 640, loss = 0.538
I0413 18:12:06.988064  1537 solver.cpp:244]     Train net output #0: accuracy = 0.816406
I0413 18:12:06.988082  1537 solver.cpp:244]     Train net output #1: loss = 0.538 (* 1 = 0.538 loss)
I0413 18:12:06.988090  1537 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 18:12:12.784076  1537 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 18:12:15.832821  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5393
I0413 18:12:15.832857  1537 solver.cpp:404]     Test net output #1: loss = 1.46013 (* 1 = 1.46013 loss)
I0413 18:12:16.064867  1537 solver.cpp:228] Iteration 660, loss = 0.538947
I0413 18:12:16.064906  1537 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 18:12:16.064918  1537 solver.cpp:244]     Train net output #1: loss = 0.538947 (* 1 = 0.538947 loss)
I0413 18:12:16.064925  1537 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 18:12:21.830967  1537 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 18:12:24.823034  1537 solver.cpp:404]     Test net output #0: accuracy = 0.587
I0413 18:12:24.823072  1537 solver.cpp:404]     Test net output #1: loss = 1.3465 (* 1 = 1.3465 loss)
I0413 18:12:25.041571  1537 solver.cpp:228] Iteration 680, loss = 0.502051
I0413 18:12:25.041623  1537 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 18:12:25.041635  1537 solver.cpp:244]     Train net output #1: loss = 0.502051 (* 1 = 0.502051 loss)
I0413 18:12:25.041643  1537 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 18:12:30.989390  1537 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 18:12:33.914029  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6052
I0413 18:12:33.914104  1537 solver.cpp:404]     Test net output #1: loss = 1.31952 (* 1 = 1.31952 loss)
I0413 18:12:34.162782  1537 solver.cpp:228] Iteration 700, loss = 0.477412
I0413 18:12:34.162829  1537 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:12:34.162842  1537 solver.cpp:244]     Train net output #1: loss = 0.477412 (* 1 = 0.477412 loss)
I0413 18:12:34.162850  1537 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 18:12:40.277514  1537 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 18:12:43.039167  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5836
I0413 18:12:43.039212  1537 solver.cpp:404]     Test net output #1: loss = 1.33011 (* 1 = 1.33011 loss)
I0413 18:12:43.278741  1537 solver.cpp:228] Iteration 720, loss = 0.498039
I0413 18:12:43.278786  1537 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:12:43.278797  1537 solver.cpp:244]     Train net output #1: loss = 0.498039 (* 1 = 0.498039 loss)
I0413 18:12:43.278810  1537 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 18:12:49.524508  1537 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 18:12:52.280838  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4906
I0413 18:12:52.280879  1537 solver.cpp:404]     Test net output #1: loss = 1.89798 (* 1 = 1.89798 loss)
I0413 18:12:52.486459  1537 solver.cpp:228] Iteration 740, loss = 0.450267
I0413 18:12:52.486498  1537 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:12:52.486510  1537 solver.cpp:244]     Train net output #1: loss = 0.450267 (* 1 = 0.450267 loss)
I0413 18:12:52.486518  1537 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 18:12:58.624215  1537 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 18:13:01.541033  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5496
I0413 18:13:01.541100  1537 solver.cpp:404]     Test net output #1: loss = 1.51716 (* 1 = 1.51716 loss)
I0413 18:13:01.749197  1537 solver.cpp:228] Iteration 760, loss = 0.494233
I0413 18:13:01.749238  1537 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:13:01.749250  1537 solver.cpp:244]     Train net output #1: loss = 0.494233 (* 1 = 0.494233 loss)
I0413 18:13:01.749258  1537 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 18:13:07.692581  1537 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 18:13:10.727634  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4813
I0413 18:13:10.727687  1537 solver.cpp:404]     Test net output #1: loss = 1.76756 (* 1 = 1.76756 loss)
I0413 18:13:10.972332  1537 solver.cpp:228] Iteration 780, loss = 0.432443
I0413 18:13:10.972420  1537 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:13:10.972440  1537 solver.cpp:244]     Train net output #1: loss = 0.432443 (* 1 = 0.432443 loss)
I0413 18:13:10.972458  1537 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 18:13:16.772413  1537 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 18:13:19.818606  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5523
I0413 18:13:19.818645  1537 solver.cpp:404]     Test net output #1: loss = 1.59361 (* 1 = 1.59361 loss)
I0413 18:13:20.053304  1537 solver.cpp:228] Iteration 800, loss = 0.507856
I0413 18:13:20.053349  1537 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 18:13:20.053361  1537 solver.cpp:244]     Train net output #1: loss = 0.507856 (* 1 = 0.507856 loss)
I0413 18:13:20.053371  1537 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 18:13:25.852916  1537 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 18:13:28.932442  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5672
I0413 18:13:28.932488  1537 solver.cpp:404]     Test net output #1: loss = 1.54133 (* 1 = 1.54133 loss)
I0413 18:13:29.146250  1537 solver.cpp:228] Iteration 820, loss = 0.48179
I0413 18:13:29.146291  1537 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:13:29.146302  1537 solver.cpp:244]     Train net output #1: loss = 0.48179 (* 1 = 0.48179 loss)
I0413 18:13:29.146316  1537 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 18:13:35.086840  1537 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 18:13:37.980621  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5361
I0413 18:13:37.980671  1537 solver.cpp:404]     Test net output #1: loss = 1.88894 (* 1 = 1.88894 loss)
I0413 18:13:38.228507  1537 solver.cpp:228] Iteration 840, loss = 0.560248
I0413 18:13:38.228545  1537 solver.cpp:244]     Train net output #0: accuracy = 0.785156
I0413 18:13:38.228557  1537 solver.cpp:244]     Train net output #1: loss = 0.560248 (* 1 = 0.560248 loss)
I0413 18:13:38.228569  1537 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 18:13:44.377529  1537 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 18:13:47.122215  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4195
I0413 18:13:47.122259  1537 solver.cpp:404]     Test net output #1: loss = 1.98999 (* 1 = 1.98999 loss)
I0413 18:13:47.348603  1537 solver.cpp:228] Iteration 860, loss = 0.47608
I0413 18:13:47.348641  1537 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 18:13:47.348654  1537 solver.cpp:244]     Train net output #1: loss = 0.47608 (* 1 = 0.47608 loss)
I0413 18:13:47.348664  1537 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 18:13:53.592489  1537 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 18:13:56.340772  1537 solver.cpp:404]     Test net output #0: accuracy = 0.537
I0413 18:13:56.340827  1537 solver.cpp:404]     Test net output #1: loss = 1.77807 (* 1 = 1.77807 loss)
I0413 18:13:56.549376  1537 solver.cpp:228] Iteration 880, loss = 0.535337
I0413 18:13:56.549419  1537 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:13:56.549434  1537 solver.cpp:244]     Train net output #1: loss = 0.535337 (* 1 = 0.535337 loss)
I0413 18:13:56.549458  1537 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 18:14:02.689081  1537 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 18:14:05.602118  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6471
I0413 18:14:05.602175  1537 solver.cpp:404]     Test net output #1: loss = 1.10103 (* 1 = 1.10103 loss)
I0413 18:14:05.812562  1537 solver.cpp:228] Iteration 900, loss = 0.518757
I0413 18:14:05.812602  1537 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 18:14:05.812613  1537 solver.cpp:244]     Train net output #1: loss = 0.518757 (* 1 = 0.518757 loss)
I0413 18:14:05.812623  1537 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 18:14:11.764622  1537 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 18:14:14.799201  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6123
I0413 18:14:14.799265  1537 solver.cpp:404]     Test net output #1: loss = 1.17003 (* 1 = 1.17003 loss)
I0413 18:14:15.057366  1537 solver.cpp:228] Iteration 920, loss = 0.509306
I0413 18:14:15.057416  1537 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 18:14:15.057428  1537 solver.cpp:244]     Train net output #1: loss = 0.509306 (* 1 = 0.509306 loss)
I0413 18:14:15.057436  1537 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 18:14:20.814824  1537 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 18:14:23.864879  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5375
I0413 18:14:23.864925  1537 solver.cpp:404]     Test net output #1: loss = 1.76642 (* 1 = 1.76642 loss)
I0413 18:14:24.086061  1537 solver.cpp:228] Iteration 940, loss = 0.421609
I0413 18:14:24.086151  1537 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:14:24.087510  1537 solver.cpp:244]     Train net output #1: loss = 0.421609 (* 1 = 0.421609 loss)
I0413 18:14:24.087549  1537 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 18:14:29.857442  1537 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 18:14:32.905475  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5789
I0413 18:14:32.905516  1537 solver.cpp:404]     Test net output #1: loss = 1.46856 (* 1 = 1.46856 loss)
I0413 18:14:33.140630  1537 solver.cpp:228] Iteration 960, loss = 0.427991
I0413 18:14:33.140676  1537 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:14:33.140687  1537 solver.cpp:244]     Train net output #1: loss = 0.427991 (* 1 = 0.427991 loss)
I0413 18:14:33.140697  1537 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 18:14:39.105530  1537 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 18:14:41.986960  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5787
I0413 18:14:41.987004  1537 solver.cpp:404]     Test net output #1: loss = 1.33246 (* 1 = 1.33246 loss)
I0413 18:14:42.218695  1537 solver.cpp:228] Iteration 980, loss = 0.427713
I0413 18:14:42.218732  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:14:42.218744  1537 solver.cpp:244]     Train net output #1: loss = 0.427713 (* 1 = 0.427713 loss)
I0413 18:14:42.218751  1537 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 18:14:48.371264  1537 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 18:14:51.091141  1537 solver.cpp:404]     Test net output #0: accuracy = 0.607
I0413 18:14:51.091192  1537 solver.cpp:404]     Test net output #1: loss = 1.22733 (* 1 = 1.22733 loss)
I0413 18:14:51.351395  1537 solver.cpp:228] Iteration 1000, loss = 0.404176
I0413 18:14:51.351430  1537 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:14:51.351441  1537 solver.cpp:244]     Train net output #1: loss = 0.404176 (* 1 = 0.404176 loss)
I0413 18:14:51.351449  1537 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 18:14:57.581104  1537 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 18:15:00.365310  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5958
I0413 18:15:00.365351  1537 solver.cpp:404]     Test net output #1: loss = 1.37262 (* 1 = 1.37262 loss)
I0413 18:15:00.571878  1537 solver.cpp:228] Iteration 1020, loss = 0.499266
I0413 18:15:00.571923  1537 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:15:00.571934  1537 solver.cpp:244]     Train net output #1: loss = 0.499266 (* 1 = 0.499266 loss)
I0413 18:15:00.571943  1537 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 18:15:06.707603  1537 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 18:15:09.628720  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5299
I0413 18:15:09.628801  1537 solver.cpp:404]     Test net output #1: loss = 1.52787 (* 1 = 1.52787 loss)
I0413 18:15:09.834115  1537 solver.cpp:228] Iteration 1040, loss = 0.467651
I0413 18:15:09.834156  1537 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:15:09.834168  1537 solver.cpp:244]     Train net output #1: loss = 0.467651 (* 1 = 0.467651 loss)
I0413 18:15:09.834177  1537 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 18:15:15.746306  1537 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 18:15:18.809890  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4965
I0413 18:15:18.809944  1537 solver.cpp:404]     Test net output #1: loss = 1.8237 (* 1 = 1.8237 loss)
I0413 18:15:19.025619  1537 solver.cpp:228] Iteration 1060, loss = 0.58696
I0413 18:15:19.025663  1537 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 18:15:19.025676  1537 solver.cpp:244]     Train net output #1: loss = 0.58696 (* 1 = 0.58696 loss)
I0413 18:15:19.025686  1537 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 18:15:24.825654  1537 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 18:15:27.844020  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5784
I0413 18:15:27.844063  1537 solver.cpp:404]     Test net output #1: loss = 1.34372 (* 1 = 1.34372 loss)
I0413 18:15:28.076462  1537 solver.cpp:228] Iteration 1080, loss = 0.467987
I0413 18:15:28.076503  1537 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:15:28.076514  1537 solver.cpp:244]     Train net output #1: loss = 0.467987 (* 1 = 0.467987 loss)
I0413 18:15:28.076521  1537 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 18:15:33.887897  1537 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 18:15:36.901731  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6104
I0413 18:15:36.901784  1537 solver.cpp:404]     Test net output #1: loss = 1.2295 (* 1 = 1.2295 loss)
I0413 18:15:37.135910  1537 solver.cpp:228] Iteration 1100, loss = 0.462071
I0413 18:15:37.135951  1537 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 18:15:37.135962  1537 solver.cpp:244]     Train net output #1: loss = 0.462071 (* 1 = 0.462071 loss)
I0413 18:15:37.135970  1537 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 18:15:43.137852  1537 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 18:15:45.983613  1537 solver.cpp:404]     Test net output #0: accuracy = 0.431
I0413 18:15:45.983651  1537 solver.cpp:404]     Test net output #1: loss = 2.21186 (* 1 = 2.21186 loss)
I0413 18:15:46.213384  1537 solver.cpp:228] Iteration 1120, loss = 0.620039
I0413 18:15:46.213426  1537 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 18:15:46.213449  1537 solver.cpp:244]     Train net output #1: loss = 0.620039 (* 1 = 0.620039 loss)
I0413 18:15:46.213459  1537 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 18:15:52.367044  1537 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 18:15:55.066112  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5789
I0413 18:15:55.066154  1537 solver.cpp:404]     Test net output #1: loss = 1.39644 (* 1 = 1.39644 loss)
I0413 18:15:55.281836  1537 solver.cpp:228] Iteration 1140, loss = 0.481444
I0413 18:15:55.281872  1537 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:15:55.281883  1537 solver.cpp:244]     Train net output #1: loss = 0.481444 (* 1 = 0.481444 loss)
I0413 18:15:55.281890  1537 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 18:16:01.552541  1537 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 18:16:04.359319  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6261
I0413 18:16:04.359372  1537 solver.cpp:404]     Test net output #1: loss = 1.21771 (* 1 = 1.21771 loss)
I0413 18:16:04.565896  1537 solver.cpp:228] Iteration 1160, loss = 0.488544
I0413 18:16:04.565958  1537 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:16:04.565974  1537 solver.cpp:244]     Train net output #1: loss = 0.488544 (* 1 = 0.488544 loss)
I0413 18:16:04.565995  1537 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 18:16:10.647420  1537 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 18:16:13.608897  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4806
I0413 18:16:13.608934  1537 solver.cpp:404]     Test net output #1: loss = 1.84673 (* 1 = 1.84673 loss)
I0413 18:16:13.814893  1537 solver.cpp:228] Iteration 1180, loss = 0.475222
I0413 18:16:13.814947  1537 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:16:13.814967  1537 solver.cpp:244]     Train net output #1: loss = 0.475222 (* 1 = 0.475222 loss)
I0413 18:16:13.814976  1537 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 18:16:19.714020  1537 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 18:16:22.779868  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6503
I0413 18:16:22.779958  1537 solver.cpp:404]     Test net output #1: loss = 1.03801 (* 1 = 1.03801 loss)
I0413 18:16:22.993140  1537 solver.cpp:228] Iteration 1200, loss = 0.472553
I0413 18:16:22.993190  1537 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:16:22.993203  1537 solver.cpp:244]     Train net output #1: loss = 0.472553 (* 1 = 0.472553 loss)
I0413 18:16:22.993217  1537 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 18:16:28.800035  1537 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 18:16:31.847668  1537 solver.cpp:404]     Test net output #0: accuracy = 0.3765
I0413 18:16:31.847728  1537 solver.cpp:404]     Test net output #1: loss = 2.69066 (* 1 = 2.69066 loss)
I0413 18:16:32.083452  1537 solver.cpp:228] Iteration 1220, loss = 0.535673
I0413 18:16:32.083494  1537 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:16:32.083508  1537 solver.cpp:244]     Train net output #1: loss = 0.535673 (* 1 = 0.535673 loss)
I0413 18:16:32.083518  1537 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 18:16:37.921814  1537 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 18:16:40.933948  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4751
I0413 18:16:40.933995  1537 solver.cpp:404]     Test net output #1: loss = 1.62547 (* 1 = 1.62547 loss)
I0413 18:16:41.150269  1537 solver.cpp:228] Iteration 1240, loss = 0.438949
I0413 18:16:41.150310  1537 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:16:41.150321  1537 solver.cpp:244]     Train net output #1: loss = 0.438949 (* 1 = 0.438949 loss)
I0413 18:16:41.150331  1537 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 18:16:47.175333  1537 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 18:16:50.029058  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5689
I0413 18:16:50.029103  1537 solver.cpp:404]     Test net output #1: loss = 1.23306 (* 1 = 1.23306 loss)
I0413 18:16:50.255667  1537 solver.cpp:228] Iteration 1260, loss = 0.382587
I0413 18:16:50.255707  1537 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:16:50.255718  1537 solver.cpp:244]     Train net output #1: loss = 0.382587 (* 1 = 0.382587 loss)
I0413 18:16:50.255729  1537 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 18:16:56.484236  1537 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 18:16:59.190537  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6335
I0413 18:16:59.190608  1537 solver.cpp:404]     Test net output #1: loss = 1.19655 (* 1 = 1.19655 loss)
I0413 18:16:59.397819  1537 solver.cpp:228] Iteration 1280, loss = 0.398601
I0413 18:16:59.397855  1537 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:16:59.397868  1537 solver.cpp:244]     Train net output #1: loss = 0.398601 (* 1 = 0.398601 loss)
I0413 18:16:59.397878  1537 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 18:17:05.631247  1537 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 18:17:08.463564  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5085
I0413 18:17:08.463618  1537 solver.cpp:404]     Test net output #1: loss = 1.96456 (* 1 = 1.96456 loss)
I0413 18:17:08.671938  1537 solver.cpp:228] Iteration 1300, loss = 0.565589
I0413 18:17:08.671978  1537 solver.cpp:244]     Train net output #0: accuracy = 0.789062
I0413 18:17:08.671990  1537 solver.cpp:244]     Train net output #1: loss = 0.565589 (* 1 = 0.565589 loss)
I0413 18:17:08.672001  1537 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 18:17:14.741673  1537 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 18:17:17.701270  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5273
I0413 18:17:17.701313  1537 solver.cpp:404]     Test net output #1: loss = 1.52065 (* 1 = 1.52065 loss)
I0413 18:17:17.906388  1537 solver.cpp:228] Iteration 1320, loss = 0.445874
I0413 18:17:17.906437  1537 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:17:17.906448  1537 solver.cpp:244]     Train net output #1: loss = 0.445874 (* 1 = 0.445874 loss)
I0413 18:17:17.906461  1537 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 18:17:23.776579  1537 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 18:17:26.829089  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5154
I0413 18:17:26.829154  1537 solver.cpp:404]     Test net output #1: loss = 1.55022 (* 1 = 1.55022 loss)
I0413 18:17:27.057535  1537 solver.cpp:228] Iteration 1340, loss = 0.532347
I0413 18:17:27.057574  1537 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 18:17:27.057585  1537 solver.cpp:244]     Train net output #1: loss = 0.532347 (* 1 = 0.532347 loss)
I0413 18:17:27.057593  1537 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 18:17:32.834504  1537 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 18:17:35.889727  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4802
I0413 18:17:35.889763  1537 solver.cpp:404]     Test net output #1: loss = 2.35009 (* 1 = 2.35009 loss)
I0413 18:17:36.109088  1537 solver.cpp:228] Iteration 1360, loss = 0.36919
I0413 18:17:36.109146  1537 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:17:36.109159  1537 solver.cpp:244]     Train net output #1: loss = 0.36919 (* 1 = 0.36919 loss)
I0413 18:17:36.109168  1537 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 18:17:41.954247  1537 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 18:17:44.941432  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5729
I0413 18:17:44.941475  1537 solver.cpp:404]     Test net output #1: loss = 1.43753 (* 1 = 1.43753 loss)
I0413 18:17:45.173599  1537 solver.cpp:228] Iteration 1380, loss = 0.518041
I0413 18:17:45.173635  1537 solver.cpp:244]     Train net output #0: accuracy = 0.820312
I0413 18:17:45.173647  1537 solver.cpp:244]     Train net output #1: loss = 0.518041 (* 1 = 0.518041 loss)
I0413 18:17:45.173657  1537 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 18:17:51.212514  1537 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 18:17:54.043349  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5908
I0413 18:17:54.043411  1537 solver.cpp:404]     Test net output #1: loss = 1.38563 (* 1 = 1.38563 loss)
I0413 18:17:54.281540  1537 solver.cpp:228] Iteration 1400, loss = 0.469946
I0413 18:17:54.281584  1537 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:17:54.281596  1537 solver.cpp:244]     Train net output #1: loss = 0.469946 (* 1 = 0.469946 loss)
I0413 18:17:54.281620  1537 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 18:18:00.529412  1537 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 18:18:03.204855  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4965
I0413 18:18:03.204895  1537 solver.cpp:404]     Test net output #1: loss = 1.983 (* 1 = 1.983 loss)
I0413 18:18:03.406368  1537 solver.cpp:228] Iteration 1420, loss = 0.549299
I0413 18:18:03.406406  1537 solver.cpp:244]     Train net output #0: accuracy = 0.800781
I0413 18:18:03.406417  1537 solver.cpp:244]     Train net output #1: loss = 0.549299 (* 1 = 0.549299 loss)
I0413 18:18:03.406425  1537 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 18:18:09.629725  1537 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 18:18:12.463862  1537 solver.cpp:404]     Test net output #0: accuracy = 0.685
I0413 18:18:12.463932  1537 solver.cpp:404]     Test net output #1: loss = 0.908808 (* 1 = 0.908808 loss)
I0413 18:18:12.666079  1537 solver.cpp:228] Iteration 1440, loss = 0.382899
I0413 18:18:12.666128  1537 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:18:12.666141  1537 solver.cpp:244]     Train net output #1: loss = 0.382899 (* 1 = 0.382899 loss)
I0413 18:18:12.666149  1537 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 18:18:18.682641  1537 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 18:18:21.697218  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6883
I0413 18:18:21.697268  1537 solver.cpp:404]     Test net output #1: loss = 0.939691 (* 1 = 0.939691 loss)
I0413 18:18:21.906898  1537 solver.cpp:228] Iteration 1460, loss = 0.448814
I0413 18:18:21.906936  1537 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:18:21.906947  1537 solver.cpp:244]     Train net output #1: loss = 0.448814 (* 1 = 0.448814 loss)
I0413 18:18:21.906955  1537 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 18:18:27.761857  1537 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 18:18:30.817353  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6166
I0413 18:18:30.817457  1537 solver.cpp:404]     Test net output #1: loss = 1.40657 (* 1 = 1.40657 loss)
I0413 18:18:31.024516  1537 solver.cpp:228] Iteration 1480, loss = 0.432915
I0413 18:18:31.024559  1537 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:18:31.024569  1537 solver.cpp:244]     Train net output #1: loss = 0.432915 (* 1 = 0.432915 loss)
I0413 18:18:31.024577  1537 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 18:18:36.807847  1537 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 18:18:39.833403  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6561
I0413 18:18:39.833461  1537 solver.cpp:404]     Test net output #1: loss = 1.01444 (* 1 = 1.01444 loss)
I0413 18:18:40.080893  1537 solver.cpp:228] Iteration 1500, loss = 0.421897
I0413 18:18:40.080931  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:18:40.080942  1537 solver.cpp:244]     Train net output #1: loss = 0.421897 (* 1 = 0.421897 loss)
I0413 18:18:40.080952  1537 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 18:18:45.951704  1537 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 18:18:48.910420  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6311
I0413 18:18:48.910462  1537 solver.cpp:404]     Test net output #1: loss = 1.08309 (* 1 = 1.08309 loss)
I0413 18:18:49.131666  1537 solver.cpp:228] Iteration 1520, loss = 0.470146
I0413 18:18:49.131707  1537 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:18:49.131718  1537 solver.cpp:244]     Train net output #1: loss = 0.470146 (* 1 = 0.470146 loss)
I0413 18:18:49.131727  1537 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 18:18:55.252758  1537 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 18:18:58.058053  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5907
I0413 18:18:58.058089  1537 solver.cpp:404]     Test net output #1: loss = 1.39096 (* 1 = 1.39096 loss)
I0413 18:18:58.285805  1537 solver.cpp:228] Iteration 1540, loss = 0.483976
I0413 18:18:58.285842  1537 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:18:58.285853  1537 solver.cpp:244]     Train net output #1: loss = 0.483976 (* 1 = 0.483976 loss)
I0413 18:18:58.285861  1537 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 18:19:04.532634  1537 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 18:19:07.226579  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5093
I0413 18:19:07.226616  1537 solver.cpp:404]     Test net output #1: loss = 1.99965 (* 1 = 1.99965 loss)
I0413 18:19:07.430105  1537 solver.cpp:228] Iteration 1560, loss = 0.553328
I0413 18:19:07.430146  1537 solver.cpp:244]     Train net output #0: accuracy = 0.796875
I0413 18:19:07.430158  1537 solver.cpp:244]     Train net output #1: loss = 0.553328 (* 1 = 0.553328 loss)
I0413 18:19:07.430168  1537 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 18:19:13.653978  1537 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 18:19:16.503821  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5558
I0413 18:19:16.503859  1537 solver.cpp:404]     Test net output #1: loss = 1.36983 (* 1 = 1.36983 loss)
I0413 18:19:16.708283  1537 solver.cpp:228] Iteration 1580, loss = 0.409773
I0413 18:19:16.708323  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:19:16.708341  1537 solver.cpp:244]     Train net output #1: loss = 0.409773 (* 1 = 0.409773 loss)
I0413 18:19:16.708350  1537 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 18:19:22.739423  1537 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 18:19:25.805187  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6568
I0413 18:19:25.805227  1537 solver.cpp:404]     Test net output #1: loss = 1.08993 (* 1 = 1.08993 loss)
I0413 18:19:25.980157  1537 solver.cpp:228] Iteration 1600, loss = 0.408244
I0413 18:19:25.980195  1537 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:19:25.980206  1537 solver.cpp:244]     Train net output #1: loss = 0.408244 (* 1 = 0.408244 loss)
I0413 18:19:25.980213  1537 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 18:19:31.817312  1537 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 18:19:34.856729  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5546
I0413 18:19:34.856766  1537 solver.cpp:404]     Test net output #1: loss = 1.74023 (* 1 = 1.74023 loss)
I0413 18:19:35.112030  1537 solver.cpp:228] Iteration 1620, loss = 0.420023
I0413 18:19:35.112092  1537 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:19:35.112118  1537 solver.cpp:244]     Train net output #1: loss = 0.420023 (* 1 = 0.420023 loss)
I0413 18:19:35.112133  1537 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 18:19:40.922426  1537 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 18:19:43.965054  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5297
I0413 18:19:43.965093  1537 solver.cpp:404]     Test net output #1: loss = 1.60679 (* 1 = 1.60679 loss)
I0413 18:19:44.174968  1537 solver.cpp:228] Iteration 1640, loss = 0.537285
I0413 18:19:44.175029  1537 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:19:44.175043  1537 solver.cpp:244]     Train net output #1: loss = 0.537285 (* 1 = 0.537285 loss)
I0413 18:19:44.175055  1537 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 18:19:50.056802  1537 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 18:19:52.995383  1537 solver.cpp:404]     Test net output #0: accuracy = 0.4954
I0413 18:19:52.995437  1537 solver.cpp:404]     Test net output #1: loss = 1.74704 (* 1 = 1.74704 loss)
I0413 18:19:53.240337  1537 solver.cpp:228] Iteration 1660, loss = 0.408903
I0413 18:19:53.240396  1537 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:19:53.240408  1537 solver.cpp:244]     Train net output #1: loss = 0.408903 (* 1 = 0.408903 loss)
I0413 18:19:53.240420  1537 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 18:19:59.299021  1537 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 18:20:02.078245  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5774
I0413 18:20:02.078302  1537 solver.cpp:404]     Test net output #1: loss = 1.45283 (* 1 = 1.45283 loss)
I0413 18:20:02.290863  1537 solver.cpp:228] Iteration 1680, loss = 0.425562
I0413 18:20:02.290902  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:20:02.290912  1537 solver.cpp:244]     Train net output #1: loss = 0.425562 (* 1 = 0.425562 loss)
I0413 18:20:02.290925  1537 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 18:20:08.559383  1537 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 18:20:11.279055  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6445
I0413 18:20:11.279120  1537 solver.cpp:404]     Test net output #1: loss = 1.13779 (* 1 = 1.13779 loss)
I0413 18:20:11.483837  1537 solver.cpp:228] Iteration 1700, loss = 0.385762
I0413 18:20:11.483875  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:20:11.483886  1537 solver.cpp:244]     Train net output #1: loss = 0.385762 (* 1 = 0.385762 loss)
I0413 18:20:11.483896  1537 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 18:20:17.636468  1537 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 18:20:20.534729  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6092
I0413 18:20:20.534777  1537 solver.cpp:404]     Test net output #1: loss = 1.48332 (* 1 = 1.48332 loss)
I0413 18:20:20.740588  1537 solver.cpp:228] Iteration 1720, loss = 0.439165
I0413 18:20:20.740667  1537 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:20:20.740686  1537 solver.cpp:244]     Train net output #1: loss = 0.439165 (* 1 = 0.439165 loss)
I0413 18:20:20.740700  1537 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 18:20:26.727435  1537 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 18:20:29.754240  1537 solver.cpp:404]     Test net output #0: accuracy = 0.658
I0413 18:20:29.754302  1537 solver.cpp:404]     Test net output #1: loss = 1.08778 (* 1 = 1.08778 loss)
I0413 18:20:29.995605  1537 solver.cpp:228] Iteration 1740, loss = 0.440602
I0413 18:20:29.995643  1537 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:20:29.995654  1537 solver.cpp:244]     Train net output #1: loss = 0.440602 (* 1 = 0.440602 loss)
I0413 18:20:29.995661  1537 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 18:20:35.763713  1537 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 18:20:38.833307  1537 solver.cpp:404]     Test net output #0: accuracy = 0.5575
I0413 18:20:38.833353  1537 solver.cpp:404]     Test net output #1: loss = 1.54615 (* 1 = 1.54615 loss)
I0413 18:20:39.064344  1537 solver.cpp:228] Iteration 1760, loss = 0.546212
I0413 18:20:39.064385  1537 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 18:20:39.064396  1537 solver.cpp:244]     Train net output #1: loss = 0.546212 (* 1 = 0.546212 loss)
I0413 18:20:39.064405  1537 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 18:20:44.859633  1537 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 18:20:47.903462  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6991
I0413 18:20:47.903506  1537 solver.cpp:404]     Test net output #1: loss = 0.874116 (* 1 = 0.874116 loss)
I0413 18:20:48.126052  1537 solver.cpp:228] Iteration 1780, loss = 0.392069
I0413 18:20:48.126096  1537 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:20:48.126107  1537 solver.cpp:244]     Train net output #1: loss = 0.392069 (* 1 = 0.392069 loss)
I0413 18:20:48.126116  1537 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 18:20:54.055266  1537 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 18:20:56.949885  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6238
I0413 18:20:56.949929  1537 solver.cpp:404]     Test net output #1: loss = 1.21926 (* 1 = 1.21926 loss)
I0413 18:20:57.195734  1537 solver.cpp:228] Iteration 1800, loss = 0.413247
I0413 18:20:57.195773  1537 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:20:57.195786  1537 solver.cpp:244]     Train net output #1: loss = 0.413247 (* 1 = 0.413247 loss)
I0413 18:20:57.195794  1537 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 18:21:03.325064  1537 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 18:21:06.084389  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6971
I0413 18:21:06.084431  1537 solver.cpp:404]     Test net output #1: loss = 0.96928 (* 1 = 0.96928 loss)
I0413 18:21:06.333675  1537 solver.cpp:228] Iteration 1820, loss = 0.426796
I0413 18:21:06.333721  1537 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:21:06.333734  1537 solver.cpp:244]     Train net output #1: loss = 0.426796 (* 1 = 0.426796 loss)
I0413 18:21:06.333745  1537 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 18:21:12.574424  1537 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 18:21:15.333231  1537 solver.cpp:404]     Test net output #0: accuracy = 0.7153
I0413 18:21:15.333272  1537 solver.cpp:404]     Test net output #1: loss = 0.835559 (* 1 = 0.835559 loss)
I0413 18:21:15.541568  1537 solver.cpp:228] Iteration 1840, loss = 0.385986
I0413 18:21:15.541607  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:21:15.541617  1537 solver.cpp:244]     Train net output #1: loss = 0.385986 (* 1 = 0.385986 loss)
I0413 18:21:15.541625  1537 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 18:21:21.693832  1537 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 18:21:24.573338  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6404
I0413 18:21:24.573418  1537 solver.cpp:404]     Test net output #1: loss = 1.19465 (* 1 = 1.19465 loss)
I0413 18:21:24.778744  1537 solver.cpp:228] Iteration 1860, loss = 0.349771
I0413 18:21:24.778789  1537 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:21:24.778800  1537 solver.cpp:244]     Train net output #1: loss = 0.349771 (* 1 = 0.349771 loss)
I0413 18:21:24.778808  1537 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 18:21:30.752831  1537 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 18:21:33.815675  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6471
I0413 18:21:33.815722  1537 solver.cpp:404]     Test net output #1: loss = 1.17663 (* 1 = 1.17663 loss)
I0413 18:21:34.028058  1537 solver.cpp:228] Iteration 1880, loss = 0.423356
I0413 18:21:34.028097  1537 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:21:34.028110  1537 solver.cpp:244]     Train net output #1: loss = 0.423356 (* 1 = 0.423356 loss)
I0413 18:21:34.028120  1537 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 18:21:39.824179  1537 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 18:21:42.843770  1537 solver.cpp:404]     Test net output #0: accuracy = 0.672
I0413 18:21:42.843809  1537 solver.cpp:404]     Test net output #1: loss = 1.08717 (* 1 = 1.08717 loss)
I0413 18:21:43.082058  1537 solver.cpp:228] Iteration 1900, loss = 0.396689
I0413 18:21:43.082121  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:21:43.082137  1537 solver.cpp:244]     Train net output #1: loss = 0.396689 (* 1 = 0.396689 loss)
I0413 18:21:43.082145  1537 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 18:21:48.868692  1537 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 18:21:51.922859  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6553
I0413 18:21:51.922905  1537 solver.cpp:404]     Test net output #1: loss = 1.11058 (* 1 = 1.11058 loss)
I0413 18:21:52.155141  1537 solver.cpp:228] Iteration 1920, loss = 0.492381
I0413 18:21:52.155184  1537 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 18:21:52.155196  1537 solver.cpp:244]     Train net output #1: loss = 0.492381 (* 1 = 0.492381 loss)
I0413 18:21:52.155205  1537 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 18:21:58.116786  1537 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 18:22:01.034998  1537 solver.cpp:404]     Test net output #0: accuracy = 0.7033
I0413 18:22:01.035044  1537 solver.cpp:404]     Test net output #1: loss = 0.956089 (* 1 = 0.956089 loss)
I0413 18:22:01.284644  1537 solver.cpp:228] Iteration 1940, loss = 0.386551
I0413 18:22:01.284689  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:22:01.284700  1537 solver.cpp:244]     Train net output #1: loss = 0.386551 (* 1 = 0.386551 loss)
I0413 18:22:01.284709  1537 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 18:22:07.387727  1537 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 18:22:10.155789  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6319
I0413 18:22:10.155823  1537 solver.cpp:404]     Test net output #1: loss = 1.33888 (* 1 = 1.33888 loss)
I0413 18:22:10.395550  1537 solver.cpp:228] Iteration 1960, loss = 0.425897
I0413 18:22:10.395592  1537 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:22:10.395603  1537 solver.cpp:244]     Train net output #1: loss = 0.425897 (* 1 = 0.425897 loss)
I0413 18:22:10.395612  1537 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 18:22:16.647763  1537 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 18:22:19.396641  1537 solver.cpp:404]     Test net output #0: accuracy = 0.6932
I0413 18:22:19.396690  1537 solver.cpp:404]     Test net output #1: loss = 0.970685 (* 1 = 0.970685 loss)
I0413 18:22:19.603081  1537 solver.cpp:228] Iteration 1980, loss = 0.405688
I0413 18:22:19.603126  1537 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:22:19.603137  1537 solver.cpp:244]     Train net output #1: loss = 0.405688 (* 1 = 0.405688 loss)
I0413 18:22:19.603157  1537 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 18:22:25.764076  1537 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar6/ResNet-cifar6_iter_2000.caffemodel
I0413 18:22:25.773322  1537 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar6/ResNet-cifar6_iter_2000.solverstate
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 18:22:28.315017 14009 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar7/ResNet-cifar7"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar7.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 18:22:28.315055 14009 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar7.prototxt
I0413 18:22:28.316632 14009 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 18:22:28.317028 14009 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_sub"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_sub"
  type: "BatchNorm"
  bottom: "conv3_sub"
  top: "conv3_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_sub"
  type: "Scale"
  bottom: "conv3_sub"
  top: "conv3_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv4_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1a"
  type: "BatchNorm"
  bottom: "conv4_1a"
  top: "conv4_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1a"
  type: "Scale"
  bottom: "conv4_1a"
  top: "conv4_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a_relu"
  type: "ReLU"
  bottom: "conv4_1a"
  top: "conv4_1a"
}
layer {
  name: "conv4_1b"
  type: "Convolution"
  bottom: "conv4_1a"
  top: "conv4_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1b"
  type: "BatchNorm"
  bottom: "conv4_1b"
  top: "conv4_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1b"
  type: "Scale"
  bottom: "conv4_1b"
  top: "conv4_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv3_sub"
  bottom: "conv4_1b"
  top: "conv4_1"
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2a"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2a"
  type: "BatchNorm"
  bottom: "conv4_2a"
  top: "conv4_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2a"
  type: "Scale"
  bottom: "conv4_2a"
  top: "conv4_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2a_relu"
  type: "ReLU"
  bottom: "conv4_2a"
  top: "conv4_2a"
}
layer {
  name: "conv4_2b"
  type: "Convolution"
  bottom: "conv4_2a"
  top: "conv4_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2b"
  type: "BatchNorm"
  bottom: "conv4_2b"
  top: "conv4_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2b"
  type: "Scale"
  bottom: "conv4_2b"
  top: "conv4_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_2b"
  top: "conv4_2"
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv4_2"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 18:22:28.317410 14009 layer_factory.hpp:77] Creating layer cifar
I0413 18:22:28.317937 14009 net.cpp:91] Creating Layer cifar
I0413 18:22:28.317955 14009 net.cpp:399] cifar -> data
I0413 18:22:28.317967 14009 net.cpp:399] cifar -> label
I0413 18:22:28.317978 14009 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 18:22:28.321441 14164 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 18:22:28.362503 14009 data_layer.cpp:41] output data size: 256,3,32,32
I0413 18:22:28.373328 14009 net.cpp:141] Setting up cifar
I0413 18:22:28.373359 14009 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 18:22:28.373378 14009 net.cpp:148] Top shape: 256 (256)
I0413 18:22:28.373385 14009 net.cpp:156] Memory required for data: 3146752
I0413 18:22:28.373394 14009 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 18:22:28.373415 14009 net.cpp:91] Creating Layer label_cifar_1_split
I0413 18:22:28.373422 14009 net.cpp:425] label_cifar_1_split <- label
I0413 18:22:28.373448 14009 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 18:22:28.373461 14009 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 18:22:28.373529 14009 net.cpp:141] Setting up label_cifar_1_split
I0413 18:22:28.373539 14009 net.cpp:148] Top shape: 256 (256)
I0413 18:22:28.373545 14009 net.cpp:148] Top shape: 256 (256)
I0413 18:22:28.373549 14009 net.cpp:156] Memory required for data: 3148800
I0413 18:22:28.373554 14009 layer_factory.hpp:77] Creating layer conv1
I0413 18:22:28.373575 14009 net.cpp:91] Creating Layer conv1
I0413 18:22:28.373580 14009 net.cpp:425] conv1 <- data
I0413 18:22:28.373589 14009 net.cpp:399] conv1 -> conv1
I0413 18:22:28.642674 14009 net.cpp:141] Setting up conv1
I0413 18:22:28.642716 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.642724 14009 net.cpp:156] Memory required for data: 19926016
I0413 18:22:28.642745 14009 layer_factory.hpp:77] Creating layer bn_conv1
I0413 18:22:28.642761 14009 net.cpp:91] Creating Layer bn_conv1
I0413 18:22:28.642768 14009 net.cpp:425] bn_conv1 <- conv1
I0413 18:22:28.642779 14009 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 18:22:28.642993 14009 net.cpp:141] Setting up bn_conv1
I0413 18:22:28.643004 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.643009 14009 net.cpp:156] Memory required for data: 36703232
I0413 18:22:28.643025 14009 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:22:28.643038 14009 net.cpp:91] Creating Layer scale_conv1
I0413 18:22:28.643043 14009 net.cpp:425] scale_conv1 <- conv1
I0413 18:22:28.643054 14009 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 18:22:28.643095 14009 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:22:28.643224 14009 net.cpp:141] Setting up scale_conv1
I0413 18:22:28.643234 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.643240 14009 net.cpp:156] Memory required for data: 53480448
I0413 18:22:28.643249 14009 layer_factory.hpp:77] Creating layer conv1_relu
I0413 18:22:28.643268 14009 net.cpp:91] Creating Layer conv1_relu
I0413 18:22:28.643276 14009 net.cpp:425] conv1_relu <- conv1
I0413 18:22:28.643283 14009 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 18:22:28.643602 14009 net.cpp:141] Setting up conv1_relu
I0413 18:22:28.643621 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.643627 14009 net.cpp:156] Memory required for data: 70257664
I0413 18:22:28.643635 14009 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 18:22:28.643643 14009 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 18:22:28.643648 14009 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 18:22:28.643656 14009 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 18:22:28.643666 14009 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 18:22:28.643713 14009 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 18:22:28.643723 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.643728 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.643734 14009 net.cpp:156] Memory required for data: 103812096
I0413 18:22:28.643739 14009 layer_factory.hpp:77] Creating layer conv2_1a
I0413 18:22:28.643759 14009 net.cpp:91] Creating Layer conv2_1a
I0413 18:22:28.643764 14009 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 18:22:28.643775 14009 net.cpp:399] conv2_1a -> conv2_1a
I0413 18:22:28.646538 14009 net.cpp:141] Setting up conv2_1a
I0413 18:22:28.646556 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.646562 14009 net.cpp:156] Memory required for data: 120589312
I0413 18:22:28.646576 14009 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 18:22:28.646589 14009 net.cpp:91] Creating Layer bn_conv2_1a
I0413 18:22:28.646595 14009 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 18:22:28.646603 14009 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 18:22:28.646800 14009 net.cpp:141] Setting up bn_conv2_1a
I0413 18:22:28.646811 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.646816 14009 net.cpp:156] Memory required for data: 137366528
I0413 18:22:28.646826 14009 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:22:28.646836 14009 net.cpp:91] Creating Layer scale_conv2_1a
I0413 18:22:28.646842 14009 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 18:22:28.646848 14009 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 18:22:28.646889 14009 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:22:28.647007 14009 net.cpp:141] Setting up scale_conv2_1a
I0413 18:22:28.647018 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.647023 14009 net.cpp:156] Memory required for data: 154143744
I0413 18:22:28.647032 14009 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 18:22:28.647042 14009 net.cpp:91] Creating Layer conv2_1a_relu
I0413 18:22:28.647048 14009 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 18:22:28.647055 14009 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 18:22:28.647367 14009 net.cpp:141] Setting up conv2_1a_relu
I0413 18:22:28.647382 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.647388 14009 net.cpp:156] Memory required for data: 170920960
I0413 18:22:28.647394 14009 layer_factory.hpp:77] Creating layer conv2_1b
I0413 18:22:28.647410 14009 net.cpp:91] Creating Layer conv2_1b
I0413 18:22:28.647416 14009 net.cpp:425] conv2_1b <- conv2_1a
I0413 18:22:28.647428 14009 net.cpp:399] conv2_1b -> conv2_1b
I0413 18:22:28.649526 14009 net.cpp:141] Setting up conv2_1b
I0413 18:22:28.649549 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.649556 14009 net.cpp:156] Memory required for data: 187698176
I0413 18:22:28.649565 14009 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 18:22:28.649576 14009 net.cpp:91] Creating Layer bn_conv2_1b
I0413 18:22:28.649582 14009 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 18:22:28.649592 14009 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 18:22:28.649798 14009 net.cpp:141] Setting up bn_conv2_1b
I0413 18:22:28.649814 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.649821 14009 net.cpp:156] Memory required for data: 204475392
I0413 18:22:28.649834 14009 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:22:28.649843 14009 net.cpp:91] Creating Layer scale_conv2_1b
I0413 18:22:28.649849 14009 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 18:22:28.649858 14009 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 18:22:28.649896 14009 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:22:28.650012 14009 net.cpp:141] Setting up scale_conv2_1b
I0413 18:22:28.650024 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.650030 14009 net.cpp:156] Memory required for data: 221252608
I0413 18:22:28.650039 14009 layer_factory.hpp:77] Creating layer conv2_1
I0413 18:22:28.650048 14009 net.cpp:91] Creating Layer conv2_1
I0413 18:22:28.650053 14009 net.cpp:425] conv2_1 <- conv2_1b
I0413 18:22:28.650060 14009 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 18:22:28.650068 14009 net.cpp:399] conv2_1 -> conv2_1
I0413 18:22:28.650097 14009 net.cpp:141] Setting up conv2_1
I0413 18:22:28.650106 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.650111 14009 net.cpp:156] Memory required for data: 238029824
I0413 18:22:28.650116 14009 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 18:22:28.650125 14009 net.cpp:91] Creating Layer conv2_1_relu
I0413 18:22:28.650130 14009 net.cpp:425] conv2_1_relu <- conv2_1
I0413 18:22:28.650138 14009 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 18:22:28.650563 14009 net.cpp:141] Setting up conv2_1_relu
I0413 18:22:28.650575 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.650581 14009 net.cpp:156] Memory required for data: 254807040
I0413 18:22:28.650588 14009 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 18:22:28.650599 14009 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 18:22:28.650605 14009 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 18:22:28.650615 14009 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 18:22:28.650624 14009 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 18:22:28.650667 14009 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 18:22:28.650677 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.650684 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.650689 14009 net.cpp:156] Memory required for data: 288361472
I0413 18:22:28.650696 14009 layer_factory.hpp:77] Creating layer conv2_2a
I0413 18:22:28.650709 14009 net.cpp:91] Creating Layer conv2_2a
I0413 18:22:28.650715 14009 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 18:22:28.650723 14009 net.cpp:399] conv2_2a -> conv2_2a
I0413 18:22:28.653643 14009 net.cpp:141] Setting up conv2_2a
I0413 18:22:28.653663 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.653671 14009 net.cpp:156] Memory required for data: 305138688
I0413 18:22:28.653681 14009 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 18:22:28.653690 14009 net.cpp:91] Creating Layer bn_conv2_2a
I0413 18:22:28.653697 14009 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 18:22:28.653707 14009 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 18:22:28.653913 14009 net.cpp:141] Setting up bn_conv2_2a
I0413 18:22:28.653923 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.653928 14009 net.cpp:156] Memory required for data: 321915904
I0413 18:22:28.653939 14009 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:22:28.653949 14009 net.cpp:91] Creating Layer scale_conv2_2a
I0413 18:22:28.653954 14009 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 18:22:28.653961 14009 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 18:22:28.654003 14009 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:22:28.654120 14009 net.cpp:141] Setting up scale_conv2_2a
I0413 18:22:28.654130 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.654140 14009 net.cpp:156] Memory required for data: 338693120
I0413 18:22:28.654150 14009 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 18:22:28.654158 14009 net.cpp:91] Creating Layer conv2_2a_relu
I0413 18:22:28.654165 14009 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 18:22:28.654172 14009 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 18:22:28.654714 14009 net.cpp:141] Setting up conv2_2a_relu
I0413 18:22:28.654731 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.654736 14009 net.cpp:156] Memory required for data: 355470336
I0413 18:22:28.654742 14009 layer_factory.hpp:77] Creating layer conv2_2b
I0413 18:22:28.654758 14009 net.cpp:91] Creating Layer conv2_2b
I0413 18:22:28.654764 14009 net.cpp:425] conv2_2b <- conv2_2a
I0413 18:22:28.654777 14009 net.cpp:399] conv2_2b -> conv2_2b
I0413 18:22:28.657634 14009 net.cpp:141] Setting up conv2_2b
I0413 18:22:28.657654 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.657660 14009 net.cpp:156] Memory required for data: 372247552
I0413 18:22:28.657670 14009 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 18:22:28.657680 14009 net.cpp:91] Creating Layer bn_conv2_2b
I0413 18:22:28.657687 14009 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 18:22:28.657696 14009 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 18:22:28.657899 14009 net.cpp:141] Setting up bn_conv2_2b
I0413 18:22:28.657909 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.657915 14009 net.cpp:156] Memory required for data: 389024768
I0413 18:22:28.657930 14009 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:22:28.657941 14009 net.cpp:91] Creating Layer scale_conv2_2b
I0413 18:22:28.657948 14009 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 18:22:28.657954 14009 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 18:22:28.657995 14009 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:22:28.658113 14009 net.cpp:141] Setting up scale_conv2_2b
I0413 18:22:28.658124 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.658130 14009 net.cpp:156] Memory required for data: 405801984
I0413 18:22:28.658139 14009 layer_factory.hpp:77] Creating layer conv2_2
I0413 18:22:28.658148 14009 net.cpp:91] Creating Layer conv2_2
I0413 18:22:28.658154 14009 net.cpp:425] conv2_2 <- conv2_2b
I0413 18:22:28.658160 14009 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 18:22:28.658167 14009 net.cpp:399] conv2_2 -> conv2_2
I0413 18:22:28.658195 14009 net.cpp:141] Setting up conv2_2
I0413 18:22:28.658205 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.658210 14009 net.cpp:156] Memory required for data: 422579200
I0413 18:22:28.658215 14009 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 18:22:28.658222 14009 net.cpp:91] Creating Layer conv2_2_relu
I0413 18:22:28.658229 14009 net.cpp:425] conv2_2_relu <- conv2_2
I0413 18:22:28.658236 14009 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 18:22:28.658550 14009 net.cpp:141] Setting up conv2_2_relu
I0413 18:22:28.658567 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.658573 14009 net.cpp:156] Memory required for data: 439356416
I0413 18:22:28.658579 14009 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 18:22:28.658588 14009 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 18:22:28.658593 14009 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 18:22:28.658601 14009 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 18:22:28.658612 14009 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 18:22:28.658660 14009 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 18:22:28.658669 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.658677 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.658682 14009 net.cpp:156] Memory required for data: 472910848
I0413 18:22:28.658687 14009 layer_factory.hpp:77] Creating layer conv2_3a
I0413 18:22:28.658704 14009 net.cpp:91] Creating Layer conv2_3a
I0413 18:22:28.658715 14009 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 18:22:28.658725 14009 net.cpp:399] conv2_3a -> conv2_3a
I0413 18:22:28.661185 14009 net.cpp:141] Setting up conv2_3a
I0413 18:22:28.661203 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.661209 14009 net.cpp:156] Memory required for data: 489688064
I0413 18:22:28.661219 14009 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 18:22:28.661231 14009 net.cpp:91] Creating Layer bn_conv2_3a
I0413 18:22:28.661238 14009 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 18:22:28.661249 14009 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 18:22:28.661455 14009 net.cpp:141] Setting up bn_conv2_3a
I0413 18:22:28.661465 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.661470 14009 net.cpp:156] Memory required for data: 506465280
I0413 18:22:28.661481 14009 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:22:28.661492 14009 net.cpp:91] Creating Layer scale_conv2_3a
I0413 18:22:28.661499 14009 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 18:22:28.661505 14009 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 18:22:28.661545 14009 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:22:28.661669 14009 net.cpp:141] Setting up scale_conv2_3a
I0413 18:22:28.661679 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.661684 14009 net.cpp:156] Memory required for data: 523242496
I0413 18:22:28.661692 14009 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 18:22:28.661701 14009 net.cpp:91] Creating Layer conv2_3a_relu
I0413 18:22:28.661706 14009 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 18:22:28.661713 14009 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 18:22:28.662209 14009 net.cpp:141] Setting up conv2_3a_relu
I0413 18:22:28.662223 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.662230 14009 net.cpp:156] Memory required for data: 540019712
I0413 18:22:28.662235 14009 layer_factory.hpp:77] Creating layer conv2_3b
I0413 18:22:28.662250 14009 net.cpp:91] Creating Layer conv2_3b
I0413 18:22:28.662256 14009 net.cpp:425] conv2_3b <- conv2_3a
I0413 18:22:28.662264 14009 net.cpp:399] conv2_3b -> conv2_3b
I0413 18:22:28.665300 14009 net.cpp:141] Setting up conv2_3b
I0413 18:22:28.665318 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.665324 14009 net.cpp:156] Memory required for data: 556796928
I0413 18:22:28.665336 14009 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 18:22:28.665351 14009 net.cpp:91] Creating Layer bn_conv2_3b
I0413 18:22:28.665359 14009 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 18:22:28.665366 14009 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 18:22:28.665576 14009 net.cpp:141] Setting up bn_conv2_3b
I0413 18:22:28.665586 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.665591 14009 net.cpp:156] Memory required for data: 573574144
I0413 18:22:28.665602 14009 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:22:28.665611 14009 net.cpp:91] Creating Layer scale_conv2_3b
I0413 18:22:28.665617 14009 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 18:22:28.665624 14009 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 18:22:28.665668 14009 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:22:28.665793 14009 net.cpp:141] Setting up scale_conv2_3b
I0413 18:22:28.665803 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.665809 14009 net.cpp:156] Memory required for data: 590351360
I0413 18:22:28.665817 14009 layer_factory.hpp:77] Creating layer conv2_3
I0413 18:22:28.665827 14009 net.cpp:91] Creating Layer conv2_3
I0413 18:22:28.665833 14009 net.cpp:425] conv2_3 <- conv2_3b
I0413 18:22:28.665839 14009 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 18:22:28.665848 14009 net.cpp:399] conv2_3 -> conv2_3
I0413 18:22:28.665875 14009 net.cpp:141] Setting up conv2_3
I0413 18:22:28.665884 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.665889 14009 net.cpp:156] Memory required for data: 607128576
I0413 18:22:28.665899 14009 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 18:22:28.665907 14009 net.cpp:91] Creating Layer conv2_3_relu
I0413 18:22:28.665913 14009 net.cpp:425] conv2_3_relu <- conv2_3
I0413 18:22:28.665921 14009 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 18:22:28.666236 14009 net.cpp:141] Setting up conv2_3_relu
I0413 18:22:28.666254 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.666260 14009 net.cpp:156] Memory required for data: 623905792
I0413 18:22:28.666265 14009 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 18:22:28.666275 14009 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 18:22:28.666281 14009 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 18:22:28.666290 14009 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 18:22:28.666301 14009 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 18:22:28.666348 14009 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 18:22:28.666357 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.666364 14009 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:22:28.666369 14009 net.cpp:156] Memory required for data: 657460224
I0413 18:22:28.666374 14009 layer_factory.hpp:77] Creating layer conv2_sub
I0413 18:22:28.666389 14009 net.cpp:91] Creating Layer conv2_sub
I0413 18:22:28.666395 14009 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 18:22:28.666406 14009 net.cpp:399] conv2_sub -> conv2_sub
I0413 18:22:28.668553 14009 net.cpp:141] Setting up conv2_sub
I0413 18:22:28.668571 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.668577 14009 net.cpp:156] Memory required for data: 665848832
I0413 18:22:28.668588 14009 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 18:22:28.668601 14009 net.cpp:91] Creating Layer bn_conv2_sub
I0413 18:22:28.668607 14009 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 18:22:28.668615 14009 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 18:22:28.668822 14009 net.cpp:141] Setting up bn_conv2_sub
I0413 18:22:28.668833 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.668838 14009 net.cpp:156] Memory required for data: 674237440
I0413 18:22:28.668848 14009 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:22:28.668858 14009 net.cpp:91] Creating Layer scale_conv2_sub
I0413 18:22:28.668862 14009 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 18:22:28.668872 14009 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 18:22:28.668911 14009 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:22:28.669029 14009 net.cpp:141] Setting up scale_conv2_sub
I0413 18:22:28.669041 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.669046 14009 net.cpp:156] Memory required for data: 682626048
I0413 18:22:28.669055 14009 layer_factory.hpp:77] Creating layer conv3_1a
I0413 18:22:28.669073 14009 net.cpp:91] Creating Layer conv3_1a
I0413 18:22:28.669080 14009 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 18:22:28.669090 14009 net.cpp:399] conv3_1a -> conv3_1a
I0413 18:22:28.670424 14009 net.cpp:141] Setting up conv3_1a
I0413 18:22:28.670442 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.670449 14009 net.cpp:156] Memory required for data: 691014656
I0413 18:22:28.670459 14009 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 18:22:28.670469 14009 net.cpp:91] Creating Layer bn_conv3_1a
I0413 18:22:28.670475 14009 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 18:22:28.670485 14009 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 18:22:28.670689 14009 net.cpp:141] Setting up bn_conv3_1a
I0413 18:22:28.670699 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.670704 14009 net.cpp:156] Memory required for data: 699403264
I0413 18:22:28.670716 14009 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:22:28.670723 14009 net.cpp:91] Creating Layer scale_conv3_1a
I0413 18:22:28.670729 14009 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 18:22:28.670740 14009 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 18:22:28.670783 14009 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:22:28.670904 14009 net.cpp:141] Setting up scale_conv3_1a
I0413 18:22:28.670914 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.670919 14009 net.cpp:156] Memory required for data: 707791872
I0413 18:22:28.670928 14009 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 18:22:28.670938 14009 net.cpp:91] Creating Layer conv3_1a_relu
I0413 18:22:28.670944 14009 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 18:22:28.670950 14009 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 18:22:28.671484 14009 net.cpp:141] Setting up conv3_1a_relu
I0413 18:22:28.671500 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.671506 14009 net.cpp:156] Memory required for data: 716180480
I0413 18:22:28.671512 14009 layer_factory.hpp:77] Creating layer conv3_1b
I0413 18:22:28.671528 14009 net.cpp:91] Creating Layer conv3_1b
I0413 18:22:28.671535 14009 net.cpp:425] conv3_1b <- conv3_1a
I0413 18:22:28.671546 14009 net.cpp:399] conv3_1b -> conv3_1b
I0413 18:22:28.673678 14009 net.cpp:141] Setting up conv3_1b
I0413 18:22:28.673698 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.673704 14009 net.cpp:156] Memory required for data: 724569088
I0413 18:22:28.673725 14009 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 18:22:28.673738 14009 net.cpp:91] Creating Layer bn_conv3_1b
I0413 18:22:28.673744 14009 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 18:22:28.673753 14009 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 18:22:28.673959 14009 net.cpp:141] Setting up bn_conv3_1b
I0413 18:22:28.673969 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.673974 14009 net.cpp:156] Memory required for data: 732957696
I0413 18:22:28.673985 14009 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:22:28.673998 14009 net.cpp:91] Creating Layer scale_conv3_1b
I0413 18:22:28.674005 14009 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 18:22:28.674012 14009 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 18:22:28.674054 14009 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:22:28.674182 14009 net.cpp:141] Setting up scale_conv3_1b
I0413 18:22:28.674193 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.674198 14009 net.cpp:156] Memory required for data: 741346304
I0413 18:22:28.674207 14009 layer_factory.hpp:77] Creating layer conv3_1
I0413 18:22:28.674216 14009 net.cpp:91] Creating Layer conv3_1
I0413 18:22:28.674221 14009 net.cpp:425] conv3_1 <- conv3_1b
I0413 18:22:28.674227 14009 net.cpp:425] conv3_1 <- conv2_sub
I0413 18:22:28.674237 14009 net.cpp:399] conv3_1 -> conv3_1
I0413 18:22:28.674260 14009 net.cpp:141] Setting up conv3_1
I0413 18:22:28.674271 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.674276 14009 net.cpp:156] Memory required for data: 749734912
I0413 18:22:28.674281 14009 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 18:22:28.674290 14009 net.cpp:91] Creating Layer conv3_1_relu
I0413 18:22:28.674295 14009 net.cpp:425] conv3_1_relu <- conv3_1
I0413 18:22:28.674302 14009 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 18:22:28.674556 14009 net.cpp:141] Setting up conv3_1_relu
I0413 18:22:28.674568 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.674573 14009 net.cpp:156] Memory required for data: 758123520
I0413 18:22:28.674579 14009 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 18:22:28.674587 14009 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 18:22:28.674592 14009 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 18:22:28.674602 14009 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 18:22:28.674612 14009 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 18:22:28.674659 14009 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 18:22:28.674674 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.674680 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.674686 14009 net.cpp:156] Memory required for data: 774900736
I0413 18:22:28.674691 14009 layer_factory.hpp:77] Creating layer conv3_2a
I0413 18:22:28.674705 14009 net.cpp:91] Creating Layer conv3_2a
I0413 18:22:28.674712 14009 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 18:22:28.674721 14009 net.cpp:399] conv3_2a -> conv3_2a
I0413 18:22:28.677647 14009 net.cpp:141] Setting up conv3_2a
I0413 18:22:28.677666 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.677672 14009 net.cpp:156] Memory required for data: 783289344
I0413 18:22:28.677683 14009 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 18:22:28.677695 14009 net.cpp:91] Creating Layer bn_conv3_2a
I0413 18:22:28.677701 14009 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 18:22:28.677712 14009 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 18:22:28.677919 14009 net.cpp:141] Setting up bn_conv3_2a
I0413 18:22:28.677929 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.677934 14009 net.cpp:156] Memory required for data: 791677952
I0413 18:22:28.677945 14009 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:22:28.677956 14009 net.cpp:91] Creating Layer scale_conv3_2a
I0413 18:22:28.677963 14009 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 18:22:28.677969 14009 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 18:22:28.678009 14009 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:22:28.678133 14009 net.cpp:141] Setting up scale_conv3_2a
I0413 18:22:28.678143 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.678148 14009 net.cpp:156] Memory required for data: 800066560
I0413 18:22:28.678156 14009 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 18:22:28.678164 14009 net.cpp:91] Creating Layer conv3_2a_relu
I0413 18:22:28.678169 14009 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 18:22:28.678180 14009 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 18:22:28.678534 14009 net.cpp:141] Setting up conv3_2a_relu
I0413 18:22:28.678547 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.678553 14009 net.cpp:156] Memory required for data: 808455168
I0413 18:22:28.678560 14009 layer_factory.hpp:77] Creating layer conv3_2b
I0413 18:22:28.678573 14009 net.cpp:91] Creating Layer conv3_2b
I0413 18:22:28.678580 14009 net.cpp:425] conv3_2b <- conv3_2a
I0413 18:22:28.678589 14009 net.cpp:399] conv3_2b -> conv3_2b
I0413 18:22:28.681722 14009 net.cpp:141] Setting up conv3_2b
I0413 18:22:28.681740 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.681746 14009 net.cpp:156] Memory required for data: 816843776
I0413 18:22:28.681756 14009 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 18:22:28.681766 14009 net.cpp:91] Creating Layer bn_conv3_2b
I0413 18:22:28.681772 14009 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 18:22:28.681782 14009 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 18:22:28.681989 14009 net.cpp:141] Setting up bn_conv3_2b
I0413 18:22:28.681999 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.682004 14009 net.cpp:156] Memory required for data: 825232384
I0413 18:22:28.682015 14009 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:22:28.682024 14009 net.cpp:91] Creating Layer scale_conv3_2b
I0413 18:22:28.682029 14009 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 18:22:28.682037 14009 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 18:22:28.682078 14009 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:22:28.682201 14009 net.cpp:141] Setting up scale_conv3_2b
I0413 18:22:28.682211 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.682216 14009 net.cpp:156] Memory required for data: 833620992
I0413 18:22:28.682225 14009 layer_factory.hpp:77] Creating layer conv3_2
I0413 18:22:28.682235 14009 net.cpp:91] Creating Layer conv3_2
I0413 18:22:28.682241 14009 net.cpp:425] conv3_2 <- conv3_2b
I0413 18:22:28.682253 14009 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 18:22:28.682261 14009 net.cpp:399] conv3_2 -> conv3_2
I0413 18:22:28.682284 14009 net.cpp:141] Setting up conv3_2
I0413 18:22:28.682293 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.682299 14009 net.cpp:156] Memory required for data: 842009600
I0413 18:22:28.682304 14009 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 18:22:28.682314 14009 net.cpp:91] Creating Layer conv3_2_relu
I0413 18:22:28.682320 14009 net.cpp:425] conv3_2_relu <- conv3_2
I0413 18:22:28.682327 14009 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 18:22:28.682756 14009 net.cpp:141] Setting up conv3_2_relu
I0413 18:22:28.682772 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.682778 14009 net.cpp:156] Memory required for data: 850398208
I0413 18:22:28.682785 14009 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 18:22:28.682796 14009 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 18:22:28.682801 14009 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 18:22:28.682809 14009 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 18:22:28.682821 14009 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 18:22:28.682873 14009 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 18:22:28.682883 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.682890 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.682896 14009 net.cpp:156] Memory required for data: 867175424
I0413 18:22:28.682901 14009 layer_factory.hpp:77] Creating layer conv3_3a
I0413 18:22:28.682916 14009 net.cpp:91] Creating Layer conv3_3a
I0413 18:22:28.682922 14009 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 18:22:28.682934 14009 net.cpp:399] conv3_3a -> conv3_3a
I0413 18:22:28.686281 14009 net.cpp:141] Setting up conv3_3a
I0413 18:22:28.686300 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.686306 14009 net.cpp:156] Memory required for data: 875564032
I0413 18:22:28.686317 14009 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 18:22:28.686329 14009 net.cpp:91] Creating Layer bn_conv3_3a
I0413 18:22:28.686336 14009 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 18:22:28.686345 14009 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 18:22:28.686556 14009 net.cpp:141] Setting up bn_conv3_3a
I0413 18:22:28.686566 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.686571 14009 net.cpp:156] Memory required for data: 883952640
I0413 18:22:28.686583 14009 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:22:28.686594 14009 net.cpp:91] Creating Layer scale_conv3_3a
I0413 18:22:28.686599 14009 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 18:22:28.686607 14009 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 18:22:28.686647 14009 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:22:28.686774 14009 net.cpp:141] Setting up scale_conv3_3a
I0413 18:22:28.686784 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.686789 14009 net.cpp:156] Memory required for data: 892341248
I0413 18:22:28.686799 14009 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 18:22:28.686806 14009 net.cpp:91] Creating Layer conv3_3a_relu
I0413 18:22:28.686811 14009 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 18:22:28.686820 14009 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 18:22:28.687441 14009 net.cpp:141] Setting up conv3_3a_relu
I0413 18:22:28.687455 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.687461 14009 net.cpp:156] Memory required for data: 900729856
I0413 18:22:28.687468 14009 layer_factory.hpp:77] Creating layer conv3_3b
I0413 18:22:28.687489 14009 net.cpp:91] Creating Layer conv3_3b
I0413 18:22:28.687495 14009 net.cpp:425] conv3_3b <- conv3_3a
I0413 18:22:28.687505 14009 net.cpp:399] conv3_3b -> conv3_3b
I0413 18:22:28.690953 14009 net.cpp:141] Setting up conv3_3b
I0413 18:22:28.690973 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.690984 14009 net.cpp:156] Memory required for data: 909118464
I0413 18:22:28.690994 14009 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 18:22:28.691006 14009 net.cpp:91] Creating Layer bn_conv3_3b
I0413 18:22:28.691012 14009 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 18:22:28.691022 14009 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 18:22:28.691236 14009 net.cpp:141] Setting up bn_conv3_3b
I0413 18:22:28.691246 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.691251 14009 net.cpp:156] Memory required for data: 917507072
I0413 18:22:28.691262 14009 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:22:28.691272 14009 net.cpp:91] Creating Layer scale_conv3_3b
I0413 18:22:28.691278 14009 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 18:22:28.691285 14009 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 18:22:28.691325 14009 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:22:28.691449 14009 net.cpp:141] Setting up scale_conv3_3b
I0413 18:22:28.691459 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.691464 14009 net.cpp:156] Memory required for data: 925895680
I0413 18:22:28.691473 14009 layer_factory.hpp:77] Creating layer conv3_3
I0413 18:22:28.691481 14009 net.cpp:91] Creating Layer conv3_3
I0413 18:22:28.691486 14009 net.cpp:425] conv3_3 <- conv3_3b
I0413 18:22:28.691493 14009 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 18:22:28.691504 14009 net.cpp:399] conv3_3 -> conv3_3
I0413 18:22:28.691526 14009 net.cpp:141] Setting up conv3_3
I0413 18:22:28.691535 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.691540 14009 net.cpp:156] Memory required for data: 934284288
I0413 18:22:28.691545 14009 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 18:22:28.691555 14009 net.cpp:91] Creating Layer conv3_3_relu
I0413 18:22:28.691560 14009 net.cpp:425] conv3_3_relu <- conv3_3
I0413 18:22:28.691567 14009 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 18:22:28.691972 14009 net.cpp:141] Setting up conv3_3_relu
I0413 18:22:28.691984 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.691989 14009 net.cpp:156] Memory required for data: 942672896
I0413 18:22:28.691995 14009 layer_factory.hpp:77] Creating layer conv3_3_conv3_3_relu_0_split
I0413 18:22:28.692005 14009 net.cpp:91] Creating Layer conv3_3_conv3_3_relu_0_split
I0413 18:22:28.692011 14009 net.cpp:425] conv3_3_conv3_3_relu_0_split <- conv3_3
I0413 18:22:28.692023 14009 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_0
I0413 18:22:28.692033 14009 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_1
I0413 18:22:28.692080 14009 net.cpp:141] Setting up conv3_3_conv3_3_relu_0_split
I0413 18:22:28.692088 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.692095 14009 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:22:28.692101 14009 net.cpp:156] Memory required for data: 959450112
I0413 18:22:28.692106 14009 layer_factory.hpp:77] Creating layer conv3_sub
I0413 18:22:28.692119 14009 net.cpp:91] Creating Layer conv3_sub
I0413 18:22:28.692126 14009 net.cpp:425] conv3_sub <- conv3_3_conv3_3_relu_0_split_0
I0413 18:22:28.692137 14009 net.cpp:399] conv3_sub -> conv3_sub
I0413 18:22:28.695494 14009 net.cpp:141] Setting up conv3_sub
I0413 18:22:28.695513 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.695519 14009 net.cpp:156] Memory required for data: 963644416
I0413 18:22:28.695529 14009 layer_factory.hpp:77] Creating layer bn_conv3_sub
I0413 18:22:28.695541 14009 net.cpp:91] Creating Layer bn_conv3_sub
I0413 18:22:28.695549 14009 net.cpp:425] bn_conv3_sub <- conv3_sub
I0413 18:22:28.695556 14009 net.cpp:386] bn_conv3_sub -> conv3_sub (in-place)
I0413 18:22:28.695777 14009 net.cpp:141] Setting up bn_conv3_sub
I0413 18:22:28.695787 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.695792 14009 net.cpp:156] Memory required for data: 967838720
I0413 18:22:28.695803 14009 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:22:28.695817 14009 net.cpp:91] Creating Layer scale_conv3_sub
I0413 18:22:28.695823 14009 net.cpp:425] scale_conv3_sub <- conv3_sub
I0413 18:22:28.695830 14009 net.cpp:386] scale_conv3_sub -> conv3_sub (in-place)
I0413 18:22:28.695876 14009 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:22:28.696008 14009 net.cpp:141] Setting up scale_conv3_sub
I0413 18:22:28.696020 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.696025 14009 net.cpp:156] Memory required for data: 972033024
I0413 18:22:28.696034 14009 layer_factory.hpp:77] Creating layer conv4_1a
I0413 18:22:28.696049 14009 net.cpp:91] Creating Layer conv4_1a
I0413 18:22:28.696055 14009 net.cpp:425] conv4_1a <- conv3_3_conv3_3_relu_0_split_1
I0413 18:22:28.696064 14009 net.cpp:399] conv4_1a -> conv4_1a
I0413 18:22:28.698890 14009 net.cpp:141] Setting up conv4_1a
I0413 18:22:28.698909 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.698915 14009 net.cpp:156] Memory required for data: 976227328
I0413 18:22:28.698925 14009 layer_factory.hpp:77] Creating layer bn_conv4_1a
I0413 18:22:28.698937 14009 net.cpp:91] Creating Layer bn_conv4_1a
I0413 18:22:28.698945 14009 net.cpp:425] bn_conv4_1a <- conv4_1a
I0413 18:22:28.698952 14009 net.cpp:386] bn_conv4_1a -> conv4_1a (in-place)
I0413 18:22:28.699177 14009 net.cpp:141] Setting up bn_conv4_1a
I0413 18:22:28.699187 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.699193 14009 net.cpp:156] Memory required for data: 980421632
I0413 18:22:28.699203 14009 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:22:28.699218 14009 net.cpp:91] Creating Layer scale_conv4_1a
I0413 18:22:28.699223 14009 net.cpp:425] scale_conv4_1a <- conv4_1a
I0413 18:22:28.699230 14009 net.cpp:386] scale_conv4_1a -> conv4_1a (in-place)
I0413 18:22:28.699275 14009 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:22:28.699404 14009 net.cpp:141] Setting up scale_conv4_1a
I0413 18:22:28.699414 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.699419 14009 net.cpp:156] Memory required for data: 984615936
I0413 18:22:28.699429 14009 layer_factory.hpp:77] Creating layer conv4_1a_relu
I0413 18:22:28.699439 14009 net.cpp:91] Creating Layer conv4_1a_relu
I0413 18:22:28.699445 14009 net.cpp:425] conv4_1a_relu <- conv4_1a
I0413 18:22:28.699450 14009 net.cpp:386] conv4_1a_relu -> conv4_1a (in-place)
I0413 18:22:28.699909 14009 net.cpp:141] Setting up conv4_1a_relu
I0413 18:22:28.699925 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.699931 14009 net.cpp:156] Memory required for data: 988810240
I0413 18:22:28.699937 14009 layer_factory.hpp:77] Creating layer conv4_1b
I0413 18:22:28.699954 14009 net.cpp:91] Creating Layer conv4_1b
I0413 18:22:28.699961 14009 net.cpp:425] conv4_1b <- conv4_1a
I0413 18:22:28.699970 14009 net.cpp:399] conv4_1b -> conv4_1b
I0413 18:22:28.704807 14009 net.cpp:141] Setting up conv4_1b
I0413 18:22:28.704826 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.704833 14009 net.cpp:156] Memory required for data: 993004544
I0413 18:22:28.704843 14009 layer_factory.hpp:77] Creating layer bn_conv4_1b
I0413 18:22:28.704854 14009 net.cpp:91] Creating Layer bn_conv4_1b
I0413 18:22:28.704861 14009 net.cpp:425] bn_conv4_1b <- conv4_1b
I0413 18:22:28.704869 14009 net.cpp:386] bn_conv4_1b -> conv4_1b (in-place)
I0413 18:22:28.705093 14009 net.cpp:141] Setting up bn_conv4_1b
I0413 18:22:28.705104 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.705114 14009 net.cpp:156] Memory required for data: 997198848
I0413 18:22:28.705133 14009 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:22:28.705143 14009 net.cpp:91] Creating Layer scale_conv4_1b
I0413 18:22:28.705149 14009 net.cpp:425] scale_conv4_1b <- conv4_1b
I0413 18:22:28.705157 14009 net.cpp:386] scale_conv4_1b -> conv4_1b (in-place)
I0413 18:22:28.705204 14009 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:22:28.705340 14009 net.cpp:141] Setting up scale_conv4_1b
I0413 18:22:28.705350 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.705360 14009 net.cpp:156] Memory required for data: 1001393152
I0413 18:22:28.705370 14009 layer_factory.hpp:77] Creating layer conv4_1
I0413 18:22:28.705380 14009 net.cpp:91] Creating Layer conv4_1
I0413 18:22:28.705386 14009 net.cpp:425] conv4_1 <- conv3_sub
I0413 18:22:28.705392 14009 net.cpp:425] conv4_1 <- conv4_1b
I0413 18:22:28.705399 14009 net.cpp:399] conv4_1 -> conv4_1
I0413 18:22:28.705425 14009 net.cpp:141] Setting up conv4_1
I0413 18:22:28.705440 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.705445 14009 net.cpp:156] Memory required for data: 1005587456
I0413 18:22:28.705449 14009 layer_factory.hpp:77] Creating layer conv4_1_relu
I0413 18:22:28.705459 14009 net.cpp:91] Creating Layer conv4_1_relu
I0413 18:22:28.705466 14009 net.cpp:425] conv4_1_relu <- conv4_1
I0413 18:22:28.705472 14009 net.cpp:386] conv4_1_relu -> conv4_1 (in-place)
I0413 18:22:28.705832 14009 net.cpp:141] Setting up conv4_1_relu
I0413 18:22:28.705848 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.705854 14009 net.cpp:156] Memory required for data: 1009781760
I0413 18:22:28.705860 14009 layer_factory.hpp:77] Creating layer conv4_1_conv4_1_relu_0_split
I0413 18:22:28.705868 14009 net.cpp:91] Creating Layer conv4_1_conv4_1_relu_0_split
I0413 18:22:28.705874 14009 net.cpp:425] conv4_1_conv4_1_relu_0_split <- conv4_1
I0413 18:22:28.705884 14009 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_0
I0413 18:22:28.705894 14009 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_1
I0413 18:22:28.705945 14009 net.cpp:141] Setting up conv4_1_conv4_1_relu_0_split
I0413 18:22:28.705956 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.705962 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.705967 14009 net.cpp:156] Memory required for data: 1018170368
I0413 18:22:28.705973 14009 layer_factory.hpp:77] Creating layer conv4_2a
I0413 18:22:28.705991 14009 net.cpp:91] Creating Layer conv4_2a
I0413 18:22:28.705996 14009 net.cpp:425] conv4_2a <- conv4_1_conv4_1_relu_0_split_0
I0413 18:22:28.706006 14009 net.cpp:399] conv4_2a -> conv4_2a
I0413 18:22:28.709363 14009 net.cpp:141] Setting up conv4_2a
I0413 18:22:28.709381 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.709388 14009 net.cpp:156] Memory required for data: 1022364672
I0413 18:22:28.709398 14009 layer_factory.hpp:77] Creating layer bn_conv4_2a
I0413 18:22:28.709416 14009 net.cpp:91] Creating Layer bn_conv4_2a
I0413 18:22:28.709422 14009 net.cpp:425] bn_conv4_2a <- conv4_2a
I0413 18:22:28.709434 14009 net.cpp:386] bn_conv4_2a -> conv4_2a (in-place)
I0413 18:22:28.709678 14009 net.cpp:141] Setting up bn_conv4_2a
I0413 18:22:28.709688 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.709694 14009 net.cpp:156] Memory required for data: 1026558976
I0413 18:22:28.709704 14009 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:22:28.709715 14009 net.cpp:91] Creating Layer scale_conv4_2a
I0413 18:22:28.709722 14009 net.cpp:425] scale_conv4_2a <- conv4_2a
I0413 18:22:28.709728 14009 net.cpp:386] scale_conv4_2a -> conv4_2a (in-place)
I0413 18:22:28.709774 14009 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:22:28.709909 14009 net.cpp:141] Setting up scale_conv4_2a
I0413 18:22:28.709919 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.709925 14009 net.cpp:156] Memory required for data: 1030753280
I0413 18:22:28.709933 14009 layer_factory.hpp:77] Creating layer conv4_2a_relu
I0413 18:22:28.709945 14009 net.cpp:91] Creating Layer conv4_2a_relu
I0413 18:22:28.709951 14009 net.cpp:425] conv4_2a_relu <- conv4_2a
I0413 18:22:28.709957 14009 net.cpp:386] conv4_2a_relu -> conv4_2a (in-place)
I0413 18:22:28.710352 14009 net.cpp:141] Setting up conv4_2a_relu
I0413 18:22:28.710364 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.710369 14009 net.cpp:156] Memory required for data: 1034947584
I0413 18:22:28.710376 14009 layer_factory.hpp:77] Creating layer conv4_2b
I0413 18:22:28.710396 14009 net.cpp:91] Creating Layer conv4_2b
I0413 18:22:28.710402 14009 net.cpp:425] conv4_2b <- conv4_2a
I0413 18:22:28.710412 14009 net.cpp:399] conv4_2b -> conv4_2b
I0413 18:22:28.713883 14009 net.cpp:141] Setting up conv4_2b
I0413 18:22:28.713901 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.713908 14009 net.cpp:156] Memory required for data: 1039141888
I0413 18:22:28.713918 14009 layer_factory.hpp:77] Creating layer bn_conv4_2b
I0413 18:22:28.713932 14009 net.cpp:91] Creating Layer bn_conv4_2b
I0413 18:22:28.713939 14009 net.cpp:425] bn_conv4_2b <- conv4_2b
I0413 18:22:28.713948 14009 net.cpp:386] bn_conv4_2b -> conv4_2b (in-place)
I0413 18:22:28.714174 14009 net.cpp:141] Setting up bn_conv4_2b
I0413 18:22:28.714184 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.714190 14009 net.cpp:156] Memory required for data: 1043336192
I0413 18:22:28.714222 14009 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:22:28.714233 14009 net.cpp:91] Creating Layer scale_conv4_2b
I0413 18:22:28.714239 14009 net.cpp:425] scale_conv4_2b <- conv4_2b
I0413 18:22:28.714246 14009 net.cpp:386] scale_conv4_2b -> conv4_2b (in-place)
I0413 18:22:28.714296 14009 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:22:28.714434 14009 net.cpp:141] Setting up scale_conv4_2b
I0413 18:22:28.714445 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.714450 14009 net.cpp:156] Memory required for data: 1047530496
I0413 18:22:28.714459 14009 layer_factory.hpp:77] Creating layer conv4_2
I0413 18:22:28.714469 14009 net.cpp:91] Creating Layer conv4_2
I0413 18:22:28.714475 14009 net.cpp:425] conv4_2 <- conv4_1_conv4_1_relu_0_split_1
I0413 18:22:28.714483 14009 net.cpp:425] conv4_2 <- conv4_2b
I0413 18:22:28.714490 14009 net.cpp:399] conv4_2 -> conv4_2
I0413 18:22:28.714514 14009 net.cpp:141] Setting up conv4_2
I0413 18:22:28.714524 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.714529 14009 net.cpp:156] Memory required for data: 1051724800
I0413 18:22:28.714534 14009 layer_factory.hpp:77] Creating layer conv4_2_relu
I0413 18:22:28.714542 14009 net.cpp:91] Creating Layer conv4_2_relu
I0413 18:22:28.714547 14009 net.cpp:425] conv4_2_relu <- conv4_2
I0413 18:22:28.714556 14009 net.cpp:386] conv4_2_relu -> conv4_2 (in-place)
I0413 18:22:28.714895 14009 net.cpp:141] Setting up conv4_2_relu
I0413 18:22:28.714910 14009 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:22:28.714916 14009 net.cpp:156] Memory required for data: 1055919104
I0413 18:22:28.714921 14009 layer_factory.hpp:77] Creating layer global_pool
I0413 18:22:28.714932 14009 net.cpp:91] Creating Layer global_pool
I0413 18:22:28.714938 14009 net.cpp:425] global_pool <- conv4_2
I0413 18:22:28.714948 14009 net.cpp:399] global_pool -> global_pool
I0413 18:22:28.716050 14009 net.cpp:141] Setting up global_pool
I0413 18:22:28.716064 14009 net.cpp:148] Top shape: 256 64 1 1 (16384)
I0413 18:22:28.716070 14009 net.cpp:156] Memory required for data: 1055984640
I0413 18:22:28.716076 14009 layer_factory.hpp:77] Creating layer ip
I0413 18:22:28.716087 14009 net.cpp:91] Creating Layer ip
I0413 18:22:28.716094 14009 net.cpp:425] ip <- global_pool
I0413 18:22:28.716104 14009 net.cpp:399] ip -> ip
I0413 18:22:28.716235 14009 net.cpp:141] Setting up ip
I0413 18:22:28.716248 14009 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:22:28.716253 14009 net.cpp:156] Memory required for data: 1055994880
I0413 18:22:28.716262 14009 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 18:22:28.716270 14009 net.cpp:91] Creating Layer ip_ip_0_split
I0413 18:22:28.716276 14009 net.cpp:425] ip_ip_0_split <- ip
I0413 18:22:28.716284 14009 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 18:22:28.716292 14009 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 18:22:28.716334 14009 net.cpp:141] Setting up ip_ip_0_split
I0413 18:22:28.716343 14009 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:22:28.716351 14009 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:22:28.716356 14009 net.cpp:156] Memory required for data: 1056015360
I0413 18:22:28.716366 14009 layer_factory.hpp:77] Creating layer accuracy
I0413 18:22:28.716379 14009 net.cpp:91] Creating Layer accuracy
I0413 18:22:28.716384 14009 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 18:22:28.716392 14009 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 18:22:28.716398 14009 net.cpp:399] accuracy -> accuracy
I0413 18:22:28.716409 14009 net.cpp:141] Setting up accuracy
I0413 18:22:28.716418 14009 net.cpp:148] Top shape: (1)
I0413 18:22:28.716423 14009 net.cpp:156] Memory required for data: 1056015364
I0413 18:22:28.716428 14009 layer_factory.hpp:77] Creating layer loss
I0413 18:22:28.716439 14009 net.cpp:91] Creating Layer loss
I0413 18:22:28.716444 14009 net.cpp:425] loss <- ip_ip_0_split_1
I0413 18:22:28.716450 14009 net.cpp:425] loss <- label_cifar_1_split_1
I0413 18:22:28.716457 14009 net.cpp:399] loss -> loss
I0413 18:22:28.716475 14009 layer_factory.hpp:77] Creating layer loss
I0413 18:22:28.717270 14009 net.cpp:141] Setting up loss
I0413 18:22:28.717288 14009 net.cpp:148] Top shape: (1)
I0413 18:22:28.717294 14009 net.cpp:151]     with loss weight 1
I0413 18:22:28.717306 14009 net.cpp:156] Memory required for data: 1056015368
I0413 18:22:28.717313 14009 net.cpp:217] loss needs backward computation.
I0413 18:22:28.717319 14009 net.cpp:219] accuracy does not need backward computation.
I0413 18:22:28.717325 14009 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 18:22:28.717330 14009 net.cpp:217] ip needs backward computation.
I0413 18:22:28.717335 14009 net.cpp:217] global_pool needs backward computation.
I0413 18:22:28.717341 14009 net.cpp:217] conv4_2_relu needs backward computation.
I0413 18:22:28.717346 14009 net.cpp:217] conv4_2 needs backward computation.
I0413 18:22:28.717351 14009 net.cpp:217] scale_conv4_2b needs backward computation.
I0413 18:22:28.717356 14009 net.cpp:217] bn_conv4_2b needs backward computation.
I0413 18:22:28.717361 14009 net.cpp:217] conv4_2b needs backward computation.
I0413 18:22:28.717367 14009 net.cpp:217] conv4_2a_relu needs backward computation.
I0413 18:22:28.717372 14009 net.cpp:217] scale_conv4_2a needs backward computation.
I0413 18:22:28.717376 14009 net.cpp:217] bn_conv4_2a needs backward computation.
I0413 18:22:28.717381 14009 net.cpp:217] conv4_2a needs backward computation.
I0413 18:22:28.717391 14009 net.cpp:217] conv4_1_conv4_1_relu_0_split needs backward computation.
I0413 18:22:28.717397 14009 net.cpp:217] conv4_1_relu needs backward computation.
I0413 18:22:28.717402 14009 net.cpp:217] conv4_1 needs backward computation.
I0413 18:22:28.717408 14009 net.cpp:217] scale_conv4_1b needs backward computation.
I0413 18:22:28.717413 14009 net.cpp:217] bn_conv4_1b needs backward computation.
I0413 18:22:28.717417 14009 net.cpp:217] conv4_1b needs backward computation.
I0413 18:22:28.717423 14009 net.cpp:217] conv4_1a_relu needs backward computation.
I0413 18:22:28.717428 14009 net.cpp:217] scale_conv4_1a needs backward computation.
I0413 18:22:28.717432 14009 net.cpp:217] bn_conv4_1a needs backward computation.
I0413 18:22:28.717439 14009 net.cpp:217] conv4_1a needs backward computation.
I0413 18:22:28.717445 14009 net.cpp:217] scale_conv3_sub needs backward computation.
I0413 18:22:28.717450 14009 net.cpp:217] bn_conv3_sub needs backward computation.
I0413 18:22:28.717455 14009 net.cpp:217] conv3_sub needs backward computation.
I0413 18:22:28.717460 14009 net.cpp:217] conv3_3_conv3_3_relu_0_split needs backward computation.
I0413 18:22:28.717465 14009 net.cpp:217] conv3_3_relu needs backward computation.
I0413 18:22:28.717470 14009 net.cpp:217] conv3_3 needs backward computation.
I0413 18:22:28.717476 14009 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 18:22:28.717481 14009 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 18:22:28.717486 14009 net.cpp:217] conv3_3b needs backward computation.
I0413 18:22:28.717491 14009 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 18:22:28.717496 14009 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 18:22:28.717501 14009 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 18:22:28.717510 14009 net.cpp:217] conv3_3a needs backward computation.
I0413 18:22:28.717516 14009 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 18:22:28.717521 14009 net.cpp:217] conv3_2_relu needs backward computation.
I0413 18:22:28.717526 14009 net.cpp:217] conv3_2 needs backward computation.
I0413 18:22:28.717532 14009 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 18:22:28.717537 14009 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 18:22:28.717542 14009 net.cpp:217] conv3_2b needs backward computation.
I0413 18:22:28.717547 14009 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 18:22:28.717552 14009 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 18:22:28.717557 14009 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 18:22:28.717562 14009 net.cpp:217] conv3_2a needs backward computation.
I0413 18:22:28.717567 14009 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 18:22:28.717572 14009 net.cpp:217] conv3_1_relu needs backward computation.
I0413 18:22:28.717577 14009 net.cpp:217] conv3_1 needs backward computation.
I0413 18:22:28.717583 14009 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 18:22:28.717588 14009 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 18:22:28.717593 14009 net.cpp:217] conv3_1b needs backward computation.
I0413 18:22:28.717598 14009 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 18:22:28.717603 14009 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 18:22:28.717608 14009 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 18:22:28.717613 14009 net.cpp:217] conv3_1a needs backward computation.
I0413 18:22:28.717618 14009 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 18:22:28.717623 14009 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 18:22:28.717628 14009 net.cpp:217] conv2_sub needs backward computation.
I0413 18:22:28.717634 14009 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 18:22:28.717639 14009 net.cpp:217] conv2_3_relu needs backward computation.
I0413 18:22:28.717644 14009 net.cpp:217] conv2_3 needs backward computation.
I0413 18:22:28.717649 14009 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 18:22:28.717654 14009 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 18:22:28.717659 14009 net.cpp:217] conv2_3b needs backward computation.
I0413 18:22:28.717665 14009 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 18:22:28.717670 14009 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 18:22:28.717674 14009 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 18:22:28.717679 14009 net.cpp:217] conv2_3a needs backward computation.
I0413 18:22:28.717684 14009 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 18:22:28.717690 14009 net.cpp:217] conv2_2_relu needs backward computation.
I0413 18:22:28.717695 14009 net.cpp:217] conv2_2 needs backward computation.
I0413 18:22:28.717701 14009 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 18:22:28.717706 14009 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 18:22:28.717711 14009 net.cpp:217] conv2_2b needs backward computation.
I0413 18:22:28.717717 14009 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 18:22:28.717722 14009 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 18:22:28.717727 14009 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 18:22:28.717732 14009 net.cpp:217] conv2_2a needs backward computation.
I0413 18:22:28.717738 14009 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 18:22:28.717743 14009 net.cpp:217] conv2_1_relu needs backward computation.
I0413 18:22:28.717748 14009 net.cpp:217] conv2_1 needs backward computation.
I0413 18:22:28.717754 14009 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 18:22:28.717761 14009 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 18:22:28.717770 14009 net.cpp:217] conv2_1b needs backward computation.
I0413 18:22:28.717775 14009 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 18:22:28.717782 14009 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 18:22:28.717787 14009 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 18:22:28.717792 14009 net.cpp:217] conv2_1a needs backward computation.
I0413 18:22:28.717797 14009 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 18:22:28.717803 14009 net.cpp:217] conv1_relu needs backward computation.
I0413 18:22:28.717808 14009 net.cpp:217] scale_conv1 needs backward computation.
I0413 18:22:28.717813 14009 net.cpp:217] bn_conv1 needs backward computation.
I0413 18:22:28.717818 14009 net.cpp:217] conv1 needs backward computation.
I0413 18:22:28.717824 14009 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 18:22:28.717830 14009 net.cpp:219] cifar does not need backward computation.
I0413 18:22:28.717835 14009 net.cpp:261] This network produces output accuracy
I0413 18:22:28.717841 14009 net.cpp:261] This network produces output loss
I0413 18:22:28.717905 14009 net.cpp:274] Network initialization done.
I0413 18:22:28.720216 14009 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar7.prototxt
I0413 18:22:28.720345 14009 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 18:22:28.720861 14009 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_sub"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_sub"
  type: "BatchNorm"
  bottom: "conv3_sub"
  top: "conv3_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_sub"
  type: "Scale"
  bottom: "conv3_sub"
  top: "conv3_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv4_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1a"
  type: "BatchNorm"
  bottom: "conv4_1a"
  top: "conv4_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1a"
  type: "Scale"
  bottom: "conv4_1a"
  top: "conv4_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a_relu"
  type: "ReLU"
  bottom: "conv4_1a"
  top: "conv4_1a"
}
layer {
  name: "conv4_1b"
  type: "Convolution"
  bottom: "conv4_1a"
  top: "conv4_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1b"
  type: "BatchNorm"
  bottom: "conv4_1b"
  top: "conv4_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1b"
  type: "Scale"
  bottom: "conv4_1b"
  top: "conv4_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv3_sub"
  bottom: "conv4_1b"
  top: "conv4_1"
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2a"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2a"
  type: "BatchNorm"
  bottom: "conv4_2a"
  top: "conv4_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2a"
  type: "Scale"
  bottom: "conv4_2a"
  top: "conv4_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2a_relu"
  type: "ReLU"
  bottom: "conv4_2a"
  top: "conv4_2a"
}
layer {
  name: "conv4_2b"
  type: "Convolution"
  bottom: "conv4_2a"
  top: "conv4_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2b"
  type: "BatchNorm"
  bottom: "conv4_2b"
  top: "conv4_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2b"
  type: "Scale"
  bottom: "conv4_2b"
  top: "conv4_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_2b"
  top: "conv4_2"
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv4_2"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 18:22:28.721309 14009 layer_factory.hpp:77] Creating layer cifar
I0413 18:22:28.721467 14009 net.cpp:91] Creating Layer cifar
I0413 18:22:28.721480 14009 net.cpp:399] cifar -> data
I0413 18:22:28.721493 14009 net.cpp:399] cifar -> label
I0413 18:22:28.721513 14009 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 18:22:28.722332 14367 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 18:22:28.722476 14009 data_layer.cpp:41] output data size: 100,3,32,32
I0413 18:22:28.728919 14009 net.cpp:141] Setting up cifar
I0413 18:22:28.728938 14009 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 18:22:28.728947 14009 net.cpp:148] Top shape: 100 (100)
I0413 18:22:28.728952 14009 net.cpp:156] Memory required for data: 1229200
I0413 18:22:28.728960 14009 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 18:22:28.728976 14009 net.cpp:91] Creating Layer label_cifar_1_split
I0413 18:22:28.728981 14009 net.cpp:425] label_cifar_1_split <- label
I0413 18:22:28.728989 14009 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 18:22:28.729002 14009 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 18:22:28.729085 14009 net.cpp:141] Setting up label_cifar_1_split
I0413 18:22:28.729097 14009 net.cpp:148] Top shape: 100 (100)
I0413 18:22:28.729104 14009 net.cpp:148] Top shape: 100 (100)
I0413 18:22:28.729109 14009 net.cpp:156] Memory required for data: 1230000
I0413 18:22:28.729127 14009 layer_factory.hpp:77] Creating layer conv1
I0413 18:22:28.729143 14009 net.cpp:91] Creating Layer conv1
I0413 18:22:28.729149 14009 net.cpp:425] conv1 <- data
I0413 18:22:28.729161 14009 net.cpp:399] conv1 -> conv1
I0413 18:22:28.733762 14009 net.cpp:141] Setting up conv1
I0413 18:22:28.733785 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.733793 14009 net.cpp:156] Memory required for data: 7783600
I0413 18:22:28.733806 14009 layer_factory.hpp:77] Creating layer bn_conv1
I0413 18:22:28.733817 14009 net.cpp:91] Creating Layer bn_conv1
I0413 18:22:28.733824 14009 net.cpp:425] bn_conv1 <- conv1
I0413 18:22:28.733834 14009 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 18:22:28.734077 14009 net.cpp:141] Setting up bn_conv1
I0413 18:22:28.734087 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.734092 14009 net.cpp:156] Memory required for data: 14337200
I0413 18:22:28.734108 14009 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:22:28.734119 14009 net.cpp:91] Creating Layer scale_conv1
I0413 18:22:28.734125 14009 net.cpp:425] scale_conv1 <- conv1
I0413 18:22:28.734135 14009 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 18:22:28.734187 14009 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:22:28.734325 14009 net.cpp:141] Setting up scale_conv1
I0413 18:22:28.734336 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.734343 14009 net.cpp:156] Memory required for data: 20890800
I0413 18:22:28.734351 14009 layer_factory.hpp:77] Creating layer conv1_relu
I0413 18:22:28.734359 14009 net.cpp:91] Creating Layer conv1_relu
I0413 18:22:28.734376 14009 net.cpp:425] conv1_relu <- conv1
I0413 18:22:28.734383 14009 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 18:22:28.734601 14009 net.cpp:141] Setting up conv1_relu
I0413 18:22:28.734614 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.734625 14009 net.cpp:156] Memory required for data: 27444400
I0413 18:22:28.734632 14009 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 18:22:28.734652 14009 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 18:22:28.734658 14009 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 18:22:28.734665 14009 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 18:22:28.734684 14009 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 18:22:28.734741 14009 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 18:22:28.734752 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.734758 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.734763 14009 net.cpp:156] Memory required for data: 40551600
I0413 18:22:28.734769 14009 layer_factory.hpp:77] Creating layer conv2_1a
I0413 18:22:28.734783 14009 net.cpp:91] Creating Layer conv2_1a
I0413 18:22:28.734789 14009 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 18:22:28.734799 14009 net.cpp:399] conv2_1a -> conv2_1a
I0413 18:22:28.743818 14009 net.cpp:141] Setting up conv2_1a
I0413 18:22:28.743860 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.743866 14009 net.cpp:156] Memory required for data: 47105200
I0413 18:22:28.743906 14009 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 18:22:28.743981 14009 net.cpp:91] Creating Layer bn_conv2_1a
I0413 18:22:28.743998 14009 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 18:22:28.744015 14009 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 18:22:28.745273 14009 net.cpp:141] Setting up bn_conv2_1a
I0413 18:22:28.745288 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.745295 14009 net.cpp:156] Memory required for data: 53658800
I0413 18:22:28.745306 14009 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:22:28.745332 14009 net.cpp:91] Creating Layer scale_conv2_1a
I0413 18:22:28.745339 14009 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 18:22:28.745347 14009 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 18:22:28.745604 14009 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:22:28.745759 14009 net.cpp:141] Setting up scale_conv2_1a
I0413 18:22:28.745772 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.745779 14009 net.cpp:156] Memory required for data: 60212400
I0413 18:22:28.745787 14009 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 18:22:28.745817 14009 net.cpp:91] Creating Layer conv2_1a_relu
I0413 18:22:28.745825 14009 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 18:22:28.745836 14009 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 18:22:28.746660 14009 net.cpp:141] Setting up conv2_1a_relu
I0413 18:22:28.746678 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.746687 14009 net.cpp:156] Memory required for data: 66766000
I0413 18:22:28.746695 14009 layer_factory.hpp:77] Creating layer conv2_1b
I0413 18:22:28.746737 14009 net.cpp:91] Creating Layer conv2_1b
I0413 18:22:28.746743 14009 net.cpp:425] conv2_1b <- conv2_1a
I0413 18:22:28.746762 14009 net.cpp:399] conv2_1b -> conv2_1b
I0413 18:22:28.750358 14009 net.cpp:141] Setting up conv2_1b
I0413 18:22:28.750380 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.750387 14009 net.cpp:156] Memory required for data: 73319600
I0413 18:22:28.750408 14009 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 18:22:28.750437 14009 net.cpp:91] Creating Layer bn_conv2_1b
I0413 18:22:28.750444 14009 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 18:22:28.750458 14009 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 18:22:28.750707 14009 net.cpp:141] Setting up bn_conv2_1b
I0413 18:22:28.750718 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.750725 14009 net.cpp:156] Memory required for data: 79873200
I0413 18:22:28.750744 14009 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:22:28.750771 14009 net.cpp:91] Creating Layer scale_conv2_1b
I0413 18:22:28.750782 14009 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 18:22:28.750789 14009 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 18:22:28.750847 14009 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:22:28.751001 14009 net.cpp:141] Setting up scale_conv2_1b
I0413 18:22:28.751015 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.751021 14009 net.cpp:156] Memory required for data: 86426800
I0413 18:22:28.751039 14009 layer_factory.hpp:77] Creating layer conv2_1
I0413 18:22:28.751049 14009 net.cpp:91] Creating Layer conv2_1
I0413 18:22:28.751055 14009 net.cpp:425] conv2_1 <- conv2_1b
I0413 18:22:28.751062 14009 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 18:22:28.751070 14009 net.cpp:399] conv2_1 -> conv2_1
I0413 18:22:28.751104 14009 net.cpp:141] Setting up conv2_1
I0413 18:22:28.751117 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.751122 14009 net.cpp:156] Memory required for data: 92980400
I0413 18:22:28.751128 14009 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 18:22:28.751135 14009 net.cpp:91] Creating Layer conv2_1_relu
I0413 18:22:28.751140 14009 net.cpp:425] conv2_1_relu <- conv2_1
I0413 18:22:28.751149 14009 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 18:22:28.751509 14009 net.cpp:141] Setting up conv2_1_relu
I0413 18:22:28.751525 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.751543 14009 net.cpp:156] Memory required for data: 99534000
I0413 18:22:28.751557 14009 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 18:22:28.751571 14009 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 18:22:28.751577 14009 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 18:22:28.751595 14009 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 18:22:28.751605 14009 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 18:22:28.751665 14009 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 18:22:28.751677 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.751684 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.751690 14009 net.cpp:156] Memory required for data: 112641200
I0413 18:22:28.751695 14009 layer_factory.hpp:77] Creating layer conv2_2a
I0413 18:22:28.751721 14009 net.cpp:91] Creating Layer conv2_2a
I0413 18:22:28.751729 14009 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 18:22:28.751742 14009 net.cpp:399] conv2_2a -> conv2_2a
I0413 18:22:28.754604 14009 net.cpp:141] Setting up conv2_2a
I0413 18:22:28.754623 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.754631 14009 net.cpp:156] Memory required for data: 119194800
I0413 18:22:28.754640 14009 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 18:22:28.754649 14009 net.cpp:91] Creating Layer bn_conv2_2a
I0413 18:22:28.754657 14009 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 18:22:28.754667 14009 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 18:22:28.754912 14009 net.cpp:141] Setting up bn_conv2_2a
I0413 18:22:28.754922 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.754928 14009 net.cpp:156] Memory required for data: 125748400
I0413 18:22:28.754938 14009 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:22:28.754953 14009 net.cpp:91] Creating Layer scale_conv2_2a
I0413 18:22:28.754961 14009 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 18:22:28.754969 14009 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 18:22:28.755020 14009 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:22:28.755162 14009 net.cpp:141] Setting up scale_conv2_2a
I0413 18:22:28.755175 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.755180 14009 net.cpp:156] Memory required for data: 132302000
I0413 18:22:28.755194 14009 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 18:22:28.755211 14009 net.cpp:91] Creating Layer conv2_2a_relu
I0413 18:22:28.755218 14009 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 18:22:28.755223 14009 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 18:22:28.755626 14009 net.cpp:141] Setting up conv2_2a_relu
I0413 18:22:28.755640 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.755650 14009 net.cpp:156] Memory required for data: 138855600
I0413 18:22:28.755656 14009 layer_factory.hpp:77] Creating layer conv2_2b
I0413 18:22:28.755676 14009 net.cpp:91] Creating Layer conv2_2b
I0413 18:22:28.755682 14009 net.cpp:425] conv2_2b <- conv2_2a
I0413 18:22:28.755693 14009 net.cpp:399] conv2_2b -> conv2_2b
I0413 18:22:28.759167 14009 net.cpp:141] Setting up conv2_2b
I0413 18:22:28.759186 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.759192 14009 net.cpp:156] Memory required for data: 145409200
I0413 18:22:28.759202 14009 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 18:22:28.759212 14009 net.cpp:91] Creating Layer bn_conv2_2b
I0413 18:22:28.759218 14009 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 18:22:28.759230 14009 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 18:22:28.759479 14009 net.cpp:141] Setting up bn_conv2_2b
I0413 18:22:28.759490 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.759495 14009 net.cpp:156] Memory required for data: 151962800
I0413 18:22:28.759512 14009 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:22:28.759521 14009 net.cpp:91] Creating Layer scale_conv2_2b
I0413 18:22:28.759527 14009 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 18:22:28.759534 14009 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 18:22:28.759588 14009 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:22:28.759728 14009 net.cpp:141] Setting up scale_conv2_2b
I0413 18:22:28.759739 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.759744 14009 net.cpp:156] Memory required for data: 158516400
I0413 18:22:28.759759 14009 layer_factory.hpp:77] Creating layer conv2_2
I0413 18:22:28.759769 14009 net.cpp:91] Creating Layer conv2_2
I0413 18:22:28.759775 14009 net.cpp:425] conv2_2 <- conv2_2b
I0413 18:22:28.759781 14009 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 18:22:28.759789 14009 net.cpp:399] conv2_2 -> conv2_2
I0413 18:22:28.759821 14009 net.cpp:141] Setting up conv2_2
I0413 18:22:28.759830 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.759836 14009 net.cpp:156] Memory required for data: 165070000
I0413 18:22:28.759841 14009 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 18:22:28.759848 14009 net.cpp:91] Creating Layer conv2_2_relu
I0413 18:22:28.759853 14009 net.cpp:425] conv2_2_relu <- conv2_2
I0413 18:22:28.759862 14009 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 18:22:28.760175 14009 net.cpp:141] Setting up conv2_2_relu
I0413 18:22:28.760190 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.760195 14009 net.cpp:156] Memory required for data: 171623600
I0413 18:22:28.760200 14009 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 18:22:28.760208 14009 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 18:22:28.760213 14009 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 18:22:28.760221 14009 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 18:22:28.760231 14009 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 18:22:28.760287 14009 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 18:22:28.760295 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.760303 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.760308 14009 net.cpp:156] Memory required for data: 184730800
I0413 18:22:28.760313 14009 layer_factory.hpp:77] Creating layer conv2_3a
I0413 18:22:28.760337 14009 net.cpp:91] Creating Layer conv2_3a
I0413 18:22:28.760344 14009 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 18:22:28.760352 14009 net.cpp:399] conv2_3a -> conv2_3a
I0413 18:22:28.763706 14009 net.cpp:141] Setting up conv2_3a
I0413 18:22:28.763725 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.763731 14009 net.cpp:156] Memory required for data: 191284400
I0413 18:22:28.763747 14009 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 18:22:28.763767 14009 net.cpp:91] Creating Layer bn_conv2_3a
I0413 18:22:28.763778 14009 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 18:22:28.763789 14009 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 18:22:28.764044 14009 net.cpp:141] Setting up bn_conv2_3a
I0413 18:22:28.764055 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.764060 14009 net.cpp:156] Memory required for data: 197838000
I0413 18:22:28.764070 14009 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:22:28.764086 14009 net.cpp:91] Creating Layer scale_conv2_3a
I0413 18:22:28.764092 14009 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 18:22:28.764099 14009 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 18:22:28.764155 14009 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:22:28.764300 14009 net.cpp:141] Setting up scale_conv2_3a
I0413 18:22:28.764310 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.764315 14009 net.cpp:156] Memory required for data: 204391600
I0413 18:22:28.764324 14009 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 18:22:28.764331 14009 net.cpp:91] Creating Layer conv2_3a_relu
I0413 18:22:28.764338 14009 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 18:22:28.764348 14009 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 18:22:28.764787 14009 net.cpp:141] Setting up conv2_3a_relu
I0413 18:22:28.764803 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.764809 14009 net.cpp:156] Memory required for data: 210945200
I0413 18:22:28.764816 14009 layer_factory.hpp:77] Creating layer conv2_3b
I0413 18:22:28.764837 14009 net.cpp:91] Creating Layer conv2_3b
I0413 18:22:28.764844 14009 net.cpp:425] conv2_3b <- conv2_3a
I0413 18:22:28.764854 14009 net.cpp:399] conv2_3b -> conv2_3b
I0413 18:22:28.769600 14009 net.cpp:141] Setting up conv2_3b
I0413 18:22:28.769619 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.769625 14009 net.cpp:156] Memory required for data: 217498800
I0413 18:22:28.769641 14009 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 18:22:28.769655 14009 net.cpp:91] Creating Layer bn_conv2_3b
I0413 18:22:28.769662 14009 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 18:22:28.769670 14009 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 18:22:28.769922 14009 net.cpp:141] Setting up bn_conv2_3b
I0413 18:22:28.769932 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.769937 14009 net.cpp:156] Memory required for data: 224052400
I0413 18:22:28.769948 14009 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:22:28.769955 14009 net.cpp:91] Creating Layer scale_conv2_3b
I0413 18:22:28.769961 14009 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 18:22:28.769969 14009 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 18:22:28.770023 14009 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:22:28.770169 14009 net.cpp:141] Setting up scale_conv2_3b
I0413 18:22:28.770179 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.770184 14009 net.cpp:156] Memory required for data: 230606000
I0413 18:22:28.770192 14009 layer_factory.hpp:77] Creating layer conv2_3
I0413 18:22:28.770200 14009 net.cpp:91] Creating Layer conv2_3
I0413 18:22:28.770207 14009 net.cpp:425] conv2_3 <- conv2_3b
I0413 18:22:28.770215 14009 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 18:22:28.770221 14009 net.cpp:399] conv2_3 -> conv2_3
I0413 18:22:28.770251 14009 net.cpp:141] Setting up conv2_3
I0413 18:22:28.770261 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.770267 14009 net.cpp:156] Memory required for data: 237159600
I0413 18:22:28.770272 14009 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 18:22:28.770280 14009 net.cpp:91] Creating Layer conv2_3_relu
I0413 18:22:28.770287 14009 net.cpp:425] conv2_3_relu <- conv2_3
I0413 18:22:28.770292 14009 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 18:22:28.770619 14009 net.cpp:141] Setting up conv2_3_relu
I0413 18:22:28.770632 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.770637 14009 net.cpp:156] Memory required for data: 243713200
I0413 18:22:28.770656 14009 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 18:22:28.770668 14009 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 18:22:28.770673 14009 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 18:22:28.770680 14009 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 18:22:28.770690 14009 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 18:22:28.770746 14009 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 18:22:28.770756 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.770762 14009 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:22:28.770767 14009 net.cpp:156] Memory required for data: 256820400
I0413 18:22:28.770772 14009 layer_factory.hpp:77] Creating layer conv2_sub
I0413 18:22:28.770792 14009 net.cpp:91] Creating Layer conv2_sub
I0413 18:22:28.770798 14009 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 18:22:28.770809 14009 net.cpp:399] conv2_sub -> conv2_sub
I0413 18:22:28.774189 14009 net.cpp:141] Setting up conv2_sub
I0413 18:22:28.774210 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.774217 14009 net.cpp:156] Memory required for data: 260097200
I0413 18:22:28.774227 14009 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 18:22:28.774237 14009 net.cpp:91] Creating Layer bn_conv2_sub
I0413 18:22:28.774243 14009 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 18:22:28.774253 14009 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 18:22:28.774502 14009 net.cpp:141] Setting up bn_conv2_sub
I0413 18:22:28.774513 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.774518 14009 net.cpp:156] Memory required for data: 263374000
I0413 18:22:28.774528 14009 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:22:28.774536 14009 net.cpp:91] Creating Layer scale_conv2_sub
I0413 18:22:28.774543 14009 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 18:22:28.774549 14009 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 18:22:28.774603 14009 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:22:28.774749 14009 net.cpp:141] Setting up scale_conv2_sub
I0413 18:22:28.774760 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.774765 14009 net.cpp:156] Memory required for data: 266650800
I0413 18:22:28.774778 14009 layer_factory.hpp:77] Creating layer conv3_1a
I0413 18:22:28.774792 14009 net.cpp:91] Creating Layer conv3_1a
I0413 18:22:28.774798 14009 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 18:22:28.774809 14009 net.cpp:399] conv3_1a -> conv3_1a
I0413 18:22:28.777667 14009 net.cpp:141] Setting up conv3_1a
I0413 18:22:28.777686 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.777693 14009 net.cpp:156] Memory required for data: 269927600
I0413 18:22:28.777703 14009 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 18:22:28.777719 14009 net.cpp:91] Creating Layer bn_conv3_1a
I0413 18:22:28.777726 14009 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 18:22:28.777734 14009 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 18:22:28.777977 14009 net.cpp:141] Setting up bn_conv3_1a
I0413 18:22:28.777987 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.777992 14009 net.cpp:156] Memory required for data: 273204400
I0413 18:22:28.778003 14009 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:22:28.778012 14009 net.cpp:91] Creating Layer scale_conv3_1a
I0413 18:22:28.778017 14009 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 18:22:28.778024 14009 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 18:22:28.778080 14009 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:22:28.778225 14009 net.cpp:141] Setting up scale_conv3_1a
I0413 18:22:28.778235 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.778240 14009 net.cpp:156] Memory required for data: 276481200
I0413 18:22:28.778249 14009 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 18:22:28.778270 14009 net.cpp:91] Creating Layer conv3_1a_relu
I0413 18:22:28.778277 14009 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 18:22:28.778285 14009 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 18:22:28.778992 14009 net.cpp:141] Setting up conv3_1a_relu
I0413 18:22:28.779006 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.779011 14009 net.cpp:156] Memory required for data: 279758000
I0413 18:22:28.779017 14009 layer_factory.hpp:77] Creating layer conv3_1b
I0413 18:22:28.779031 14009 net.cpp:91] Creating Layer conv3_1b
I0413 18:22:28.779036 14009 net.cpp:425] conv3_1b <- conv3_1a
I0413 18:22:28.779047 14009 net.cpp:399] conv3_1b -> conv3_1b
I0413 18:22:28.783313 14009 net.cpp:141] Setting up conv3_1b
I0413 18:22:28.783331 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.783339 14009 net.cpp:156] Memory required for data: 283034800
I0413 18:22:28.783360 14009 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 18:22:28.783378 14009 net.cpp:91] Creating Layer bn_conv3_1b
I0413 18:22:28.783386 14009 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 18:22:28.783396 14009 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 18:22:28.783641 14009 net.cpp:141] Setting up bn_conv3_1b
I0413 18:22:28.783653 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.783658 14009 net.cpp:156] Memory required for data: 286311600
I0413 18:22:28.783668 14009 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:22:28.783676 14009 net.cpp:91] Creating Layer scale_conv3_1b
I0413 18:22:28.783682 14009 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 18:22:28.783691 14009 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 18:22:28.783746 14009 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:22:28.783906 14009 net.cpp:141] Setting up scale_conv3_1b
I0413 18:22:28.783917 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.783922 14009 net.cpp:156] Memory required for data: 289588400
I0413 18:22:28.783931 14009 layer_factory.hpp:77] Creating layer conv3_1
I0413 18:22:28.783944 14009 net.cpp:91] Creating Layer conv3_1
I0413 18:22:28.783951 14009 net.cpp:425] conv3_1 <- conv3_1b
I0413 18:22:28.783957 14009 net.cpp:425] conv3_1 <- conv2_sub
I0413 18:22:28.783965 14009 net.cpp:399] conv3_1 -> conv3_1
I0413 18:22:28.783993 14009 net.cpp:141] Setting up conv3_1
I0413 18:22:28.784004 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.784009 14009 net.cpp:156] Memory required for data: 292865200
I0413 18:22:28.784015 14009 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 18:22:28.784021 14009 net.cpp:91] Creating Layer conv3_1_relu
I0413 18:22:28.784027 14009 net.cpp:425] conv3_1_relu <- conv3_1
I0413 18:22:28.784034 14009 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 18:22:28.784366 14009 net.cpp:141] Setting up conv3_1_relu
I0413 18:22:28.784385 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.784391 14009 net.cpp:156] Memory required for data: 296142000
I0413 18:22:28.784397 14009 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 18:22:28.784405 14009 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 18:22:28.784411 14009 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 18:22:28.784418 14009 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 18:22:28.784428 14009 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 18:22:28.784485 14009 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 18:22:28.784494 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.784502 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.784507 14009 net.cpp:156] Memory required for data: 302695600
I0413 18:22:28.784512 14009 layer_factory.hpp:77] Creating layer conv3_2a
I0413 18:22:28.784524 14009 net.cpp:91] Creating Layer conv3_2a
I0413 18:22:28.784534 14009 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 18:22:28.784543 14009 net.cpp:399] conv3_2a -> conv3_2a
I0413 18:22:28.787868 14009 net.cpp:141] Setting up conv3_2a
I0413 18:22:28.787891 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.787899 14009 net.cpp:156] Memory required for data: 305972400
I0413 18:22:28.787914 14009 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 18:22:28.787926 14009 net.cpp:91] Creating Layer bn_conv3_2a
I0413 18:22:28.787932 14009 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 18:22:28.787940 14009 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 18:22:28.788187 14009 net.cpp:141] Setting up bn_conv3_2a
I0413 18:22:28.788197 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.788203 14009 net.cpp:156] Memory required for data: 309249200
I0413 18:22:28.788213 14009 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:22:28.788221 14009 net.cpp:91] Creating Layer scale_conv3_2a
I0413 18:22:28.788228 14009 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 18:22:28.788239 14009 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 18:22:28.788290 14009 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:22:28.788437 14009 net.cpp:141] Setting up scale_conv3_2a
I0413 18:22:28.788449 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.788453 14009 net.cpp:156] Memory required for data: 312526000
I0413 18:22:28.788462 14009 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 18:22:28.788475 14009 net.cpp:91] Creating Layer conv3_2a_relu
I0413 18:22:28.788480 14009 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 18:22:28.788487 14009 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 18:22:28.788882 14009 net.cpp:141] Setting up conv3_2a_relu
I0413 18:22:28.788897 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.788902 14009 net.cpp:156] Memory required for data: 315802800
I0413 18:22:28.788908 14009 layer_factory.hpp:77] Creating layer conv3_2b
I0413 18:22:28.788924 14009 net.cpp:91] Creating Layer conv3_2b
I0413 18:22:28.788931 14009 net.cpp:425] conv3_2b <- conv3_2a
I0413 18:22:28.788944 14009 net.cpp:399] conv3_2b -> conv3_2b
I0413 18:22:28.793498 14009 net.cpp:141] Setting up conv3_2b
I0413 18:22:28.793516 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.793522 14009 net.cpp:156] Memory required for data: 319079600
I0413 18:22:28.793540 14009 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 18:22:28.793551 14009 net.cpp:91] Creating Layer bn_conv3_2b
I0413 18:22:28.793557 14009 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 18:22:28.793567 14009 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 18:22:28.793813 14009 net.cpp:141] Setting up bn_conv3_2b
I0413 18:22:28.793823 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.793829 14009 net.cpp:156] Memory required for data: 322356400
I0413 18:22:28.793839 14009 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:22:28.793849 14009 net.cpp:91] Creating Layer scale_conv3_2b
I0413 18:22:28.793855 14009 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 18:22:28.793864 14009 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 18:22:28.793920 14009 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:22:28.794070 14009 net.cpp:141] Setting up scale_conv3_2b
I0413 18:22:28.794080 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.794085 14009 net.cpp:156] Memory required for data: 325633200
I0413 18:22:28.794093 14009 layer_factory.hpp:77] Creating layer conv3_2
I0413 18:22:28.794103 14009 net.cpp:91] Creating Layer conv3_2
I0413 18:22:28.794108 14009 net.cpp:425] conv3_2 <- conv3_2b
I0413 18:22:28.794116 14009 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 18:22:28.794122 14009 net.cpp:399] conv3_2 -> conv3_2
I0413 18:22:28.794152 14009 net.cpp:141] Setting up conv3_2
I0413 18:22:28.794160 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.794165 14009 net.cpp:156] Memory required for data: 328910000
I0413 18:22:28.794170 14009 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 18:22:28.794178 14009 net.cpp:91] Creating Layer conv3_2_relu
I0413 18:22:28.794183 14009 net.cpp:425] conv3_2_relu <- conv3_2
I0413 18:22:28.794195 14009 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 18:22:28.794479 14009 net.cpp:141] Setting up conv3_2_relu
I0413 18:22:28.794492 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.794497 14009 net.cpp:156] Memory required for data: 332186800
I0413 18:22:28.794509 14009 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 18:22:28.794517 14009 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 18:22:28.794524 14009 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 18:22:28.794533 14009 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 18:22:28.794543 14009 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 18:22:28.794602 14009 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 18:22:28.794611 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.794618 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.794625 14009 net.cpp:156] Memory required for data: 338740400
I0413 18:22:28.794630 14009 layer_factory.hpp:77] Creating layer conv3_3a
I0413 18:22:28.794643 14009 net.cpp:91] Creating Layer conv3_3a
I0413 18:22:28.794649 14009 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 18:22:28.794661 14009 net.cpp:399] conv3_3a -> conv3_3a
I0413 18:22:28.798028 14009 net.cpp:141] Setting up conv3_3a
I0413 18:22:28.798048 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.798053 14009 net.cpp:156] Memory required for data: 342017200
I0413 18:22:28.798063 14009 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 18:22:28.798074 14009 net.cpp:91] Creating Layer bn_conv3_3a
I0413 18:22:28.798081 14009 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 18:22:28.798089 14009 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 18:22:28.798341 14009 net.cpp:141] Setting up bn_conv3_3a
I0413 18:22:28.798351 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.798355 14009 net.cpp:156] Memory required for data: 345294000
I0413 18:22:28.798367 14009 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:22:28.798377 14009 net.cpp:91] Creating Layer scale_conv3_3a
I0413 18:22:28.798382 14009 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 18:22:28.798389 14009 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 18:22:28.798444 14009 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:22:28.798599 14009 net.cpp:141] Setting up scale_conv3_3a
I0413 18:22:28.798609 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.798614 14009 net.cpp:156] Memory required for data: 348570800
I0413 18:22:28.798629 14009 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 18:22:28.798637 14009 net.cpp:91] Creating Layer conv3_3a_relu
I0413 18:22:28.798643 14009 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 18:22:28.798651 14009 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 18:22:28.799027 14009 net.cpp:141] Setting up conv3_3a_relu
I0413 18:22:28.799044 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.799051 14009 net.cpp:156] Memory required for data: 351847600
I0413 18:22:28.799057 14009 layer_factory.hpp:77] Creating layer conv3_3b
I0413 18:22:28.799080 14009 net.cpp:91] Creating Layer conv3_3b
I0413 18:22:28.799088 14009 net.cpp:425] conv3_3b <- conv3_3a
I0413 18:22:28.799099 14009 net.cpp:399] conv3_3b -> conv3_3b
I0413 18:22:28.802589 14009 net.cpp:141] Setting up conv3_3b
I0413 18:22:28.802608 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.802614 14009 net.cpp:156] Memory required for data: 355124400
I0413 18:22:28.802624 14009 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 18:22:28.802635 14009 net.cpp:91] Creating Layer bn_conv3_3b
I0413 18:22:28.802642 14009 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 18:22:28.802649 14009 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 18:22:28.802909 14009 net.cpp:141] Setting up bn_conv3_3b
I0413 18:22:28.802920 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.802932 14009 net.cpp:156] Memory required for data: 358401200
I0413 18:22:28.802942 14009 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:22:28.802958 14009 net.cpp:91] Creating Layer scale_conv3_3b
I0413 18:22:28.802963 14009 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 18:22:28.802970 14009 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 18:22:28.803028 14009 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:22:28.803180 14009 net.cpp:141] Setting up scale_conv3_3b
I0413 18:22:28.803190 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.803196 14009 net.cpp:156] Memory required for data: 361678000
I0413 18:22:28.803205 14009 layer_factory.hpp:77] Creating layer conv3_3
I0413 18:22:28.803212 14009 net.cpp:91] Creating Layer conv3_3
I0413 18:22:28.803218 14009 net.cpp:425] conv3_3 <- conv3_3b
I0413 18:22:28.803225 14009 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 18:22:28.803234 14009 net.cpp:399] conv3_3 -> conv3_3
I0413 18:22:28.803261 14009 net.cpp:141] Setting up conv3_3
I0413 18:22:28.803270 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.803275 14009 net.cpp:156] Memory required for data: 364954800
I0413 18:22:28.803280 14009 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 18:22:28.803290 14009 net.cpp:91] Creating Layer conv3_3_relu
I0413 18:22:28.803297 14009 net.cpp:425] conv3_3_relu <- conv3_3
I0413 18:22:28.803303 14009 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 18:22:28.804708 14009 net.cpp:141] Setting up conv3_3_relu
I0413 18:22:28.804725 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.804731 14009 net.cpp:156] Memory required for data: 368231600
I0413 18:22:28.804738 14009 layer_factory.hpp:77] Creating layer conv3_3_conv3_3_relu_0_split
I0413 18:22:28.804747 14009 net.cpp:91] Creating Layer conv3_3_conv3_3_relu_0_split
I0413 18:22:28.804754 14009 net.cpp:425] conv3_3_conv3_3_relu_0_split <- conv3_3
I0413 18:22:28.804761 14009 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_0
I0413 18:22:28.804771 14009 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_1
I0413 18:22:28.804829 14009 net.cpp:141] Setting up conv3_3_conv3_3_relu_0_split
I0413 18:22:28.804839 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.804846 14009 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:22:28.804850 14009 net.cpp:156] Memory required for data: 374785200
I0413 18:22:28.804862 14009 layer_factory.hpp:77] Creating layer conv3_sub
I0413 18:22:28.804877 14009 net.cpp:91] Creating Layer conv3_sub
I0413 18:22:28.804883 14009 net.cpp:425] conv3_sub <- conv3_3_conv3_3_relu_0_split_0
I0413 18:22:28.804893 14009 net.cpp:399] conv3_sub -> conv3_sub
I0413 18:22:28.808322 14009 net.cpp:141] Setting up conv3_sub
I0413 18:22:28.808341 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.808347 14009 net.cpp:156] Memory required for data: 376423600
I0413 18:22:28.808357 14009 layer_factory.hpp:77] Creating layer bn_conv3_sub
I0413 18:22:28.808368 14009 net.cpp:91] Creating Layer bn_conv3_sub
I0413 18:22:28.808375 14009 net.cpp:425] bn_conv3_sub <- conv3_sub
I0413 18:22:28.808383 14009 net.cpp:386] bn_conv3_sub -> conv3_sub (in-place)
I0413 18:22:28.808650 14009 net.cpp:141] Setting up bn_conv3_sub
I0413 18:22:28.808661 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.808666 14009 net.cpp:156] Memory required for data: 378062000
I0413 18:22:28.808677 14009 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:22:28.808696 14009 net.cpp:91] Creating Layer scale_conv3_sub
I0413 18:22:28.808702 14009 net.cpp:425] scale_conv3_sub <- conv3_sub
I0413 18:22:28.808711 14009 net.cpp:386] scale_conv3_sub -> conv3_sub (in-place)
I0413 18:22:28.808768 14009 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:22:28.808922 14009 net.cpp:141] Setting up scale_conv3_sub
I0413 18:22:28.808933 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.808938 14009 net.cpp:156] Memory required for data: 379700400
I0413 18:22:28.808951 14009 layer_factory.hpp:77] Creating layer conv4_1a
I0413 18:22:28.808969 14009 net.cpp:91] Creating Layer conv4_1a
I0413 18:22:28.808975 14009 net.cpp:425] conv4_1a <- conv3_3_conv3_3_relu_0_split_1
I0413 18:22:28.808984 14009 net.cpp:399] conv4_1a -> conv4_1a
I0413 18:22:28.811729 14009 net.cpp:141] Setting up conv4_1a
I0413 18:22:28.811748 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.811754 14009 net.cpp:156] Memory required for data: 381338800
I0413 18:22:28.811764 14009 layer_factory.hpp:77] Creating layer bn_conv4_1a
I0413 18:22:28.811775 14009 net.cpp:91] Creating Layer bn_conv4_1a
I0413 18:22:28.811782 14009 net.cpp:425] bn_conv4_1a <- conv4_1a
I0413 18:22:28.811791 14009 net.cpp:386] bn_conv4_1a -> conv4_1a (in-place)
I0413 18:22:28.812047 14009 net.cpp:141] Setting up bn_conv4_1a
I0413 18:22:28.812058 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.812063 14009 net.cpp:156] Memory required for data: 382977200
I0413 18:22:28.812088 14009 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:22:28.812098 14009 net.cpp:91] Creating Layer scale_conv4_1a
I0413 18:22:28.812104 14009 net.cpp:425] scale_conv4_1a <- conv4_1a
I0413 18:22:28.812111 14009 net.cpp:386] scale_conv4_1a -> conv4_1a (in-place)
I0413 18:22:28.812168 14009 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:22:28.812319 14009 net.cpp:141] Setting up scale_conv4_1a
I0413 18:22:28.812328 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.812333 14009 net.cpp:156] Memory required for data: 384615600
I0413 18:22:28.812342 14009 layer_factory.hpp:77] Creating layer conv4_1a_relu
I0413 18:22:28.812350 14009 net.cpp:91] Creating Layer conv4_1a_relu
I0413 18:22:28.812355 14009 net.cpp:425] conv4_1a_relu <- conv4_1a
I0413 18:22:28.812363 14009 net.cpp:386] conv4_1a_relu -> conv4_1a (in-place)
I0413 18:22:28.812736 14009 net.cpp:141] Setting up conv4_1a_relu
I0413 18:22:28.812752 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.812758 14009 net.cpp:156] Memory required for data: 386254000
I0413 18:22:28.812764 14009 layer_factory.hpp:77] Creating layer conv4_1b
I0413 18:22:28.812779 14009 net.cpp:91] Creating Layer conv4_1b
I0413 18:22:28.812793 14009 net.cpp:425] conv4_1b <- conv4_1a
I0413 18:22:28.812804 14009 net.cpp:399] conv4_1b -> conv4_1b
I0413 18:22:28.817517 14009 net.cpp:141] Setting up conv4_1b
I0413 18:22:28.817535 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.817541 14009 net.cpp:156] Memory required for data: 387892400
I0413 18:22:28.817551 14009 layer_factory.hpp:77] Creating layer bn_conv4_1b
I0413 18:22:28.817569 14009 net.cpp:91] Creating Layer bn_conv4_1b
I0413 18:22:28.817576 14009 net.cpp:425] bn_conv4_1b <- conv4_1b
I0413 18:22:28.817584 14009 net.cpp:386] bn_conv4_1b -> conv4_1b (in-place)
I0413 18:22:28.817853 14009 net.cpp:141] Setting up bn_conv4_1b
I0413 18:22:28.817864 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.817869 14009 net.cpp:156] Memory required for data: 389530800
I0413 18:22:28.817881 14009 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:22:28.817893 14009 net.cpp:91] Creating Layer scale_conv4_1b
I0413 18:22:28.817898 14009 net.cpp:425] scale_conv4_1b <- conv4_1b
I0413 18:22:28.817905 14009 net.cpp:386] scale_conv4_1b -> conv4_1b (in-place)
I0413 18:22:28.817963 14009 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:22:28.818120 14009 net.cpp:141] Setting up scale_conv4_1b
I0413 18:22:28.818130 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.818135 14009 net.cpp:156] Memory required for data: 391169200
I0413 18:22:28.818145 14009 layer_factory.hpp:77] Creating layer conv4_1
I0413 18:22:28.818155 14009 net.cpp:91] Creating Layer conv4_1
I0413 18:22:28.818161 14009 net.cpp:425] conv4_1 <- conv3_sub
I0413 18:22:28.818166 14009 net.cpp:425] conv4_1 <- conv4_1b
I0413 18:22:28.818173 14009 net.cpp:399] conv4_1 -> conv4_1
I0413 18:22:28.818209 14009 net.cpp:141] Setting up conv4_1
I0413 18:22:28.818218 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.818228 14009 net.cpp:156] Memory required for data: 392807600
I0413 18:22:28.818234 14009 layer_factory.hpp:77] Creating layer conv4_1_relu
I0413 18:22:28.818241 14009 net.cpp:91] Creating Layer conv4_1_relu
I0413 18:22:28.818248 14009 net.cpp:425] conv4_1_relu <- conv4_1
I0413 18:22:28.818256 14009 net.cpp:386] conv4_1_relu -> conv4_1 (in-place)
I0413 18:22:28.818495 14009 net.cpp:141] Setting up conv4_1_relu
I0413 18:22:28.818507 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.818512 14009 net.cpp:156] Memory required for data: 394446000
I0413 18:22:28.818517 14009 layer_factory.hpp:77] Creating layer conv4_1_conv4_1_relu_0_split
I0413 18:22:28.818526 14009 net.cpp:91] Creating Layer conv4_1_conv4_1_relu_0_split
I0413 18:22:28.818531 14009 net.cpp:425] conv4_1_conv4_1_relu_0_split <- conv4_1
I0413 18:22:28.818542 14009 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_0
I0413 18:22:28.818552 14009 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_1
I0413 18:22:28.818608 14009 net.cpp:141] Setting up conv4_1_conv4_1_relu_0_split
I0413 18:22:28.818617 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.818624 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.818629 14009 net.cpp:156] Memory required for data: 397722800
I0413 18:22:28.818634 14009 layer_factory.hpp:77] Creating layer conv4_2a
I0413 18:22:28.818650 14009 net.cpp:91] Creating Layer conv4_2a
I0413 18:22:28.818656 14009 net.cpp:425] conv4_2a <- conv4_1_conv4_1_relu_0_split_0
I0413 18:22:28.818665 14009 net.cpp:399] conv4_2a -> conv4_2a
I0413 18:22:28.822082 14009 net.cpp:141] Setting up conv4_2a
I0413 18:22:28.822118 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.822124 14009 net.cpp:156] Memory required for data: 399361200
I0413 18:22:28.822137 14009 layer_factory.hpp:77] Creating layer bn_conv4_2a
I0413 18:22:28.822154 14009 net.cpp:91] Creating Layer bn_conv4_2a
I0413 18:22:28.822162 14009 net.cpp:425] bn_conv4_2a <- conv4_2a
I0413 18:22:28.822172 14009 net.cpp:386] bn_conv4_2a -> conv4_2a (in-place)
I0413 18:22:28.822456 14009 net.cpp:141] Setting up bn_conv4_2a
I0413 18:22:28.822468 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.822474 14009 net.cpp:156] Memory required for data: 400999600
I0413 18:22:28.822485 14009 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:22:28.822499 14009 net.cpp:91] Creating Layer scale_conv4_2a
I0413 18:22:28.822505 14009 net.cpp:425] scale_conv4_2a <- conv4_2a
I0413 18:22:28.822513 14009 net.cpp:386] scale_conv4_2a -> conv4_2a (in-place)
I0413 18:22:28.822578 14009 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:22:28.822743 14009 net.cpp:141] Setting up scale_conv4_2a
I0413 18:22:28.822754 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.822759 14009 net.cpp:156] Memory required for data: 402638000
I0413 18:22:28.822769 14009 layer_factory.hpp:77] Creating layer conv4_2a_relu
I0413 18:22:28.822780 14009 net.cpp:91] Creating Layer conv4_2a_relu
I0413 18:22:28.822787 14009 net.cpp:425] conv4_2a_relu <- conv4_2a
I0413 18:22:28.822793 14009 net.cpp:386] conv4_2a_relu -> conv4_2a (in-place)
I0413 18:22:28.823238 14009 net.cpp:141] Setting up conv4_2a_relu
I0413 18:22:28.823256 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.823261 14009 net.cpp:156] Memory required for data: 404276400
I0413 18:22:28.823267 14009 layer_factory.hpp:77] Creating layer conv4_2b
I0413 18:22:28.823292 14009 net.cpp:91] Creating Layer conv4_2b
I0413 18:22:28.823299 14009 net.cpp:425] conv4_2b <- conv4_2a
I0413 18:22:28.823309 14009 net.cpp:399] conv4_2b -> conv4_2b
I0413 18:22:28.827913 14009 net.cpp:141] Setting up conv4_2b
I0413 18:22:28.827942 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.827950 14009 net.cpp:156] Memory required for data: 405914800
I0413 18:22:28.827960 14009 layer_factory.hpp:77] Creating layer bn_conv4_2b
I0413 18:22:28.827975 14009 net.cpp:91] Creating Layer bn_conv4_2b
I0413 18:22:28.827983 14009 net.cpp:425] bn_conv4_2b <- conv4_2b
I0413 18:22:28.828002 14009 net.cpp:386] bn_conv4_2b -> conv4_2b (in-place)
I0413 18:22:28.828270 14009 net.cpp:141] Setting up bn_conv4_2b
I0413 18:22:28.828281 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.828286 14009 net.cpp:156] Memory required for data: 407553200
I0413 18:22:28.828323 14009 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:22:28.828336 14009 net.cpp:91] Creating Layer scale_conv4_2b
I0413 18:22:28.828342 14009 net.cpp:425] scale_conv4_2b <- conv4_2b
I0413 18:22:28.828349 14009 net.cpp:386] scale_conv4_2b -> conv4_2b (in-place)
I0413 18:22:28.828413 14009 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:22:28.828569 14009 net.cpp:141] Setting up scale_conv4_2b
I0413 18:22:28.828580 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.828585 14009 net.cpp:156] Memory required for data: 409191600
I0413 18:22:28.828594 14009 layer_factory.hpp:77] Creating layer conv4_2
I0413 18:22:28.828608 14009 net.cpp:91] Creating Layer conv4_2
I0413 18:22:28.828614 14009 net.cpp:425] conv4_2 <- conv4_1_conv4_1_relu_0_split_1
I0413 18:22:28.828620 14009 net.cpp:425] conv4_2 <- conv4_2b
I0413 18:22:28.828629 14009 net.cpp:399] conv4_2 -> conv4_2
I0413 18:22:28.828666 14009 net.cpp:141] Setting up conv4_2
I0413 18:22:28.828675 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.828681 14009 net.cpp:156] Memory required for data: 410830000
I0413 18:22:28.828686 14009 layer_factory.hpp:77] Creating layer conv4_2_relu
I0413 18:22:28.828694 14009 net.cpp:91] Creating Layer conv4_2_relu
I0413 18:22:28.828699 14009 net.cpp:425] conv4_2_relu <- conv4_2
I0413 18:22:28.828716 14009 net.cpp:386] conv4_2_relu -> conv4_2 (in-place)
I0413 18:22:28.829053 14009 net.cpp:141] Setting up conv4_2_relu
I0413 18:22:28.829069 14009 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:22:28.829076 14009 net.cpp:156] Memory required for data: 412468400
I0413 18:22:28.829080 14009 layer_factory.hpp:77] Creating layer global_pool
I0413 18:22:28.829097 14009 net.cpp:91] Creating Layer global_pool
I0413 18:22:28.829102 14009 net.cpp:425] global_pool <- conv4_2
I0413 18:22:28.829123 14009 net.cpp:399] global_pool -> global_pool
I0413 18:22:28.830052 14009 net.cpp:141] Setting up global_pool
I0413 18:22:28.830068 14009 net.cpp:148] Top shape: 100 64 1 1 (6400)
I0413 18:22:28.830075 14009 net.cpp:156] Memory required for data: 412494000
I0413 18:22:28.830080 14009 layer_factory.hpp:77] Creating layer ip
I0413 18:22:28.830090 14009 net.cpp:91] Creating Layer ip
I0413 18:22:28.830096 14009 net.cpp:425] ip <- global_pool
I0413 18:22:28.830104 14009 net.cpp:399] ip -> ip
I0413 18:22:28.830325 14009 net.cpp:141] Setting up ip
I0413 18:22:28.830338 14009 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:22:28.830343 14009 net.cpp:156] Memory required for data: 412498000
I0413 18:22:28.830353 14009 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 18:22:28.830363 14009 net.cpp:91] Creating Layer ip_ip_0_split
I0413 18:22:28.830368 14009 net.cpp:425] ip_ip_0_split <- ip
I0413 18:22:28.830376 14009 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 18:22:28.830385 14009 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 18:22:28.830440 14009 net.cpp:141] Setting up ip_ip_0_split
I0413 18:22:28.830449 14009 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:22:28.830456 14009 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:22:28.830461 14009 net.cpp:156] Memory required for data: 412506000
I0413 18:22:28.830466 14009 layer_factory.hpp:77] Creating layer accuracy
I0413 18:22:28.830473 14009 net.cpp:91] Creating Layer accuracy
I0413 18:22:28.830479 14009 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 18:22:28.830485 14009 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 18:22:28.830497 14009 net.cpp:399] accuracy -> accuracy
I0413 18:22:28.830508 14009 net.cpp:141] Setting up accuracy
I0413 18:22:28.830515 14009 net.cpp:148] Top shape: (1)
I0413 18:22:28.830520 14009 net.cpp:156] Memory required for data: 412506004
I0413 18:22:28.830525 14009 layer_factory.hpp:77] Creating layer loss
I0413 18:22:28.830538 14009 net.cpp:91] Creating Layer loss
I0413 18:22:28.830544 14009 net.cpp:425] loss <- ip_ip_0_split_1
I0413 18:22:28.830550 14009 net.cpp:425] loss <- label_cifar_1_split_1
I0413 18:22:28.830559 14009 net.cpp:399] loss -> loss
I0413 18:22:28.830571 14009 layer_factory.hpp:77] Creating layer loss
I0413 18:22:28.831279 14009 net.cpp:141] Setting up loss
I0413 18:22:28.831293 14009 net.cpp:148] Top shape: (1)
I0413 18:22:28.831300 14009 net.cpp:151]     with loss weight 1
I0413 18:22:28.831315 14009 net.cpp:156] Memory required for data: 412506008
I0413 18:22:28.831320 14009 net.cpp:217] loss needs backward computation.
I0413 18:22:28.831326 14009 net.cpp:219] accuracy does not need backward computation.
I0413 18:22:28.831332 14009 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 18:22:28.831337 14009 net.cpp:217] ip needs backward computation.
I0413 18:22:28.831342 14009 net.cpp:217] global_pool needs backward computation.
I0413 18:22:28.831348 14009 net.cpp:217] conv4_2_relu needs backward computation.
I0413 18:22:28.831352 14009 net.cpp:217] conv4_2 needs backward computation.
I0413 18:22:28.831358 14009 net.cpp:217] scale_conv4_2b needs backward computation.
I0413 18:22:28.831363 14009 net.cpp:217] bn_conv4_2b needs backward computation.
I0413 18:22:28.831368 14009 net.cpp:217] conv4_2b needs backward computation.
I0413 18:22:28.831374 14009 net.cpp:217] conv4_2a_relu needs backward computation.
I0413 18:22:28.831379 14009 net.cpp:217] scale_conv4_2a needs backward computation.
I0413 18:22:28.831384 14009 net.cpp:217] bn_conv4_2a needs backward computation.
I0413 18:22:28.831389 14009 net.cpp:217] conv4_2a needs backward computation.
I0413 18:22:28.831395 14009 net.cpp:217] conv4_1_conv4_1_relu_0_split needs backward computation.
I0413 18:22:28.831400 14009 net.cpp:217] conv4_1_relu needs backward computation.
I0413 18:22:28.831405 14009 net.cpp:217] conv4_1 needs backward computation.
I0413 18:22:28.831411 14009 net.cpp:217] scale_conv4_1b needs backward computation.
I0413 18:22:28.831418 14009 net.cpp:217] bn_conv4_1b needs backward computation.
I0413 18:22:28.831423 14009 net.cpp:217] conv4_1b needs backward computation.
I0413 18:22:28.831428 14009 net.cpp:217] conv4_1a_relu needs backward computation.
I0413 18:22:28.831434 14009 net.cpp:217] scale_conv4_1a needs backward computation.
I0413 18:22:28.831439 14009 net.cpp:217] bn_conv4_1a needs backward computation.
I0413 18:22:28.831444 14009 net.cpp:217] conv4_1a needs backward computation.
I0413 18:22:28.831449 14009 net.cpp:217] scale_conv3_sub needs backward computation.
I0413 18:22:28.831454 14009 net.cpp:217] bn_conv3_sub needs backward computation.
I0413 18:22:28.831459 14009 net.cpp:217] conv3_sub needs backward computation.
I0413 18:22:28.831465 14009 net.cpp:217] conv3_3_conv3_3_relu_0_split needs backward computation.
I0413 18:22:28.831471 14009 net.cpp:217] conv3_3_relu needs backward computation.
I0413 18:22:28.831476 14009 net.cpp:217] conv3_3 needs backward computation.
I0413 18:22:28.831482 14009 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 18:22:28.831487 14009 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 18:22:28.831493 14009 net.cpp:217] conv3_3b needs backward computation.
I0413 18:22:28.831498 14009 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 18:22:28.831503 14009 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 18:22:28.831509 14009 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 18:22:28.831514 14009 net.cpp:217] conv3_3a needs backward computation.
I0413 18:22:28.831519 14009 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 18:22:28.831526 14009 net.cpp:217] conv3_2_relu needs backward computation.
I0413 18:22:28.831532 14009 net.cpp:217] conv3_2 needs backward computation.
I0413 18:22:28.831538 14009 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 18:22:28.831543 14009 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 18:22:28.831548 14009 net.cpp:217] conv3_2b needs backward computation.
I0413 18:22:28.831558 14009 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 18:22:28.831563 14009 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 18:22:28.831568 14009 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 18:22:28.831574 14009 net.cpp:217] conv3_2a needs backward computation.
I0413 18:22:28.831579 14009 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 18:22:28.831585 14009 net.cpp:217] conv3_1_relu needs backward computation.
I0413 18:22:28.831590 14009 net.cpp:217] conv3_1 needs backward computation.
I0413 18:22:28.831596 14009 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 18:22:28.831603 14009 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 18:22:28.831607 14009 net.cpp:217] conv3_1b needs backward computation.
I0413 18:22:28.831612 14009 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 18:22:28.831619 14009 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 18:22:28.831624 14009 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 18:22:28.831629 14009 net.cpp:217] conv3_1a needs backward computation.
I0413 18:22:28.831634 14009 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 18:22:28.831640 14009 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 18:22:28.831645 14009 net.cpp:217] conv2_sub needs backward computation.
I0413 18:22:28.831650 14009 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 18:22:28.831655 14009 net.cpp:217] conv2_3_relu needs backward computation.
I0413 18:22:28.831660 14009 net.cpp:217] conv2_3 needs backward computation.
I0413 18:22:28.831666 14009 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 18:22:28.831671 14009 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 18:22:28.831676 14009 net.cpp:217] conv2_3b needs backward computation.
I0413 18:22:28.831681 14009 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 18:22:28.831687 14009 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 18:22:28.831692 14009 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 18:22:28.831697 14009 net.cpp:217] conv2_3a needs backward computation.
I0413 18:22:28.831702 14009 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 18:22:28.831708 14009 net.cpp:217] conv2_2_relu needs backward computation.
I0413 18:22:28.831713 14009 net.cpp:217] conv2_2 needs backward computation.
I0413 18:22:28.831719 14009 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 18:22:28.831725 14009 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 18:22:28.831730 14009 net.cpp:217] conv2_2b needs backward computation.
I0413 18:22:28.831735 14009 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 18:22:28.831740 14009 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 18:22:28.831746 14009 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 18:22:28.831751 14009 net.cpp:217] conv2_2a needs backward computation.
I0413 18:22:28.831756 14009 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 18:22:28.831761 14009 net.cpp:217] conv2_1_relu needs backward computation.
I0413 18:22:28.831768 14009 net.cpp:217] conv2_1 needs backward computation.
I0413 18:22:28.831773 14009 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 18:22:28.831779 14009 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 18:22:28.831784 14009 net.cpp:217] conv2_1b needs backward computation.
I0413 18:22:28.831789 14009 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 18:22:28.831794 14009 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 18:22:28.831799 14009 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 18:22:28.831804 14009 net.cpp:217] conv2_1a needs backward computation.
I0413 18:22:28.831809 14009 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 18:22:28.831815 14009 net.cpp:217] conv1_relu needs backward computation.
I0413 18:22:28.831823 14009 net.cpp:217] scale_conv1 needs backward computation.
I0413 18:22:28.831828 14009 net.cpp:217] bn_conv1 needs backward computation.
I0413 18:22:28.831833 14009 net.cpp:217] conv1 needs backward computation.
I0413 18:22:28.831840 14009 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 18:22:28.831845 14009 net.cpp:219] cifar does not need backward computation.
I0413 18:22:28.831851 14009 net.cpp:261] This network produces output accuracy
I0413 18:22:28.831856 14009 net.cpp:261] This network produces output loss
I0413 18:22:28.831920 14009 net.cpp:274] Network initialization done.
I0413 18:22:28.832414 14009 solver.cpp:60] Solver scaffolding done.
I0413 18:22:29.313513 14009 solver.cpp:228] Iteration 0, loss = 0.411062
I0413 18:22:29.313555 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:22:29.313567 14009 solver.cpp:244]     Train net output #1: loss = 0.411062 (* 1 = 0.411062 loss)
I0413 18:22:29.313586 14009 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 18:22:35.961832 14009 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 18:22:38.974078 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5665
I0413 18:22:38.974131 14009 solver.cpp:404]     Test net output #1: loss = 2.02076 (* 1 = 2.02076 loss)
I0413 18:22:39.250397 14009 solver.cpp:228] Iteration 20, loss = 0.445012
I0413 18:22:39.250433 14009 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:22:39.250445 14009 solver.cpp:244]     Train net output #1: loss = 0.445012 (* 1 = 0.445012 loss)
I0413 18:22:39.250459 14009 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 18:22:46.051609 14009 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 18:22:48.914355 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6643
I0413 18:22:48.914413 14009 solver.cpp:404]     Test net output #1: loss = 1.12573 (* 1 = 1.12573 loss)
I0413 18:22:49.142098 14009 solver.cpp:228] Iteration 40, loss = 0.468163
I0413 18:22:49.142145 14009 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:22:49.142158 14009 solver.cpp:244]     Train net output #1: loss = 0.468163 (* 1 = 0.468163 loss)
I0413 18:22:49.142168 14009 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 18:22:55.925472 14009 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 18:22:58.899672 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6724
I0413 18:22:58.899718 14009 solver.cpp:404]     Test net output #1: loss = 1.13711 (* 1 = 1.13711 loss)
I0413 18:22:59.131577 14009 solver.cpp:228] Iteration 60, loss = 0.470754
I0413 18:22:59.131677 14009 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:22:59.131722 14009 solver.cpp:244]     Train net output #1: loss = 0.470754 (* 1 = 0.470754 loss)
I0413 18:22:59.131748 14009 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 18:23:05.781268 14009 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 18:23:08.841397 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6057
I0413 18:23:08.841452 14009 solver.cpp:404]     Test net output #1: loss = 1.53667 (* 1 = 1.53667 loss)
I0413 18:23:09.069563 14009 solver.cpp:228] Iteration 80, loss = 0.381642
I0413 18:23:09.069586 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:23:09.069597 14009 solver.cpp:244]     Train net output #1: loss = 0.381642 (* 1 = 0.381642 loss)
I0413 18:23:09.069607 14009 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 18:23:15.670186 14009 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 18:23:18.781384 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7221
I0413 18:23:18.781441 14009 solver.cpp:404]     Test net output #1: loss = 0.823241 (* 1 = 0.823241 loss)
I0413 18:23:19.011338 14009 solver.cpp:228] Iteration 100, loss = 0.43856
I0413 18:23:19.011392 14009 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:23:19.011407 14009 solver.cpp:244]     Train net output #1: loss = 0.43856 (* 1 = 0.43856 loss)
I0413 18:23:19.011420 14009 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 18:23:25.507966 14009 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 18:23:28.719202 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6459
I0413 18:23:28.719240 14009 solver.cpp:404]     Test net output #1: loss = 1.1587 (* 1 = 1.1587 loss)
I0413 18:23:28.948902 14009 solver.cpp:228] Iteration 120, loss = 0.505086
I0413 18:23:28.948953 14009 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:23:28.948966 14009 solver.cpp:244]     Train net output #1: loss = 0.505086 (* 1 = 0.505086 loss)
I0413 18:23:28.948976 14009 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 18:23:35.369098 14009 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 18:23:38.635563 14009 solver.cpp:404]     Test net output #0: accuracy = 0.577
I0413 18:23:38.635637 14009 solver.cpp:404]     Test net output #1: loss = 1.42444 (* 1 = 1.42444 loss)
I0413 18:23:38.893903 14009 solver.cpp:228] Iteration 140, loss = 0.388137
I0413 18:23:38.893955 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:23:38.893970 14009 solver.cpp:244]     Train net output #1: loss = 0.388137 (* 1 = 0.388137 loss)
I0413 18:23:38.893981 14009 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 18:23:45.267990 14009 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 18:23:48.522470 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6171
I0413 18:23:48.522524 14009 solver.cpp:404]     Test net output #1: loss = 1.27579 (* 1 = 1.27579 loss)
I0413 18:23:48.758162 14009 solver.cpp:228] Iteration 160, loss = 0.376849
I0413 18:23:48.758218 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:23:48.758229 14009 solver.cpp:244]     Train net output #1: loss = 0.376849 (* 1 = 0.376849 loss)
I0413 18:23:48.758239 14009 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 18:23:55.106215 14009 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 18:23:58.345587 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6319
I0413 18:23:58.345674 14009 solver.cpp:404]     Test net output #1: loss = 1.15151 (* 1 = 1.15151 loss)
I0413 18:23:58.627697 14009 solver.cpp:228] Iteration 180, loss = 0.42642
I0413 18:23:58.627748 14009 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:23:58.627761 14009 solver.cpp:244]     Train net output #1: loss = 0.42642 (* 1 = 0.42642 loss)
I0413 18:23:58.627773 14009 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 18:24:04.941391 14009 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 18:24:08.194352 14009 solver.cpp:404]     Test net output #0: accuracy = 0.682
I0413 18:24:08.194422 14009 solver.cpp:404]     Test net output #1: loss = 0.984532 (* 1 = 0.984532 loss)
I0413 18:24:08.432070 14009 solver.cpp:228] Iteration 200, loss = 0.393341
I0413 18:24:08.432112 14009 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:24:08.432128 14009 solver.cpp:244]     Train net output #1: loss = 0.393341 (* 1 = 0.393341 loss)
I0413 18:24:08.432139 14009 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 18:24:14.846704 14009 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 18:24:18.052364 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7153
I0413 18:24:18.052428 14009 solver.cpp:404]     Test net output #1: loss = 0.904362 (* 1 = 0.904362 loss)
I0413 18:24:18.309944 14009 solver.cpp:228] Iteration 220, loss = 0.31476
I0413 18:24:18.309990 14009 solver.cpp:244]     Train net output #0: accuracy = 0.902344
I0413 18:24:18.310004 14009 solver.cpp:244]     Train net output #1: loss = 0.31476 (* 1 = 0.31476 loss)
I0413 18:24:18.310015 14009 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 18:24:24.785549 14009 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 18:24:27.922655 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7016
I0413 18:24:27.922708 14009 solver.cpp:404]     Test net output #1: loss = 1.03852 (* 1 = 1.03852 loss)
I0413 18:24:28.202023 14009 solver.cpp:228] Iteration 240, loss = 0.400199
I0413 18:24:28.202080 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:24:28.202097 14009 solver.cpp:244]     Train net output #1: loss = 0.400199 (* 1 = 0.400199 loss)
I0413 18:24:28.202119 14009 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 18:24:34.766695 14009 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 18:24:37.848717 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6887
I0413 18:24:37.848778 14009 solver.cpp:404]     Test net output #1: loss = 1.01338 (* 1 = 1.01338 loss)
I0413 18:24:38.112738 14009 solver.cpp:228] Iteration 260, loss = 0.428633
I0413 18:24:38.112795 14009 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:24:38.112812 14009 solver.cpp:244]     Train net output #1: loss = 0.428633 (* 1 = 0.428633 loss)
I0413 18:24:38.112823 14009 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 18:24:44.725508 14009 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 18:24:47.735672 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6911
I0413 18:24:47.735729 14009 solver.cpp:404]     Test net output #1: loss = 0.997074 (* 1 = 0.997074 loss)
I0413 18:24:48.020076 14009 solver.cpp:228] Iteration 280, loss = 0.454692
I0413 18:24:48.020130 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:24:48.020145 14009 solver.cpp:244]     Train net output #1: loss = 0.454692 (* 1 = 0.454692 loss)
I0413 18:24:48.020156 14009 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 18:24:54.746522 14009 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 18:24:57.656889 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6131
I0413 18:24:57.656949 14009 solver.cpp:404]     Test net output #1: loss = 1.2935 (* 1 = 1.2935 loss)
I0413 18:24:57.934185 14009 solver.cpp:228] Iteration 300, loss = 0.534122
I0413 18:24:57.934299 14009 solver.cpp:244]     Train net output #0: accuracy = 0.808594
I0413 18:24:57.934345 14009 solver.cpp:244]     Train net output #1: loss = 0.534122 (* 1 = 0.534122 loss)
I0413 18:24:57.934360 14009 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 18:25:04.718422 14009 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 18:25:07.693816 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6751
I0413 18:25:07.693866 14009 solver.cpp:404]     Test net output #1: loss = 1.11694 (* 1 = 1.11694 loss)
I0413 18:25:07.919828 14009 solver.cpp:228] Iteration 320, loss = 0.480402
I0413 18:25:07.919872 14009 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:25:07.919883 14009 solver.cpp:244]     Train net output #1: loss = 0.480402 (* 1 = 0.480402 loss)
I0413 18:25:07.919893 14009 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 18:25:14.670430 14009 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 18:25:17.655932 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5704
I0413 18:25:17.655992 14009 solver.cpp:404]     Test net output #1: loss = 1.64271 (* 1 = 1.64271 loss)
I0413 18:25:17.879925 14009 solver.cpp:228] Iteration 340, loss = 0.415768
I0413 18:25:17.879973 14009 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:25:17.879988 14009 solver.cpp:244]     Train net output #1: loss = 0.415768 (* 1 = 0.415768 loss)
I0413 18:25:17.879999 14009 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 18:25:24.507488 14009 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 18:25:27.584301 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6189
I0413 18:25:27.584349 14009 solver.cpp:404]     Test net output #1: loss = 1.26587 (* 1 = 1.26587 loss)
I0413 18:25:27.819648 14009 solver.cpp:228] Iteration 360, loss = 0.306698
I0413 18:25:27.819690 14009 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:25:27.819705 14009 solver.cpp:244]     Train net output #1: loss = 0.306698 (* 1 = 0.306698 loss)
I0413 18:25:27.819715 14009 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 18:25:34.379849 14009 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 18:25:37.544725 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6205
I0413 18:25:37.544807 14009 solver.cpp:404]     Test net output #1: loss = 1.28857 (* 1 = 1.28857 loss)
I0413 18:25:37.778358 14009 solver.cpp:228] Iteration 380, loss = 0.493303
I0413 18:25:37.778414 14009 solver.cpp:244]     Train net output #0: accuracy = 0.804688
I0413 18:25:37.778429 14009 solver.cpp:244]     Train net output #1: loss = 0.493303 (* 1 = 0.493303 loss)
I0413 18:25:37.778445 14009 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 18:25:44.254742 14009 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 18:25:47.472509 14009 solver.cpp:404]     Test net output #0: accuracy = 0.581
I0413 18:25:47.472565 14009 solver.cpp:404]     Test net output #1: loss = 1.57303 (* 1 = 1.57303 loss)
I0413 18:25:47.729588 14009 solver.cpp:228] Iteration 400, loss = 0.358955
I0413 18:25:47.729632 14009 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:25:47.729646 14009 solver.cpp:244]     Train net output #1: loss = 0.358955 (* 1 = 0.358955 loss)
I0413 18:25:47.729656 14009 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 18:25:54.049671 14009 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 18:25:57.278025 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7223
I0413 18:25:57.278080 14009 solver.cpp:404]     Test net output #1: loss = 0.874994 (* 1 = 0.874994 loss)
I0413 18:25:57.525085 14009 solver.cpp:228] Iteration 420, loss = 0.340777
I0413 18:25:57.525236 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:25:57.525281 14009 solver.cpp:244]     Train net output #1: loss = 0.340777 (* 1 = 0.340777 loss)
I0413 18:25:57.525293 14009 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 18:26:03.841053 14009 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 18:26:07.091940 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7291
I0413 18:26:07.092002 14009 solver.cpp:404]     Test net output #1: loss = 0.828931 (* 1 = 0.828931 loss)
I0413 18:26:07.348225 14009 solver.cpp:228] Iteration 440, loss = 0.314748
I0413 18:26:07.348263 14009 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:26:07.348275 14009 solver.cpp:244]     Train net output #1: loss = 0.314748 (* 1 = 0.314748 loss)
I0413 18:26:07.348287 14009 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 18:26:13.679257 14009 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 18:26:16.928014 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6879
I0413 18:26:16.928066 14009 solver.cpp:404]     Test net output #1: loss = 0.928596 (* 1 = 0.928596 loss)
I0413 18:26:17.176833 14009 solver.cpp:228] Iteration 460, loss = 0.368121
I0413 18:26:17.176872 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:26:17.176885 14009 solver.cpp:244]     Train net output #1: loss = 0.368121 (* 1 = 0.368121 loss)
I0413 18:26:17.176898 14009 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 18:26:23.523802 14009 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 18:26:26.787677 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6998
I0413 18:26:26.787724 14009 solver.cpp:404]     Test net output #1: loss = 0.923527 (* 1 = 0.923527 loss)
I0413 18:26:27.032207 14009 solver.cpp:228] Iteration 480, loss = 0.418813
I0413 18:26:27.032253 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:26:27.032263 14009 solver.cpp:244]     Train net output #1: loss = 0.418813 (* 1 = 0.418813 loss)
I0413 18:26:27.032272 14009 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 18:26:33.504637 14009 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 18:26:36.658977 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6009
I0413 18:26:36.659024 14009 solver.cpp:404]     Test net output #1: loss = 1.56145 (* 1 = 1.56145 loss)
I0413 18:26:36.941814 14009 solver.cpp:228] Iteration 500, loss = 0.358912
I0413 18:26:36.941860 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:26:36.941872 14009 solver.cpp:244]     Train net output #1: loss = 0.358912 (* 1 = 0.358912 loss)
I0413 18:26:36.941884 14009 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 18:26:43.460927 14009 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 18:26:46.570683 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6903
I0413 18:26:46.570757 14009 solver.cpp:404]     Test net output #1: loss = 1.04956 (* 1 = 1.04956 loss)
I0413 18:26:46.842735 14009 solver.cpp:228] Iteration 520, loss = 0.598012
I0413 18:26:46.842788 14009 solver.cpp:244]     Train net output #0: accuracy = 0.765625
I0413 18:26:46.842800 14009 solver.cpp:244]     Train net output #1: loss = 0.598012 (* 1 = 0.598012 loss)
I0413 18:26:46.842809 14009 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 18:26:53.439646 14009 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 18:26:56.465014 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6321
I0413 18:26:56.465061 14009 solver.cpp:404]     Test net output #1: loss = 1.19557 (* 1 = 1.19557 loss)
I0413 18:26:56.705662 14009 solver.cpp:228] Iteration 540, loss = 0.337048
I0413 18:26:56.705703 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:26:56.705715 14009 solver.cpp:244]     Train net output #1: loss = 0.337048 (* 1 = 0.337048 loss)
I0413 18:26:56.705724 14009 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 18:27:03.415874 14009 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 18:27:06.412148 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7707
I0413 18:27:06.412204 14009 solver.cpp:404]     Test net output #1: loss = 0.703631 (* 1 = 0.703631 loss)
I0413 18:27:06.671057 14009 solver.cpp:228] Iteration 560, loss = 0.394761
I0413 18:27:06.671105 14009 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:27:06.671119 14009 solver.cpp:244]     Train net output #1: loss = 0.394761 (* 1 = 0.394761 loss)
I0413 18:27:06.671131 14009 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 18:27:13.461256 14009 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 18:27:16.358566 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5915
I0413 18:27:16.358610 14009 solver.cpp:404]     Test net output #1: loss = 1.69235 (* 1 = 1.69235 loss)
I0413 18:27:16.588212 14009 solver.cpp:228] Iteration 580, loss = 0.372483
I0413 18:27:16.588248 14009 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:27:16.588259 14009 solver.cpp:244]     Train net output #1: loss = 0.372483 (* 1 = 0.372483 loss)
I0413 18:27:16.588268 14009 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 18:27:23.355851 14009 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 18:27:26.324576 14009 solver.cpp:404]     Test net output #0: accuracy = 0.506
I0413 18:27:26.324630 14009 solver.cpp:404]     Test net output #1: loss = 1.9775 (* 1 = 1.9775 loss)
I0413 18:27:26.554291 14009 solver.cpp:228] Iteration 600, loss = 0.385037
I0413 18:27:26.554338 14009 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:27:26.554350 14009 solver.cpp:244]     Train net output #1: loss = 0.385037 (* 1 = 0.385037 loss)
I0413 18:27:26.554363 14009 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 18:27:33.265898 14009 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 18:27:36.310853 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7254
I0413 18:27:36.310904 14009 solver.cpp:404]     Test net output #1: loss = 0.851591 (* 1 = 0.851591 loss)
I0413 18:27:36.537379 14009 solver.cpp:228] Iteration 620, loss = 0.459673
I0413 18:27:36.537434 14009 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:27:36.537449 14009 solver.cpp:244]     Train net output #1: loss = 0.459673 (* 1 = 0.459673 loss)
I0413 18:27:36.537461 14009 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 18:27:43.138722 14009 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 18:27:46.264261 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5977
I0413 18:27:46.264302 14009 solver.cpp:404]     Test net output #1: loss = 1.51205 (* 1 = 1.51205 loss)
I0413 18:27:46.490973 14009 solver.cpp:228] Iteration 640, loss = 0.35192
I0413 18:27:46.491008 14009 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:27:46.491019 14009 solver.cpp:244]     Train net output #1: loss = 0.35192 (* 1 = 0.35192 loss)
I0413 18:27:46.491027 14009 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 18:27:53.027756 14009 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 18:27:56.180234 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6092
I0413 18:27:56.180327 14009 solver.cpp:404]     Test net output #1: loss = 1.28009 (* 1 = 1.28009 loss)
I0413 18:27:56.416851 14009 solver.cpp:228] Iteration 660, loss = 0.471392
I0413 18:27:56.416910 14009 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:27:56.416925 14009 solver.cpp:244]     Train net output #1: loss = 0.471392 (* 1 = 0.471392 loss)
I0413 18:27:56.416941 14009 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 18:28:02.828284 14009 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 18:28:06.077711 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6511
I0413 18:28:06.077761 14009 solver.cpp:404]     Test net output #1: loss = 1.20889 (* 1 = 1.20889 loss)
I0413 18:28:06.347007 14009 solver.cpp:228] Iteration 680, loss = 0.400108
I0413 18:28:06.347067 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:28:06.347082 14009 solver.cpp:244]     Train net output #1: loss = 0.400108 (* 1 = 0.400108 loss)
I0413 18:28:06.347095 14009 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 18:28:12.717877 14009 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 18:28:15.983515 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5597
I0413 18:28:15.983563 14009 solver.cpp:404]     Test net output #1: loss = 1.82787 (* 1 = 1.82787 loss)
I0413 18:28:16.234206 14009 solver.cpp:228] Iteration 700, loss = 0.375003
I0413 18:28:16.234262 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:28:16.234274 14009 solver.cpp:244]     Train net output #1: loss = 0.375003 (* 1 = 0.375003 loss)
I0413 18:28:16.234284 14009 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 18:28:22.608314 14009 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 18:28:25.860998 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5725
I0413 18:28:25.861040 14009 solver.cpp:404]     Test net output #1: loss = 1.54515 (* 1 = 1.54515 loss)
I0413 18:28:26.092070 14009 solver.cpp:228] Iteration 720, loss = 0.391743
I0413 18:28:26.092123 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:28:26.092136 14009 solver.cpp:244]     Train net output #1: loss = 0.391743 (* 1 = 0.391743 loss)
I0413 18:28:26.092149 14009 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 18:28:32.451930 14009 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 18:28:35.706712 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5234
I0413 18:28:35.706765 14009 solver.cpp:404]     Test net output #1: loss = 2.11695 (* 1 = 2.11695 loss)
I0413 18:28:35.971374 14009 solver.cpp:228] Iteration 740, loss = 0.352604
I0413 18:28:35.971429 14009 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:28:35.971442 14009 solver.cpp:244]     Train net output #1: loss = 0.352604 (* 1 = 0.352604 loss)
I0413 18:28:35.971451 14009 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 18:28:42.325738 14009 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 18:28:45.562106 14009 solver.cpp:404]     Test net output #0: accuracy = 0.61
I0413 18:28:45.562162 14009 solver.cpp:404]     Test net output #1: loss = 1.38203 (* 1 = 1.38203 loss)
I0413 18:28:45.816401 14009 solver.cpp:228] Iteration 760, loss = 0.372749
I0413 18:28:45.816450 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:28:45.816467 14009 solver.cpp:244]     Train net output #1: loss = 0.372749 (* 1 = 0.372749 loss)
I0413 18:28:45.816478 14009 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 18:28:52.250833 14009 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 18:28:55.420557 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6649
I0413 18:28:55.420609 14009 solver.cpp:404]     Test net output #1: loss = 1.1504 (* 1 = 1.1504 loss)
I0413 18:28:55.666642 14009 solver.cpp:228] Iteration 780, loss = 0.314714
I0413 18:28:55.666676 14009 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:28:55.666695 14009 solver.cpp:244]     Train net output #1: loss = 0.314714 (* 1 = 0.314714 loss)
I0413 18:28:55.666703 14009 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 18:29:02.215265 14009 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 18:29:05.317497 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6314
I0413 18:29:05.317556 14009 solver.cpp:404]     Test net output #1: loss = 1.25053 (* 1 = 1.25053 loss)
I0413 18:29:05.556908 14009 solver.cpp:228] Iteration 800, loss = 0.357677
I0413 18:29:05.556980 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:29:05.557019 14009 solver.cpp:244]     Train net output #1: loss = 0.357677 (* 1 = 0.357677 loss)
I0413 18:29:05.557044 14009 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 18:29:12.131124 14009 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 18:29:15.105139 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6286
I0413 18:29:15.105196 14009 solver.cpp:404]     Test net output #1: loss = 1.14985 (* 1 = 1.14985 loss)
I0413 18:29:15.378568 14009 solver.cpp:228] Iteration 820, loss = 0.392878
I0413 18:29:15.378615 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:29:15.378628 14009 solver.cpp:244]     Train net output #1: loss = 0.392878 (* 1 = 0.392878 loss)
I0413 18:29:15.378640 14009 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 18:29:22.055088 14009 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 18:29:24.982794 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7411
I0413 18:29:24.982836 14009 solver.cpp:404]     Test net output #1: loss = 0.787989 (* 1 = 0.787989 loss)
I0413 18:29:25.248077 14009 solver.cpp:228] Iteration 840, loss = 0.362324
I0413 18:29:25.248121 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:29:25.248134 14009 solver.cpp:244]     Train net output #1: loss = 0.362324 (* 1 = 0.362324 loss)
I0413 18:29:25.248144 14009 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 18:29:32.021302 14009 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 18:29:34.956501 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5625
I0413 18:29:34.956547 14009 solver.cpp:404]     Test net output #1: loss = 1.50133 (* 1 = 1.50133 loss)
I0413 18:29:35.185626 14009 solver.cpp:228] Iteration 860, loss = 0.364334
I0413 18:29:35.185668 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:29:35.185680 14009 solver.cpp:244]     Train net output #1: loss = 0.364334 (* 1 = 0.364334 loss)
I0413 18:29:35.185689 14009 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 18:29:41.911816 14009 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 18:29:44.962574 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6981
I0413 18:29:44.962653 14009 solver.cpp:404]     Test net output #1: loss = 0.916765 (* 1 = 0.916765 loss)
I0413 18:29:45.193461 14009 solver.cpp:228] Iteration 880, loss = 0.422323
I0413 18:29:45.193506 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:29:45.193518 14009 solver.cpp:244]     Train net output #1: loss = 0.422323 (* 1 = 0.422323 loss)
I0413 18:29:45.193533 14009 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 18:29:51.847375 14009 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 18:29:54.917783 14009 solver.cpp:404]     Test net output #0: accuracy = 0.729
I0413 18:29:54.917832 14009 solver.cpp:404]     Test net output #1: loss = 0.830098 (* 1 = 0.830098 loss)
I0413 18:29:55.150106 14009 solver.cpp:228] Iteration 900, loss = 0.413204
I0413 18:29:55.150151 14009 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:29:55.150164 14009 solver.cpp:244]     Train net output #1: loss = 0.413204 (* 1 = 0.413204 loss)
I0413 18:29:55.150174 14009 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 18:30:01.715225 14009 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 18:30:04.867290 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7326
I0413 18:30:04.867352 14009 solver.cpp:404]     Test net output #1: loss = 0.780732 (* 1 = 0.780732 loss)
I0413 18:30:05.091681 14009 solver.cpp:228] Iteration 920, loss = 0.427151
I0413 18:30:05.091747 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:30:05.091764 14009 solver.cpp:244]     Train net output #1: loss = 0.427151 (* 1 = 0.427151 loss)
I0413 18:30:05.091775 14009 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 18:30:11.526712 14009 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 18:30:14.764750 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7178
I0413 18:30:14.764824 14009 solver.cpp:404]     Test net output #1: loss = 0.849765 (* 1 = 0.849765 loss)
I0413 18:30:15.047444 14009 solver.cpp:228] Iteration 940, loss = 0.367489
I0413 18:30:15.047497 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:30:15.047513 14009 solver.cpp:244]     Train net output #1: loss = 0.367489 (* 1 = 0.367489 loss)
I0413 18:30:15.047529 14009 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 18:30:21.368309 14009 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 18:30:24.634404 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6618
I0413 18:30:24.634456 14009 solver.cpp:404]     Test net output #1: loss = 1.15333 (* 1 = 1.15333 loss)
I0413 18:30:24.884948 14009 solver.cpp:228] Iteration 960, loss = 0.348983
I0413 18:30:24.885012 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:30:24.885027 14009 solver.cpp:244]     Train net output #1: loss = 0.348983 (* 1 = 0.348983 loss)
I0413 18:30:24.885040 14009 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 18:30:31.226392 14009 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 18:30:34.444722 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6959
I0413 18:30:34.444768 14009 solver.cpp:404]     Test net output #1: loss = 0.920464 (* 1 = 0.920464 loss)
I0413 18:30:34.697160 14009 solver.cpp:228] Iteration 980, loss = 0.342239
I0413 18:30:34.697203 14009 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:30:34.697216 14009 solver.cpp:244]     Train net output #1: loss = 0.342239 (* 1 = 0.342239 loss)
I0413 18:30:34.697230 14009 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 18:30:41.032727 14009 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 18:30:44.306397 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7233
I0413 18:30:44.306440 14009 solver.cpp:404]     Test net output #1: loss = 0.800576 (* 1 = 0.800576 loss)
I0413 18:30:44.572022 14009 solver.cpp:228] Iteration 1000, loss = 0.348329
I0413 18:30:44.572103 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:30:44.572115 14009 solver.cpp:244]     Train net output #1: loss = 0.348329 (* 1 = 0.348329 loss)
I0413 18:30:44.572126 14009 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 18:30:50.914551 14009 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 18:30:54.162387 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6186
I0413 18:30:54.162438 14009 solver.cpp:404]     Test net output #1: loss = 1.2293 (* 1 = 1.2293 loss)
I0413 18:30:54.428213 14009 solver.cpp:228] Iteration 1020, loss = 0.378455
I0413 18:30:54.428272 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:30:54.428288 14009 solver.cpp:244]     Train net output #1: loss = 0.378455 (* 1 = 0.378455 loss)
I0413 18:30:54.428299 14009 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 18:31:00.872073 14009 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 18:31:04.093631 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6214
I0413 18:31:04.093688 14009 solver.cpp:404]     Test net output #1: loss = 1.18066 (* 1 = 1.18066 loss)
I0413 18:31:04.349314 14009 solver.cpp:228] Iteration 1040, loss = 0.392495
I0413 18:31:04.349371 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:31:04.349385 14009 solver.cpp:244]     Train net output #1: loss = 0.392495 (* 1 = 0.392495 loss)
I0413 18:31:04.349393 14009 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 18:31:10.872895 14009 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 18:31:14.016096 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6679
I0413 18:31:14.016154 14009 solver.cpp:404]     Test net output #1: loss = 1.05993 (* 1 = 1.05993 loss)
I0413 18:31:14.274027 14009 solver.cpp:228] Iteration 1060, loss = 0.527772
I0413 18:31:14.274078 14009 solver.cpp:244]     Train net output #0: accuracy = 0.792969
I0413 18:31:14.274093 14009 solver.cpp:244]     Train net output #1: loss = 0.527772 (* 1 = 0.527772 loss)
I0413 18:31:14.274104 14009 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 18:31:20.845594 14009 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 18:31:23.937472 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6488
I0413 18:31:23.937522 14009 solver.cpp:404]     Test net output #1: loss = 1.15008 (* 1 = 1.15008 loss)
I0413 18:31:24.189935 14009 solver.cpp:228] Iteration 1080, loss = 0.391391
I0413 18:31:24.189973 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:31:24.189985 14009 solver.cpp:244]     Train net output #1: loss = 0.391391 (* 1 = 0.391391 loss)
I0413 18:31:24.189993 14009 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 18:31:30.857007 14009 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 18:31:33.846349 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7309
I0413 18:31:33.846415 14009 solver.cpp:404]     Test net output #1: loss = 0.771698 (* 1 = 0.771698 loss)
I0413 18:31:34.080550 14009 solver.cpp:228] Iteration 1100, loss = 0.46783
I0413 18:31:34.080598 14009 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:31:34.080610 14009 solver.cpp:244]     Train net output #1: loss = 0.46783 (* 1 = 0.46783 loss)
I0413 18:31:34.080623 14009 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 18:31:40.845170 14009 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 18:31:43.788070 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6904
I0413 18:31:43.788130 14009 solver.cpp:404]     Test net output #1: loss = 0.93422 (* 1 = 0.93422 loss)
I0413 18:31:44.044478 14009 solver.cpp:228] Iteration 1120, loss = 0.497818
I0413 18:31:44.044530 14009 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:31:44.044544 14009 solver.cpp:244]     Train net output #1: loss = 0.497818 (* 1 = 0.497818 loss)
I0413 18:31:44.044556 14009 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 18:31:50.844904 14009 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 18:31:53.741003 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6934
I0413 18:31:53.741056 14009 solver.cpp:404]     Test net output #1: loss = 0.982324 (* 1 = 0.982324 loss)
I0413 18:31:53.971053 14009 solver.cpp:228] Iteration 1140, loss = 0.414401
I0413 18:31:53.971114 14009 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:31:53.971132 14009 solver.cpp:244]     Train net output #1: loss = 0.414401 (* 1 = 0.414401 loss)
I0413 18:31:53.971143 14009 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 18:32:00.717233 14009 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 18:32:03.738687 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7181
I0413 18:32:03.738764 14009 solver.cpp:404]     Test net output #1: loss = 0.913497 (* 1 = 0.913497 loss)
I0413 18:32:03.974812 14009 solver.cpp:228] Iteration 1160, loss = 0.3419
I0413 18:32:03.974885 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:32:03.974907 14009 solver.cpp:244]     Train net output #1: loss = 0.3419 (* 1 = 0.3419 loss)
I0413 18:32:03.974931 14009 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 18:32:10.639483 14009 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 18:32:13.679886 14009 solver.cpp:404]     Test net output #0: accuracy = 0.618
I0413 18:32:13.679926 14009 solver.cpp:404]     Test net output #1: loss = 1.41928 (* 1 = 1.41928 loss)
I0413 18:32:13.910109 14009 solver.cpp:228] Iteration 1180, loss = 0.318347
I0413 18:32:13.910159 14009 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:32:13.910171 14009 solver.cpp:244]     Train net output #1: loss = 0.318347 (* 1 = 0.318347 loss)
I0413 18:32:13.910192 14009 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 18:32:20.426416 14009 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 18:32:23.643703 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7272
I0413 18:32:23.643750 14009 solver.cpp:404]     Test net output #1: loss = 0.817524 (* 1 = 0.817524 loss)
I0413 18:32:23.872881 14009 solver.cpp:228] Iteration 1200, loss = 0.354723
I0413 18:32:23.872926 14009 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:32:23.872938 14009 solver.cpp:244]     Train net output #1: loss = 0.354723 (* 1 = 0.354723 loss)
I0413 18:32:23.872948 14009 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 18:32:30.269819 14009 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 18:32:33.493558 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6791
I0413 18:32:33.493628 14009 solver.cpp:404]     Test net output #1: loss = 1.0175 (* 1 = 1.0175 loss)
I0413 18:32:33.752528 14009 solver.cpp:228] Iteration 1220, loss = 0.423675
I0413 18:32:33.752586 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:32:33.752604 14009 solver.cpp:244]     Train net output #1: loss = 0.423675 (* 1 = 0.423675 loss)
I0413 18:32:33.752617 14009 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 18:32:40.150527 14009 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 18:32:43.385012 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6051
I0413 18:32:43.385059 14009 solver.cpp:404]     Test net output #1: loss = 1.49211 (* 1 = 1.49211 loss)
I0413 18:32:43.669351 14009 solver.cpp:228] Iteration 1240, loss = 0.421868
I0413 18:32:43.669397 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:32:43.669420 14009 solver.cpp:244]     Train net output #1: loss = 0.421868 (* 1 = 0.421868 loss)
I0413 18:32:43.669428 14009 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 18:32:49.981550 14009 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 18:32:53.224774 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7647
I0413 18:32:53.224833 14009 solver.cpp:404]     Test net output #1: loss = 0.693291 (* 1 = 0.693291 loss)
I0413 18:32:53.459915 14009 solver.cpp:228] Iteration 1260, loss = 0.302722
I0413 18:32:53.459969 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:32:53.459982 14009 solver.cpp:244]     Train net output #1: loss = 0.302722 (* 1 = 0.302722 loss)
I0413 18:32:53.459991 14009 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 18:32:59.772307 14009 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 18:33:03.016021 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6739
I0413 18:33:03.016062 14009 solver.cpp:404]     Test net output #1: loss = 1.07607 (* 1 = 1.07607 loss)
I0413 18:33:03.288794 14009 solver.cpp:228] Iteration 1280, loss = 0.362215
I0413 18:33:03.288842 14009 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:33:03.288856 14009 solver.cpp:244]     Train net output #1: loss = 0.362215 (* 1 = 0.362215 loss)
I0413 18:33:03.288868 14009 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 18:33:09.689786 14009 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 18:33:12.909023 14009 solver.cpp:404]     Test net output #0: accuracy = 0.546
I0413 18:33:12.909077 14009 solver.cpp:404]     Test net output #1: loss = 1.58049 (* 1 = 1.58049 loss)
I0413 18:33:13.141239 14009 solver.cpp:228] Iteration 1300, loss = 0.487336
I0413 18:33:13.141296 14009 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0413 18:33:13.141310 14009 solver.cpp:244]     Train net output #1: loss = 0.487336 (* 1 = 0.487336 loss)
I0413 18:33:13.141320 14009 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 18:33:19.565727 14009 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 18:33:22.725045 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6003
I0413 18:33:22.725096 14009 solver.cpp:404]     Test net output #1: loss = 1.33735 (* 1 = 1.33735 loss)
I0413 18:33:22.982414 14009 solver.cpp:228] Iteration 1320, loss = 0.399161
I0413 18:33:22.982467 14009 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:33:22.982483 14009 solver.cpp:244]     Train net output #1: loss = 0.399161 (* 1 = 0.399161 loss)
I0413 18:33:22.982496 14009 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 18:33:29.574293 14009 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 18:33:32.654683 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6278
I0413 18:33:32.654729 14009 solver.cpp:404]     Test net output #1: loss = 1.24756 (* 1 = 1.24756 loss)
I0413 18:33:32.908973 14009 solver.cpp:228] Iteration 1340, loss = 0.404709
I0413 18:33:32.909023 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:33:32.909037 14009 solver.cpp:244]     Train net output #1: loss = 0.404709 (* 1 = 0.404709 loss)
I0413 18:33:32.909049 14009 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 18:33:39.549556 14009 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 18:33:42.578225 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6494
I0413 18:33:42.578285 14009 solver.cpp:404]     Test net output #1: loss = 1.29328 (* 1 = 1.29328 loss)
I0413 18:33:42.842428 14009 solver.cpp:228] Iteration 1360, loss = 0.341342
I0413 18:33:42.842492 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:33:42.842509 14009 solver.cpp:244]     Train net output #1: loss = 0.341342 (* 1 = 0.341342 loss)
I0413 18:33:42.842525 14009 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 18:33:49.523421 14009 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 18:33:52.397719 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6806
I0413 18:33:52.397768 14009 solver.cpp:404]     Test net output #1: loss = 1.02176 (* 1 = 1.02176 loss)
I0413 18:33:52.662503 14009 solver.cpp:228] Iteration 1380, loss = 0.384625
I0413 18:33:52.662551 14009 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:33:52.662564 14009 solver.cpp:244]     Train net output #1: loss = 0.384625 (* 1 = 0.384625 loss)
I0413 18:33:52.662574 14009 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 18:33:59.426262 14009 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 18:34:02.366662 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6675
I0413 18:34:02.366719 14009 solver.cpp:404]     Test net output #1: loss = 1.03707 (* 1 = 1.03707 loss)
I0413 18:34:02.595512 14009 solver.cpp:228] Iteration 1400, loss = 0.34551
I0413 18:34:02.595551 14009 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:34:02.595563 14009 solver.cpp:244]     Train net output #1: loss = 0.34551 (* 1 = 0.34551 loss)
I0413 18:34:02.595577 14009 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 18:34:09.276419 14009 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 18:34:12.288550 14009 solver.cpp:404]     Test net output #0: accuracy = 0.4283
I0413 18:34:12.288619 14009 solver.cpp:404]     Test net output #1: loss = 3.11211 (* 1 = 3.11211 loss)
I0413 18:34:12.519956 14009 solver.cpp:228] Iteration 1420, loss = 0.459313
I0413 18:34:12.520002 14009 solver.cpp:244]     Train net output #0: accuracy = 0.832031
I0413 18:34:12.520016 14009 solver.cpp:244]     Train net output #1: loss = 0.459313 (* 1 = 0.459313 loss)
I0413 18:34:12.520027 14009 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 18:34:19.163149 14009 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 18:34:22.205732 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6944
I0413 18:34:22.205787 14009 solver.cpp:404]     Test net output #1: loss = 0.914717 (* 1 = 0.914717 loss)
I0413 18:34:22.434177 14009 solver.cpp:228] Iteration 1440, loss = 0.310846
I0413 18:34:22.434228 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:34:22.434242 14009 solver.cpp:244]     Train net output #1: loss = 0.310846 (* 1 = 0.310846 loss)
I0413 18:34:22.434255 14009 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 18:34:28.993376 14009 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 18:34:32.160387 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6933
I0413 18:34:32.160456 14009 solver.cpp:404]     Test net output #1: loss = 0.95011 (* 1 = 0.95011 loss)
I0413 18:34:32.389595 14009 solver.cpp:228] Iteration 1460, loss = 0.402369
I0413 18:34:32.389721 14009 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:34:32.389780 14009 solver.cpp:244]     Train net output #1: loss = 0.402369 (* 1 = 0.402369 loss)
I0413 18:34:32.389796 14009 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 18:34:38.841075 14009 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 18:34:42.112166 14009 solver.cpp:404]     Test net output #0: accuracy = 0.602
I0413 18:34:42.112213 14009 solver.cpp:404]     Test net output #1: loss = 1.31452 (* 1 = 1.31452 loss)
I0413 18:34:42.351805 14009 solver.cpp:228] Iteration 1480, loss = 0.274846
I0413 18:34:42.351853 14009 solver.cpp:244]     Train net output #0: accuracy = 0.917969
I0413 18:34:42.351866 14009 solver.cpp:244]     Train net output #1: loss = 0.274846 (* 1 = 0.274846 loss)
I0413 18:34:42.351874 14009 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 18:34:48.739006 14009 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 18:34:52.032245 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6267
I0413 18:34:52.032299 14009 solver.cpp:404]     Test net output #1: loss = 1.21535 (* 1 = 1.21535 loss)
I0413 18:34:52.272835 14009 solver.cpp:228] Iteration 1500, loss = 0.353753
I0413 18:34:52.272883 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:34:52.272896 14009 solver.cpp:244]     Train net output #1: loss = 0.353753 (* 1 = 0.353753 loss)
I0413 18:34:52.272904 14009 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 18:34:58.641886 14009 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 18:35:01.876250 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6801
I0413 18:35:01.876289 14009 solver.cpp:404]     Test net output #1: loss = 0.979431 (* 1 = 0.979431 loss)
I0413 18:35:02.142496 14009 solver.cpp:228] Iteration 1520, loss = 0.367637
I0413 18:35:02.142544 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:35:02.142556 14009 solver.cpp:244]     Train net output #1: loss = 0.367637 (* 1 = 0.367637 loss)
I0413 18:35:02.142566 14009 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 18:35:08.466181 14009 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 18:35:11.740530 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5234
I0413 18:35:11.740582 14009 solver.cpp:404]     Test net output #1: loss = 1.64628 (* 1 = 1.64628 loss)
I0413 18:35:12.010860 14009 solver.cpp:228] Iteration 1540, loss = 0.353956
I0413 18:35:12.010900 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:35:12.010913 14009 solver.cpp:244]     Train net output #1: loss = 0.353956 (* 1 = 0.353956 loss)
I0413 18:35:12.010922 14009 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 18:35:18.350039 14009 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 18:35:21.653249 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6693
I0413 18:35:21.653291 14009 solver.cpp:404]     Test net output #1: loss = 1.10239 (* 1 = 1.10239 loss)
I0413 18:35:21.907224 14009 solver.cpp:228] Iteration 1560, loss = 0.478003
I0413 18:35:21.907269 14009 solver.cpp:244]     Train net output #0: accuracy = 0.824219
I0413 18:35:21.907281 14009 solver.cpp:244]     Train net output #1: loss = 0.478003 (* 1 = 0.478003 loss)
I0413 18:35:21.907290 14009 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 18:35:28.318399 14009 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 18:35:31.480867 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6601
I0413 18:35:31.480918 14009 solver.cpp:404]     Test net output #1: loss = 1.0486 (* 1 = 1.0486 loss)
I0413 18:35:31.742846 14009 solver.cpp:228] Iteration 1580, loss = 0.323233
I0413 18:35:31.742884 14009 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:35:31.742899 14009 solver.cpp:244]     Train net output #1: loss = 0.323233 (* 1 = 0.323233 loss)
I0413 18:35:31.742919 14009 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 18:35:38.267117 14009 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 18:35:41.361286 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7678
I0413 18:35:41.361330 14009 solver.cpp:404]     Test net output #1: loss = 0.674266 (* 1 = 0.674266 loss)
I0413 18:35:41.631844 14009 solver.cpp:228] Iteration 1600, loss = 0.379359
I0413 18:35:41.631891 14009 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:35:41.631903 14009 solver.cpp:244]     Train net output #1: loss = 0.379359 (* 1 = 0.379359 loss)
I0413 18:35:41.631911 14009 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 18:35:48.199743 14009 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 18:35:51.210894 14009 solver.cpp:404]     Test net output #0: accuracy = 0.725
I0413 18:35:51.210935 14009 solver.cpp:404]     Test net output #1: loss = 0.829928 (* 1 = 0.829928 loss)
I0413 18:35:51.458096 14009 solver.cpp:228] Iteration 1620, loss = 0.337161
I0413 18:35:51.458154 14009 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:35:51.458166 14009 solver.cpp:244]     Train net output #1: loss = 0.337161 (* 1 = 0.337161 loss)
I0413 18:35:51.458176 14009 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 18:35:58.176703 14009 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 18:36:01.166081 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5537
I0413 18:36:01.166121 14009 solver.cpp:404]     Test net output #1: loss = 1.54384 (* 1 = 1.54384 loss)
I0413 18:36:01.403481 14009 solver.cpp:228] Iteration 1640, loss = 0.502471
I0413 18:36:01.403534 14009 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:36:01.403555 14009 solver.cpp:244]     Train net output #1: loss = 0.502471 (* 1 = 0.502471 loss)
I0413 18:36:01.403589 14009 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 18:36:08.212746 14009 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 18:36:11.121770 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6184
I0413 18:36:11.121819 14009 solver.cpp:404]     Test net output #1: loss = 1.23407 (* 1 = 1.23407 loss)
I0413 18:36:11.355880 14009 solver.cpp:228] Iteration 1660, loss = 0.279682
I0413 18:36:11.355916 14009 solver.cpp:244]     Train net output #0: accuracy = 0.894531
I0413 18:36:11.355927 14009 solver.cpp:244]     Train net output #1: loss = 0.279682 (* 1 = 0.279682 loss)
I0413 18:36:11.355937 14009 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 18:36:18.103715 14009 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 18:36:21.099318 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6901
I0413 18:36:21.099366 14009 solver.cpp:404]     Test net output #1: loss = 1.01863 (* 1 = 1.01863 loss)
I0413 18:36:21.325352 14009 solver.cpp:228] Iteration 1680, loss = 0.351213
I0413 18:36:21.325404 14009 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:36:21.325419 14009 solver.cpp:244]     Train net output #1: loss = 0.351213 (* 1 = 0.351213 loss)
I0413 18:36:21.325431 14009 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 18:36:27.995324 14009 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 18:36:31.036197 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6794
I0413 18:36:31.036245 14009 solver.cpp:404]     Test net output #1: loss = 1.03218 (* 1 = 1.03218 loss)
I0413 18:36:31.265880 14009 solver.cpp:228] Iteration 1700, loss = 0.361417
I0413 18:36:31.265938 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:36:31.265949 14009 solver.cpp:244]     Train net output #1: loss = 0.361417 (* 1 = 0.361417 loss)
I0413 18:36:31.265959 14009 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 18:36:37.904703 14009 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 18:36:41.009508 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6685
I0413 18:36:41.009557 14009 solver.cpp:404]     Test net output #1: loss = 1.09463 (* 1 = 1.09463 loss)
I0413 18:36:41.237656 14009 solver.cpp:228] Iteration 1720, loss = 0.353711
I0413 18:36:41.237721 14009 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:36:41.237735 14009 solver.cpp:244]     Train net output #1: loss = 0.353711 (* 1 = 0.353711 loss)
I0413 18:36:41.237745 14009 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 18:36:47.747409 14009 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 18:36:50.964771 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5731
I0413 18:36:50.964828 14009 solver.cpp:404]     Test net output #1: loss = 1.5566 (* 1 = 1.5566 loss)
I0413 18:36:51.180764 14009 solver.cpp:228] Iteration 1740, loss = 0.333006
I0413 18:36:51.180811 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:36:51.180827 14009 solver.cpp:244]     Train net output #1: loss = 0.333006 (* 1 = 0.333006 loss)
I0413 18:36:51.180840 14009 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 18:36:57.595469 14009 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 18:37:00.833737 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5755
I0413 18:37:00.833789 14009 solver.cpp:404]     Test net output #1: loss = 1.67322 (* 1 = 1.67322 loss)
I0413 18:37:01.074995 14009 solver.cpp:228] Iteration 1760, loss = 0.460179
I0413 18:37:01.075052 14009 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:37:01.075067 14009 solver.cpp:244]     Train net output #1: loss = 0.460179 (* 1 = 0.460179 loss)
I0413 18:37:01.075078 14009 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 18:37:07.429710 14009 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 18:37:10.688663 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6946
I0413 18:37:10.688712 14009 solver.cpp:404]     Test net output #1: loss = 0.943339 (* 1 = 0.943339 loss)
I0413 18:37:10.948103 14009 solver.cpp:228] Iteration 1780, loss = 0.324205
I0413 18:37:10.948150 14009 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:37:10.948161 14009 solver.cpp:244]     Train net output #1: loss = 0.324205 (* 1 = 0.324205 loss)
I0413 18:37:10.948170 14009 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 18:37:17.235780 14009 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 18:37:20.491202 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6912
I0413 18:37:20.491250 14009 solver.cpp:404]     Test net output #1: loss = 0.966408 (* 1 = 0.966408 loss)
I0413 18:37:20.724572 14009 solver.cpp:228] Iteration 1800, loss = 0.33672
I0413 18:37:20.724627 14009 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:37:20.724643 14009 solver.cpp:244]     Train net output #1: loss = 0.33672 (* 1 = 0.33672 loss)
I0413 18:37:20.724655 14009 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 18:37:27.048396 14009 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 18:37:30.299427 14009 solver.cpp:404]     Test net output #0: accuracy = 0.699
I0413 18:37:30.299492 14009 solver.cpp:404]     Test net output #1: loss = 0.960801 (* 1 = 0.960801 loss)
I0413 18:37:30.583964 14009 solver.cpp:228] Iteration 1820, loss = 0.352265
I0413 18:37:30.584012 14009 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0413 18:37:30.584022 14009 solver.cpp:244]     Train net output #1: loss = 0.352265 (* 1 = 0.352265 loss)
I0413 18:37:30.584036 14009 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 18:37:36.981377 14009 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 18:37:40.189337 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7438
I0413 18:37:40.189383 14009 solver.cpp:404]     Test net output #1: loss = 0.760678 (* 1 = 0.760678 loss)
I0413 18:37:40.458106 14009 solver.cpp:228] Iteration 1840, loss = 0.372246
I0413 18:37:40.458164 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:37:40.458178 14009 solver.cpp:244]     Train net output #1: loss = 0.372246 (* 1 = 0.372246 loss)
I0413 18:37:40.458189 14009 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 18:37:46.950042 14009 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 18:37:50.082717 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5908
I0413 18:37:50.082788 14009 solver.cpp:404]     Test net output #1: loss = 1.4572 (* 1 = 1.4572 loss)
I0413 18:37:50.323988 14009 solver.cpp:228] Iteration 1860, loss = 0.301804
I0413 18:37:50.324056 14009 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:37:50.324072 14009 solver.cpp:244]     Train net output #1: loss = 0.301804 (* 1 = 0.301804 loss)
I0413 18:37:50.324084 14009 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 18:37:56.889906 14009 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 18:37:59.975438 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6931
I0413 18:37:59.975489 14009 solver.cpp:404]     Test net output #1: loss = 0.951322 (* 1 = 0.951322 loss)
I0413 18:38:00.210047 14009 solver.cpp:228] Iteration 1880, loss = 0.403843
I0413 18:38:00.210111 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:38:00.210131 14009 solver.cpp:244]     Train net output #1: loss = 0.403843 (* 1 = 0.403843 loss)
I0413 18:38:00.210146 14009 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 18:38:06.895611 14009 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 18:38:09.844261 14009 solver.cpp:404]     Test net output #0: accuracy = 0.7167
I0413 18:38:09.844306 14009 solver.cpp:404]     Test net output #1: loss = 0.919053 (* 1 = 0.919053 loss)
I0413 18:38:10.101423 14009 solver.cpp:228] Iteration 1900, loss = 0.359546
I0413 18:38:10.101467 14009 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:38:10.101480 14009 solver.cpp:244]     Train net output #1: loss = 0.359546 (* 1 = 0.359546 loss)
I0413 18:38:10.101490 14009 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 18:38:16.870105 14009 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 18:38:19.778590 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6209
I0413 18:38:19.778650 14009 solver.cpp:404]     Test net output #1: loss = 1.28957 (* 1 = 1.28957 loss)
I0413 18:38:20.004330 14009 solver.cpp:228] Iteration 1920, loss = 0.390976
I0413 18:38:20.004379 14009 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:38:20.004391 14009 solver.cpp:244]     Train net output #1: loss = 0.390976 (* 1 = 0.390976 loss)
I0413 18:38:20.004400 14009 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 18:38:26.789650 14009 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 18:38:29.726444 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5954
I0413 18:38:29.726485 14009 solver.cpp:404]     Test net output #1: loss = 1.36398 (* 1 = 1.36398 loss)
I0413 18:38:29.956043 14009 solver.cpp:228] Iteration 1940, loss = 0.356183
I0413 18:38:29.956102 14009 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:38:29.956115 14009 solver.cpp:244]     Train net output #1: loss = 0.356183 (* 1 = 0.356183 loss)
I0413 18:38:29.956125 14009 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 18:38:36.585836 14009 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 18:38:39.642037 14009 solver.cpp:404]     Test net output #0: accuracy = 0.6574
I0413 18:38:39.642078 14009 solver.cpp:404]     Test net output #1: loss = 1.15404 (* 1 = 1.15404 loss)
I0413 18:38:39.868357 14009 solver.cpp:228] Iteration 1960, loss = 0.347604
I0413 18:38:39.868399 14009 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:38:39.868412 14009 solver.cpp:244]     Train net output #1: loss = 0.347604 (* 1 = 0.347604 loss)
I0413 18:38:39.868422 14009 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 18:38:46.486088 14009 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 18:38:49.587991 14009 solver.cpp:404]     Test net output #0: accuracy = 0.5802
I0413 18:38:49.588037 14009 solver.cpp:404]     Test net output #1: loss = 1.54853 (* 1 = 1.54853 loss)
I0413 18:38:49.815309 14009 solver.cpp:228] Iteration 1980, loss = 0.35974
I0413 18:38:49.815381 14009 solver.cpp:244]     Train net output #0: accuracy = 0.855469
I0413 18:38:49.815395 14009 solver.cpp:244]     Train net output #1: loss = 0.35974 (* 1 = 0.35974 loss)
I0413 18:38:49.815407 14009 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 18:38:56.363091 14009 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar7/ResNet-cifar7_iter_2000.caffemodel
I0413 18:38:56.371157 14009 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar7/ResNet-cifar7_iter_2000.solverstate
cmd: src/solve_network.py
snapshot_prefix: results/snapshots/ResNet-cifar
loss_prefix: results/loss/ResNet-cifar
cleaning
cmd: src/solve_network.py
Training ResNet-cifar 0
src/solve_network.py prototxt/DyResNet/ResNet-cifar0-solver.prototxt --train-loss results/loss/ResNet-cifar0/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar0/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar0/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar0/ResNet-cifar-acc.val --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.867969703674
Training ResNet-cifar 1
src/solve_network.py prototxt/DyResNet/ResNet-cifar1-solver.prototxt --train-loss results/loss/ResNet-cifar1/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar1/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar1/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar1/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar0/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.74163928926
Training ResNet-cifar 2
src/solve_network.py prototxt/DyResNet/ResNet-cifar2-solver.prototxt --train-loss results/loss/ResNet-cifar2/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar2/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar2/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar2/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar1/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.659147492051
Training ResNet-cifar 3
src/solve_network.py prototxt/DyResNet/ResNet-cifar3-solver.prototxt --train-loss results/loss/ResNet-cifar3/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar3/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar3/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar3/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar2/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.627856215835
Training ResNet-cifar 4
src/solve_network.py prototxt/DyResNet/ResNet-cifar4-solver.prototxt --train-loss results/loss/ResNet-cifar4/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar4/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar4/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar4/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar3/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.504782161117
Training ResNet-cifar 5
src/solve_network.py prototxt/DyResNet/ResNet-cifar5-solver.prototxt --train-loss results/loss/ResNet-cifar5/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar5/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar5/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar5/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar4/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.437325452268
Training ResNet-cifar 6
src/solve_network.py prototxt/DyResNet/ResNet-cifar6-solver.prototxt --train-loss results/loss/ResNet-cifar6/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar6/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar6/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar6/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar5/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.428605091572
Training ResNet-cifar 7
src/solve_network.py prototxt/DyResNet/ResNet-cifar7-solver.prototxt --train-loss results/loss/ResNet-cifar7/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar7/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar7/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar7/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar6/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.352803355455
Training ResNet-cifar 8
src/solve_network.py prototxt/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
/home/liangjiang/code/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.
  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0413 18:38:59.023900 30343 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 20
base_lr: 0.1
display: 20
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot_prefix: "results/snapshots/ResNet-cifar8/ResNet-cifar8"
solver_mode: GPU
net: "prototxt/DyResNet/ResNet-cifar8.prototxt"
test_initialization: false
average_loss: 20
stepvalue: 32000
stepvalue: 48000
type: "SGD"
I0413 18:38:59.023943 30343 solver.cpp:91] Creating training net from net file: prototxt/DyResNet/ResNet-cifar8.prototxt
I0413 18:38:59.027748 30343 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0413 18:38:59.028451 30343 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_sub"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_sub"
  type: "BatchNorm"
  bottom: "conv3_sub"
  top: "conv3_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_sub"
  type: "Scale"
  bottom: "conv3_sub"
  top: "conv3_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv4_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1a"
  type: "BatchNorm"
  bottom: "conv4_1a"
  top: "conv4_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1a"
  type: "Scale"
  bottom: "conv4_1a"
  top: "conv4_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a_relu"
  type: "ReLU"
  bottom: "conv4_1a"
  top: "conv4_1a"
}
layer {
  name: "conv4_1b"
  type: "Convolution"
  bottom: "conv4_1a"
  top: "conv4_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1b"
  type: "BatchNorm"
  bottom: "conv4_1b"
  top: "conv4_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1b"
  type: "Scale"
  bottom: "conv4_1b"
  top: "conv4_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv3_sub"
  bottom: "conv4_1b"
  top: "conv4_1"
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2a"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2a"
  type: "BatchNorm"
  bottom: "conv4_2a"
  top: "conv4_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2a"
  type: "Scale"
  bottom: "conv4_2a"
  top: "conv4_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2a_relu"
  type: "ReLU"
  bottom: "conv4_2a"
  top: "conv4_2a"
}
layer {
  name: "conv4_2b"
  type: "Convolution"
  bottom: "conv4_2a"
  top: "conv4_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2b"
  type: "BatchNorm"
  bottom: "conv4_2b"
  top: "conv4_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2b"
  type: "Scale"
  bottom: "conv4_2b"
  top: "conv4_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_2b"
  top: "conv4_2"
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3a"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_3a"
  type: "BatchNorm"
  bottom: "conv4_3a"
  top: "conv4_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_3a"
  type: "Scale"
  bottom: "conv4_3a"
  top: "conv4_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3a_relu"
  type: "ReLU"
  bottom: "conv4_3a"
  top: "conv4_3a"
}
layer {
  name: "conv4_3b"
  type: "Convolution"
  bottom: "conv4_3a"
  top: "conv4_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_3b"
  type: "BatchNorm"
  bottom: "conv4_3b"
  top: "conv4_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_3b"
  type: "Scale"
  bottom: "conv4_3b"
  top: "conv4_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3"
  type: "Eltwise"
  bottom: "conv4_2"
  bottom: "conv4_3b"
  top: "conv4_3"
}
layer {
  name: "conv4_3_relu"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv4_3"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 18:38:59.029153 30343 layer_factory.hpp:77] Creating layer cifar
I0413 18:38:59.031769 30343 net.cpp:91] Creating Layer cifar
I0413 18:38:59.031831 30343 net.cpp:399] cifar -> data
I0413 18:38:59.031853 30343 net.cpp:399] cifar -> label
I0413 18:38:59.031867 30343 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 18:38:59.035233 30471 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_train_lmdb
I0413 18:38:59.077733 30343 data_layer.cpp:41] output data size: 256,3,32,32
I0413 18:38:59.089203 30343 net.cpp:141] Setting up cifar
I0413 18:38:59.089241 30343 net.cpp:148] Top shape: 256 3 32 32 (786432)
I0413 18:38:59.089248 30343 net.cpp:148] Top shape: 256 (256)
I0413 18:38:59.089253 30343 net.cpp:156] Memory required for data: 3146752
I0413 18:38:59.089263 30343 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 18:38:59.089313 30343 net.cpp:91] Creating Layer label_cifar_1_split
I0413 18:38:59.089323 30343 net.cpp:425] label_cifar_1_split <- label
I0413 18:38:59.089334 30343 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 18:38:59.089349 30343 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 18:38:59.089426 30343 net.cpp:141] Setting up label_cifar_1_split
I0413 18:38:59.089442 30343 net.cpp:148] Top shape: 256 (256)
I0413 18:38:59.089448 30343 net.cpp:148] Top shape: 256 (256)
I0413 18:38:59.089459 30343 net.cpp:156] Memory required for data: 3148800
I0413 18:38:59.089465 30343 layer_factory.hpp:77] Creating layer conv1
I0413 18:38:59.089499 30343 net.cpp:91] Creating Layer conv1
I0413 18:38:59.089506 30343 net.cpp:425] conv1 <- data
I0413 18:38:59.089516 30343 net.cpp:399] conv1 -> conv1
I0413 18:38:59.363093 30343 net.cpp:141] Setting up conv1
I0413 18:38:59.363136 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.363142 30343 net.cpp:156] Memory required for data: 19926016
I0413 18:38:59.363163 30343 layer_factory.hpp:77] Creating layer bn_conv1
I0413 18:38:59.363180 30343 net.cpp:91] Creating Layer bn_conv1
I0413 18:38:59.363188 30343 net.cpp:425] bn_conv1 <- conv1
I0413 18:38:59.363199 30343 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 18:38:59.363411 30343 net.cpp:141] Setting up bn_conv1
I0413 18:38:59.363421 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.363426 30343 net.cpp:156] Memory required for data: 36703232
I0413 18:38:59.363440 30343 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:38:59.363453 30343 net.cpp:91] Creating Layer scale_conv1
I0413 18:38:59.363459 30343 net.cpp:425] scale_conv1 <- conv1
I0413 18:38:59.363468 30343 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 18:38:59.363512 30343 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:38:59.363636 30343 net.cpp:141] Setting up scale_conv1
I0413 18:38:59.363646 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.363651 30343 net.cpp:156] Memory required for data: 53480448
I0413 18:38:59.363661 30343 layer_factory.hpp:77] Creating layer conv1_relu
I0413 18:38:59.363672 30343 net.cpp:91] Creating Layer conv1_relu
I0413 18:38:59.363677 30343 net.cpp:425] conv1_relu <- conv1
I0413 18:38:59.363683 30343 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 18:38:59.364096 30343 net.cpp:141] Setting up conv1_relu
I0413 18:38:59.364112 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.364117 30343 net.cpp:156] Memory required for data: 70257664
I0413 18:38:59.364123 30343 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 18:38:59.364131 30343 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 18:38:59.364137 30343 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 18:38:59.364145 30343 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 18:38:59.364156 30343 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 18:38:59.364204 30343 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 18:38:59.364212 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.364219 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.364224 30343 net.cpp:156] Memory required for data: 103812096
I0413 18:38:59.364229 30343 layer_factory.hpp:77] Creating layer conv2_1a
I0413 18:38:59.364248 30343 net.cpp:91] Creating Layer conv2_1a
I0413 18:38:59.364254 30343 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 18:38:59.364264 30343 net.cpp:399] conv2_1a -> conv2_1a
I0413 18:38:59.367828 30343 net.cpp:141] Setting up conv2_1a
I0413 18:38:59.367908 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.367925 30343 net.cpp:156] Memory required for data: 120589312
I0413 18:38:59.367938 30343 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 18:38:59.367950 30343 net.cpp:91] Creating Layer bn_conv2_1a
I0413 18:38:59.367957 30343 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 18:38:59.367966 30343 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 18:38:59.368401 30343 net.cpp:141] Setting up bn_conv2_1a
I0413 18:38:59.368443 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.368453 30343 net.cpp:156] Memory required for data: 137366528
I0413 18:38:59.368479 30343 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:38:59.368512 30343 net.cpp:91] Creating Layer scale_conv2_1a
I0413 18:38:59.368532 30343 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 18:38:59.368553 30343 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 18:38:59.368690 30343 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:38:59.368917 30343 net.cpp:141] Setting up scale_conv2_1a
I0413 18:38:59.368996 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.369007 30343 net.cpp:156] Memory required for data: 154143744
I0413 18:38:59.369032 30343 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 18:38:59.369062 30343 net.cpp:91] Creating Layer conv2_1a_relu
I0413 18:38:59.369067 30343 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 18:38:59.369076 30343 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 18:38:59.370146 30343 net.cpp:141] Setting up conv2_1a_relu
I0413 18:38:59.370198 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.370203 30343 net.cpp:156] Memory required for data: 170920960
I0413 18:38:59.370209 30343 layer_factory.hpp:77] Creating layer conv2_1b
I0413 18:38:59.370224 30343 net.cpp:91] Creating Layer conv2_1b
I0413 18:38:59.370239 30343 net.cpp:425] conv2_1b <- conv2_1a
I0413 18:38:59.370280 30343 net.cpp:399] conv2_1b -> conv2_1b
I0413 18:38:59.373481 30343 net.cpp:141] Setting up conv2_1b
I0413 18:38:59.373560 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.373580 30343 net.cpp:156] Memory required for data: 187698176
I0413 18:38:59.373605 30343 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 18:38:59.373615 30343 net.cpp:91] Creating Layer bn_conv2_1b
I0413 18:38:59.373620 30343 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 18:38:59.373630 30343 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 18:38:59.374052 30343 net.cpp:141] Setting up bn_conv2_1b
I0413 18:38:59.374094 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.374104 30343 net.cpp:156] Memory required for data: 204475392
I0413 18:38:59.374151 30343 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:38:59.374192 30343 net.cpp:91] Creating Layer scale_conv2_1b
I0413 18:38:59.374212 30343 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 18:38:59.374228 30343 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 18:38:59.374361 30343 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:38:59.374644 30343 net.cpp:141] Setting up scale_conv2_1b
I0413 18:38:59.374671 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.374680 30343 net.cpp:156] Memory required for data: 221252608
I0413 18:38:59.374696 30343 layer_factory.hpp:77] Creating layer conv2_1
I0413 18:38:59.374722 30343 net.cpp:91] Creating Layer conv2_1
I0413 18:38:59.374730 30343 net.cpp:425] conv2_1 <- conv2_1b
I0413 18:38:59.374737 30343 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 18:38:59.374744 30343 net.cpp:399] conv2_1 -> conv2_1
I0413 18:38:59.374783 30343 net.cpp:141] Setting up conv2_1
I0413 18:38:59.374825 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.374845 30343 net.cpp:156] Memory required for data: 238029824
I0413 18:38:59.374852 30343 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 18:38:59.374888 30343 net.cpp:91] Creating Layer conv2_1_relu
I0413 18:38:59.374900 30343 net.cpp:425] conv2_1_relu <- conv2_1
I0413 18:38:59.374915 30343 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 18:38:59.375442 30343 net.cpp:141] Setting up conv2_1_relu
I0413 18:38:59.375488 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.375494 30343 net.cpp:156] Memory required for data: 254807040
I0413 18:38:59.375499 30343 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 18:38:59.375514 30343 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 18:38:59.375519 30343 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 18:38:59.375535 30343 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 18:38:59.375569 30343 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 18:38:59.375749 30343 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 18:38:59.375783 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.375797 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.375805 30343 net.cpp:156] Memory required for data: 288361472
I0413 18:38:59.375818 30343 layer_factory.hpp:77] Creating layer conv2_2a
I0413 18:38:59.375867 30343 net.cpp:91] Creating Layer conv2_2a
I0413 18:38:59.375874 30343 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 18:38:59.375885 30343 net.cpp:399] conv2_2a -> conv2_2a
I0413 18:38:59.379137 30343 net.cpp:141] Setting up conv2_2a
I0413 18:38:59.379221 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.379242 30343 net.cpp:156] Memory required for data: 305138688
I0413 18:38:59.379252 30343 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 18:38:59.379262 30343 net.cpp:91] Creating Layer bn_conv2_2a
I0413 18:38:59.379267 30343 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 18:38:59.379277 30343 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 18:38:59.379711 30343 net.cpp:141] Setting up bn_conv2_2a
I0413 18:38:59.379756 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.379770 30343 net.cpp:156] Memory required for data: 321915904
I0413 18:38:59.379786 30343 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:38:59.379813 30343 net.cpp:91] Creating Layer scale_conv2_2a
I0413 18:38:59.379827 30343 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 18:38:59.379843 30343 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 18:38:59.379981 30343 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:38:59.380234 30343 net.cpp:141] Setting up scale_conv2_2a
I0413 18:38:59.380261 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.380275 30343 net.cpp:156] Memory required for data: 338693120
I0413 18:38:59.380300 30343 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 18:38:59.380326 30343 net.cpp:91] Creating Layer conv2_2a_relu
I0413 18:38:59.380347 30343 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 18:38:59.380370 30343 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 18:38:59.381458 30343 net.cpp:141] Setting up conv2_2a_relu
I0413 18:38:59.381510 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.381515 30343 net.cpp:156] Memory required for data: 355470336
I0413 18:38:59.381520 30343 layer_factory.hpp:77] Creating layer conv2_2b
I0413 18:38:59.381543 30343 net.cpp:91] Creating Layer conv2_2b
I0413 18:38:59.381564 30343 net.cpp:425] conv2_2b <- conv2_2a
I0413 18:38:59.381588 30343 net.cpp:399] conv2_2b -> conv2_2b
I0413 18:38:59.384464 30343 net.cpp:141] Setting up conv2_2b
I0413 18:38:59.384481 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.384486 30343 net.cpp:156] Memory required for data: 372247552
I0413 18:38:59.384495 30343 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 18:38:59.384506 30343 net.cpp:91] Creating Layer bn_conv2_2b
I0413 18:38:59.384512 30343 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 18:38:59.384521 30343 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 18:38:59.384724 30343 net.cpp:141] Setting up bn_conv2_2b
I0413 18:38:59.384733 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.384738 30343 net.cpp:156] Memory required for data: 389024768
I0413 18:38:59.384753 30343 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:38:59.384768 30343 net.cpp:91] Creating Layer scale_conv2_2b
I0413 18:38:59.384774 30343 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 18:38:59.384781 30343 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 18:38:59.384824 30343 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:38:59.384943 30343 net.cpp:141] Setting up scale_conv2_2b
I0413 18:38:59.384953 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.384958 30343 net.cpp:156] Memory required for data: 405801984
I0413 18:38:59.384965 30343 layer_factory.hpp:77] Creating layer conv2_2
I0413 18:38:59.384974 30343 net.cpp:91] Creating Layer conv2_2
I0413 18:38:59.384979 30343 net.cpp:425] conv2_2 <- conv2_2b
I0413 18:38:59.384984 30343 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 18:38:59.384992 30343 net.cpp:399] conv2_2 -> conv2_2
I0413 18:38:59.385020 30343 net.cpp:141] Setting up conv2_2
I0413 18:38:59.385030 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.385040 30343 net.cpp:156] Memory required for data: 422579200
I0413 18:38:59.385045 30343 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 18:38:59.385053 30343 net.cpp:91] Creating Layer conv2_2_relu
I0413 18:38:59.385059 30343 net.cpp:425] conv2_2_relu <- conv2_2
I0413 18:38:59.385066 30343 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 18:38:59.385432 30343 net.cpp:141] Setting up conv2_2_relu
I0413 18:38:59.385448 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.385453 30343 net.cpp:156] Memory required for data: 439356416
I0413 18:38:59.385459 30343 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 18:38:59.385468 30343 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 18:38:59.385473 30343 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 18:38:59.385480 30343 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 18:38:59.385489 30343 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 18:38:59.385540 30343 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 18:38:59.385550 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.385556 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.385560 30343 net.cpp:156] Memory required for data: 472910848
I0413 18:38:59.385565 30343 layer_factory.hpp:77] Creating layer conv2_3a
I0413 18:38:59.385584 30343 net.cpp:91] Creating Layer conv2_3a
I0413 18:38:59.385591 30343 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 18:38:59.385599 30343 net.cpp:399] conv2_3a -> conv2_3a
I0413 18:38:59.387948 30343 net.cpp:141] Setting up conv2_3a
I0413 18:38:59.387965 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.387971 30343 net.cpp:156] Memory required for data: 489688064
I0413 18:38:59.387980 30343 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 18:38:59.387991 30343 net.cpp:91] Creating Layer bn_conv2_3a
I0413 18:38:59.387997 30343 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 18:38:59.388006 30343 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 18:38:59.388214 30343 net.cpp:141] Setting up bn_conv2_3a
I0413 18:38:59.388224 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.388229 30343 net.cpp:156] Memory required for data: 506465280
I0413 18:38:59.388238 30343 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:38:59.388249 30343 net.cpp:91] Creating Layer scale_conv2_3a
I0413 18:38:59.388254 30343 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 18:38:59.388262 30343 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 18:38:59.388303 30343 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:38:59.388424 30343 net.cpp:141] Setting up scale_conv2_3a
I0413 18:38:59.388433 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.388438 30343 net.cpp:156] Memory required for data: 523242496
I0413 18:38:59.388447 30343 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 18:38:59.388453 30343 net.cpp:91] Creating Layer conv2_3a_relu
I0413 18:38:59.388459 30343 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 18:38:59.388468 30343 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 18:38:59.389011 30343 net.cpp:141] Setting up conv2_3a_relu
I0413 18:38:59.389025 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.389030 30343 net.cpp:156] Memory required for data: 540019712
I0413 18:38:59.389035 30343 layer_factory.hpp:77] Creating layer conv2_3b
I0413 18:38:59.389050 30343 net.cpp:91] Creating Layer conv2_3b
I0413 18:38:59.389055 30343 net.cpp:425] conv2_3b <- conv2_3a
I0413 18:38:59.389063 30343 net.cpp:399] conv2_3b -> conv2_3b
I0413 18:38:59.392822 30343 net.cpp:141] Setting up conv2_3b
I0413 18:38:59.392840 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.392846 30343 net.cpp:156] Memory required for data: 556796928
I0413 18:38:59.392855 30343 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 18:38:59.392870 30343 net.cpp:91] Creating Layer bn_conv2_3b
I0413 18:38:59.392881 30343 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 18:38:59.392890 30343 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 18:38:59.393100 30343 net.cpp:141] Setting up bn_conv2_3b
I0413 18:38:59.393115 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.393122 30343 net.cpp:156] Memory required for data: 573574144
I0413 18:38:59.393132 30343 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:38:59.393141 30343 net.cpp:91] Creating Layer scale_conv2_3b
I0413 18:38:59.393146 30343 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 18:38:59.393153 30343 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 18:38:59.393196 30343 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:38:59.393317 30343 net.cpp:141] Setting up scale_conv2_3b
I0413 18:38:59.393326 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.393332 30343 net.cpp:156] Memory required for data: 590351360
I0413 18:38:59.393339 30343 layer_factory.hpp:77] Creating layer conv2_3
I0413 18:38:59.393347 30343 net.cpp:91] Creating Layer conv2_3
I0413 18:38:59.393352 30343 net.cpp:425] conv2_3 <- conv2_3b
I0413 18:38:59.393358 30343 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 18:38:59.393367 30343 net.cpp:399] conv2_3 -> conv2_3
I0413 18:38:59.393393 30343 net.cpp:141] Setting up conv2_3
I0413 18:38:59.393402 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.393407 30343 net.cpp:156] Memory required for data: 607128576
I0413 18:38:59.393412 30343 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 18:38:59.393421 30343 net.cpp:91] Creating Layer conv2_3_relu
I0413 18:38:59.393426 30343 net.cpp:425] conv2_3_relu <- conv2_3
I0413 18:38:59.393432 30343 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 18:38:59.393911 30343 net.cpp:141] Setting up conv2_3_relu
I0413 18:38:59.393928 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.393932 30343 net.cpp:156] Memory required for data: 623905792
I0413 18:38:59.393937 30343 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 18:38:59.393947 30343 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 18:38:59.393952 30343 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 18:38:59.393961 30343 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 18:38:59.393971 30343 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 18:38:59.394018 30343 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 18:38:59.394027 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.394034 30343 net.cpp:148] Top shape: 256 16 32 32 (4194304)
I0413 18:38:59.394039 30343 net.cpp:156] Memory required for data: 657460224
I0413 18:38:59.394044 30343 layer_factory.hpp:77] Creating layer conv2_sub
I0413 18:38:59.394055 30343 net.cpp:91] Creating Layer conv2_sub
I0413 18:38:59.394062 30343 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 18:38:59.394071 30343 net.cpp:399] conv2_sub -> conv2_sub
I0413 18:38:59.397579 30343 net.cpp:141] Setting up conv2_sub
I0413 18:38:59.397598 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.397603 30343 net.cpp:156] Memory required for data: 665848832
I0413 18:38:59.397613 30343 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 18:38:59.397624 30343 net.cpp:91] Creating Layer bn_conv2_sub
I0413 18:38:59.397630 30343 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 18:38:59.397639 30343 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 18:38:59.397845 30343 net.cpp:141] Setting up bn_conv2_sub
I0413 18:38:59.397853 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.397858 30343 net.cpp:156] Memory required for data: 674237440
I0413 18:38:59.397868 30343 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:38:59.397876 30343 net.cpp:91] Creating Layer scale_conv2_sub
I0413 18:38:59.397881 30343 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 18:38:59.397891 30343 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 18:38:59.397936 30343 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:38:59.398061 30343 net.cpp:141] Setting up scale_conv2_sub
I0413 18:38:59.398072 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.398077 30343 net.cpp:156] Memory required for data: 682626048
I0413 18:38:59.398084 30343 layer_factory.hpp:77] Creating layer conv3_1a
I0413 18:38:59.398099 30343 net.cpp:91] Creating Layer conv3_1a
I0413 18:38:59.398104 30343 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 18:38:59.398114 30343 net.cpp:399] conv3_1a -> conv3_1a
I0413 18:38:59.400902 30343 net.cpp:141] Setting up conv3_1a
I0413 18:38:59.400920 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.400926 30343 net.cpp:156] Memory required for data: 691014656
I0413 18:38:59.400935 30343 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 18:38:59.400946 30343 net.cpp:91] Creating Layer bn_conv3_1a
I0413 18:38:59.400952 30343 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 18:38:59.400960 30343 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 18:38:59.401175 30343 net.cpp:141] Setting up bn_conv3_1a
I0413 18:38:59.401187 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.401192 30343 net.cpp:156] Memory required for data: 699403264
I0413 18:38:59.401202 30343 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:38:59.401211 30343 net.cpp:91] Creating Layer scale_conv3_1a
I0413 18:38:59.401216 30343 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 18:38:59.401226 30343 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 18:38:59.401267 30343 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:38:59.401392 30343 net.cpp:141] Setting up scale_conv3_1a
I0413 18:38:59.401403 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.401408 30343 net.cpp:156] Memory required for data: 707791872
I0413 18:38:59.401417 30343 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 18:38:59.401424 30343 net.cpp:91] Creating Layer conv3_1a_relu
I0413 18:38:59.401429 30343 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 18:38:59.401437 30343 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 18:38:59.401762 30343 net.cpp:141] Setting up conv3_1a_relu
I0413 18:38:59.401779 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.401785 30343 net.cpp:156] Memory required for data: 716180480
I0413 18:38:59.401790 30343 layer_factory.hpp:77] Creating layer conv3_1b
I0413 18:38:59.401804 30343 net.cpp:91] Creating Layer conv3_1b
I0413 18:38:59.401810 30343 net.cpp:425] conv3_1b <- conv3_1a
I0413 18:38:59.401819 30343 net.cpp:399] conv3_1b -> conv3_1b
I0413 18:38:59.405273 30343 net.cpp:141] Setting up conv3_1b
I0413 18:38:59.405293 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.405299 30343 net.cpp:156] Memory required for data: 724569088
I0413 18:38:59.405320 30343 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 18:38:59.405333 30343 net.cpp:91] Creating Layer bn_conv3_1b
I0413 18:38:59.405339 30343 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 18:38:59.405346 30343 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 18:38:59.405562 30343 net.cpp:141] Setting up bn_conv3_1b
I0413 18:38:59.405572 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.405577 30343 net.cpp:156] Memory required for data: 732957696
I0413 18:38:59.405587 30343 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:38:59.405597 30343 net.cpp:91] Creating Layer scale_conv3_1b
I0413 18:38:59.405603 30343 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 18:38:59.405611 30343 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 18:38:59.405652 30343 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:38:59.405776 30343 net.cpp:141] Setting up scale_conv3_1b
I0413 18:38:59.405786 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.405791 30343 net.cpp:156] Memory required for data: 741346304
I0413 18:38:59.405799 30343 layer_factory.hpp:77] Creating layer conv3_1
I0413 18:38:59.405808 30343 net.cpp:91] Creating Layer conv3_1
I0413 18:38:59.405818 30343 net.cpp:425] conv3_1 <- conv3_1b
I0413 18:38:59.405825 30343 net.cpp:425] conv3_1 <- conv2_sub
I0413 18:38:59.405833 30343 net.cpp:399] conv3_1 -> conv3_1
I0413 18:38:59.405858 30343 net.cpp:141] Setting up conv3_1
I0413 18:38:59.405867 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.405872 30343 net.cpp:156] Memory required for data: 749734912
I0413 18:38:59.405877 30343 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 18:38:59.405885 30343 net.cpp:91] Creating Layer conv3_1_relu
I0413 18:38:59.405890 30343 net.cpp:425] conv3_1_relu <- conv3_1
I0413 18:38:59.405896 30343 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 18:38:59.406322 30343 net.cpp:141] Setting up conv3_1_relu
I0413 18:38:59.406334 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.406339 30343 net.cpp:156] Memory required for data: 758123520
I0413 18:38:59.406344 30343 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 18:38:59.406353 30343 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 18:38:59.406359 30343 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 18:38:59.406366 30343 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 18:38:59.406375 30343 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 18:38:59.406424 30343 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 18:38:59.406432 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.406438 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.406443 30343 net.cpp:156] Memory required for data: 774900736
I0413 18:38:59.406448 30343 layer_factory.hpp:77] Creating layer conv3_2a
I0413 18:38:59.406462 30343 net.cpp:91] Creating Layer conv3_2a
I0413 18:38:59.406467 30343 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 18:38:59.406477 30343 net.cpp:399] conv3_2a -> conv3_2a
I0413 18:38:59.409876 30343 net.cpp:141] Setting up conv3_2a
I0413 18:38:59.409898 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.409904 30343 net.cpp:156] Memory required for data: 783289344
I0413 18:38:59.409912 30343 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 18:38:59.409924 30343 net.cpp:91] Creating Layer bn_conv3_2a
I0413 18:38:59.409930 30343 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 18:38:59.409939 30343 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 18:38:59.410151 30343 net.cpp:141] Setting up bn_conv3_2a
I0413 18:38:59.410159 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.410164 30343 net.cpp:156] Memory required for data: 791677952
I0413 18:38:59.410174 30343 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:38:59.410187 30343 net.cpp:91] Creating Layer scale_conv3_2a
I0413 18:38:59.410193 30343 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 18:38:59.410200 30343 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 18:38:59.410241 30343 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:38:59.410367 30343 net.cpp:141] Setting up scale_conv3_2a
I0413 18:38:59.410375 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.410380 30343 net.cpp:156] Memory required for data: 800066560
I0413 18:38:59.410388 30343 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 18:38:59.410395 30343 net.cpp:91] Creating Layer conv3_2a_relu
I0413 18:38:59.410400 30343 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 18:38:59.410410 30343 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 18:38:59.410884 30343 net.cpp:141] Setting up conv3_2a_relu
I0413 18:38:59.410895 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.410900 30343 net.cpp:156] Memory required for data: 808455168
I0413 18:38:59.410907 30343 layer_factory.hpp:77] Creating layer conv3_2b
I0413 18:38:59.410920 30343 net.cpp:91] Creating Layer conv3_2b
I0413 18:38:59.410926 30343 net.cpp:425] conv3_2b <- conv3_2a
I0413 18:38:59.410936 30343 net.cpp:399] conv3_2b -> conv3_2b
I0413 18:38:59.414402 30343 net.cpp:141] Setting up conv3_2b
I0413 18:38:59.414425 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.414432 30343 net.cpp:156] Memory required for data: 816843776
I0413 18:38:59.414440 30343 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 18:38:59.414453 30343 net.cpp:91] Creating Layer bn_conv3_2b
I0413 18:38:59.414458 30343 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 18:38:59.414465 30343 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 18:38:59.414679 30343 net.cpp:141] Setting up bn_conv3_2b
I0413 18:38:59.414687 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.414692 30343 net.cpp:156] Memory required for data: 825232384
I0413 18:38:59.414702 30343 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:38:59.414711 30343 net.cpp:91] Creating Layer scale_conv3_2b
I0413 18:38:59.414716 30343 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 18:38:59.414722 30343 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 18:38:59.414767 30343 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:38:59.414901 30343 net.cpp:141] Setting up scale_conv3_2b
I0413 18:38:59.414909 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.414914 30343 net.cpp:156] Memory required for data: 833620992
I0413 18:38:59.414922 30343 layer_factory.hpp:77] Creating layer conv3_2
I0413 18:38:59.414932 30343 net.cpp:91] Creating Layer conv3_2
I0413 18:38:59.414937 30343 net.cpp:425] conv3_2 <- conv3_2b
I0413 18:38:59.414943 30343 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 18:38:59.414952 30343 net.cpp:399] conv3_2 -> conv3_2
I0413 18:38:59.414974 30343 net.cpp:141] Setting up conv3_2
I0413 18:38:59.414983 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.414988 30343 net.cpp:156] Memory required for data: 842009600
I0413 18:38:59.414993 30343 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 18:38:59.415002 30343 net.cpp:91] Creating Layer conv3_2_relu
I0413 18:38:59.415007 30343 net.cpp:425] conv3_2_relu <- conv3_2
I0413 18:38:59.415014 30343 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 18:38:59.415426 30343 net.cpp:141] Setting up conv3_2_relu
I0413 18:38:59.415441 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.415446 30343 net.cpp:156] Memory required for data: 850398208
I0413 18:38:59.415452 30343 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 18:38:59.415460 30343 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 18:38:59.415465 30343 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 18:38:59.415475 30343 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 18:38:59.415484 30343 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 18:38:59.415539 30343 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 18:38:59.415547 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.415555 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.415560 30343 net.cpp:156] Memory required for data: 867175424
I0413 18:38:59.415565 30343 layer_factory.hpp:77] Creating layer conv3_3a
I0413 18:38:59.415580 30343 net.cpp:91] Creating Layer conv3_3a
I0413 18:38:59.415585 30343 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 18:38:59.415596 30343 net.cpp:399] conv3_3a -> conv3_3a
I0413 18:38:59.418045 30343 net.cpp:141] Setting up conv3_3a
I0413 18:38:59.418063 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.418069 30343 net.cpp:156] Memory required for data: 875564032
I0413 18:38:59.418078 30343 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 18:38:59.418089 30343 net.cpp:91] Creating Layer bn_conv3_3a
I0413 18:38:59.418095 30343 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 18:38:59.418102 30343 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 18:38:59.418313 30343 net.cpp:141] Setting up bn_conv3_3a
I0413 18:38:59.418323 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.418329 30343 net.cpp:156] Memory required for data: 883952640
I0413 18:38:59.418344 30343 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:38:59.418354 30343 net.cpp:91] Creating Layer scale_conv3_3a
I0413 18:38:59.418360 30343 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 18:38:59.418367 30343 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 18:38:59.418411 30343 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:38:59.418541 30343 net.cpp:141] Setting up scale_conv3_3a
I0413 18:38:59.418550 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.418555 30343 net.cpp:156] Memory required for data: 892341248
I0413 18:38:59.418563 30343 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 18:38:59.418571 30343 net.cpp:91] Creating Layer conv3_3a_relu
I0413 18:38:59.418576 30343 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 18:38:59.418584 30343 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 18:38:59.418782 30343 net.cpp:141] Setting up conv3_3a_relu
I0413 18:38:59.418794 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.418799 30343 net.cpp:156] Memory required for data: 900729856
I0413 18:38:59.418804 30343 layer_factory.hpp:77] Creating layer conv3_3b
I0413 18:38:59.418828 30343 net.cpp:91] Creating Layer conv3_3b
I0413 18:38:59.418834 30343 net.cpp:425] conv3_3b <- conv3_3a
I0413 18:38:59.418843 30343 net.cpp:399] conv3_3b -> conv3_3b
I0413 18:38:59.421536 30343 net.cpp:141] Setting up conv3_3b
I0413 18:38:59.421555 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.421561 30343 net.cpp:156] Memory required for data: 909118464
I0413 18:38:59.421569 30343 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 18:38:59.421583 30343 net.cpp:91] Creating Layer bn_conv3_3b
I0413 18:38:59.421589 30343 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 18:38:59.421597 30343 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 18:38:59.421813 30343 net.cpp:141] Setting up bn_conv3_3b
I0413 18:38:59.421823 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.421828 30343 net.cpp:156] Memory required for data: 917507072
I0413 18:38:59.421838 30343 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:38:59.421847 30343 net.cpp:91] Creating Layer scale_conv3_3b
I0413 18:38:59.421854 30343 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 18:38:59.421860 30343 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 18:38:59.421902 30343 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:38:59.422029 30343 net.cpp:141] Setting up scale_conv3_3b
I0413 18:38:59.422039 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.422044 30343 net.cpp:156] Memory required for data: 925895680
I0413 18:38:59.422051 30343 layer_factory.hpp:77] Creating layer conv3_3
I0413 18:38:59.422060 30343 net.cpp:91] Creating Layer conv3_3
I0413 18:38:59.422065 30343 net.cpp:425] conv3_3 <- conv3_3b
I0413 18:38:59.422070 30343 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 18:38:59.422083 30343 net.cpp:399] conv3_3 -> conv3_3
I0413 18:38:59.422107 30343 net.cpp:141] Setting up conv3_3
I0413 18:38:59.422117 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.422122 30343 net.cpp:156] Memory required for data: 934284288
I0413 18:38:59.422127 30343 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 18:38:59.422135 30343 net.cpp:91] Creating Layer conv3_3_relu
I0413 18:38:59.422140 30343 net.cpp:425] conv3_3_relu <- conv3_3
I0413 18:38:59.422147 30343 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 18:38:59.422570 30343 net.cpp:141] Setting up conv3_3_relu
I0413 18:38:59.422582 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.422587 30343 net.cpp:156] Memory required for data: 942672896
I0413 18:38:59.422592 30343 layer_factory.hpp:77] Creating layer conv3_3_conv3_3_relu_0_split
I0413 18:38:59.422600 30343 net.cpp:91] Creating Layer conv3_3_conv3_3_relu_0_split
I0413 18:38:59.422605 30343 net.cpp:425] conv3_3_conv3_3_relu_0_split <- conv3_3
I0413 18:38:59.422615 30343 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_0
I0413 18:38:59.422629 30343 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_1
I0413 18:38:59.422677 30343 net.cpp:141] Setting up conv3_3_conv3_3_relu_0_split
I0413 18:38:59.422688 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.422694 30343 net.cpp:148] Top shape: 256 32 16 16 (2097152)
I0413 18:38:59.422698 30343 net.cpp:156] Memory required for data: 959450112
I0413 18:38:59.422703 30343 layer_factory.hpp:77] Creating layer conv3_sub
I0413 18:38:59.422718 30343 net.cpp:91] Creating Layer conv3_sub
I0413 18:38:59.422724 30343 net.cpp:425] conv3_sub <- conv3_3_conv3_3_relu_0_split_0
I0413 18:38:59.422731 30343 net.cpp:399] conv3_sub -> conv3_sub
I0413 18:38:59.426158 30343 net.cpp:141] Setting up conv3_sub
I0413 18:38:59.426177 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.426184 30343 net.cpp:156] Memory required for data: 963644416
I0413 18:38:59.426193 30343 layer_factory.hpp:77] Creating layer bn_conv3_sub
I0413 18:38:59.426203 30343 net.cpp:91] Creating Layer bn_conv3_sub
I0413 18:38:59.426208 30343 net.cpp:425] bn_conv3_sub <- conv3_sub
I0413 18:38:59.426218 30343 net.cpp:386] bn_conv3_sub -> conv3_sub (in-place)
I0413 18:38:59.426446 30343 net.cpp:141] Setting up bn_conv3_sub
I0413 18:38:59.426456 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.426461 30343 net.cpp:156] Memory required for data: 967838720
I0413 18:38:59.426470 30343 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:38:59.426479 30343 net.cpp:91] Creating Layer scale_conv3_sub
I0413 18:38:59.426484 30343 net.cpp:425] scale_conv3_sub <- conv3_sub
I0413 18:38:59.426493 30343 net.cpp:386] scale_conv3_sub -> conv3_sub (in-place)
I0413 18:38:59.426537 30343 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:38:59.426673 30343 net.cpp:141] Setting up scale_conv3_sub
I0413 18:38:59.426682 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.426687 30343 net.cpp:156] Memory required for data: 972033024
I0413 18:38:59.426695 30343 layer_factory.hpp:77] Creating layer conv4_1a
I0413 18:38:59.426709 30343 net.cpp:91] Creating Layer conv4_1a
I0413 18:38:59.426715 30343 net.cpp:425] conv4_1a <- conv3_3_conv3_3_relu_0_split_1
I0413 18:38:59.426725 30343 net.cpp:399] conv4_1a -> conv4_1a
I0413 18:38:59.429577 30343 net.cpp:141] Setting up conv4_1a
I0413 18:38:59.429596 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.429602 30343 net.cpp:156] Memory required for data: 976227328
I0413 18:38:59.429611 30343 layer_factory.hpp:77] Creating layer bn_conv4_1a
I0413 18:38:59.429622 30343 net.cpp:91] Creating Layer bn_conv4_1a
I0413 18:38:59.429628 30343 net.cpp:425] bn_conv4_1a <- conv4_1a
I0413 18:38:59.429638 30343 net.cpp:386] bn_conv4_1a -> conv4_1a (in-place)
I0413 18:38:59.429862 30343 net.cpp:141] Setting up bn_conv4_1a
I0413 18:38:59.429872 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.429877 30343 net.cpp:156] Memory required for data: 980421632
I0413 18:38:59.429885 30343 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:38:59.429896 30343 net.cpp:91] Creating Layer scale_conv4_1a
I0413 18:38:59.429901 30343 net.cpp:425] scale_conv4_1a <- conv4_1a
I0413 18:38:59.429908 30343 net.cpp:386] scale_conv4_1a -> conv4_1a (in-place)
I0413 18:38:59.429951 30343 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:38:59.430084 30343 net.cpp:141] Setting up scale_conv4_1a
I0413 18:38:59.430094 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.430099 30343 net.cpp:156] Memory required for data: 984615936
I0413 18:38:59.430107 30343 layer_factory.hpp:77] Creating layer conv4_1a_relu
I0413 18:38:59.430116 30343 net.cpp:91] Creating Layer conv4_1a_relu
I0413 18:38:59.430121 30343 net.cpp:425] conv4_1a_relu <- conv4_1a
I0413 18:38:59.430129 30343 net.cpp:386] conv4_1a_relu -> conv4_1a (in-place)
I0413 18:38:59.430590 30343 net.cpp:141] Setting up conv4_1a_relu
I0413 18:38:59.430606 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.430611 30343 net.cpp:156] Memory required for data: 988810240
I0413 18:38:59.430622 30343 layer_factory.hpp:77] Creating layer conv4_1b
I0413 18:38:59.430639 30343 net.cpp:91] Creating Layer conv4_1b
I0413 18:38:59.430645 30343 net.cpp:425] conv4_1b <- conv4_1a
I0413 18:38:59.430655 30343 net.cpp:399] conv4_1b -> conv4_1b
I0413 18:38:59.434042 30343 net.cpp:141] Setting up conv4_1b
I0413 18:38:59.434062 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.434067 30343 net.cpp:156] Memory required for data: 993004544
I0413 18:38:59.434077 30343 layer_factory.hpp:77] Creating layer bn_conv4_1b
I0413 18:38:59.434088 30343 net.cpp:91] Creating Layer bn_conv4_1b
I0413 18:38:59.434094 30343 net.cpp:425] bn_conv4_1b <- conv4_1b
I0413 18:38:59.434103 30343 net.cpp:386] bn_conv4_1b -> conv4_1b (in-place)
I0413 18:38:59.434331 30343 net.cpp:141] Setting up bn_conv4_1b
I0413 18:38:59.434340 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.434345 30343 net.cpp:156] Memory required for data: 997198848
I0413 18:38:59.434355 30343 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:38:59.434363 30343 net.cpp:91] Creating Layer scale_conv4_1b
I0413 18:38:59.434368 30343 net.cpp:425] scale_conv4_1b <- conv4_1b
I0413 18:38:59.434376 30343 net.cpp:386] scale_conv4_1b -> conv4_1b (in-place)
I0413 18:38:59.434422 30343 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:38:59.434556 30343 net.cpp:141] Setting up scale_conv4_1b
I0413 18:38:59.434567 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.434572 30343 net.cpp:156] Memory required for data: 1001393152
I0413 18:38:59.434581 30343 layer_factory.hpp:77] Creating layer conv4_1
I0413 18:38:59.434588 30343 net.cpp:91] Creating Layer conv4_1
I0413 18:38:59.434594 30343 net.cpp:425] conv4_1 <- conv3_sub
I0413 18:38:59.434600 30343 net.cpp:425] conv4_1 <- conv4_1b
I0413 18:38:59.434607 30343 net.cpp:399] conv4_1 -> conv4_1
I0413 18:38:59.434633 30343 net.cpp:141] Setting up conv4_1
I0413 18:38:59.434643 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.434648 30343 net.cpp:156] Memory required for data: 1005587456
I0413 18:38:59.434653 30343 layer_factory.hpp:77] Creating layer conv4_1_relu
I0413 18:38:59.434660 30343 net.cpp:91] Creating Layer conv4_1_relu
I0413 18:38:59.434665 30343 net.cpp:425] conv4_1_relu <- conv4_1
I0413 18:38:59.434674 30343 net.cpp:386] conv4_1_relu -> conv4_1 (in-place)
I0413 18:38:59.435001 30343 net.cpp:141] Setting up conv4_1_relu
I0413 18:38:59.435016 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.435021 30343 net.cpp:156] Memory required for data: 1009781760
I0413 18:38:59.435027 30343 layer_factory.hpp:77] Creating layer conv4_1_conv4_1_relu_0_split
I0413 18:38:59.435035 30343 net.cpp:91] Creating Layer conv4_1_conv4_1_relu_0_split
I0413 18:38:59.435040 30343 net.cpp:425] conv4_1_conv4_1_relu_0_split <- conv4_1
I0413 18:38:59.435050 30343 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_0
I0413 18:38:59.435060 30343 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_1
I0413 18:38:59.435111 30343 net.cpp:141] Setting up conv4_1_conv4_1_relu_0_split
I0413 18:38:59.435119 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.435125 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.435130 30343 net.cpp:156] Memory required for data: 1018170368
I0413 18:38:59.435135 30343 layer_factory.hpp:77] Creating layer conv4_2a
I0413 18:38:59.435149 30343 net.cpp:91] Creating Layer conv4_2a
I0413 18:38:59.435155 30343 net.cpp:425] conv4_2a <- conv4_1_conv4_1_relu_0_split_0
I0413 18:38:59.435165 30343 net.cpp:399] conv4_2a -> conv4_2a
I0413 18:38:59.438712 30343 net.cpp:141] Setting up conv4_2a
I0413 18:38:59.438730 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.438736 30343 net.cpp:156] Memory required for data: 1022364672
I0413 18:38:59.438745 30343 layer_factory.hpp:77] Creating layer bn_conv4_2a
I0413 18:38:59.438756 30343 net.cpp:91] Creating Layer bn_conv4_2a
I0413 18:38:59.438762 30343 net.cpp:425] bn_conv4_2a <- conv4_2a
I0413 18:38:59.438777 30343 net.cpp:386] bn_conv4_2a -> conv4_2a (in-place)
I0413 18:38:59.439013 30343 net.cpp:141] Setting up bn_conv4_2a
I0413 18:38:59.439023 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.439028 30343 net.cpp:156] Memory required for data: 1026558976
I0413 18:38:59.439038 30343 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:38:59.439046 30343 net.cpp:91] Creating Layer scale_conv4_2a
I0413 18:38:59.439051 30343 net.cpp:425] scale_conv4_2a <- conv4_2a
I0413 18:38:59.439059 30343 net.cpp:386] scale_conv4_2a -> conv4_2a (in-place)
I0413 18:38:59.439105 30343 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:38:59.439240 30343 net.cpp:141] Setting up scale_conv4_2a
I0413 18:38:59.439249 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.439254 30343 net.cpp:156] Memory required for data: 1030753280
I0413 18:38:59.439263 30343 layer_factory.hpp:77] Creating layer conv4_2a_relu
I0413 18:38:59.439270 30343 net.cpp:91] Creating Layer conv4_2a_relu
I0413 18:38:59.439275 30343 net.cpp:425] conv4_2a_relu <- conv4_2a
I0413 18:38:59.439285 30343 net.cpp:386] conv4_2a_relu -> conv4_2a (in-place)
I0413 18:38:59.439754 30343 net.cpp:141] Setting up conv4_2a_relu
I0413 18:38:59.439765 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.439770 30343 net.cpp:156] Memory required for data: 1034947584
I0413 18:38:59.439775 30343 layer_factory.hpp:77] Creating layer conv4_2b
I0413 18:38:59.439795 30343 net.cpp:91] Creating Layer conv4_2b
I0413 18:38:59.439800 30343 net.cpp:425] conv4_2b <- conv4_2a
I0413 18:38:59.439810 30343 net.cpp:399] conv4_2b -> conv4_2b
I0413 18:38:59.443289 30343 net.cpp:141] Setting up conv4_2b
I0413 18:38:59.443307 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.443313 30343 net.cpp:156] Memory required for data: 1039141888
I0413 18:38:59.443322 30343 layer_factory.hpp:77] Creating layer bn_conv4_2b
I0413 18:38:59.443336 30343 net.cpp:91] Creating Layer bn_conv4_2b
I0413 18:38:59.443341 30343 net.cpp:425] bn_conv4_2b <- conv4_2b
I0413 18:38:59.443348 30343 net.cpp:386] bn_conv4_2b -> conv4_2b (in-place)
I0413 18:38:59.443577 30343 net.cpp:141] Setting up bn_conv4_2b
I0413 18:38:59.443585 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.443590 30343 net.cpp:156] Memory required for data: 1043336192
I0413 18:38:59.443620 30343 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:38:59.443630 30343 net.cpp:91] Creating Layer scale_conv4_2b
I0413 18:38:59.443635 30343 net.cpp:425] scale_conv4_2b <- conv4_2b
I0413 18:38:59.443642 30343 net.cpp:386] scale_conv4_2b -> conv4_2b (in-place)
I0413 18:38:59.443689 30343 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:38:59.443827 30343 net.cpp:141] Setting up scale_conv4_2b
I0413 18:38:59.443836 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.443841 30343 net.cpp:156] Memory required for data: 1047530496
I0413 18:38:59.443850 30343 layer_factory.hpp:77] Creating layer conv4_2
I0413 18:38:59.443857 30343 net.cpp:91] Creating Layer conv4_2
I0413 18:38:59.443862 30343 net.cpp:425] conv4_2 <- conv4_1_conv4_1_relu_0_split_1
I0413 18:38:59.443868 30343 net.cpp:425] conv4_2 <- conv4_2b
I0413 18:38:59.443876 30343 net.cpp:399] conv4_2 -> conv4_2
I0413 18:38:59.443900 30343 net.cpp:141] Setting up conv4_2
I0413 18:38:59.443909 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.443914 30343 net.cpp:156] Memory required for data: 1051724800
I0413 18:38:59.443918 30343 layer_factory.hpp:77] Creating layer conv4_2_relu
I0413 18:38:59.443927 30343 net.cpp:91] Creating Layer conv4_2_relu
I0413 18:38:59.443931 30343 net.cpp:425] conv4_2_relu <- conv4_2
I0413 18:38:59.443943 30343 net.cpp:386] conv4_2_relu -> conv4_2 (in-place)
I0413 18:38:59.444308 30343 net.cpp:141] Setting up conv4_2_relu
I0413 18:38:59.444324 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.444329 30343 net.cpp:156] Memory required for data: 1055919104
I0413 18:38:59.444334 30343 layer_factory.hpp:77] Creating layer conv4_2_conv4_2_relu_0_split
I0413 18:38:59.444347 30343 net.cpp:91] Creating Layer conv4_2_conv4_2_relu_0_split
I0413 18:38:59.444352 30343 net.cpp:425] conv4_2_conv4_2_relu_0_split <- conv4_2
I0413 18:38:59.444366 30343 net.cpp:399] conv4_2_conv4_2_relu_0_split -> conv4_2_conv4_2_relu_0_split_0
I0413 18:38:59.444376 30343 net.cpp:399] conv4_2_conv4_2_relu_0_split -> conv4_2_conv4_2_relu_0_split_1
I0413 18:38:59.444429 30343 net.cpp:141] Setting up conv4_2_conv4_2_relu_0_split
I0413 18:38:59.444438 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.444444 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.444449 30343 net.cpp:156] Memory required for data: 1064307712
I0413 18:38:59.444454 30343 layer_factory.hpp:77] Creating layer conv4_3a
I0413 18:38:59.444469 30343 net.cpp:91] Creating Layer conv4_3a
I0413 18:38:59.444474 30343 net.cpp:425] conv4_3a <- conv4_2_conv4_2_relu_0_split_0
I0413 18:38:59.444485 30343 net.cpp:399] conv4_3a -> conv4_3a
I0413 18:38:59.447835 30343 net.cpp:141] Setting up conv4_3a
I0413 18:38:59.447854 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.447860 30343 net.cpp:156] Memory required for data: 1068502016
I0413 18:38:59.447870 30343 layer_factory.hpp:77] Creating layer bn_conv4_3a
I0413 18:38:59.447880 30343 net.cpp:91] Creating Layer bn_conv4_3a
I0413 18:38:59.447886 30343 net.cpp:425] bn_conv4_3a <- conv4_3a
I0413 18:38:59.447895 30343 net.cpp:386] bn_conv4_3a -> conv4_3a (in-place)
I0413 18:38:59.448124 30343 net.cpp:141] Setting up bn_conv4_3a
I0413 18:38:59.448133 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.448138 30343 net.cpp:156] Memory required for data: 1072696320
I0413 18:38:59.448148 30343 layer_factory.hpp:77] Creating layer scale_conv4_3a
I0413 18:38:59.448156 30343 net.cpp:91] Creating Layer scale_conv4_3a
I0413 18:38:59.448161 30343 net.cpp:425] scale_conv4_3a <- conv4_3a
I0413 18:38:59.448168 30343 net.cpp:386] scale_conv4_3a -> conv4_3a (in-place)
I0413 18:38:59.448212 30343 layer_factory.hpp:77] Creating layer scale_conv4_3a
I0413 18:38:59.448345 30343 net.cpp:141] Setting up scale_conv4_3a
I0413 18:38:59.448354 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.448359 30343 net.cpp:156] Memory required for data: 1076890624
I0413 18:38:59.448369 30343 layer_factory.hpp:77] Creating layer conv4_3a_relu
I0413 18:38:59.448375 30343 net.cpp:91] Creating Layer conv4_3a_relu
I0413 18:38:59.448381 30343 net.cpp:425] conv4_3a_relu <- conv4_3a
I0413 18:38:59.448388 30343 net.cpp:386] conv4_3a_relu -> conv4_3a (in-place)
I0413 18:38:59.448856 30343 net.cpp:141] Setting up conv4_3a_relu
I0413 18:38:59.448873 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.448878 30343 net.cpp:156] Memory required for data: 1081084928
I0413 18:38:59.448882 30343 layer_factory.hpp:77] Creating layer conv4_3b
I0413 18:38:59.448897 30343 net.cpp:91] Creating Layer conv4_3b
I0413 18:38:59.448904 30343 net.cpp:425] conv4_3b <- conv4_3a
I0413 18:38:59.448915 30343 net.cpp:399] conv4_3b -> conv4_3b
I0413 18:38:59.452512 30343 net.cpp:141] Setting up conv4_3b
I0413 18:38:59.452529 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.452535 30343 net.cpp:156] Memory required for data: 1085279232
I0413 18:38:59.452544 30343 layer_factory.hpp:77] Creating layer bn_conv4_3b
I0413 18:38:59.452555 30343 net.cpp:91] Creating Layer bn_conv4_3b
I0413 18:38:59.452561 30343 net.cpp:425] bn_conv4_3b <- conv4_3b
I0413 18:38:59.452569 30343 net.cpp:386] bn_conv4_3b -> conv4_3b (in-place)
I0413 18:38:59.452805 30343 net.cpp:141] Setting up bn_conv4_3b
I0413 18:38:59.452814 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.452819 30343 net.cpp:156] Memory required for data: 1089473536
I0413 18:38:59.452829 30343 layer_factory.hpp:77] Creating layer scale_conv4_3b
I0413 18:38:59.452838 30343 net.cpp:91] Creating Layer scale_conv4_3b
I0413 18:38:59.452844 30343 net.cpp:425] scale_conv4_3b <- conv4_3b
I0413 18:38:59.452852 30343 net.cpp:386] scale_conv4_3b -> conv4_3b (in-place)
I0413 18:38:59.452894 30343 layer_factory.hpp:77] Creating layer scale_conv4_3b
I0413 18:38:59.453037 30343 net.cpp:141] Setting up scale_conv4_3b
I0413 18:38:59.453047 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.453052 30343 net.cpp:156] Memory required for data: 1093667840
I0413 18:38:59.453059 30343 layer_factory.hpp:77] Creating layer conv4_3
I0413 18:38:59.453066 30343 net.cpp:91] Creating Layer conv4_3
I0413 18:38:59.453071 30343 net.cpp:425] conv4_3 <- conv4_2_conv4_2_relu_0_split_1
I0413 18:38:59.453078 30343 net.cpp:425] conv4_3 <- conv4_3b
I0413 18:38:59.453088 30343 net.cpp:399] conv4_3 -> conv4_3
I0413 18:38:59.458974 30343 net.cpp:141] Setting up conv4_3
I0413 18:38:59.459038 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.459043 30343 net.cpp:156] Memory required for data: 1097862144
I0413 18:38:59.459064 30343 layer_factory.hpp:77] Creating layer conv4_3_relu
I0413 18:38:59.459094 30343 net.cpp:91] Creating Layer conv4_3_relu
I0413 18:38:59.459134 30343 net.cpp:425] conv4_3_relu <- conv4_3
I0413 18:38:59.459154 30343 net.cpp:386] conv4_3_relu -> conv4_3 (in-place)
I0413 18:38:59.460227 30343 net.cpp:141] Setting up conv4_3_relu
I0413 18:38:59.460239 30343 net.cpp:148] Top shape: 256 64 8 8 (1048576)
I0413 18:38:59.460245 30343 net.cpp:156] Memory required for data: 1102056448
I0413 18:38:59.460250 30343 layer_factory.hpp:77] Creating layer global_pool
I0413 18:38:59.460259 30343 net.cpp:91] Creating Layer global_pool
I0413 18:38:59.460265 30343 net.cpp:425] global_pool <- conv4_3
I0413 18:38:59.460274 30343 net.cpp:399] global_pool -> global_pool
I0413 18:38:59.461082 30343 net.cpp:141] Setting up global_pool
I0413 18:38:59.461099 30343 net.cpp:148] Top shape: 256 64 1 1 (16384)
I0413 18:38:59.461104 30343 net.cpp:156] Memory required for data: 1102121984
I0413 18:38:59.461125 30343 layer_factory.hpp:77] Creating layer ip
I0413 18:38:59.461148 30343 net.cpp:91] Creating Layer ip
I0413 18:38:59.461154 30343 net.cpp:425] ip <- global_pool
I0413 18:38:59.461161 30343 net.cpp:399] ip -> ip
I0413 18:38:59.461416 30343 net.cpp:141] Setting up ip
I0413 18:38:59.461427 30343 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:38:59.461432 30343 net.cpp:156] Memory required for data: 1102132224
I0413 18:38:59.461442 30343 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 18:38:59.461450 30343 net.cpp:91] Creating Layer ip_ip_0_split
I0413 18:38:59.461455 30343 net.cpp:425] ip_ip_0_split <- ip
I0413 18:38:59.461464 30343 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 18:38:59.461473 30343 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 18:38:59.461519 30343 net.cpp:141] Setting up ip_ip_0_split
I0413 18:38:59.461526 30343 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:38:59.461532 30343 net.cpp:148] Top shape: 256 10 (2560)
I0413 18:38:59.461537 30343 net.cpp:156] Memory required for data: 1102152704
I0413 18:38:59.461542 30343 layer_factory.hpp:77] Creating layer accuracy
I0413 18:38:59.461568 30343 net.cpp:91] Creating Layer accuracy
I0413 18:38:59.461575 30343 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 18:38:59.461580 30343 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 18:38:59.461596 30343 net.cpp:399] accuracy -> accuracy
I0413 18:38:59.461607 30343 net.cpp:141] Setting up accuracy
I0413 18:38:59.461614 30343 net.cpp:148] Top shape: (1)
I0413 18:38:59.461619 30343 net.cpp:156] Memory required for data: 1102152708
I0413 18:38:59.461632 30343 layer_factory.hpp:77] Creating layer loss
I0413 18:38:59.461638 30343 net.cpp:91] Creating Layer loss
I0413 18:38:59.461643 30343 net.cpp:425] loss <- ip_ip_0_split_1
I0413 18:38:59.461650 30343 net.cpp:425] loss <- label_cifar_1_split_1
I0413 18:38:59.461659 30343 net.cpp:399] loss -> loss
I0413 18:38:59.461671 30343 layer_factory.hpp:77] Creating layer loss
I0413 18:38:59.462234 30343 net.cpp:141] Setting up loss
I0413 18:38:59.462249 30343 net.cpp:148] Top shape: (1)
I0413 18:38:59.462254 30343 net.cpp:151]     with loss weight 1
I0413 18:38:59.462272 30343 net.cpp:156] Memory required for data: 1102152712
I0413 18:38:59.462277 30343 net.cpp:217] loss needs backward computation.
I0413 18:38:59.462291 30343 net.cpp:219] accuracy does not need backward computation.
I0413 18:38:59.462296 30343 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 18:38:59.462301 30343 net.cpp:217] ip needs backward computation.
I0413 18:38:59.462306 30343 net.cpp:217] global_pool needs backward computation.
I0413 18:38:59.462311 30343 net.cpp:217] conv4_3_relu needs backward computation.
I0413 18:38:59.462316 30343 net.cpp:217] conv4_3 needs backward computation.
I0413 18:38:59.462330 30343 net.cpp:217] scale_conv4_3b needs backward computation.
I0413 18:38:59.462337 30343 net.cpp:217] bn_conv4_3b needs backward computation.
I0413 18:38:59.462342 30343 net.cpp:217] conv4_3b needs backward computation.
I0413 18:38:59.462352 30343 net.cpp:217] conv4_3a_relu needs backward computation.
I0413 18:38:59.462357 30343 net.cpp:217] scale_conv4_3a needs backward computation.
I0413 18:38:59.462362 30343 net.cpp:217] bn_conv4_3a needs backward computation.
I0413 18:38:59.462366 30343 net.cpp:217] conv4_3a needs backward computation.
I0413 18:38:59.462373 30343 net.cpp:217] conv4_2_conv4_2_relu_0_split needs backward computation.
I0413 18:38:59.462378 30343 net.cpp:217] conv4_2_relu needs backward computation.
I0413 18:38:59.462383 30343 net.cpp:217] conv4_2 needs backward computation.
I0413 18:38:59.462388 30343 net.cpp:217] scale_conv4_2b needs backward computation.
I0413 18:38:59.462393 30343 net.cpp:217] bn_conv4_2b needs backward computation.
I0413 18:38:59.462398 30343 net.cpp:217] conv4_2b needs backward computation.
I0413 18:38:59.462404 30343 net.cpp:217] conv4_2a_relu needs backward computation.
I0413 18:38:59.462407 30343 net.cpp:217] scale_conv4_2a needs backward computation.
I0413 18:38:59.462412 30343 net.cpp:217] bn_conv4_2a needs backward computation.
I0413 18:38:59.462417 30343 net.cpp:217] conv4_2a needs backward computation.
I0413 18:38:59.462422 30343 net.cpp:217] conv4_1_conv4_1_relu_0_split needs backward computation.
I0413 18:38:59.462431 30343 net.cpp:217] conv4_1_relu needs backward computation.
I0413 18:38:59.462436 30343 net.cpp:217] conv4_1 needs backward computation.
I0413 18:38:59.462445 30343 net.cpp:217] scale_conv4_1b needs backward computation.
I0413 18:38:59.462450 30343 net.cpp:217] bn_conv4_1b needs backward computation.
I0413 18:38:59.462455 30343 net.cpp:217] conv4_1b needs backward computation.
I0413 18:38:59.462465 30343 net.cpp:217] conv4_1a_relu needs backward computation.
I0413 18:38:59.462469 30343 net.cpp:217] scale_conv4_1a needs backward computation.
I0413 18:38:59.462474 30343 net.cpp:217] bn_conv4_1a needs backward computation.
I0413 18:38:59.462478 30343 net.cpp:217] conv4_1a needs backward computation.
I0413 18:38:59.462484 30343 net.cpp:217] scale_conv3_sub needs backward computation.
I0413 18:38:59.462489 30343 net.cpp:217] bn_conv3_sub needs backward computation.
I0413 18:38:59.462493 30343 net.cpp:217] conv3_sub needs backward computation.
I0413 18:38:59.462498 30343 net.cpp:217] conv3_3_conv3_3_relu_0_split needs backward computation.
I0413 18:38:59.462504 30343 net.cpp:217] conv3_3_relu needs backward computation.
I0413 18:38:59.462509 30343 net.cpp:217] conv3_3 needs backward computation.
I0413 18:38:59.462522 30343 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 18:38:59.462527 30343 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 18:38:59.462532 30343 net.cpp:217] conv3_3b needs backward computation.
I0413 18:38:59.462543 30343 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 18:38:59.462548 30343 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 18:38:59.462553 30343 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 18:38:59.462558 30343 net.cpp:217] conv3_3a needs backward computation.
I0413 18:38:59.462565 30343 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 18:38:59.462574 30343 net.cpp:217] conv3_2_relu needs backward computation.
I0413 18:38:59.462580 30343 net.cpp:217] conv3_2 needs backward computation.
I0413 18:38:59.462585 30343 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 18:38:59.462592 30343 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 18:38:59.462597 30343 net.cpp:217] conv3_2b needs backward computation.
I0413 18:38:59.462610 30343 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 18:38:59.462615 30343 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 18:38:59.462620 30343 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 18:38:59.462625 30343 net.cpp:217] conv3_2a needs backward computation.
I0413 18:38:59.462632 30343 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 18:38:59.462643 30343 net.cpp:217] conv3_1_relu needs backward computation.
I0413 18:38:59.462648 30343 net.cpp:217] conv3_1 needs backward computation.
I0413 18:38:59.462659 30343 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 18:38:59.462664 30343 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 18:38:59.462669 30343 net.cpp:217] conv3_1b needs backward computation.
I0413 18:38:59.462678 30343 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 18:38:59.462683 30343 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 18:38:59.462688 30343 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 18:38:59.462692 30343 net.cpp:217] conv3_1a needs backward computation.
I0413 18:38:59.462697 30343 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 18:38:59.462702 30343 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 18:38:59.462710 30343 net.cpp:217] conv2_sub needs backward computation.
I0413 18:38:59.462719 30343 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 18:38:59.462728 30343 net.cpp:217] conv2_3_relu needs backward computation.
I0413 18:38:59.462733 30343 net.cpp:217] conv2_3 needs backward computation.
I0413 18:38:59.462743 30343 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 18:38:59.462748 30343 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 18:38:59.462752 30343 net.cpp:217] conv2_3b needs backward computation.
I0413 18:38:59.462762 30343 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 18:38:59.462767 30343 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 18:38:59.462772 30343 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 18:38:59.462776 30343 net.cpp:217] conv2_3a needs backward computation.
I0413 18:38:59.462782 30343 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 18:38:59.462787 30343 net.cpp:217] conv2_2_relu needs backward computation.
I0413 18:38:59.462792 30343 net.cpp:217] conv2_2 needs backward computation.
I0413 18:38:59.462797 30343 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 18:38:59.462802 30343 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 18:38:59.462807 30343 net.cpp:217] conv2_2b needs backward computation.
I0413 18:38:59.462816 30343 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 18:38:59.462821 30343 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 18:38:59.462826 30343 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 18:38:59.462831 30343 net.cpp:217] conv2_2a needs backward computation.
I0413 18:38:59.462836 30343 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 18:38:59.462841 30343 net.cpp:217] conv2_1_relu needs backward computation.
I0413 18:38:59.462846 30343 net.cpp:217] conv2_1 needs backward computation.
I0413 18:38:59.462858 30343 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 18:38:59.462863 30343 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 18:38:59.462868 30343 net.cpp:217] conv2_1b needs backward computation.
I0413 18:38:59.462873 30343 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 18:38:59.462878 30343 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 18:38:59.462882 30343 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 18:38:59.462891 30343 net.cpp:217] conv2_1a needs backward computation.
I0413 18:38:59.462900 30343 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 18:38:59.462905 30343 net.cpp:217] conv1_relu needs backward computation.
I0413 18:38:59.462910 30343 net.cpp:217] scale_conv1 needs backward computation.
I0413 18:38:59.462915 30343 net.cpp:217] bn_conv1 needs backward computation.
I0413 18:38:59.462920 30343 net.cpp:217] conv1 needs backward computation.
I0413 18:38:59.462926 30343 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 18:38:59.462931 30343 net.cpp:219] cifar does not need backward computation.
I0413 18:38:59.462940 30343 net.cpp:261] This network produces output accuracy
I0413 18:38:59.462945 30343 net.cpp:261] This network produces output loss
I0413 18:38:59.463026 30343 net.cpp:274] Network initialization done.
I0413 18:38:59.465847 30343 solver.cpp:181] Creating test net (#0) specified by net file: prototxt/DyResNet/ResNet-cifar8.prototxt
I0413 18:38:59.465991 30343 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0413 18:38:59.466564 30343 net.cpp:49] Initializing net from parameters: 
name: "ResNet-cifar"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1a"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1a"
  type: "BatchNorm"
  bottom: "conv2_1a"
  top: "conv2_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1a"
  type: "Scale"
  bottom: "conv2_1a"
  top: "conv2_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1a_relu"
  type: "ReLU"
  bottom: "conv2_1a"
  top: "conv2_1a"
}
layer {
  name: "conv2_1b"
  type: "Convolution"
  bottom: "conv2_1a"
  top: "conv2_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_1b"
  type: "BatchNorm"
  bottom: "conv2_1b"
  top: "conv2_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_1b"
  type: "Scale"
  bottom: "conv2_1b"
  top: "conv2_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1b"
  bottom: "conv1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_relu"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2a"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2a"
  type: "BatchNorm"
  bottom: "conv2_2a"
  top: "conv2_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2a"
  type: "Scale"
  bottom: "conv2_2a"
  top: "conv2_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2a_relu"
  type: "ReLU"
  bottom: "conv2_2a"
  top: "conv2_2a"
}
layer {
  name: "conv2_2b"
  type: "Convolution"
  bottom: "conv2_2a"
  top: "conv2_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_2b"
  type: "BatchNorm"
  bottom: "conv2_2b"
  top: "conv2_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_2b"
  type: "Scale"
  bottom: "conv2_2b"
  top: "conv2_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2b"
  bottom: "conv2_1"
  top: "conv2_2"
}
layer {
  name: "conv2_2_relu"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_3a"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv2_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3a"
  type: "BatchNorm"
  bottom: "conv2_3a"
  top: "conv2_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3a"
  type: "Scale"
  bottom: "conv2_3a"
  top: "conv2_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3a_relu"
  type: "ReLU"
  bottom: "conv2_3a"
  top: "conv2_3a"
}
layer {
  name: "conv2_3b"
  type: "Convolution"
  bottom: "conv2_3a"
  top: "conv2_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_3b"
  type: "BatchNorm"
  bottom: "conv2_3b"
  top: "conv2_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_3b"
  type: "Scale"
  bottom: "conv2_3b"
  top: "conv2_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3"
  type: "Eltwise"
  bottom: "conv2_3b"
  bottom: "conv2_2"
  top: "conv2_3"
}
layer {
  name: "conv2_3_relu"
  type: "ReLU"
  bottom: "conv2_3"
  top: "conv2_3"
}
layer {
  name: "conv2_sub"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv2_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv2_sub"
  type: "BatchNorm"
  bottom: "conv2_sub"
  top: "conv2_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv2_sub"
  type: "Scale"
  bottom: "conv2_sub"
  top: "conv2_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a"
  type: "Convolution"
  bottom: "conv2_3"
  top: "conv3_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1a"
  type: "BatchNorm"
  bottom: "conv3_1a"
  top: "conv3_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1a"
  type: "Scale"
  bottom: "conv3_1a"
  top: "conv3_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1a_relu"
  type: "ReLU"
  bottom: "conv3_1a"
  top: "conv3_1a"
}
layer {
  name: "conv3_1b"
  type: "Convolution"
  bottom: "conv3_1a"
  top: "conv3_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_1b"
  type: "BatchNorm"
  bottom: "conv3_1b"
  top: "conv3_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_1b"
  type: "Scale"
  bottom: "conv3_1b"
  top: "conv3_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1b"
  bottom: "conv2_sub"
  top: "conv3_1"
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2a"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2a"
  type: "BatchNorm"
  bottom: "conv3_2a"
  top: "conv3_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2a"
  type: "Scale"
  bottom: "conv3_2a"
  top: "conv3_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2a_relu"
  type: "ReLU"
  bottom: "conv3_2a"
  top: "conv3_2a"
}
layer {
  name: "conv3_2b"
  type: "Convolution"
  bottom: "conv3_2a"
  top: "conv3_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_2b"
  type: "BatchNorm"
  bottom: "conv3_2b"
  top: "conv3_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_2b"
  type: "Scale"
  bottom: "conv3_2b"
  top: "conv3_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2b"
  bottom: "conv3_1"
  top: "conv3_2"
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3a"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3a"
  type: "BatchNorm"
  bottom: "conv3_3a"
  top: "conv3_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3a"
  type: "Scale"
  bottom: "conv3_3a"
  top: "conv3_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3a_relu"
  type: "ReLU"
  bottom: "conv3_3a"
  top: "conv3_3a"
}
layer {
  name: "conv3_3b"
  type: "Convolution"
  bottom: "conv3_3a"
  top: "conv3_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_3b"
  type: "BatchNorm"
  bottom: "conv3_3b"
  top: "conv3_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_3b"
  type: "Scale"
  bottom: "conv3_3b"
  top: "conv3_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3"
  type: "Eltwise"
  bottom: "conv3_3b"
  bottom: "conv3_2"
  top: "conv3_3"
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_sub"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_sub"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv3_sub"
  type: "BatchNorm"
  bottom: "conv3_sub"
  top: "conv3_sub"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv3_sub"
  type: "Scale"
  bottom: "conv3_sub"
  top: "conv3_sub"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv4_1a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1a"
  type: "BatchNorm"
  bottom: "conv4_1a"
  top: "conv4_1a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1a"
  type: "Scale"
  bottom: "conv4_1a"
  top: "conv4_1a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1a_relu"
  type: "ReLU"
  bottom: "conv4_1a"
  top: "conv4_1a"
}
layer {
  name: "conv4_1b"
  type: "Convolution"
  bottom: "conv4_1a"
  top: "conv4_1b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_1b"
  type: "BatchNorm"
  bottom: "conv4_1b"
  top: "conv4_1b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_1b"
  type: "Scale"
  bottom: "conv4_1b"
  top: "conv4_1b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv3_sub"
  bottom: "conv4_1b"
  top: "conv4_1"
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2a"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2a"
  type: "BatchNorm"
  bottom: "conv4_2a"
  top: "conv4_2a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2a"
  type: "Scale"
  bottom: "conv4_2a"
  top: "conv4_2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2a_relu"
  type: "ReLU"
  bottom: "conv4_2a"
  top: "conv4_2a"
}
layer {
  name: "conv4_2b"
  type: "Convolution"
  bottom: "conv4_2a"
  top: "conv4_2b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_2b"
  type: "BatchNorm"
  bottom: "conv4_2b"
  top: "conv4_2b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_2b"
  type: "Scale"
  bottom: "conv4_2b"
  top: "conv4_2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2"
  type: "Eltwise"
  bottom: "conv4_1"
  bottom: "conv4_2b"
  top: "conv4_2"
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3a"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3a"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_3a"
  type: "BatchNorm"
  bottom: "conv4_3a"
  top: "conv4_3a"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_3a"
  type: "Scale"
  bottom: "conv4_3a"
  top: "conv4_3a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3a_relu"
  type: "ReLU"
  bottom: "conv4_3a"
  top: "conv4_3a"
}
layer {
  name: "conv4_3b"
  type: "Convolution"
  bottom: "conv4_3a"
  top: "conv4_3b"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_conv4_3b"
  type: "BatchNorm"
  bottom: "conv4_3b"
  top: "conv4_3b"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "scale_conv4_3b"
  type: "Scale"
  bottom: "conv4_3b"
  top: "conv4_3b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3"
  type: "Eltwise"
  bottom: "conv4_2"
  bottom: "conv4_3b"
  top: "conv4_3"
}
layer {
  name: "conv4_3_relu"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "conv4_3"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 8
    stride: 8
  }
}
layer {
  name: "ip"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "ip"
  inner_product_param {
    num_output: 10
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip"
  bottom: "label"
  top: "accuracy"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip"
  bottom: "label"
  top: "loss"
}
I0413 18:38:59.467011 30343 layer_factory.hpp:77] Creating layer cifar
I0413 18:38:59.467181 30343 net.cpp:91] Creating Layer cifar
I0413 18:38:59.467196 30343 net.cpp:399] cifar -> data
I0413 18:38:59.467208 30343 net.cpp:399] cifar -> label
I0413 18:38:59.467221 30343 data_transformer.cpp:25] Loading mean file from: data/cifar10/mean.binaryproto
I0413 18:38:59.468446 30640 db_lmdb.cpp:38] Opened lmdb data/cifar10/cifar10_test_lmdb
I0413 18:38:59.468636 30343 data_layer.cpp:41] output data size: 100,3,32,32
I0413 18:38:59.474298 30343 net.cpp:141] Setting up cifar
I0413 18:38:59.474319 30343 net.cpp:148] Top shape: 100 3 32 32 (307200)
I0413 18:38:59.474328 30343 net.cpp:148] Top shape: 100 (100)
I0413 18:38:59.474333 30343 net.cpp:156] Memory required for data: 1229200
I0413 18:38:59.474339 30343 layer_factory.hpp:77] Creating layer label_cifar_1_split
I0413 18:38:59.474349 30343 net.cpp:91] Creating Layer label_cifar_1_split
I0413 18:38:59.474354 30343 net.cpp:425] label_cifar_1_split <- label
I0413 18:38:59.474362 30343 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_0
I0413 18:38:59.474377 30343 net.cpp:399] label_cifar_1_split -> label_cifar_1_split_1
I0413 18:38:59.474509 30343 net.cpp:141] Setting up label_cifar_1_split
I0413 18:38:59.474521 30343 net.cpp:148] Top shape: 100 (100)
I0413 18:38:59.474527 30343 net.cpp:148] Top shape: 100 (100)
I0413 18:38:59.474532 30343 net.cpp:156] Memory required for data: 1230000
I0413 18:38:59.474537 30343 layer_factory.hpp:77] Creating layer conv1
I0413 18:38:59.474565 30343 net.cpp:91] Creating Layer conv1
I0413 18:38:59.474570 30343 net.cpp:425] conv1 <- data
I0413 18:38:59.474580 30343 net.cpp:399] conv1 -> conv1
I0413 18:38:59.478274 30343 net.cpp:141] Setting up conv1
I0413 18:38:59.478297 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.478303 30343 net.cpp:156] Memory required for data: 7783600
I0413 18:38:59.478324 30343 layer_factory.hpp:77] Creating layer bn_conv1
I0413 18:38:59.478333 30343 net.cpp:91] Creating Layer bn_conv1
I0413 18:38:59.478339 30343 net.cpp:425] bn_conv1 <- conv1
I0413 18:38:59.478348 30343 net.cpp:386] bn_conv1 -> conv1 (in-place)
I0413 18:38:59.478595 30343 net.cpp:141] Setting up bn_conv1
I0413 18:38:59.478606 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.478611 30343 net.cpp:156] Memory required for data: 14337200
I0413 18:38:59.478643 30343 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:38:59.478653 30343 net.cpp:91] Creating Layer scale_conv1
I0413 18:38:59.478659 30343 net.cpp:425] scale_conv1 <- conv1
I0413 18:38:59.478668 30343 net.cpp:386] scale_conv1 -> conv1 (in-place)
I0413 18:38:59.478721 30343 layer_factory.hpp:77] Creating layer scale_conv1
I0413 18:38:59.478862 30343 net.cpp:141] Setting up scale_conv1
I0413 18:38:59.478873 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.478878 30343 net.cpp:156] Memory required for data: 20890800
I0413 18:38:59.478888 30343 layer_factory.hpp:77] Creating layer conv1_relu
I0413 18:38:59.478894 30343 net.cpp:91] Creating Layer conv1_relu
I0413 18:38:59.478899 30343 net.cpp:425] conv1_relu <- conv1
I0413 18:38:59.478905 30343 net.cpp:386] conv1_relu -> conv1 (in-place)
I0413 18:38:59.479269 30343 net.cpp:141] Setting up conv1_relu
I0413 18:38:59.479285 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.479310 30343 net.cpp:156] Memory required for data: 27444400
I0413 18:38:59.479315 30343 layer_factory.hpp:77] Creating layer conv1_conv1_relu_0_split
I0413 18:38:59.479322 30343 net.cpp:91] Creating Layer conv1_conv1_relu_0_split
I0413 18:38:59.479327 30343 net.cpp:425] conv1_conv1_relu_0_split <- conv1
I0413 18:38:59.479337 30343 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_0
I0413 18:38:59.479347 30343 net.cpp:399] conv1_conv1_relu_0_split -> conv1_conv1_relu_0_split_1
I0413 18:38:59.479403 30343 net.cpp:141] Setting up conv1_conv1_relu_0_split
I0413 18:38:59.479413 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.479423 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.479429 30343 net.cpp:156] Memory required for data: 40551600
I0413 18:38:59.479434 30343 layer_factory.hpp:77] Creating layer conv2_1a
I0413 18:38:59.479449 30343 net.cpp:91] Creating Layer conv2_1a
I0413 18:38:59.479454 30343 net.cpp:425] conv2_1a <- conv1_conv1_relu_0_split_0
I0413 18:38:59.479463 30343 net.cpp:399] conv2_1a -> conv2_1a
I0413 18:38:59.481640 30343 net.cpp:141] Setting up conv2_1a
I0413 18:38:59.481659 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.481665 30343 net.cpp:156] Memory required for data: 47105200
I0413 18:38:59.481681 30343 layer_factory.hpp:77] Creating layer bn_conv2_1a
I0413 18:38:59.481693 30343 net.cpp:91] Creating Layer bn_conv2_1a
I0413 18:38:59.481699 30343 net.cpp:425] bn_conv2_1a <- conv2_1a
I0413 18:38:59.481708 30343 net.cpp:386] bn_conv2_1a -> conv2_1a (in-place)
I0413 18:38:59.481966 30343 net.cpp:141] Setting up bn_conv2_1a
I0413 18:38:59.481976 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.481981 30343 net.cpp:156] Memory required for data: 53658800
I0413 18:38:59.481992 30343 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:38:59.482000 30343 net.cpp:91] Creating Layer scale_conv2_1a
I0413 18:38:59.482007 30343 net.cpp:425] scale_conv2_1a <- conv2_1a
I0413 18:38:59.482013 30343 net.cpp:386] scale_conv2_1a -> conv2_1a (in-place)
I0413 18:38:59.482213 30343 layer_factory.hpp:77] Creating layer scale_conv2_1a
I0413 18:38:59.482363 30343 net.cpp:141] Setting up scale_conv2_1a
I0413 18:38:59.482373 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.482379 30343 net.cpp:156] Memory required for data: 60212400
I0413 18:38:59.482388 30343 layer_factory.hpp:77] Creating layer conv2_1a_relu
I0413 18:38:59.482396 30343 net.cpp:91] Creating Layer conv2_1a_relu
I0413 18:38:59.482403 30343 net.cpp:425] conv2_1a_relu <- conv2_1a
I0413 18:38:59.482409 30343 net.cpp:386] conv2_1a_relu -> conv2_1a (in-place)
I0413 18:38:59.482622 30343 net.cpp:141] Setting up conv2_1a_relu
I0413 18:38:59.482635 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.482640 30343 net.cpp:156] Memory required for data: 66766000
I0413 18:38:59.482645 30343 layer_factory.hpp:77] Creating layer conv2_1b
I0413 18:38:59.482658 30343 net.cpp:91] Creating Layer conv2_1b
I0413 18:38:59.482668 30343 net.cpp:425] conv2_1b <- conv2_1a
I0413 18:38:59.482697 30343 net.cpp:399] conv2_1b -> conv2_1b
I0413 18:38:59.485196 30343 net.cpp:141] Setting up conv2_1b
I0413 18:38:59.485224 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.485229 30343 net.cpp:156] Memory required for data: 73319600
I0413 18:38:59.485239 30343 layer_factory.hpp:77] Creating layer bn_conv2_1b
I0413 18:38:59.485251 30343 net.cpp:91] Creating Layer bn_conv2_1b
I0413 18:38:59.485266 30343 net.cpp:425] bn_conv2_1b <- conv2_1b
I0413 18:38:59.485275 30343 net.cpp:386] bn_conv2_1b -> conv2_1b (in-place)
I0413 18:38:59.485523 30343 net.cpp:141] Setting up bn_conv2_1b
I0413 18:38:59.485533 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.485538 30343 net.cpp:156] Memory required for data: 79873200
I0413 18:38:59.485553 30343 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:38:59.485563 30343 net.cpp:91] Creating Layer scale_conv2_1b
I0413 18:38:59.485569 30343 net.cpp:425] scale_conv2_1b <- conv2_1b
I0413 18:38:59.485575 30343 net.cpp:386] scale_conv2_1b -> conv2_1b (in-place)
I0413 18:38:59.485631 30343 layer_factory.hpp:77] Creating layer scale_conv2_1b
I0413 18:38:59.485785 30343 net.cpp:141] Setting up scale_conv2_1b
I0413 18:38:59.485798 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.485806 30343 net.cpp:156] Memory required for data: 86426800
I0413 18:38:59.485815 30343 layer_factory.hpp:77] Creating layer conv2_1
I0413 18:38:59.485822 30343 net.cpp:91] Creating Layer conv2_1
I0413 18:38:59.485827 30343 net.cpp:425] conv2_1 <- conv2_1b
I0413 18:38:59.485833 30343 net.cpp:425] conv2_1 <- conv1_conv1_relu_0_split_1
I0413 18:38:59.485842 30343 net.cpp:399] conv2_1 -> conv2_1
I0413 18:38:59.485884 30343 net.cpp:141] Setting up conv2_1
I0413 18:38:59.485893 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.485898 30343 net.cpp:156] Memory required for data: 92980400
I0413 18:38:59.485903 30343 layer_factory.hpp:77] Creating layer conv2_1_relu
I0413 18:38:59.485913 30343 net.cpp:91] Creating Layer conv2_1_relu
I0413 18:38:59.485918 30343 net.cpp:425] conv2_1_relu <- conv2_1
I0413 18:38:59.485924 30343 net.cpp:386] conv2_1_relu -> conv2_1 (in-place)
I0413 18:38:59.486208 30343 net.cpp:141] Setting up conv2_1_relu
I0413 18:38:59.486222 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.486227 30343 net.cpp:156] Memory required for data: 99534000
I0413 18:38:59.486232 30343 layer_factory.hpp:77] Creating layer conv2_1_conv2_1_relu_0_split
I0413 18:38:59.486243 30343 net.cpp:91] Creating Layer conv2_1_conv2_1_relu_0_split
I0413 18:38:59.486249 30343 net.cpp:425] conv2_1_conv2_1_relu_0_split <- conv2_1
I0413 18:38:59.486256 30343 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_0
I0413 18:38:59.486266 30343 net.cpp:399] conv2_1_conv2_1_relu_0_split -> conv2_1_conv2_1_relu_0_split_1
I0413 18:38:59.486325 30343 net.cpp:141] Setting up conv2_1_conv2_1_relu_0_split
I0413 18:38:59.486335 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.486341 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.486346 30343 net.cpp:156] Memory required for data: 112641200
I0413 18:38:59.486351 30343 layer_factory.hpp:77] Creating layer conv2_2a
I0413 18:38:59.486364 30343 net.cpp:91] Creating Layer conv2_2a
I0413 18:38:59.486371 30343 net.cpp:425] conv2_2a <- conv2_1_conv2_1_relu_0_split_0
I0413 18:38:59.486380 30343 net.cpp:399] conv2_2a -> conv2_2a
I0413 18:38:59.489817 30343 net.cpp:141] Setting up conv2_2a
I0413 18:38:59.489845 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.489850 30343 net.cpp:156] Memory required for data: 119194800
I0413 18:38:59.489859 30343 layer_factory.hpp:77] Creating layer bn_conv2_2a
I0413 18:38:59.489871 30343 net.cpp:91] Creating Layer bn_conv2_2a
I0413 18:38:59.489881 30343 net.cpp:425] bn_conv2_2a <- conv2_2a
I0413 18:38:59.489888 30343 net.cpp:386] bn_conv2_2a -> conv2_2a (in-place)
I0413 18:38:59.490137 30343 net.cpp:141] Setting up bn_conv2_2a
I0413 18:38:59.490154 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.490159 30343 net.cpp:156] Memory required for data: 125748400
I0413 18:38:59.490170 30343 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:38:59.490178 30343 net.cpp:91] Creating Layer scale_conv2_2a
I0413 18:38:59.490202 30343 net.cpp:425] scale_conv2_2a <- conv2_2a
I0413 18:38:59.490209 30343 net.cpp:386] scale_conv2_2a -> conv2_2a (in-place)
I0413 18:38:59.490267 30343 layer_factory.hpp:77] Creating layer scale_conv2_2a
I0413 18:38:59.490412 30343 net.cpp:141] Setting up scale_conv2_2a
I0413 18:38:59.490422 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.490427 30343 net.cpp:156] Memory required for data: 132302000
I0413 18:38:59.490437 30343 layer_factory.hpp:77] Creating layer conv2_2a_relu
I0413 18:38:59.490443 30343 net.cpp:91] Creating Layer conv2_2a_relu
I0413 18:38:59.490448 30343 net.cpp:425] conv2_2a_relu <- conv2_2a
I0413 18:38:59.490460 30343 net.cpp:386] conv2_2a_relu -> conv2_2a (in-place)
I0413 18:38:59.490860 30343 net.cpp:141] Setting up conv2_2a_relu
I0413 18:38:59.490876 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.490882 30343 net.cpp:156] Memory required for data: 138855600
I0413 18:38:59.490887 30343 layer_factory.hpp:77] Creating layer conv2_2b
I0413 18:38:59.490901 30343 net.cpp:91] Creating Layer conv2_2b
I0413 18:38:59.490912 30343 net.cpp:425] conv2_2b <- conv2_2a
I0413 18:38:59.490923 30343 net.cpp:399] conv2_2b -> conv2_2b
I0413 18:38:59.494437 30343 net.cpp:141] Setting up conv2_2b
I0413 18:38:59.494457 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.494463 30343 net.cpp:156] Memory required for data: 145409200
I0413 18:38:59.494472 30343 layer_factory.hpp:77] Creating layer bn_conv2_2b
I0413 18:38:59.494482 30343 net.cpp:91] Creating Layer bn_conv2_2b
I0413 18:38:59.494488 30343 net.cpp:425] bn_conv2_2b <- conv2_2b
I0413 18:38:59.494496 30343 net.cpp:386] bn_conv2_2b -> conv2_2b (in-place)
I0413 18:38:59.494755 30343 net.cpp:141] Setting up bn_conv2_2b
I0413 18:38:59.494765 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.494770 30343 net.cpp:156] Memory required for data: 151962800
I0413 18:38:59.494784 30343 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:38:59.494794 30343 net.cpp:91] Creating Layer scale_conv2_2b
I0413 18:38:59.494801 30343 net.cpp:425] scale_conv2_2b <- conv2_2b
I0413 18:38:59.494807 30343 net.cpp:386] scale_conv2_2b -> conv2_2b (in-place)
I0413 18:38:59.494861 30343 layer_factory.hpp:77] Creating layer scale_conv2_2b
I0413 18:38:59.495003 30343 net.cpp:141] Setting up scale_conv2_2b
I0413 18:38:59.495013 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.495018 30343 net.cpp:156] Memory required for data: 158516400
I0413 18:38:59.495026 30343 layer_factory.hpp:77] Creating layer conv2_2
I0413 18:38:59.495033 30343 net.cpp:91] Creating Layer conv2_2
I0413 18:38:59.495038 30343 net.cpp:425] conv2_2 <- conv2_2b
I0413 18:38:59.495044 30343 net.cpp:425] conv2_2 <- conv2_1_conv2_1_relu_0_split_1
I0413 18:38:59.495054 30343 net.cpp:399] conv2_2 -> conv2_2
I0413 18:38:59.495086 30343 net.cpp:141] Setting up conv2_2
I0413 18:38:59.495095 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.495100 30343 net.cpp:156] Memory required for data: 165070000
I0413 18:38:59.495105 30343 layer_factory.hpp:77] Creating layer conv2_2_relu
I0413 18:38:59.495112 30343 net.cpp:91] Creating Layer conv2_2_relu
I0413 18:38:59.495117 30343 net.cpp:425] conv2_2_relu <- conv2_2
I0413 18:38:59.495123 30343 net.cpp:386] conv2_2_relu -> conv2_2 (in-place)
I0413 18:38:59.495581 30343 net.cpp:141] Setting up conv2_2_relu
I0413 18:38:59.495595 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.495600 30343 net.cpp:156] Memory required for data: 171623600
I0413 18:38:59.495605 30343 layer_factory.hpp:77] Creating layer conv2_2_conv2_2_relu_0_split
I0413 18:38:59.495612 30343 net.cpp:91] Creating Layer conv2_2_conv2_2_relu_0_split
I0413 18:38:59.495617 30343 net.cpp:425] conv2_2_conv2_2_relu_0_split <- conv2_2
I0413 18:38:59.495630 30343 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_0
I0413 18:38:59.495640 30343 net.cpp:399] conv2_2_conv2_2_relu_0_split -> conv2_2_conv2_2_relu_0_split_1
I0413 18:38:59.495697 30343 net.cpp:141] Setting up conv2_2_conv2_2_relu_0_split
I0413 18:38:59.495705 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.495712 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.495718 30343 net.cpp:156] Memory required for data: 184730800
I0413 18:38:59.495723 30343 layer_factory.hpp:77] Creating layer conv2_3a
I0413 18:38:59.495738 30343 net.cpp:91] Creating Layer conv2_3a
I0413 18:38:59.495743 30343 net.cpp:425] conv2_3a <- conv2_2_conv2_2_relu_0_split_0
I0413 18:38:59.495751 30343 net.cpp:399] conv2_3a -> conv2_3a
I0413 18:38:59.498029 30343 net.cpp:141] Setting up conv2_3a
I0413 18:38:59.498049 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.498054 30343 net.cpp:156] Memory required for data: 191284400
I0413 18:38:59.498064 30343 layer_factory.hpp:77] Creating layer bn_conv2_3a
I0413 18:38:59.498073 30343 net.cpp:91] Creating Layer bn_conv2_3a
I0413 18:38:59.498080 30343 net.cpp:425] bn_conv2_3a <- conv2_3a
I0413 18:38:59.498090 30343 net.cpp:386] bn_conv2_3a -> conv2_3a (in-place)
I0413 18:38:59.498337 30343 net.cpp:141] Setting up bn_conv2_3a
I0413 18:38:59.498347 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.498353 30343 net.cpp:156] Memory required for data: 197838000
I0413 18:38:59.498363 30343 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:38:59.498373 30343 net.cpp:91] Creating Layer scale_conv2_3a
I0413 18:38:59.498378 30343 net.cpp:425] scale_conv2_3a <- conv2_3a
I0413 18:38:59.498384 30343 net.cpp:386] scale_conv2_3a -> conv2_3a (in-place)
I0413 18:38:59.498437 30343 layer_factory.hpp:77] Creating layer scale_conv2_3a
I0413 18:38:59.498579 30343 net.cpp:141] Setting up scale_conv2_3a
I0413 18:38:59.498589 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.498594 30343 net.cpp:156] Memory required for data: 204391600
I0413 18:38:59.498602 30343 layer_factory.hpp:77] Creating layer conv2_3a_relu
I0413 18:38:59.498610 30343 net.cpp:91] Creating Layer conv2_3a_relu
I0413 18:38:59.498615 30343 net.cpp:425] conv2_3a_relu <- conv2_3a
I0413 18:38:59.498622 30343 net.cpp:386] conv2_3a_relu -> conv2_3a (in-place)
I0413 18:38:59.499008 30343 net.cpp:141] Setting up conv2_3a_relu
I0413 18:38:59.499020 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.499025 30343 net.cpp:156] Memory required for data: 210945200
I0413 18:38:59.499030 30343 layer_factory.hpp:77] Creating layer conv2_3b
I0413 18:38:59.499043 30343 net.cpp:91] Creating Layer conv2_3b
I0413 18:38:59.499048 30343 net.cpp:425] conv2_3b <- conv2_3a
I0413 18:38:59.499058 30343 net.cpp:399] conv2_3b -> conv2_3b
I0413 18:38:59.502605 30343 net.cpp:141] Setting up conv2_3b
I0413 18:38:59.502624 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.502630 30343 net.cpp:156] Memory required for data: 217498800
I0413 18:38:59.502640 30343 layer_factory.hpp:77] Creating layer bn_conv2_3b
I0413 18:38:59.502652 30343 net.cpp:91] Creating Layer bn_conv2_3b
I0413 18:38:59.502658 30343 net.cpp:425] bn_conv2_3b <- conv2_3b
I0413 18:38:59.502667 30343 net.cpp:386] bn_conv2_3b -> conv2_3b (in-place)
I0413 18:38:59.502912 30343 net.cpp:141] Setting up bn_conv2_3b
I0413 18:38:59.502921 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.502926 30343 net.cpp:156] Memory required for data: 224052400
I0413 18:38:59.502936 30343 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:38:59.502945 30343 net.cpp:91] Creating Layer scale_conv2_3b
I0413 18:38:59.502950 30343 net.cpp:425] scale_conv2_3b <- conv2_3b
I0413 18:38:59.502957 30343 net.cpp:386] scale_conv2_3b -> conv2_3b (in-place)
I0413 18:38:59.503008 30343 layer_factory.hpp:77] Creating layer scale_conv2_3b
I0413 18:38:59.503150 30343 net.cpp:141] Setting up scale_conv2_3b
I0413 18:38:59.503165 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.503170 30343 net.cpp:156] Memory required for data: 230606000
I0413 18:38:59.503178 30343 layer_factory.hpp:77] Creating layer conv2_3
I0413 18:38:59.503187 30343 net.cpp:91] Creating Layer conv2_3
I0413 18:38:59.503192 30343 net.cpp:425] conv2_3 <- conv2_3b
I0413 18:38:59.503199 30343 net.cpp:425] conv2_3 <- conv2_2_conv2_2_relu_0_split_1
I0413 18:38:59.503206 30343 net.cpp:399] conv2_3 -> conv2_3
I0413 18:38:59.503240 30343 net.cpp:141] Setting up conv2_3
I0413 18:38:59.503249 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.503254 30343 net.cpp:156] Memory required for data: 237159600
I0413 18:38:59.503259 30343 layer_factory.hpp:77] Creating layer conv2_3_relu
I0413 18:38:59.503267 30343 net.cpp:91] Creating Layer conv2_3_relu
I0413 18:38:59.503271 30343 net.cpp:425] conv2_3_relu <- conv2_3
I0413 18:38:59.503279 30343 net.cpp:386] conv2_3_relu -> conv2_3 (in-place)
I0413 18:38:59.503751 30343 net.cpp:141] Setting up conv2_3_relu
I0413 18:38:59.503767 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.503772 30343 net.cpp:156] Memory required for data: 243713200
I0413 18:38:59.503777 30343 layer_factory.hpp:77] Creating layer conv2_3_conv2_3_relu_0_split
I0413 18:38:59.503785 30343 net.cpp:91] Creating Layer conv2_3_conv2_3_relu_0_split
I0413 18:38:59.503790 30343 net.cpp:425] conv2_3_conv2_3_relu_0_split <- conv2_3
I0413 18:38:59.503801 30343 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_0
I0413 18:38:59.503811 30343 net.cpp:399] conv2_3_conv2_3_relu_0_split -> conv2_3_conv2_3_relu_0_split_1
I0413 18:38:59.503866 30343 net.cpp:141] Setting up conv2_3_conv2_3_relu_0_split
I0413 18:38:59.503877 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.503883 30343 net.cpp:148] Top shape: 100 16 32 32 (1638400)
I0413 18:38:59.503887 30343 net.cpp:156] Memory required for data: 256820400
I0413 18:38:59.503892 30343 layer_factory.hpp:77] Creating layer conv2_sub
I0413 18:38:59.503906 30343 net.cpp:91] Creating Layer conv2_sub
I0413 18:38:59.503911 30343 net.cpp:425] conv2_sub <- conv2_3_conv2_3_relu_0_split_0
I0413 18:38:59.503921 30343 net.cpp:399] conv2_sub -> conv2_sub
I0413 18:38:59.507247 30343 net.cpp:141] Setting up conv2_sub
I0413 18:38:59.507266 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.507272 30343 net.cpp:156] Memory required for data: 260097200
I0413 18:38:59.507282 30343 layer_factory.hpp:77] Creating layer bn_conv2_sub
I0413 18:38:59.507292 30343 net.cpp:91] Creating Layer bn_conv2_sub
I0413 18:38:59.507298 30343 net.cpp:425] bn_conv2_sub <- conv2_sub
I0413 18:38:59.507308 30343 net.cpp:386] bn_conv2_sub -> conv2_sub (in-place)
I0413 18:38:59.507555 30343 net.cpp:141] Setting up bn_conv2_sub
I0413 18:38:59.507565 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.507570 30343 net.cpp:156] Memory required for data: 263374000
I0413 18:38:59.507580 30343 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:38:59.507589 30343 net.cpp:91] Creating Layer scale_conv2_sub
I0413 18:38:59.507594 30343 net.cpp:425] scale_conv2_sub <- conv2_sub
I0413 18:38:59.507601 30343 net.cpp:386] scale_conv2_sub -> conv2_sub (in-place)
I0413 18:38:59.507654 30343 layer_factory.hpp:77] Creating layer scale_conv2_sub
I0413 18:38:59.507796 30343 net.cpp:141] Setting up scale_conv2_sub
I0413 18:38:59.507804 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.507809 30343 net.cpp:156] Memory required for data: 266650800
I0413 18:38:59.507817 30343 layer_factory.hpp:77] Creating layer conv3_1a
I0413 18:38:59.507829 30343 net.cpp:91] Creating Layer conv3_1a
I0413 18:38:59.507836 30343 net.cpp:425] conv3_1a <- conv2_3_conv2_3_relu_0_split_1
I0413 18:38:59.507845 30343 net.cpp:399] conv3_1a -> conv3_1a
I0413 18:38:59.510679 30343 net.cpp:141] Setting up conv3_1a
I0413 18:38:59.510699 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.510704 30343 net.cpp:156] Memory required for data: 269927600
I0413 18:38:59.510720 30343 layer_factory.hpp:77] Creating layer bn_conv3_1a
I0413 18:38:59.510728 30343 net.cpp:91] Creating Layer bn_conv3_1a
I0413 18:38:59.510735 30343 net.cpp:425] bn_conv3_1a <- conv3_1a
I0413 18:38:59.510743 30343 net.cpp:386] bn_conv3_1a -> conv3_1a (in-place)
I0413 18:38:59.510987 30343 net.cpp:141] Setting up bn_conv3_1a
I0413 18:38:59.510996 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.511001 30343 net.cpp:156] Memory required for data: 273204400
I0413 18:38:59.511011 30343 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:38:59.511019 30343 net.cpp:91] Creating Layer scale_conv3_1a
I0413 18:38:59.511024 30343 net.cpp:425] scale_conv3_1a <- conv3_1a
I0413 18:38:59.511031 30343 net.cpp:386] scale_conv3_1a -> conv3_1a (in-place)
I0413 18:38:59.511085 30343 layer_factory.hpp:77] Creating layer scale_conv3_1a
I0413 18:38:59.511224 30343 net.cpp:141] Setting up scale_conv3_1a
I0413 18:38:59.511234 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.511239 30343 net.cpp:156] Memory required for data: 276481200
I0413 18:38:59.511246 30343 layer_factory.hpp:77] Creating layer conv3_1a_relu
I0413 18:38:59.511253 30343 net.cpp:91] Creating Layer conv3_1a_relu
I0413 18:38:59.511258 30343 net.cpp:425] conv3_1a_relu <- conv3_1a
I0413 18:38:59.511265 30343 net.cpp:386] conv3_1a_relu -> conv3_1a (in-place)
I0413 18:38:59.511734 30343 net.cpp:141] Setting up conv3_1a_relu
I0413 18:38:59.511749 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.511754 30343 net.cpp:156] Memory required for data: 279758000
I0413 18:38:59.511759 30343 layer_factory.hpp:77] Creating layer conv3_1b
I0413 18:38:59.511773 30343 net.cpp:91] Creating Layer conv3_1b
I0413 18:38:59.511780 30343 net.cpp:425] conv3_1b <- conv3_1a
I0413 18:38:59.511790 30343 net.cpp:399] conv3_1b -> conv3_1b
I0413 18:38:59.514199 30343 net.cpp:141] Setting up conv3_1b
I0413 18:38:59.514219 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.514225 30343 net.cpp:156] Memory required for data: 283034800
I0413 18:38:59.514245 30343 layer_factory.hpp:77] Creating layer bn_conv3_1b
I0413 18:38:59.514256 30343 net.cpp:91] Creating Layer bn_conv3_1b
I0413 18:38:59.514262 30343 net.cpp:425] bn_conv3_1b <- conv3_1b
I0413 18:38:59.514269 30343 net.cpp:386] bn_conv3_1b -> conv3_1b (in-place)
I0413 18:38:59.514518 30343 net.cpp:141] Setting up bn_conv3_1b
I0413 18:38:59.514528 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.514533 30343 net.cpp:156] Memory required for data: 286311600
I0413 18:38:59.514544 30343 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:38:59.514551 30343 net.cpp:91] Creating Layer scale_conv3_1b
I0413 18:38:59.514556 30343 net.cpp:425] scale_conv3_1b <- conv3_1b
I0413 18:38:59.514565 30343 net.cpp:386] scale_conv3_1b -> conv3_1b (in-place)
I0413 18:38:59.514616 30343 layer_factory.hpp:77] Creating layer scale_conv3_1b
I0413 18:38:59.514760 30343 net.cpp:141] Setting up scale_conv3_1b
I0413 18:38:59.514770 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.514773 30343 net.cpp:156] Memory required for data: 289588400
I0413 18:38:59.514781 30343 layer_factory.hpp:77] Creating layer conv3_1
I0413 18:38:59.514789 30343 net.cpp:91] Creating Layer conv3_1
I0413 18:38:59.514793 30343 net.cpp:425] conv3_1 <- conv3_1b
I0413 18:38:59.514801 30343 net.cpp:425] conv3_1 <- conv2_sub
I0413 18:38:59.514807 30343 net.cpp:399] conv3_1 -> conv3_1
I0413 18:38:59.514837 30343 net.cpp:141] Setting up conv3_1
I0413 18:38:59.514845 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.514850 30343 net.cpp:156] Memory required for data: 292865200
I0413 18:38:59.514854 30343 layer_factory.hpp:77] Creating layer conv3_1_relu
I0413 18:38:59.514863 30343 net.cpp:91] Creating Layer conv3_1_relu
I0413 18:38:59.514868 30343 net.cpp:425] conv3_1_relu <- conv3_1
I0413 18:38:59.514875 30343 net.cpp:386] conv3_1_relu -> conv3_1 (in-place)
I0413 18:38:59.515151 30343 net.cpp:141] Setting up conv3_1_relu
I0413 18:38:59.515162 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.515172 30343 net.cpp:156] Memory required for data: 296142000
I0413 18:38:59.515178 30343 layer_factory.hpp:77] Creating layer conv3_1_conv3_1_relu_0_split
I0413 18:38:59.515187 30343 net.cpp:91] Creating Layer conv3_1_conv3_1_relu_0_split
I0413 18:38:59.515192 30343 net.cpp:425] conv3_1_conv3_1_relu_0_split <- conv3_1
I0413 18:38:59.515200 30343 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_0
I0413 18:38:59.515211 30343 net.cpp:399] conv3_1_conv3_1_relu_0_split -> conv3_1_conv3_1_relu_0_split_1
I0413 18:38:59.515265 30343 net.cpp:141] Setting up conv3_1_conv3_1_relu_0_split
I0413 18:38:59.515274 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.515280 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.515285 30343 net.cpp:156] Memory required for data: 302695600
I0413 18:38:59.515290 30343 layer_factory.hpp:77] Creating layer conv3_2a
I0413 18:38:59.515302 30343 net.cpp:91] Creating Layer conv3_2a
I0413 18:38:59.515308 30343 net.cpp:425] conv3_2a <- conv3_1_conv3_1_relu_0_split_0
I0413 18:38:59.515319 30343 net.cpp:399] conv3_2a -> conv3_2a
I0413 18:38:59.518769 30343 net.cpp:141] Setting up conv3_2a
I0413 18:38:59.518786 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.518792 30343 net.cpp:156] Memory required for data: 305972400
I0413 18:38:59.518801 30343 layer_factory.hpp:77] Creating layer bn_conv3_2a
I0413 18:38:59.518812 30343 net.cpp:91] Creating Layer bn_conv3_2a
I0413 18:38:59.518818 30343 net.cpp:425] bn_conv3_2a <- conv3_2a
I0413 18:38:59.518828 30343 net.cpp:386] bn_conv3_2a -> conv3_2a (in-place)
I0413 18:38:59.519078 30343 net.cpp:141] Setting up bn_conv3_2a
I0413 18:38:59.519088 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.519091 30343 net.cpp:156] Memory required for data: 309249200
I0413 18:38:59.519101 30343 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:38:59.519109 30343 net.cpp:91] Creating Layer scale_conv3_2a
I0413 18:38:59.519114 30343 net.cpp:425] scale_conv3_2a <- conv3_2a
I0413 18:38:59.519124 30343 net.cpp:386] scale_conv3_2a -> conv3_2a (in-place)
I0413 18:38:59.519176 30343 layer_factory.hpp:77] Creating layer scale_conv3_2a
I0413 18:38:59.519323 30343 net.cpp:141] Setting up scale_conv3_2a
I0413 18:38:59.519332 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.519337 30343 net.cpp:156] Memory required for data: 312526000
I0413 18:38:59.519345 30343 layer_factory.hpp:77] Creating layer conv3_2a_relu
I0413 18:38:59.519352 30343 net.cpp:91] Creating Layer conv3_2a_relu
I0413 18:38:59.519357 30343 net.cpp:425] conv3_2a_relu <- conv3_2a
I0413 18:38:59.519366 30343 net.cpp:386] conv3_2a_relu -> conv3_2a (in-place)
I0413 18:38:59.519816 30343 net.cpp:141] Setting up conv3_2a_relu
I0413 18:38:59.519832 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.519837 30343 net.cpp:156] Memory required for data: 315802800
I0413 18:38:59.519843 30343 layer_factory.hpp:77] Creating layer conv3_2b
I0413 18:38:59.519857 30343 net.cpp:91] Creating Layer conv3_2b
I0413 18:38:59.519863 30343 net.cpp:425] conv3_2b <- conv3_2a
I0413 18:38:59.519875 30343 net.cpp:399] conv3_2b -> conv3_2b
I0413 18:38:59.523403 30343 net.cpp:141] Setting up conv3_2b
I0413 18:38:59.523423 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.523428 30343 net.cpp:156] Memory required for data: 319079600
I0413 18:38:59.523437 30343 layer_factory.hpp:77] Creating layer bn_conv3_2b
I0413 18:38:59.523447 30343 net.cpp:91] Creating Layer bn_conv3_2b
I0413 18:38:59.523452 30343 net.cpp:425] bn_conv3_2b <- conv3_2b
I0413 18:38:59.523463 30343 net.cpp:386] bn_conv3_2b -> conv3_2b (in-place)
I0413 18:38:59.523717 30343 net.cpp:141] Setting up bn_conv3_2b
I0413 18:38:59.523727 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.523732 30343 net.cpp:156] Memory required for data: 322356400
I0413 18:38:59.523741 30343 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:38:59.523749 30343 net.cpp:91] Creating Layer scale_conv3_2b
I0413 18:38:59.523759 30343 net.cpp:425] scale_conv3_2b <- conv3_2b
I0413 18:38:59.523767 30343 net.cpp:386] scale_conv3_2b -> conv3_2b (in-place)
I0413 18:38:59.523825 30343 layer_factory.hpp:77] Creating layer scale_conv3_2b
I0413 18:38:59.523974 30343 net.cpp:141] Setting up scale_conv3_2b
I0413 18:38:59.523984 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.523988 30343 net.cpp:156] Memory required for data: 325633200
I0413 18:38:59.523998 30343 layer_factory.hpp:77] Creating layer conv3_2
I0413 18:38:59.524006 30343 net.cpp:91] Creating Layer conv3_2
I0413 18:38:59.524011 30343 net.cpp:425] conv3_2 <- conv3_2b
I0413 18:38:59.524018 30343 net.cpp:425] conv3_2 <- conv3_1_conv3_1_relu_0_split_1
I0413 18:38:59.524025 30343 net.cpp:399] conv3_2 -> conv3_2
I0413 18:38:59.524052 30343 net.cpp:141] Setting up conv3_2
I0413 18:38:59.524060 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.524065 30343 net.cpp:156] Memory required for data: 328910000
I0413 18:38:59.524070 30343 layer_factory.hpp:77] Creating layer conv3_2_relu
I0413 18:38:59.524080 30343 net.cpp:91] Creating Layer conv3_2_relu
I0413 18:38:59.524085 30343 net.cpp:425] conv3_2_relu <- conv3_2
I0413 18:38:59.524091 30343 net.cpp:386] conv3_2_relu -> conv3_2 (in-place)
I0413 18:38:59.524433 30343 net.cpp:141] Setting up conv3_2_relu
I0413 18:38:59.524449 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.524454 30343 net.cpp:156] Memory required for data: 332186800
I0413 18:38:59.524461 30343 layer_factory.hpp:77] Creating layer conv3_2_conv3_2_relu_0_split
I0413 18:38:59.524468 30343 net.cpp:91] Creating Layer conv3_2_conv3_2_relu_0_split
I0413 18:38:59.524473 30343 net.cpp:425] conv3_2_conv3_2_relu_0_split <- conv3_2
I0413 18:38:59.524483 30343 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_0
I0413 18:38:59.524493 30343 net.cpp:399] conv3_2_conv3_2_relu_0_split -> conv3_2_conv3_2_relu_0_split_1
I0413 18:38:59.524554 30343 net.cpp:141] Setting up conv3_2_conv3_2_relu_0_split
I0413 18:38:59.524562 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.524569 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.524574 30343 net.cpp:156] Memory required for data: 338740400
I0413 18:38:59.524579 30343 layer_factory.hpp:77] Creating layer conv3_3a
I0413 18:38:59.524591 30343 net.cpp:91] Creating Layer conv3_3a
I0413 18:38:59.524597 30343 net.cpp:425] conv3_3a <- conv3_2_conv3_2_relu_0_split_0
I0413 18:38:59.524607 30343 net.cpp:399] conv3_3a -> conv3_3a
I0413 18:38:59.527983 30343 net.cpp:141] Setting up conv3_3a
I0413 18:38:59.528002 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.528007 30343 net.cpp:156] Memory required for data: 342017200
I0413 18:38:59.528017 30343 layer_factory.hpp:77] Creating layer bn_conv3_3a
I0413 18:38:59.528028 30343 net.cpp:91] Creating Layer bn_conv3_3a
I0413 18:38:59.528034 30343 net.cpp:425] bn_conv3_3a <- conv3_3a
I0413 18:38:59.528043 30343 net.cpp:386] bn_conv3_3a -> conv3_3a (in-place)
I0413 18:38:59.528293 30343 net.cpp:141] Setting up bn_conv3_3a
I0413 18:38:59.528302 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.528307 30343 net.cpp:156] Memory required for data: 345294000
I0413 18:38:59.528317 30343 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:38:59.528327 30343 net.cpp:91] Creating Layer scale_conv3_3a
I0413 18:38:59.528332 30343 net.cpp:425] scale_conv3_3a <- conv3_3a
I0413 18:38:59.528339 30343 net.cpp:386] scale_conv3_3a -> conv3_3a (in-place)
I0413 18:38:59.528398 30343 layer_factory.hpp:77] Creating layer scale_conv3_3a
I0413 18:38:59.528548 30343 net.cpp:141] Setting up scale_conv3_3a
I0413 18:38:59.528558 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.528563 30343 net.cpp:156] Memory required for data: 348570800
I0413 18:38:59.528570 30343 layer_factory.hpp:77] Creating layer conv3_3a_relu
I0413 18:38:59.528584 30343 net.cpp:91] Creating Layer conv3_3a_relu
I0413 18:38:59.528589 30343 net.cpp:425] conv3_3a_relu <- conv3_3a
I0413 18:38:59.528595 30343 net.cpp:386] conv3_3a_relu -> conv3_3a (in-place)
I0413 18:38:59.528983 30343 net.cpp:141] Setting up conv3_3a_relu
I0413 18:38:59.528996 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.529002 30343 net.cpp:156] Memory required for data: 351847600
I0413 18:38:59.529007 30343 layer_factory.hpp:77] Creating layer conv3_3b
I0413 18:38:59.529027 30343 net.cpp:91] Creating Layer conv3_3b
I0413 18:38:59.529034 30343 net.cpp:425] conv3_3b <- conv3_3a
I0413 18:38:59.529042 30343 net.cpp:399] conv3_3b -> conv3_3b
I0413 18:38:59.530618 30343 net.cpp:141] Setting up conv3_3b
I0413 18:38:59.530637 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.530642 30343 net.cpp:156] Memory required for data: 355124400
I0413 18:38:59.530652 30343 layer_factory.hpp:77] Creating layer bn_conv3_3b
I0413 18:38:59.530663 30343 net.cpp:91] Creating Layer bn_conv3_3b
I0413 18:38:59.530669 30343 net.cpp:425] bn_conv3_3b <- conv3_3b
I0413 18:38:59.530676 30343 net.cpp:386] bn_conv3_3b -> conv3_3b (in-place)
I0413 18:38:59.530930 30343 net.cpp:141] Setting up bn_conv3_3b
I0413 18:38:59.530938 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.530943 30343 net.cpp:156] Memory required for data: 358401200
I0413 18:38:59.530953 30343 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:38:59.530963 30343 net.cpp:91] Creating Layer scale_conv3_3b
I0413 18:38:59.530968 30343 net.cpp:425] scale_conv3_3b <- conv3_3b
I0413 18:38:59.530975 30343 net.cpp:386] scale_conv3_3b -> conv3_3b (in-place)
I0413 18:38:59.531030 30343 layer_factory.hpp:77] Creating layer scale_conv3_3b
I0413 18:38:59.531185 30343 net.cpp:141] Setting up scale_conv3_3b
I0413 18:38:59.531194 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.531199 30343 net.cpp:156] Memory required for data: 361678000
I0413 18:38:59.531208 30343 layer_factory.hpp:77] Creating layer conv3_3
I0413 18:38:59.531216 30343 net.cpp:91] Creating Layer conv3_3
I0413 18:38:59.531221 30343 net.cpp:425] conv3_3 <- conv3_3b
I0413 18:38:59.531227 30343 net.cpp:425] conv3_3 <- conv3_2_conv3_2_relu_0_split_1
I0413 18:38:59.531236 30343 net.cpp:399] conv3_3 -> conv3_3
I0413 18:38:59.531263 30343 net.cpp:141] Setting up conv3_3
I0413 18:38:59.531272 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.531277 30343 net.cpp:156] Memory required for data: 364954800
I0413 18:38:59.531282 30343 layer_factory.hpp:77] Creating layer conv3_3_relu
I0413 18:38:59.531289 30343 net.cpp:91] Creating Layer conv3_3_relu
I0413 18:38:59.531294 30343 net.cpp:425] conv3_3_relu <- conv3_3
I0413 18:38:59.531302 30343 net.cpp:386] conv3_3_relu -> conv3_3 (in-place)
I0413 18:38:59.531646 30343 net.cpp:141] Setting up conv3_3_relu
I0413 18:38:59.531661 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.531666 30343 net.cpp:156] Memory required for data: 368231600
I0413 18:38:59.531671 30343 layer_factory.hpp:77] Creating layer conv3_3_conv3_3_relu_0_split
I0413 18:38:59.531678 30343 net.cpp:91] Creating Layer conv3_3_conv3_3_relu_0_split
I0413 18:38:59.531683 30343 net.cpp:425] conv3_3_conv3_3_relu_0_split <- conv3_3
I0413 18:38:59.531693 30343 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_0
I0413 18:38:59.531703 30343 net.cpp:399] conv3_3_conv3_3_relu_0_split -> conv3_3_conv3_3_relu_0_split_1
I0413 18:38:59.531762 30343 net.cpp:141] Setting up conv3_3_conv3_3_relu_0_split
I0413 18:38:59.531771 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.531777 30343 net.cpp:148] Top shape: 100 32 16 16 (819200)
I0413 18:38:59.531782 30343 net.cpp:156] Memory required for data: 374785200
I0413 18:38:59.531787 30343 layer_factory.hpp:77] Creating layer conv3_sub
I0413 18:38:59.531800 30343 net.cpp:91] Creating Layer conv3_sub
I0413 18:38:59.531805 30343 net.cpp:425] conv3_sub <- conv3_3_conv3_3_relu_0_split_0
I0413 18:38:59.531813 30343 net.cpp:399] conv3_sub -> conv3_sub
I0413 18:38:59.535003 30343 net.cpp:141] Setting up conv3_sub
I0413 18:38:59.535022 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.535032 30343 net.cpp:156] Memory required for data: 376423600
I0413 18:38:59.535042 30343 layer_factory.hpp:77] Creating layer bn_conv3_sub
I0413 18:38:59.535053 30343 net.cpp:91] Creating Layer bn_conv3_sub
I0413 18:38:59.535058 30343 net.cpp:425] bn_conv3_sub <- conv3_sub
I0413 18:38:59.535066 30343 net.cpp:386] bn_conv3_sub -> conv3_sub (in-place)
I0413 18:38:59.535332 30343 net.cpp:141] Setting up bn_conv3_sub
I0413 18:38:59.535342 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.535347 30343 net.cpp:156] Memory required for data: 378062000
I0413 18:38:59.535357 30343 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:38:59.535365 30343 net.cpp:91] Creating Layer scale_conv3_sub
I0413 18:38:59.535372 30343 net.cpp:425] scale_conv3_sub <- conv3_sub
I0413 18:38:59.535378 30343 net.cpp:386] scale_conv3_sub -> conv3_sub (in-place)
I0413 18:38:59.535437 30343 layer_factory.hpp:77] Creating layer scale_conv3_sub
I0413 18:38:59.535589 30343 net.cpp:141] Setting up scale_conv3_sub
I0413 18:38:59.535599 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.535604 30343 net.cpp:156] Memory required for data: 379700400
I0413 18:38:59.535612 30343 layer_factory.hpp:77] Creating layer conv4_1a
I0413 18:38:59.535626 30343 net.cpp:91] Creating Layer conv4_1a
I0413 18:38:59.535631 30343 net.cpp:425] conv4_1a <- conv3_3_conv3_3_relu_0_split_1
I0413 18:38:59.535640 30343 net.cpp:399] conv4_1a -> conv4_1a
I0413 18:38:59.538470 30343 net.cpp:141] Setting up conv4_1a
I0413 18:38:59.538488 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.538494 30343 net.cpp:156] Memory required for data: 381338800
I0413 18:38:59.538503 30343 layer_factory.hpp:77] Creating layer bn_conv4_1a
I0413 18:38:59.538514 30343 net.cpp:91] Creating Layer bn_conv4_1a
I0413 18:38:59.538521 30343 net.cpp:425] bn_conv4_1a <- conv4_1a
I0413 18:38:59.538527 30343 net.cpp:386] bn_conv4_1a -> conv4_1a (in-place)
I0413 18:38:59.538795 30343 net.cpp:141] Setting up bn_conv4_1a
I0413 18:38:59.538805 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.538810 30343 net.cpp:156] Memory required for data: 382977200
I0413 18:38:59.538820 30343 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:38:59.538827 30343 net.cpp:91] Creating Layer scale_conv4_1a
I0413 18:38:59.538832 30343 net.cpp:425] scale_conv4_1a <- conv4_1a
I0413 18:38:59.538839 30343 net.cpp:386] scale_conv4_1a -> conv4_1a (in-place)
I0413 18:38:59.538897 30343 layer_factory.hpp:77] Creating layer scale_conv4_1a
I0413 18:38:59.539052 30343 net.cpp:141] Setting up scale_conv4_1a
I0413 18:38:59.539062 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.539067 30343 net.cpp:156] Memory required for data: 384615600
I0413 18:38:59.539075 30343 layer_factory.hpp:77] Creating layer conv4_1a_relu
I0413 18:38:59.539083 30343 net.cpp:91] Creating Layer conv4_1a_relu
I0413 18:38:59.539088 30343 net.cpp:425] conv4_1a_relu <- conv4_1a
I0413 18:38:59.539094 30343 net.cpp:386] conv4_1a_relu -> conv4_1a (in-place)
I0413 18:38:59.539466 30343 net.cpp:141] Setting up conv4_1a_relu
I0413 18:38:59.539482 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.539487 30343 net.cpp:156] Memory required for data: 386254000
I0413 18:38:59.539494 30343 layer_factory.hpp:77] Creating layer conv4_1b
I0413 18:38:59.539507 30343 net.cpp:91] Creating Layer conv4_1b
I0413 18:38:59.539513 30343 net.cpp:425] conv4_1b <- conv4_1a
I0413 18:38:59.539523 30343 net.cpp:399] conv4_1b -> conv4_1b
I0413 18:38:59.543006 30343 net.cpp:141] Setting up conv4_1b
I0413 18:38:59.543025 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.543030 30343 net.cpp:156] Memory required for data: 387892400
I0413 18:38:59.543038 30343 layer_factory.hpp:77] Creating layer bn_conv4_1b
I0413 18:38:59.543047 30343 net.cpp:91] Creating Layer bn_conv4_1b
I0413 18:38:59.543053 30343 net.cpp:425] bn_conv4_1b <- conv4_1b
I0413 18:38:59.543063 30343 net.cpp:386] bn_conv4_1b -> conv4_1b (in-place)
I0413 18:38:59.543328 30343 net.cpp:141] Setting up bn_conv4_1b
I0413 18:38:59.543345 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.543350 30343 net.cpp:156] Memory required for data: 389530800
I0413 18:38:59.543360 30343 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:38:59.543368 30343 net.cpp:91] Creating Layer scale_conv4_1b
I0413 18:38:59.543375 30343 net.cpp:425] scale_conv4_1b <- conv4_1b
I0413 18:38:59.543383 30343 net.cpp:386] scale_conv4_1b -> conv4_1b (in-place)
I0413 18:38:59.543438 30343 layer_factory.hpp:77] Creating layer scale_conv4_1b
I0413 18:38:59.543593 30343 net.cpp:141] Setting up scale_conv4_1b
I0413 18:38:59.543602 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.543607 30343 net.cpp:156] Memory required for data: 391169200
I0413 18:38:59.543615 30343 layer_factory.hpp:77] Creating layer conv4_1
I0413 18:38:59.543624 30343 net.cpp:91] Creating Layer conv4_1
I0413 18:38:59.543629 30343 net.cpp:425] conv4_1 <- conv3_sub
I0413 18:38:59.543637 30343 net.cpp:425] conv4_1 <- conv4_1b
I0413 18:38:59.543643 30343 net.cpp:399] conv4_1 -> conv4_1
I0413 18:38:59.543678 30343 net.cpp:141] Setting up conv4_1
I0413 18:38:59.543687 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.543692 30343 net.cpp:156] Memory required for data: 392807600
I0413 18:38:59.543697 30343 layer_factory.hpp:77] Creating layer conv4_1_relu
I0413 18:38:59.543704 30343 net.cpp:91] Creating Layer conv4_1_relu
I0413 18:38:59.543709 30343 net.cpp:425] conv4_1_relu <- conv4_1
I0413 18:38:59.543717 30343 net.cpp:386] conv4_1_relu -> conv4_1 (in-place)
I0413 18:38:59.544086 30343 net.cpp:141] Setting up conv4_1_relu
I0413 18:38:59.544101 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.544106 30343 net.cpp:156] Memory required for data: 394446000
I0413 18:38:59.544112 30343 layer_factory.hpp:77] Creating layer conv4_1_conv4_1_relu_0_split
I0413 18:38:59.544121 30343 net.cpp:91] Creating Layer conv4_1_conv4_1_relu_0_split
I0413 18:38:59.544126 30343 net.cpp:425] conv4_1_conv4_1_relu_0_split <- conv4_1
I0413 18:38:59.544136 30343 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_0
I0413 18:38:59.544145 30343 net.cpp:399] conv4_1_conv4_1_relu_0_split -> conv4_1_conv4_1_relu_0_split_1
I0413 18:38:59.544203 30343 net.cpp:141] Setting up conv4_1_conv4_1_relu_0_split
I0413 18:38:59.544211 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.544216 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.544221 30343 net.cpp:156] Memory required for data: 397722800
I0413 18:38:59.544226 30343 layer_factory.hpp:77] Creating layer conv4_2a
I0413 18:38:59.544241 30343 net.cpp:91] Creating Layer conv4_2a
I0413 18:38:59.544247 30343 net.cpp:425] conv4_2a <- conv4_1_conv4_1_relu_0_split_0
I0413 18:38:59.544255 30343 net.cpp:399] conv4_2a -> conv4_2a
I0413 18:38:59.546809 30343 net.cpp:141] Setting up conv4_2a
I0413 18:38:59.546829 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.546835 30343 net.cpp:156] Memory required for data: 399361200
I0413 18:38:59.546844 30343 layer_factory.hpp:77] Creating layer bn_conv4_2a
I0413 18:38:59.546854 30343 net.cpp:91] Creating Layer bn_conv4_2a
I0413 18:38:59.546859 30343 net.cpp:425] bn_conv4_2a <- conv4_2a
I0413 18:38:59.546869 30343 net.cpp:386] bn_conv4_2a -> conv4_2a (in-place)
I0413 18:38:59.547137 30343 net.cpp:141] Setting up bn_conv4_2a
I0413 18:38:59.547147 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.547152 30343 net.cpp:156] Memory required for data: 400999600
I0413 18:38:59.547160 30343 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:38:59.547169 30343 net.cpp:91] Creating Layer scale_conv4_2a
I0413 18:38:59.547174 30343 net.cpp:425] scale_conv4_2a <- conv4_2a
I0413 18:38:59.547183 30343 net.cpp:386] scale_conv4_2a -> conv4_2a (in-place)
I0413 18:38:59.547238 30343 layer_factory.hpp:77] Creating layer scale_conv4_2a
I0413 18:38:59.547392 30343 net.cpp:141] Setting up scale_conv4_2a
I0413 18:38:59.547402 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.547406 30343 net.cpp:156] Memory required for data: 402638000
I0413 18:38:59.547420 30343 layer_factory.hpp:77] Creating layer conv4_2a_relu
I0413 18:38:59.547427 30343 net.cpp:91] Creating Layer conv4_2a_relu
I0413 18:38:59.547432 30343 net.cpp:425] conv4_2a_relu <- conv4_2a
I0413 18:38:59.547441 30343 net.cpp:386] conv4_2a_relu -> conv4_2a (in-place)
I0413 18:38:59.547654 30343 net.cpp:141] Setting up conv4_2a_relu
I0413 18:38:59.547667 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.547672 30343 net.cpp:156] Memory required for data: 404276400
I0413 18:38:59.547677 30343 layer_factory.hpp:77] Creating layer conv4_2b
I0413 18:38:59.547693 30343 net.cpp:91] Creating Layer conv4_2b
I0413 18:38:59.547700 30343 net.cpp:425] conv4_2b <- conv4_2a
I0413 18:38:59.547708 30343 net.cpp:399] conv4_2b -> conv4_2b
I0413 18:38:59.552268 30343 net.cpp:141] Setting up conv4_2b
I0413 18:38:59.552287 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.552294 30343 net.cpp:156] Memory required for data: 405914800
I0413 18:38:59.552302 30343 layer_factory.hpp:77] Creating layer bn_conv4_2b
I0413 18:38:59.552311 30343 net.cpp:91] Creating Layer bn_conv4_2b
I0413 18:38:59.552317 30343 net.cpp:425] bn_conv4_2b <- conv4_2b
I0413 18:38:59.552326 30343 net.cpp:386] bn_conv4_2b -> conv4_2b (in-place)
I0413 18:38:59.552592 30343 net.cpp:141] Setting up bn_conv4_2b
I0413 18:38:59.552602 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.552606 30343 net.cpp:156] Memory required for data: 407553200
I0413 18:38:59.552634 30343 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:38:59.552645 30343 net.cpp:91] Creating Layer scale_conv4_2b
I0413 18:38:59.552650 30343 net.cpp:425] scale_conv4_2b <- conv4_2b
I0413 18:38:59.552657 30343 net.cpp:386] scale_conv4_2b -> conv4_2b (in-place)
I0413 18:38:59.552717 30343 layer_factory.hpp:77] Creating layer scale_conv4_2b
I0413 18:38:59.552870 30343 net.cpp:141] Setting up scale_conv4_2b
I0413 18:38:59.552880 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.552884 30343 net.cpp:156] Memory required for data: 409191600
I0413 18:38:59.552892 30343 layer_factory.hpp:77] Creating layer conv4_2
I0413 18:38:59.552901 30343 net.cpp:91] Creating Layer conv4_2
I0413 18:38:59.552906 30343 net.cpp:425] conv4_2 <- conv4_1_conv4_1_relu_0_split_1
I0413 18:38:59.552911 30343 net.cpp:425] conv4_2 <- conv4_2b
I0413 18:38:59.552918 30343 net.cpp:399] conv4_2 -> conv4_2
I0413 18:38:59.552956 30343 net.cpp:141] Setting up conv4_2
I0413 18:38:59.552966 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.552971 30343 net.cpp:156] Memory required for data: 410830000
I0413 18:38:59.552976 30343 layer_factory.hpp:77] Creating layer conv4_2_relu
I0413 18:38:59.552984 30343 net.cpp:91] Creating Layer conv4_2_relu
I0413 18:38:59.552990 30343 net.cpp:425] conv4_2_relu <- conv4_2
I0413 18:38:59.552997 30343 net.cpp:386] conv4_2_relu -> conv4_2 (in-place)
I0413 18:38:59.553356 30343 net.cpp:141] Setting up conv4_2_relu
I0413 18:38:59.553374 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.553380 30343 net.cpp:156] Memory required for data: 412468400
I0413 18:38:59.553385 30343 layer_factory.hpp:77] Creating layer conv4_2_conv4_2_relu_0_split
I0413 18:38:59.553395 30343 net.cpp:91] Creating Layer conv4_2_conv4_2_relu_0_split
I0413 18:38:59.553400 30343 net.cpp:425] conv4_2_conv4_2_relu_0_split <- conv4_2
I0413 18:38:59.553407 30343 net.cpp:399] conv4_2_conv4_2_relu_0_split -> conv4_2_conv4_2_relu_0_split_0
I0413 18:38:59.553417 30343 net.cpp:399] conv4_2_conv4_2_relu_0_split -> conv4_2_conv4_2_relu_0_split_1
I0413 18:38:59.553483 30343 net.cpp:141] Setting up conv4_2_conv4_2_relu_0_split
I0413 18:38:59.553493 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.553498 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.553503 30343 net.cpp:156] Memory required for data: 415745200
I0413 18:38:59.553508 30343 layer_factory.hpp:77] Creating layer conv4_3a
I0413 18:38:59.553521 30343 net.cpp:91] Creating Layer conv4_3a
I0413 18:38:59.553527 30343 net.cpp:425] conv4_3a <- conv4_2_conv4_2_relu_0_split_0
I0413 18:38:59.553542 30343 net.cpp:399] conv4_3a -> conv4_3a
I0413 18:38:59.556857 30343 net.cpp:141] Setting up conv4_3a
I0413 18:38:59.556875 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.556881 30343 net.cpp:156] Memory required for data: 417383600
I0413 18:38:59.556890 30343 layer_factory.hpp:77] Creating layer bn_conv4_3a
I0413 18:38:59.556901 30343 net.cpp:91] Creating Layer bn_conv4_3a
I0413 18:38:59.556907 30343 net.cpp:425] bn_conv4_3a <- conv4_3a
I0413 18:38:59.556915 30343 net.cpp:386] bn_conv4_3a -> conv4_3a (in-place)
I0413 18:38:59.557199 30343 net.cpp:141] Setting up bn_conv4_3a
I0413 18:38:59.557211 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.557216 30343 net.cpp:156] Memory required for data: 419022000
I0413 18:38:59.557226 30343 layer_factory.hpp:77] Creating layer scale_conv4_3a
I0413 18:38:59.557236 30343 net.cpp:91] Creating Layer scale_conv4_3a
I0413 18:38:59.557241 30343 net.cpp:425] scale_conv4_3a <- conv4_3a
I0413 18:38:59.557248 30343 net.cpp:386] scale_conv4_3a -> conv4_3a (in-place)
I0413 18:38:59.557307 30343 layer_factory.hpp:77] Creating layer scale_conv4_3a
I0413 18:38:59.557464 30343 net.cpp:141] Setting up scale_conv4_3a
I0413 18:38:59.557474 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.557479 30343 net.cpp:156] Memory required for data: 420660400
I0413 18:38:59.557487 30343 layer_factory.hpp:77] Creating layer conv4_3a_relu
I0413 18:38:59.557502 30343 net.cpp:91] Creating Layer conv4_3a_relu
I0413 18:38:59.557507 30343 net.cpp:425] conv4_3a_relu <- conv4_3a
I0413 18:38:59.557514 30343 net.cpp:386] conv4_3a_relu -> conv4_3a (in-place)
I0413 18:38:59.557858 30343 net.cpp:141] Setting up conv4_3a_relu
I0413 18:38:59.557874 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.557879 30343 net.cpp:156] Memory required for data: 422298800
I0413 18:38:59.557885 30343 layer_factory.hpp:77] Creating layer conv4_3b
I0413 18:38:59.557901 30343 net.cpp:91] Creating Layer conv4_3b
I0413 18:38:59.557909 30343 net.cpp:425] conv4_3b <- conv4_3a
I0413 18:38:59.557917 30343 net.cpp:399] conv4_3b -> conv4_3b
I0413 18:38:59.561403 30343 net.cpp:141] Setting up conv4_3b
I0413 18:38:59.561422 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.561427 30343 net.cpp:156] Memory required for data: 423937200
I0413 18:38:59.561437 30343 layer_factory.hpp:77] Creating layer bn_conv4_3b
I0413 18:38:59.561446 30343 net.cpp:91] Creating Layer bn_conv4_3b
I0413 18:38:59.561452 30343 net.cpp:425] bn_conv4_3b <- conv4_3b
I0413 18:38:59.561461 30343 net.cpp:386] bn_conv4_3b -> conv4_3b (in-place)
I0413 18:38:59.561733 30343 net.cpp:141] Setting up bn_conv4_3b
I0413 18:38:59.561743 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.561748 30343 net.cpp:156] Memory required for data: 425575600
I0413 18:38:59.561756 30343 layer_factory.hpp:77] Creating layer scale_conv4_3b
I0413 18:38:59.561764 30343 net.cpp:91] Creating Layer scale_conv4_3b
I0413 18:38:59.561770 30343 net.cpp:425] scale_conv4_3b <- conv4_3b
I0413 18:38:59.561779 30343 net.cpp:386] scale_conv4_3b -> conv4_3b (in-place)
I0413 18:38:59.561835 30343 layer_factory.hpp:77] Creating layer scale_conv4_3b
I0413 18:38:59.561995 30343 net.cpp:141] Setting up scale_conv4_3b
I0413 18:38:59.562005 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.562010 30343 net.cpp:156] Memory required for data: 427214000
I0413 18:38:59.562017 30343 layer_factory.hpp:77] Creating layer conv4_3
I0413 18:38:59.562024 30343 net.cpp:91] Creating Layer conv4_3
I0413 18:38:59.562031 30343 net.cpp:425] conv4_3 <- conv4_2_conv4_2_relu_0_split_1
I0413 18:38:59.562036 30343 net.cpp:425] conv4_3 <- conv4_3b
I0413 18:38:59.562046 30343 net.cpp:399] conv4_3 -> conv4_3
I0413 18:38:59.562083 30343 net.cpp:141] Setting up conv4_3
I0413 18:38:59.562091 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.562096 30343 net.cpp:156] Memory required for data: 428852400
I0413 18:38:59.562101 30343 layer_factory.hpp:77] Creating layer conv4_3_relu
I0413 18:38:59.562114 30343 net.cpp:91] Creating Layer conv4_3_relu
I0413 18:38:59.562119 30343 net.cpp:425] conv4_3_relu <- conv4_3
I0413 18:38:59.562125 30343 net.cpp:386] conv4_3_relu -> conv4_3 (in-place)
I0413 18:38:59.562340 30343 net.cpp:141] Setting up conv4_3_relu
I0413 18:38:59.562352 30343 net.cpp:148] Top shape: 100 64 8 8 (409600)
I0413 18:38:59.562357 30343 net.cpp:156] Memory required for data: 430490800
I0413 18:38:59.562362 30343 layer_factory.hpp:77] Creating layer global_pool
I0413 18:38:59.562373 30343 net.cpp:91] Creating Layer global_pool
I0413 18:38:59.562378 30343 net.cpp:425] global_pool <- conv4_3
I0413 18:38:59.562386 30343 net.cpp:399] global_pool -> global_pool
I0413 18:38:59.562754 30343 net.cpp:141] Setting up global_pool
I0413 18:38:59.562770 30343 net.cpp:148] Top shape: 100 64 1 1 (6400)
I0413 18:38:59.562775 30343 net.cpp:156] Memory required for data: 430516400
I0413 18:38:59.562780 30343 layer_factory.hpp:77] Creating layer ip
I0413 18:38:59.562793 30343 net.cpp:91] Creating Layer ip
I0413 18:38:59.562798 30343 net.cpp:425] ip <- global_pool
I0413 18:38:59.562805 30343 net.cpp:399] ip -> ip
I0413 18:38:59.562968 30343 net.cpp:141] Setting up ip
I0413 18:38:59.562979 30343 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:38:59.562984 30343 net.cpp:156] Memory required for data: 430520400
I0413 18:38:59.562993 30343 layer_factory.hpp:77] Creating layer ip_ip_0_split
I0413 18:38:59.563001 30343 net.cpp:91] Creating Layer ip_ip_0_split
I0413 18:38:59.563006 30343 net.cpp:425] ip_ip_0_split <- ip
I0413 18:38:59.563014 30343 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_0
I0413 18:38:59.563022 30343 net.cpp:399] ip_ip_0_split -> ip_ip_0_split_1
I0413 18:38:59.563077 30343 net.cpp:141] Setting up ip_ip_0_split
I0413 18:38:59.563086 30343 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:38:59.563091 30343 net.cpp:148] Top shape: 100 10 (1000)
I0413 18:38:59.563097 30343 net.cpp:156] Memory required for data: 430528400
I0413 18:38:59.563102 30343 layer_factory.hpp:77] Creating layer accuracy
I0413 18:38:59.563109 30343 net.cpp:91] Creating Layer accuracy
I0413 18:38:59.563114 30343 net.cpp:425] accuracy <- ip_ip_0_split_0
I0413 18:38:59.563120 30343 net.cpp:425] accuracy <- label_cifar_1_split_0
I0413 18:38:59.563128 30343 net.cpp:399] accuracy -> accuracy
I0413 18:38:59.563139 30343 net.cpp:141] Setting up accuracy
I0413 18:38:59.563146 30343 net.cpp:148] Top shape: (1)
I0413 18:38:59.563150 30343 net.cpp:156] Memory required for data: 430528404
I0413 18:38:59.563155 30343 layer_factory.hpp:77] Creating layer loss
I0413 18:38:59.563164 30343 net.cpp:91] Creating Layer loss
I0413 18:38:59.563170 30343 net.cpp:425] loss <- ip_ip_0_split_1
I0413 18:38:59.563176 30343 net.cpp:425] loss <- label_cifar_1_split_1
I0413 18:38:59.563184 30343 net.cpp:399] loss -> loss
I0413 18:38:59.563196 30343 layer_factory.hpp:77] Creating layer loss
I0413 18:38:59.563935 30343 net.cpp:141] Setting up loss
I0413 18:38:59.563948 30343 net.cpp:148] Top shape: (1)
I0413 18:38:59.563953 30343 net.cpp:151]     with loss weight 1
I0413 18:38:59.563964 30343 net.cpp:156] Memory required for data: 430528408
I0413 18:38:59.563969 30343 net.cpp:217] loss needs backward computation.
I0413 18:38:59.563976 30343 net.cpp:219] accuracy does not need backward computation.
I0413 18:38:59.563982 30343 net.cpp:217] ip_ip_0_split needs backward computation.
I0413 18:38:59.563987 30343 net.cpp:217] ip needs backward computation.
I0413 18:38:59.563992 30343 net.cpp:217] global_pool needs backward computation.
I0413 18:38:59.563995 30343 net.cpp:217] conv4_3_relu needs backward computation.
I0413 18:38:59.564000 30343 net.cpp:217] conv4_3 needs backward computation.
I0413 18:38:59.564005 30343 net.cpp:217] scale_conv4_3b needs backward computation.
I0413 18:38:59.564010 30343 net.cpp:217] bn_conv4_3b needs backward computation.
I0413 18:38:59.564015 30343 net.cpp:217] conv4_3b needs backward computation.
I0413 18:38:59.564020 30343 net.cpp:217] conv4_3a_relu needs backward computation.
I0413 18:38:59.564025 30343 net.cpp:217] scale_conv4_3a needs backward computation.
I0413 18:38:59.564034 30343 net.cpp:217] bn_conv4_3a needs backward computation.
I0413 18:38:59.564039 30343 net.cpp:217] conv4_3a needs backward computation.
I0413 18:38:59.564044 30343 net.cpp:217] conv4_2_conv4_2_relu_0_split needs backward computation.
I0413 18:38:59.564049 30343 net.cpp:217] conv4_2_relu needs backward computation.
I0413 18:38:59.564054 30343 net.cpp:217] conv4_2 needs backward computation.
I0413 18:38:59.564059 30343 net.cpp:217] scale_conv4_2b needs backward computation.
I0413 18:38:59.564064 30343 net.cpp:217] bn_conv4_2b needs backward computation.
I0413 18:38:59.564069 30343 net.cpp:217] conv4_2b needs backward computation.
I0413 18:38:59.564074 30343 net.cpp:217] conv4_2a_relu needs backward computation.
I0413 18:38:59.564079 30343 net.cpp:217] scale_conv4_2a needs backward computation.
I0413 18:38:59.564082 30343 net.cpp:217] bn_conv4_2a needs backward computation.
I0413 18:38:59.564087 30343 net.cpp:217] conv4_2a needs backward computation.
I0413 18:38:59.564092 30343 net.cpp:217] conv4_1_conv4_1_relu_0_split needs backward computation.
I0413 18:38:59.564097 30343 net.cpp:217] conv4_1_relu needs backward computation.
I0413 18:38:59.564101 30343 net.cpp:217] conv4_1 needs backward computation.
I0413 18:38:59.564107 30343 net.cpp:217] scale_conv4_1b needs backward computation.
I0413 18:38:59.564112 30343 net.cpp:217] bn_conv4_1b needs backward computation.
I0413 18:38:59.564116 30343 net.cpp:217] conv4_1b needs backward computation.
I0413 18:38:59.564121 30343 net.cpp:217] conv4_1a_relu needs backward computation.
I0413 18:38:59.564126 30343 net.cpp:217] scale_conv4_1a needs backward computation.
I0413 18:38:59.564131 30343 net.cpp:217] bn_conv4_1a needs backward computation.
I0413 18:38:59.564136 30343 net.cpp:217] conv4_1a needs backward computation.
I0413 18:38:59.564141 30343 net.cpp:217] scale_conv3_sub needs backward computation.
I0413 18:38:59.564146 30343 net.cpp:217] bn_conv3_sub needs backward computation.
I0413 18:38:59.564151 30343 net.cpp:217] conv3_sub needs backward computation.
I0413 18:38:59.564155 30343 net.cpp:217] conv3_3_conv3_3_relu_0_split needs backward computation.
I0413 18:38:59.564160 30343 net.cpp:217] conv3_3_relu needs backward computation.
I0413 18:38:59.564165 30343 net.cpp:217] conv3_3 needs backward computation.
I0413 18:38:59.564170 30343 net.cpp:217] scale_conv3_3b needs backward computation.
I0413 18:38:59.564175 30343 net.cpp:217] bn_conv3_3b needs backward computation.
I0413 18:38:59.564180 30343 net.cpp:217] conv3_3b needs backward computation.
I0413 18:38:59.564185 30343 net.cpp:217] conv3_3a_relu needs backward computation.
I0413 18:38:59.564190 30343 net.cpp:217] scale_conv3_3a needs backward computation.
I0413 18:38:59.564194 30343 net.cpp:217] bn_conv3_3a needs backward computation.
I0413 18:38:59.564199 30343 net.cpp:217] conv3_3a needs backward computation.
I0413 18:38:59.564204 30343 net.cpp:217] conv3_2_conv3_2_relu_0_split needs backward computation.
I0413 18:38:59.564209 30343 net.cpp:217] conv3_2_relu needs backward computation.
I0413 18:38:59.564214 30343 net.cpp:217] conv3_2 needs backward computation.
I0413 18:38:59.564220 30343 net.cpp:217] scale_conv3_2b needs backward computation.
I0413 18:38:59.564225 30343 net.cpp:217] bn_conv3_2b needs backward computation.
I0413 18:38:59.564230 30343 net.cpp:217] conv3_2b needs backward computation.
I0413 18:38:59.564235 30343 net.cpp:217] conv3_2a_relu needs backward computation.
I0413 18:38:59.564240 30343 net.cpp:217] scale_conv3_2a needs backward computation.
I0413 18:38:59.564244 30343 net.cpp:217] bn_conv3_2a needs backward computation.
I0413 18:38:59.564249 30343 net.cpp:217] conv3_2a needs backward computation.
I0413 18:38:59.564254 30343 net.cpp:217] conv3_1_conv3_1_relu_0_split needs backward computation.
I0413 18:38:59.564260 30343 net.cpp:217] conv3_1_relu needs backward computation.
I0413 18:38:59.564265 30343 net.cpp:217] conv3_1 needs backward computation.
I0413 18:38:59.564270 30343 net.cpp:217] scale_conv3_1b needs backward computation.
I0413 18:38:59.564277 30343 net.cpp:217] bn_conv3_1b needs backward computation.
I0413 18:38:59.564282 30343 net.cpp:217] conv3_1b needs backward computation.
I0413 18:38:59.564288 30343 net.cpp:217] conv3_1a_relu needs backward computation.
I0413 18:38:59.564292 30343 net.cpp:217] scale_conv3_1a needs backward computation.
I0413 18:38:59.564297 30343 net.cpp:217] bn_conv3_1a needs backward computation.
I0413 18:38:59.564302 30343 net.cpp:217] conv3_1a needs backward computation.
I0413 18:38:59.564307 30343 net.cpp:217] scale_conv2_sub needs backward computation.
I0413 18:38:59.564312 30343 net.cpp:217] bn_conv2_sub needs backward computation.
I0413 18:38:59.564317 30343 net.cpp:217] conv2_sub needs backward computation.
I0413 18:38:59.564322 30343 net.cpp:217] conv2_3_conv2_3_relu_0_split needs backward computation.
I0413 18:38:59.564329 30343 net.cpp:217] conv2_3_relu needs backward computation.
I0413 18:38:59.564335 30343 net.cpp:217] conv2_3 needs backward computation.
I0413 18:38:59.564340 30343 net.cpp:217] scale_conv2_3b needs backward computation.
I0413 18:38:59.564345 30343 net.cpp:217] bn_conv2_3b needs backward computation.
I0413 18:38:59.564350 30343 net.cpp:217] conv2_3b needs backward computation.
I0413 18:38:59.564355 30343 net.cpp:217] conv2_3a_relu needs backward computation.
I0413 18:38:59.564360 30343 net.cpp:217] scale_conv2_3a needs backward computation.
I0413 18:38:59.564365 30343 net.cpp:217] bn_conv2_3a needs backward computation.
I0413 18:38:59.564369 30343 net.cpp:217] conv2_3a needs backward computation.
I0413 18:38:59.564375 30343 net.cpp:217] conv2_2_conv2_2_relu_0_split needs backward computation.
I0413 18:38:59.564380 30343 net.cpp:217] conv2_2_relu needs backward computation.
I0413 18:38:59.564385 30343 net.cpp:217] conv2_2 needs backward computation.
I0413 18:38:59.564391 30343 net.cpp:217] scale_conv2_2b needs backward computation.
I0413 18:38:59.564395 30343 net.cpp:217] bn_conv2_2b needs backward computation.
I0413 18:38:59.564400 30343 net.cpp:217] conv2_2b needs backward computation.
I0413 18:38:59.564406 30343 net.cpp:217] conv2_2a_relu needs backward computation.
I0413 18:38:59.564410 30343 net.cpp:217] scale_conv2_2a needs backward computation.
I0413 18:38:59.564415 30343 net.cpp:217] bn_conv2_2a needs backward computation.
I0413 18:38:59.564420 30343 net.cpp:217] conv2_2a needs backward computation.
I0413 18:38:59.564425 30343 net.cpp:217] conv2_1_conv2_1_relu_0_split needs backward computation.
I0413 18:38:59.564431 30343 net.cpp:217] conv2_1_relu needs backward computation.
I0413 18:38:59.564435 30343 net.cpp:217] conv2_1 needs backward computation.
I0413 18:38:59.564441 30343 net.cpp:217] scale_conv2_1b needs backward computation.
I0413 18:38:59.564446 30343 net.cpp:217] bn_conv2_1b needs backward computation.
I0413 18:38:59.564451 30343 net.cpp:217] conv2_1b needs backward computation.
I0413 18:38:59.564456 30343 net.cpp:217] conv2_1a_relu needs backward computation.
I0413 18:38:59.564461 30343 net.cpp:217] scale_conv2_1a needs backward computation.
I0413 18:38:59.564466 30343 net.cpp:217] bn_conv2_1a needs backward computation.
I0413 18:38:59.564471 30343 net.cpp:217] conv2_1a needs backward computation.
I0413 18:38:59.564476 30343 net.cpp:217] conv1_conv1_relu_0_split needs backward computation.
I0413 18:38:59.564481 30343 net.cpp:217] conv1_relu needs backward computation.
I0413 18:38:59.564486 30343 net.cpp:217] scale_conv1 needs backward computation.
I0413 18:38:59.564491 30343 net.cpp:217] bn_conv1 needs backward computation.
I0413 18:38:59.564496 30343 net.cpp:217] conv1 needs backward computation.
I0413 18:38:59.564502 30343 net.cpp:219] label_cifar_1_split does not need backward computation.
I0413 18:38:59.564507 30343 net.cpp:219] cifar does not need backward computation.
I0413 18:38:59.564512 30343 net.cpp:261] This network produces output accuracy
I0413 18:38:59.564518 30343 net.cpp:261] This network produces output loss
I0413 18:38:59.564594 30343 net.cpp:274] Network initialization done.
I0413 18:38:59.565026 30343 solver.cpp:60] Solver scaffolding done.
I0413 18:39:00.092272 30343 solver.cpp:228] Iteration 0, loss = 0.37393
I0413 18:39:00.092324 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:39:00.092340 30343 solver.cpp:244]     Train net output #1: loss = 0.37393 (* 1 = 0.37393 loss)
I0413 18:39:00.092351 30343 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0413 18:39:07.708176 30343 solver.cpp:337] Iteration 20, Testing net (#0)
I0413 18:39:11.041893 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5588
I0413 18:39:11.041977 30343 solver.cpp:404]     Test net output #1: loss = 1.76237 (* 1 = 1.76237 loss)
I0413 18:39:11.348667 30343 solver.cpp:228] Iteration 20, loss = 0.379104
I0413 18:39:11.348724 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:39:11.348737 30343 solver.cpp:244]     Train net output #1: loss = 0.379104 (* 1 = 0.379104 loss)
I0413 18:39:11.348748 30343 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0413 18:39:18.932921 30343 solver.cpp:337] Iteration 40, Testing net (#0)
I0413 18:39:22.226409 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6472
I0413 18:39:22.226464 30343 solver.cpp:404]     Test net output #1: loss = 1.36725 (* 1 = 1.36725 loss)
I0413 18:39:22.515146 30343 solver.cpp:228] Iteration 40, loss = 0.439319
I0413 18:39:22.515197 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:39:22.515208 30343 solver.cpp:244]     Train net output #1: loss = 0.439319 (* 1 = 0.439319 loss)
I0413 18:39:22.515218 30343 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0413 18:39:30.055280 30343 solver.cpp:337] Iteration 60, Testing net (#0)
I0413 18:39:33.370386 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6744
I0413 18:39:33.370450 30343 solver.cpp:404]     Test net output #1: loss = 1.15856 (* 1 = 1.15856 loss)
I0413 18:39:33.672708 30343 solver.cpp:228] Iteration 60, loss = 0.379994
I0413 18:39:33.672757 30343 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:39:33.672771 30343 solver.cpp:244]     Train net output #1: loss = 0.379994 (* 1 = 0.379994 loss)
I0413 18:39:33.672786 30343 sgd_solver.cpp:106] Iteration 60, lr = 0.1
I0413 18:39:41.183683 30343 solver.cpp:337] Iteration 80, Testing net (#0)
I0413 18:39:44.519979 30343 solver.cpp:404]     Test net output #0: accuracy = 0.633
I0413 18:39:44.520040 30343 solver.cpp:404]     Test net output #1: loss = 1.49413 (* 1 = 1.49413 loss)
I0413 18:39:44.815044 30343 solver.cpp:228] Iteration 80, loss = 0.370805
I0413 18:39:44.815095 30343 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:39:44.815109 30343 solver.cpp:244]     Train net output #1: loss = 0.370805 (* 1 = 0.370805 loss)
I0413 18:39:44.815125 30343 sgd_solver.cpp:106] Iteration 80, lr = 0.1
I0413 18:39:52.312378 30343 solver.cpp:337] Iteration 100, Testing net (#0)
I0413 18:39:55.670290 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5883
I0413 18:39:55.670356 30343 solver.cpp:404]     Test net output #1: loss = 1.43605 (* 1 = 1.43605 loss)
I0413 18:39:55.967537 30343 solver.cpp:228] Iteration 100, loss = 0.383351
I0413 18:39:55.967576 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:39:55.967588 30343 solver.cpp:244]     Train net output #1: loss = 0.383351 (* 1 = 0.383351 loss)
I0413 18:39:55.967602 30343 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0413 18:40:03.463795 30343 solver.cpp:337] Iteration 120, Testing net (#0)
I0413 18:40:06.866498 30343 solver.cpp:404]     Test net output #0: accuracy = 0.72
I0413 18:40:06.866551 30343 solver.cpp:404]     Test net output #1: loss = 0.852662 (* 1 = 0.852662 loss)
I0413 18:40:07.172819 30343 solver.cpp:228] Iteration 120, loss = 0.443734
I0413 18:40:07.172865 30343 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:40:07.172878 30343 solver.cpp:244]     Train net output #1: loss = 0.443734 (* 1 = 0.443734 loss)
I0413 18:40:07.172888 30343 sgd_solver.cpp:106] Iteration 120, lr = 0.1
I0413 18:40:14.620779 30343 solver.cpp:337] Iteration 140, Testing net (#0)
I0413 18:40:18.040452 30343 solver.cpp:404]     Test net output #0: accuracy = 0.69
I0413 18:40:18.040523 30343 solver.cpp:404]     Test net output #1: loss = 0.994556 (* 1 = 0.994556 loss)
I0413 18:40:18.363749 30343 solver.cpp:228] Iteration 140, loss = 0.341719
I0413 18:40:18.363796 30343 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:40:18.363809 30343 solver.cpp:244]     Train net output #1: loss = 0.341719 (* 1 = 0.341719 loss)
I0413 18:40:18.363819 30343 sgd_solver.cpp:106] Iteration 140, lr = 0.1
I0413 18:40:25.807334 30343 solver.cpp:337] Iteration 160, Testing net (#0)
I0413 18:40:29.270699 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6148
I0413 18:40:29.270756 30343 solver.cpp:404]     Test net output #1: loss = 1.41237 (* 1 = 1.41237 loss)
I0413 18:40:29.580085 30343 solver.cpp:228] Iteration 160, loss = 0.375657
I0413 18:40:29.580130 30343 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:40:29.580142 30343 solver.cpp:244]     Train net output #1: loss = 0.375657 (* 1 = 0.375657 loss)
I0413 18:40:29.580154 30343 sgd_solver.cpp:106] Iteration 160, lr = 0.1
I0413 18:40:36.929877 30343 solver.cpp:337] Iteration 180, Testing net (#0)
I0413 18:40:40.437240 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5485
I0413 18:40:40.437296 30343 solver.cpp:404]     Test net output #1: loss = 1.58971 (* 1 = 1.58971 loss)
I0413 18:40:40.735332 30343 solver.cpp:228] Iteration 180, loss = 0.351851
I0413 18:40:40.735383 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:40:40.735394 30343 solver.cpp:244]     Train net output #1: loss = 0.351851 (* 1 = 0.351851 loss)
I0413 18:40:40.735404 30343 sgd_solver.cpp:106] Iteration 180, lr = 0.1
I0413 18:40:48.071712 30343 solver.cpp:337] Iteration 200, Testing net (#0)
I0413 18:40:51.581025 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6546
I0413 18:40:51.581085 30343 solver.cpp:404]     Test net output #1: loss = 1.23513 (* 1 = 1.23513 loss)
I0413 18:40:51.902215 30343 solver.cpp:228] Iteration 200, loss = 0.324987
I0413 18:40:51.902266 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:40:51.902281 30343 solver.cpp:244]     Train net output #1: loss = 0.324987 (* 1 = 0.324987 loss)
I0413 18:40:51.902295 30343 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0413 18:40:59.248544 30343 solver.cpp:337] Iteration 220, Testing net (#0)
I0413 18:41:02.804078 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6211
I0413 18:41:02.804129 30343 solver.cpp:404]     Test net output #1: loss = 1.42686 (* 1 = 1.42686 loss)
I0413 18:41:03.124004 30343 solver.cpp:228] Iteration 220, loss = 0.257069
I0413 18:41:03.124058 30343 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:41:03.124073 30343 solver.cpp:244]     Train net output #1: loss = 0.257069 (* 1 = 0.257069 loss)
I0413 18:41:03.124083 30343 sgd_solver.cpp:106] Iteration 220, lr = 0.1
I0413 18:41:10.499478 30343 solver.cpp:337] Iteration 240, Testing net (#0)
I0413 18:41:14.108084 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6791
I0413 18:41:14.108130 30343 solver.cpp:404]     Test net output #1: loss = 1.06489 (* 1 = 1.06489 loss)
I0413 18:41:14.414981 30343 solver.cpp:228] Iteration 240, loss = 0.402105
I0413 18:41:14.415030 30343 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:41:14.415040 30343 solver.cpp:244]     Train net output #1: loss = 0.402105 (* 1 = 0.402105 loss)
I0413 18:41:14.415050 30343 sgd_solver.cpp:106] Iteration 240, lr = 0.1
I0413 18:41:21.716275 30343 solver.cpp:337] Iteration 260, Testing net (#0)
I0413 18:41:25.302321 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7634
I0413 18:41:25.302389 30343 solver.cpp:404]     Test net output #1: loss = 0.703867 (* 1 = 0.703867 loss)
I0413 18:41:25.625315 30343 solver.cpp:228] Iteration 260, loss = 0.412374
I0413 18:41:25.625365 30343 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:41:25.625376 30343 solver.cpp:244]     Train net output #1: loss = 0.412374 (* 1 = 0.412374 loss)
I0413 18:41:25.625390 30343 sgd_solver.cpp:106] Iteration 260, lr = 0.1
I0413 18:41:32.888809 30343 solver.cpp:337] Iteration 280, Testing net (#0)
I0413 18:41:36.487324 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6968
I0413 18:41:36.487371 30343 solver.cpp:404]     Test net output #1: loss = 0.957131 (* 1 = 0.957131 loss)
I0413 18:41:36.781059 30343 solver.cpp:228] Iteration 280, loss = 0.311544
I0413 18:41:36.781102 30343 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:41:36.781132 30343 solver.cpp:244]     Train net output #1: loss = 0.311544 (* 1 = 0.311544 loss)
I0413 18:41:36.781144 30343 sgd_solver.cpp:106] Iteration 280, lr = 0.1
I0413 18:41:43.995949 30343 solver.cpp:337] Iteration 300, Testing net (#0)
I0413 18:41:47.579138 30343 solver.cpp:404]     Test net output #0: accuracy = 0.4741
I0413 18:41:47.579203 30343 solver.cpp:404]     Test net output #1: loss = 2.51489 (* 1 = 2.51489 loss)
I0413 18:41:47.891357 30343 solver.cpp:228] Iteration 300, loss = 0.439387
I0413 18:41:47.891402 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:41:47.891413 30343 solver.cpp:244]     Train net output #1: loss = 0.439387 (* 1 = 0.439387 loss)
I0413 18:41:47.891427 30343 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0413 18:41:55.215863 30343 solver.cpp:337] Iteration 320, Testing net (#0)
I0413 18:41:58.787768 30343 solver.cpp:404]     Test net output #0: accuracy = 0.725
I0413 18:41:58.787824 30343 solver.cpp:404]     Test net output #1: loss = 0.855503 (* 1 = 0.855503 loss)
I0413 18:41:59.109513 30343 solver.cpp:228] Iteration 320, loss = 0.363814
I0413 18:41:59.109558 30343 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:41:59.109570 30343 solver.cpp:244]     Train net output #1: loss = 0.363814 (* 1 = 0.363814 loss)
I0413 18:41:59.109578 30343 sgd_solver.cpp:106] Iteration 320, lr = 0.1
I0413 18:42:06.392253 30343 solver.cpp:337] Iteration 340, Testing net (#0)
I0413 18:42:10.005048 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5692
I0413 18:42:10.005177 30343 solver.cpp:404]     Test net output #1: loss = 1.61939 (* 1 = 1.61939 loss)
I0413 18:42:10.299620 30343 solver.cpp:228] Iteration 340, loss = 0.381194
I0413 18:42:10.299680 30343 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:42:10.299691 30343 solver.cpp:244]     Train net output #1: loss = 0.381194 (* 1 = 0.381194 loss)
I0413 18:42:10.299706 30343 sgd_solver.cpp:106] Iteration 340, lr = 0.1
I0413 18:42:17.558589 30343 solver.cpp:337] Iteration 360, Testing net (#0)
I0413 18:42:21.161916 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6866
I0413 18:42:21.161974 30343 solver.cpp:404]     Test net output #1: loss = 0.978031 (* 1 = 0.978031 loss)
I0413 18:42:21.457259 30343 solver.cpp:228] Iteration 360, loss = 0.23028
I0413 18:42:21.457306 30343 solver.cpp:244]     Train net output #0: accuracy = 0.917969
I0413 18:42:21.457317 30343 solver.cpp:244]     Train net output #1: loss = 0.23028 (* 1 = 0.23028 loss)
I0413 18:42:21.457327 30343 sgd_solver.cpp:106] Iteration 360, lr = 0.1
I0413 18:42:28.796727 30343 solver.cpp:337] Iteration 380, Testing net (#0)
I0413 18:42:32.409018 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6111
I0413 18:42:32.409144 30343 solver.cpp:404]     Test net output #1: loss = 1.59161 (* 1 = 1.59161 loss)
I0413 18:42:32.702916 30343 solver.cpp:228] Iteration 380, loss = 0.353965
I0413 18:42:32.702965 30343 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:42:32.702980 30343 solver.cpp:244]     Train net output #1: loss = 0.353965 (* 1 = 0.353965 loss)
I0413 18:42:32.702991 30343 sgd_solver.cpp:106] Iteration 380, lr = 0.1
I0413 18:42:40.028913 30343 solver.cpp:337] Iteration 400, Testing net (#0)
I0413 18:42:43.615876 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5407
I0413 18:42:43.615948 30343 solver.cpp:404]     Test net output #1: loss = 1.83341 (* 1 = 1.83341 loss)
I0413 18:42:43.910917 30343 solver.cpp:228] Iteration 400, loss = 0.252217
I0413 18:42:43.910960 30343 solver.cpp:244]     Train net output #0: accuracy = 0.902344
I0413 18:42:43.910984 30343 solver.cpp:244]     Train net output #1: loss = 0.252217 (* 1 = 0.252217 loss)
I0413 18:42:43.910998 30343 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0413 18:42:51.185979 30343 solver.cpp:337] Iteration 420, Testing net (#0)
I0413 18:42:54.777961 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6042
I0413 18:42:54.778023 30343 solver.cpp:404]     Test net output #1: loss = 1.42885 (* 1 = 1.42885 loss)
I0413 18:42:55.095036 30343 solver.cpp:228] Iteration 420, loss = 0.256728
I0413 18:42:55.095091 30343 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:42:55.095103 30343 solver.cpp:244]     Train net output #1: loss = 0.256728 (* 1 = 0.256728 loss)
I0413 18:42:55.095113 30343 sgd_solver.cpp:106] Iteration 420, lr = 0.1
I0413 18:43:02.377405 30343 solver.cpp:337] Iteration 440, Testing net (#0)
I0413 18:43:05.981138 30343 solver.cpp:404]     Test net output #0: accuracy = 0.596
I0413 18:43:05.981256 30343 solver.cpp:404]     Test net output #1: loss = 1.38775 (* 1 = 1.38775 loss)
I0413 18:43:06.274729 30343 solver.cpp:228] Iteration 440, loss = 0.266313
I0413 18:43:06.274778 30343 solver.cpp:244]     Train net output #0: accuracy = 0.925781
I0413 18:43:06.274791 30343 solver.cpp:244]     Train net output #1: loss = 0.266313 (* 1 = 0.266313 loss)
I0413 18:43:06.274801 30343 sgd_solver.cpp:106] Iteration 440, lr = 0.1
I0413 18:43:13.586218 30343 solver.cpp:337] Iteration 460, Testing net (#0)
I0413 18:43:17.209244 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6918
I0413 18:43:17.209302 30343 solver.cpp:404]     Test net output #1: loss = 0.986871 (* 1 = 0.986871 loss)
I0413 18:43:17.501875 30343 solver.cpp:228] Iteration 460, loss = 0.285233
I0413 18:43:17.501921 30343 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:43:17.501934 30343 solver.cpp:244]     Train net output #1: loss = 0.285233 (* 1 = 0.285233 loss)
I0413 18:43:17.501946 30343 sgd_solver.cpp:106] Iteration 460, lr = 0.1
I0413 18:43:24.762657 30343 solver.cpp:337] Iteration 480, Testing net (#0)
I0413 18:43:28.364274 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7126
I0413 18:43:28.364322 30343 solver.cpp:404]     Test net output #1: loss = 0.874627 (* 1 = 0.874627 loss)
I0413 18:43:28.624464 30343 solver.cpp:228] Iteration 480, loss = 0.346254
I0413 18:43:28.624510 30343 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:43:28.624524 30343 solver.cpp:244]     Train net output #1: loss = 0.346254 (* 1 = 0.346254 loss)
I0413 18:43:28.624534 30343 sgd_solver.cpp:106] Iteration 480, lr = 0.1
I0413 18:43:35.963156 30343 solver.cpp:337] Iteration 500, Testing net (#0)
I0413 18:43:39.533716 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5734
I0413 18:43:39.533818 30343 solver.cpp:404]     Test net output #1: loss = 1.50798 (* 1 = 1.50798 loss)
I0413 18:43:39.800734 30343 solver.cpp:228] Iteration 500, loss = 0.277587
I0413 18:43:39.800811 30343 solver.cpp:244]     Train net output #0: accuracy = 0.925781
I0413 18:43:39.800837 30343 solver.cpp:244]     Train net output #1: loss = 0.277587 (* 1 = 0.277587 loss)
I0413 18:43:39.800860 30343 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0413 18:43:47.170303 30343 solver.cpp:337] Iteration 520, Testing net (#0)
I0413 18:43:50.675945 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6333
I0413 18:43:50.675994 30343 solver.cpp:404]     Test net output #1: loss = 1.19826 (* 1 = 1.19826 loss)
I0413 18:43:50.948388 30343 solver.cpp:228] Iteration 520, loss = 0.4243
I0413 18:43:50.948431 30343 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:43:50.948442 30343 solver.cpp:244]     Train net output #1: loss = 0.4243 (* 1 = 0.4243 loss)
I0413 18:43:50.948451 30343 sgd_solver.cpp:106] Iteration 520, lr = 0.1
I0413 18:43:58.290144 30343 solver.cpp:337] Iteration 540, Testing net (#0)
I0413 18:44:01.796280 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7224
I0413 18:44:01.796352 30343 solver.cpp:404]     Test net output #1: loss = 0.865821 (* 1 = 0.865821 loss)
I0413 18:44:02.068665 30343 solver.cpp:228] Iteration 540, loss = 0.279135
I0413 18:44:02.068711 30343 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:44:02.068727 30343 solver.cpp:244]     Train net output #1: loss = 0.279135 (* 1 = 0.279135 loss)
I0413 18:44:02.068737 30343 sgd_solver.cpp:106] Iteration 540, lr = 0.1
I0413 18:44:09.498230 30343 solver.cpp:337] Iteration 560, Testing net (#0)
I0413 18:44:12.953685 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6921
I0413 18:44:12.953730 30343 solver.cpp:404]     Test net output #1: loss = 1.00634 (* 1 = 1.00634 loss)
I0413 18:44:13.218829 30343 solver.cpp:228] Iteration 560, loss = 0.385573
I0413 18:44:13.218886 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:44:13.218901 30343 solver.cpp:244]     Train net output #1: loss = 0.385573 (* 1 = 0.385573 loss)
I0413 18:44:13.218912 30343 sgd_solver.cpp:106] Iteration 560, lr = 0.1
I0413 18:44:20.676880 30343 solver.cpp:337] Iteration 580, Testing net (#0)
I0413 18:44:24.101788 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6195
I0413 18:44:24.101840 30343 solver.cpp:404]     Test net output #1: loss = 1.4545 (* 1 = 1.4545 loss)
I0413 18:44:24.373553 30343 solver.cpp:228] Iteration 580, loss = 0.297007
I0413 18:44:24.373591 30343 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:44:24.373603 30343 solver.cpp:244]     Train net output #1: loss = 0.297007 (* 1 = 0.297007 loss)
I0413 18:44:24.373612 30343 sgd_solver.cpp:106] Iteration 580, lr = 0.1
I0413 18:44:31.857394 30343 solver.cpp:337] Iteration 600, Testing net (#0)
I0413 18:44:35.261662 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5866
I0413 18:44:35.261729 30343 solver.cpp:404]     Test net output #1: loss = 1.70704 (* 1 = 1.70704 loss)
I0413 18:44:35.534232 30343 solver.cpp:228] Iteration 600, loss = 0.308531
I0413 18:44:35.534291 30343 solver.cpp:244]     Train net output #0: accuracy = 0.902344
I0413 18:44:35.534306 30343 solver.cpp:244]     Train net output #1: loss = 0.308531 (* 1 = 0.308531 loss)
I0413 18:44:35.534322 30343 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0413 18:44:43.075137 30343 solver.cpp:337] Iteration 620, Testing net (#0)
I0413 18:44:46.426307 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7298
I0413 18:44:46.426353 30343 solver.cpp:404]     Test net output #1: loss = 0.758509 (* 1 = 0.758509 loss)
I0413 18:44:46.696907 30343 solver.cpp:228] Iteration 620, loss = 0.401124
I0413 18:44:46.696946 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:44:46.696959 30343 solver.cpp:244]     Train net output #1: loss = 0.401124 (* 1 = 0.401124 loss)
I0413 18:44:46.696969 30343 sgd_solver.cpp:106] Iteration 620, lr = 0.1
I0413 18:44:54.213691 30343 solver.cpp:337] Iteration 640, Testing net (#0)
I0413 18:44:57.549762 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7641
I0413 18:44:57.549808 30343 solver.cpp:404]     Test net output #1: loss = 0.684968 (* 1 = 0.684968 loss)
I0413 18:44:57.823017 30343 solver.cpp:228] Iteration 640, loss = 0.264902
I0413 18:44:57.823057 30343 solver.cpp:244]     Train net output #0: accuracy = 0.902344
I0413 18:44:57.823070 30343 solver.cpp:244]     Train net output #1: loss = 0.264902 (* 1 = 0.264902 loss)
I0413 18:44:57.823081 30343 sgd_solver.cpp:106] Iteration 640, lr = 0.1
I0413 18:45:05.335940 30343 solver.cpp:337] Iteration 660, Testing net (#0)
I0413 18:45:08.645339 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6218
I0413 18:45:08.645382 30343 solver.cpp:404]     Test net output #1: loss = 1.2344 (* 1 = 1.2344 loss)
I0413 18:45:08.918792 30343 solver.cpp:228] Iteration 660, loss = 0.405701
I0413 18:45:08.918830 30343 solver.cpp:244]     Train net output #0: accuracy = 0.847656
I0413 18:45:08.918841 30343 solver.cpp:244]     Train net output #1: loss = 0.405701 (* 1 = 0.405701 loss)
I0413 18:45:08.918849 30343 sgd_solver.cpp:106] Iteration 660, lr = 0.1
I0413 18:45:16.481676 30343 solver.cpp:337] Iteration 680, Testing net (#0)
I0413 18:45:19.769321 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6556
I0413 18:45:19.769412 30343 solver.cpp:404]     Test net output #1: loss = 1.06663 (* 1 = 1.06663 loss)
I0413 18:45:20.041543 30343 solver.cpp:228] Iteration 680, loss = 0.34942
I0413 18:45:20.041597 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:45:20.041613 30343 solver.cpp:244]     Train net output #1: loss = 0.34942 (* 1 = 0.34942 loss)
I0413 18:45:20.041626 30343 sgd_solver.cpp:106] Iteration 680, lr = 0.1
I0413 18:45:27.632946 30343 solver.cpp:337] Iteration 700, Testing net (#0)
I0413 18:45:30.873221 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6794
I0413 18:45:30.873268 30343 solver.cpp:404]     Test net output #1: loss = 1.03226 (* 1 = 1.03226 loss)
I0413 18:45:31.147050 30343 solver.cpp:228] Iteration 700, loss = 0.275405
I0413 18:45:31.147110 30343 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:45:31.147127 30343 solver.cpp:244]     Train net output #1: loss = 0.275405 (* 1 = 0.275405 loss)
I0413 18:45:31.147143 30343 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0413 18:45:38.786702 30343 solver.cpp:337] Iteration 720, Testing net (#0)
I0413 18:45:42.026401 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6405
I0413 18:45:42.026459 30343 solver.cpp:404]     Test net output #1: loss = 1.07731 (* 1 = 1.07731 loss)
I0413 18:45:42.291474 30343 solver.cpp:228] Iteration 720, loss = 0.363692
I0413 18:45:42.291517 30343 solver.cpp:244]     Train net output #0: accuracy = 0.890625
I0413 18:45:42.291530 30343 solver.cpp:244]     Train net output #1: loss = 0.363692 (* 1 = 0.363692 loss)
I0413 18:45:42.291543 30343 sgd_solver.cpp:106] Iteration 720, lr = 0.1
I0413 18:45:49.986685 30343 solver.cpp:337] Iteration 740, Testing net (#0)
I0413 18:45:53.199095 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6396
I0413 18:45:53.199153 30343 solver.cpp:404]     Test net output #1: loss = 1.13341 (* 1 = 1.13341 loss)
I0413 18:45:53.467434 30343 solver.cpp:228] Iteration 740, loss = 0.289766
I0413 18:45:53.467479 30343 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0413 18:45:53.467491 30343 solver.cpp:244]     Train net output #1: loss = 0.289766 (* 1 = 0.289766 loss)
I0413 18:45:53.467505 30343 sgd_solver.cpp:106] Iteration 740, lr = 0.1
I0413 18:46:01.109830 30343 solver.cpp:337] Iteration 760, Testing net (#0)
I0413 18:46:04.301664 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6584
I0413 18:46:04.301725 30343 solver.cpp:404]     Test net output #1: loss = 1.12464 (* 1 = 1.12464 loss)
I0413 18:46:04.576033 30343 solver.cpp:228] Iteration 760, loss = 0.31748
I0413 18:46:04.576082 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:46:04.576094 30343 solver.cpp:244]     Train net output #1: loss = 0.31748 (* 1 = 0.31748 loss)
I0413 18:46:04.576107 30343 sgd_solver.cpp:106] Iteration 760, lr = 0.1
I0413 18:46:12.316715 30343 solver.cpp:337] Iteration 780, Testing net (#0)
I0413 18:46:15.456018 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6605
I0413 18:46:15.456069 30343 solver.cpp:404]     Test net output #1: loss = 1.28866 (* 1 = 1.28866 loss)
I0413 18:46:15.764220 30343 solver.cpp:228] Iteration 780, loss = 0.31685
I0413 18:46:15.764266 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:46:15.764279 30343 solver.cpp:244]     Train net output #1: loss = 0.31685 (* 1 = 0.31685 loss)
I0413 18:46:15.764287 30343 sgd_solver.cpp:106] Iteration 780, lr = 0.1
I0413 18:46:23.411536 30343 solver.cpp:337] Iteration 800, Testing net (#0)
I0413 18:46:26.612326 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6034
I0413 18:46:26.612397 30343 solver.cpp:404]     Test net output #1: loss = 1.42328 (* 1 = 1.42328 loss)
I0413 18:46:26.908030 30343 solver.cpp:228] Iteration 800, loss = 0.359594
I0413 18:46:26.908095 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:46:26.908112 30343 solver.cpp:244]     Train net output #1: loss = 0.359594 (* 1 = 0.359594 loss)
I0413 18:46:26.908138 30343 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0413 18:46:34.553982 30343 solver.cpp:337] Iteration 820, Testing net (#0)
I0413 18:46:37.774442 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6548
I0413 18:46:37.774477 30343 solver.cpp:404]     Test net output #1: loss = 1.06987 (* 1 = 1.06987 loss)
I0413 18:46:38.094174 30343 solver.cpp:228] Iteration 820, loss = 0.340734
I0413 18:46:38.094221 30343 solver.cpp:244]     Train net output #0: accuracy = 0.894531
I0413 18:46:38.094233 30343 solver.cpp:244]     Train net output #1: loss = 0.340734 (* 1 = 0.340734 loss)
I0413 18:46:38.094240 30343 sgd_solver.cpp:106] Iteration 820, lr = 0.1
I0413 18:46:45.690677 30343 solver.cpp:337] Iteration 840, Testing net (#0)
I0413 18:46:48.959424 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7096
I0413 18:46:48.959481 30343 solver.cpp:404]     Test net output #1: loss = 0.953364 (* 1 = 0.953364 loss)
I0413 18:46:49.251224 30343 solver.cpp:228] Iteration 840, loss = 0.393748
I0413 18:46:49.251276 30343 solver.cpp:244]     Train net output #0: accuracy = 0.851562
I0413 18:46:49.251291 30343 solver.cpp:244]     Train net output #1: loss = 0.393748 (* 1 = 0.393748 loss)
I0413 18:46:49.251302 30343 sgd_solver.cpp:106] Iteration 840, lr = 0.1
I0413 18:46:56.822540 30343 solver.cpp:337] Iteration 860, Testing net (#0)
I0413 18:47:00.106817 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6237
I0413 18:47:00.106881 30343 solver.cpp:404]     Test net output #1: loss = 1.20059 (* 1 = 1.20059 loss)
I0413 18:47:00.402943 30343 solver.cpp:228] Iteration 860, loss = 0.394417
I0413 18:47:00.402984 30343 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0413 18:47:00.402997 30343 solver.cpp:244]     Train net output #1: loss = 0.394417 (* 1 = 0.394417 loss)
I0413 18:47:00.403005 30343 sgd_solver.cpp:106] Iteration 860, lr = 0.1
I0413 18:47:07.956625 30343 solver.cpp:337] Iteration 880, Testing net (#0)
I0413 18:47:11.261984 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6632
I0413 18:47:11.262037 30343 solver.cpp:404]     Test net output #1: loss = 1.08927 (* 1 = 1.08927 loss)
I0413 18:47:11.571929 30343 solver.cpp:228] Iteration 880, loss = 0.39011
I0413 18:47:11.572006 30343 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:47:11.572029 30343 solver.cpp:244]     Train net output #1: loss = 0.39011 (* 1 = 0.39011 loss)
I0413 18:47:11.572047 30343 sgd_solver.cpp:106] Iteration 880, lr = 0.1
I0413 18:47:19.098508 30343 solver.cpp:337] Iteration 900, Testing net (#0)
I0413 18:47:22.453802 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6181
I0413 18:47:22.453851 30343 solver.cpp:404]     Test net output #1: loss = 1.47295 (* 1 = 1.47295 loss)
I0413 18:47:22.779090 30343 solver.cpp:228] Iteration 900, loss = 0.357241
I0413 18:47:22.779146 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:47:22.779158 30343 solver.cpp:244]     Train net output #1: loss = 0.357241 (* 1 = 0.357241 loss)
I0413 18:47:22.779171 30343 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0413 18:47:30.232787 30343 solver.cpp:337] Iteration 920, Testing net (#0)
I0413 18:47:33.619611 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7401
I0413 18:47:33.619670 30343 solver.cpp:404]     Test net output #1: loss = 0.79702 (* 1 = 0.79702 loss)
I0413 18:47:33.909591 30343 solver.cpp:228] Iteration 920, loss = 0.328588
I0413 18:47:33.909638 30343 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:47:33.909649 30343 solver.cpp:244]     Train net output #1: loss = 0.328588 (* 1 = 0.328588 loss)
I0413 18:47:33.909658 30343 sgd_solver.cpp:106] Iteration 920, lr = 0.1
I0413 18:47:41.394150 30343 solver.cpp:337] Iteration 940, Testing net (#0)
I0413 18:47:44.783118 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6907
I0413 18:47:44.783196 30343 solver.cpp:404]     Test net output #1: loss = 0.991953 (* 1 = 0.991953 loss)
I0413 18:47:45.083906 30343 solver.cpp:228] Iteration 940, loss = 0.347885
I0413 18:47:45.083956 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:47:45.083981 30343 solver.cpp:244]     Train net output #1: loss = 0.347885 (* 1 = 0.347885 loss)
I0413 18:47:45.083995 30343 sgd_solver.cpp:106] Iteration 940, lr = 0.1
I0413 18:47:52.525856 30343 solver.cpp:337] Iteration 960, Testing net (#0)
I0413 18:47:55.942378 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6242
I0413 18:47:55.942431 30343 solver.cpp:404]     Test net output #1: loss = 1.38702 (* 1 = 1.38702 loss)
I0413 18:47:56.257650 30343 solver.cpp:228] Iteration 960, loss = 0.289412
I0413 18:47:56.257699 30343 solver.cpp:244]     Train net output #0: accuracy = 0.894531
I0413 18:47:56.257711 30343 solver.cpp:244]     Train net output #1: loss = 0.289412 (* 1 = 0.289412 loss)
I0413 18:47:56.257725 30343 sgd_solver.cpp:106] Iteration 960, lr = 0.1
I0413 18:48:03.678905 30343 solver.cpp:337] Iteration 980, Testing net (#0)
I0413 18:48:07.142645 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6492
I0413 18:48:07.142705 30343 solver.cpp:404]     Test net output #1: loss = 1.26964 (* 1 = 1.26964 loss)
I0413 18:48:07.463202 30343 solver.cpp:228] Iteration 980, loss = 0.258661
I0413 18:48:07.463248 30343 solver.cpp:244]     Train net output #0: accuracy = 0.917969
I0413 18:48:07.463258 30343 solver.cpp:244]     Train net output #1: loss = 0.258661 (* 1 = 0.258661 loss)
I0413 18:48:07.463270 30343 sgd_solver.cpp:106] Iteration 980, lr = 0.1
I0413 18:48:14.832763 30343 solver.cpp:337] Iteration 1000, Testing net (#0)
I0413 18:48:18.352285 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6838
I0413 18:48:18.352335 30343 solver.cpp:404]     Test net output #1: loss = 0.981823 (* 1 = 0.981823 loss)
I0413 18:48:18.643748 30343 solver.cpp:228] Iteration 1000, loss = 0.277231
I0413 18:48:18.643800 30343 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:48:18.643811 30343 solver.cpp:244]     Train net output #1: loss = 0.277231 (* 1 = 0.277231 loss)
I0413 18:48:18.643821 30343 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0413 18:48:25.995113 30343 solver.cpp:337] Iteration 1020, Testing net (#0)
I0413 18:48:29.541579 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7317
I0413 18:48:29.541635 30343 solver.cpp:404]     Test net output #1: loss = 0.782784 (* 1 = 0.782784 loss)
I0413 18:48:29.825872 30343 solver.cpp:228] Iteration 1020, loss = 0.34901
I0413 18:48:29.825947 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:48:29.825973 30343 solver.cpp:244]     Train net output #1: loss = 0.34901 (* 1 = 0.34901 loss)
I0413 18:48:29.825990 30343 sgd_solver.cpp:106] Iteration 1020, lr = 0.1
I0413 18:48:37.155189 30343 solver.cpp:337] Iteration 1040, Testing net (#0)
I0413 18:48:40.702224 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7149
I0413 18:48:40.702278 30343 solver.cpp:404]     Test net output #1: loss = 0.932794 (* 1 = 0.932794 loss)
I0413 18:48:40.993711 30343 solver.cpp:228] Iteration 1040, loss = 0.340153
I0413 18:48:40.993749 30343 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0413 18:48:40.993762 30343 solver.cpp:244]     Train net output #1: loss = 0.340153 (* 1 = 0.340153 loss)
I0413 18:48:40.993773 30343 sgd_solver.cpp:106] Iteration 1040, lr = 0.1
I0413 18:48:48.296785 30343 solver.cpp:337] Iteration 1060, Testing net (#0)
I0413 18:48:51.899384 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6945
I0413 18:48:51.899430 30343 solver.cpp:404]     Test net output #1: loss = 0.960508 (* 1 = 0.960508 loss)
I0413 18:48:52.205559 30343 solver.cpp:228] Iteration 1060, loss = 0.418089
I0413 18:48:52.205598 30343 solver.cpp:244]     Train net output #0: accuracy = 0.835938
I0413 18:48:52.205610 30343 solver.cpp:244]     Train net output #1: loss = 0.418089 (* 1 = 0.418089 loss)
I0413 18:48:52.205618 30343 sgd_solver.cpp:106] Iteration 1060, lr = 0.1
I0413 18:48:59.490768 30343 solver.cpp:337] Iteration 1080, Testing net (#0)
I0413 18:49:03.061310 30343 solver.cpp:404]     Test net output #0: accuracy = 0.626
I0413 18:49:03.061358 30343 solver.cpp:404]     Test net output #1: loss = 1.32264 (* 1 = 1.32264 loss)
I0413 18:49:03.380036 30343 solver.cpp:228] Iteration 1080, loss = 0.308982
I0413 18:49:03.380077 30343 solver.cpp:244]     Train net output #0: accuracy = 0.894531
I0413 18:49:03.380087 30343 solver.cpp:244]     Train net output #1: loss = 0.308982 (* 1 = 0.308982 loss)
I0413 18:49:03.380097 30343 sgd_solver.cpp:106] Iteration 1080, lr = 0.1
I0413 18:49:10.649852 30343 solver.cpp:337] Iteration 1100, Testing net (#0)
I0413 18:49:14.274338 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6622
I0413 18:49:14.274395 30343 solver.cpp:404]     Test net output #1: loss = 1.10984 (* 1 = 1.10984 loss)
I0413 18:49:14.598459 30343 solver.cpp:228] Iteration 1100, loss = 0.356454
I0413 18:49:14.598496 30343 solver.cpp:244]     Train net output #0: accuracy = 0.863281
I0413 18:49:14.598508 30343 solver.cpp:244]     Train net output #1: loss = 0.356454 (* 1 = 0.356454 loss)
I0413 18:49:14.598521 30343 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0413 18:49:21.869988 30343 solver.cpp:337] Iteration 1120, Testing net (#0)
I0413 18:49:25.467413 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6824
I0413 18:49:25.467458 30343 solver.cpp:404]     Test net output #1: loss = 0.948081 (* 1 = 0.948081 loss)
I0413 18:49:25.759902 30343 solver.cpp:228] Iteration 1120, loss = 0.418247
I0413 18:49:25.759954 30343 solver.cpp:244]     Train net output #0: accuracy = 0.828125
I0413 18:49:25.759969 30343 solver.cpp:244]     Train net output #1: loss = 0.418247 (* 1 = 0.418247 loss)
I0413 18:49:25.759980 30343 sgd_solver.cpp:106] Iteration 1120, lr = 0.1
I0413 18:49:33.045966 30343 solver.cpp:337] Iteration 1140, Testing net (#0)
I0413 18:49:36.658885 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7065
I0413 18:49:36.658968 30343 solver.cpp:404]     Test net output #1: loss = 0.895313 (* 1 = 0.895313 loss)
I0413 18:49:36.955111 30343 solver.cpp:228] Iteration 1140, loss = 0.354353
I0413 18:49:36.955189 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:49:36.955207 30343 solver.cpp:244]     Train net output #1: loss = 0.354353 (* 1 = 0.354353 loss)
I0413 18:49:36.955226 30343 sgd_solver.cpp:106] Iteration 1140, lr = 0.1
I0413 18:49:44.242995 30343 solver.cpp:337] Iteration 1160, Testing net (#0)
I0413 18:49:47.848975 30343 solver.cpp:404]     Test net output #0: accuracy = 0.618
I0413 18:49:47.849030 30343 solver.cpp:404]     Test net output #1: loss = 1.4861 (* 1 = 1.4861 loss)
I0413 18:49:48.144256 30343 solver.cpp:228] Iteration 1160, loss = 0.35421
I0413 18:49:48.144296 30343 solver.cpp:244]     Train net output #0: accuracy = 0.867188
I0413 18:49:48.144307 30343 solver.cpp:244]     Train net output #1: loss = 0.35421 (* 1 = 0.35421 loss)
I0413 18:49:48.144320 30343 sgd_solver.cpp:106] Iteration 1160, lr = 0.1
I0413 18:49:55.458096 30343 solver.cpp:337] Iteration 1180, Testing net (#0)
I0413 18:49:59.050854 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7718
I0413 18:49:59.050915 30343 solver.cpp:404]     Test net output #1: loss = 0.691408 (* 1 = 0.691408 loss)
I0413 18:49:59.347730 30343 solver.cpp:228] Iteration 1180, loss = 0.289486
I0413 18:49:59.347770 30343 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:49:59.347784 30343 solver.cpp:244]     Train net output #1: loss = 0.289486 (* 1 = 0.289486 loss)
I0413 18:49:59.347796 30343 sgd_solver.cpp:106] Iteration 1180, lr = 0.1
I0413 18:50:06.649878 30343 solver.cpp:337] Iteration 1200, Testing net (#0)
I0413 18:50:10.203410 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6405
I0413 18:50:10.203479 30343 solver.cpp:404]     Test net output #1: loss = 1.26573 (* 1 = 1.26573 loss)
I0413 18:50:10.513053 30343 solver.cpp:228] Iteration 1200, loss = 0.282175
I0413 18:50:10.513118 30343 solver.cpp:244]     Train net output #0: accuracy = 0.921875
I0413 18:50:10.513134 30343 solver.cpp:244]     Train net output #1: loss = 0.282175 (* 1 = 0.282175 loss)
I0413 18:50:10.513145 30343 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0413 18:50:17.821069 30343 solver.cpp:337] Iteration 1220, Testing net (#0)
I0413 18:50:21.394949 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6589
I0413 18:50:21.394995 30343 solver.cpp:404]     Test net output #1: loss = 1.14158 (* 1 = 1.14158 loss)
I0413 18:50:21.718490 30343 solver.cpp:228] Iteration 1220, loss = 0.355711
I0413 18:50:21.718530 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:50:21.718544 30343 solver.cpp:244]     Train net output #1: loss = 0.355711 (* 1 = 0.355711 loss)
I0413 18:50:21.718552 30343 sgd_solver.cpp:106] Iteration 1220, lr = 0.1
I0413 18:50:28.992759 30343 solver.cpp:337] Iteration 1240, Testing net (#0)
I0413 18:50:32.553483 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6621
I0413 18:50:32.553540 30343 solver.cpp:404]     Test net output #1: loss = 1.19541 (* 1 = 1.19541 loss)
I0413 18:50:32.864773 30343 solver.cpp:228] Iteration 1240, loss = 0.334983
I0413 18:50:32.864816 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:50:32.864828 30343 solver.cpp:244]     Train net output #1: loss = 0.334983 (* 1 = 0.334983 loss)
I0413 18:50:32.864843 30343 sgd_solver.cpp:106] Iteration 1240, lr = 0.1
I0413 18:50:40.125115 30343 solver.cpp:337] Iteration 1260, Testing net (#0)
I0413 18:50:43.724756 30343 solver.cpp:404]     Test net output #0: accuracy = 0.703
I0413 18:50:43.724839 30343 solver.cpp:404]     Test net output #1: loss = 0.998121 (* 1 = 0.998121 loss)
I0413 18:50:44.017590 30343 solver.cpp:228] Iteration 1260, loss = 0.332624
I0413 18:50:44.017649 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:50:44.017666 30343 solver.cpp:244]     Train net output #1: loss = 0.332624 (* 1 = 0.332624 loss)
I0413 18:50:44.017678 30343 sgd_solver.cpp:106] Iteration 1260, lr = 0.1
I0413 18:50:51.294971 30343 solver.cpp:337] Iteration 1280, Testing net (#0)
I0413 18:50:54.843199 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5354
I0413 18:50:54.843255 30343 solver.cpp:404]     Test net output #1: loss = 2.03247 (* 1 = 2.03247 loss)
I0413 18:50:55.153569 30343 solver.cpp:228] Iteration 1280, loss = 0.339608
I0413 18:50:55.153611 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:50:55.153623 30343 solver.cpp:244]     Train net output #1: loss = 0.339608 (* 1 = 0.339608 loss)
I0413 18:50:55.153632 30343 sgd_solver.cpp:106] Iteration 1280, lr = 0.1
I0413 18:51:02.489873 30343 solver.cpp:337] Iteration 1300, Testing net (#0)
I0413 18:51:06.020875 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6816
I0413 18:51:06.020920 30343 solver.cpp:404]     Test net output #1: loss = 1.05312 (* 1 = 1.05312 loss)
I0413 18:51:06.285997 30343 solver.cpp:228] Iteration 1300, loss = 0.481723
I0413 18:51:06.286046 30343 solver.cpp:244]     Train net output #0: accuracy = 0.839844
I0413 18:51:06.286058 30343 solver.cpp:244]     Train net output #1: loss = 0.481723 (* 1 = 0.481723 loss)
I0413 18:51:06.286072 30343 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0413 18:51:13.652410 30343 solver.cpp:337] Iteration 1320, Testing net (#0)
I0413 18:51:17.159107 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6057
I0413 18:51:17.159150 30343 solver.cpp:404]     Test net output #1: loss = 1.38394 (* 1 = 1.38394 loss)
I0413 18:51:17.435758 30343 solver.cpp:228] Iteration 1320, loss = 0.337022
I0413 18:51:17.435816 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:51:17.435832 30343 solver.cpp:244]     Train net output #1: loss = 0.337022 (* 1 = 0.337022 loss)
I0413 18:51:17.435844 30343 sgd_solver.cpp:106] Iteration 1320, lr = 0.1
I0413 18:51:24.794893 30343 solver.cpp:337] Iteration 1340, Testing net (#0)
I0413 18:51:28.282716 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5997
I0413 18:51:28.282768 30343 solver.cpp:404]     Test net output #1: loss = 1.58818 (* 1 = 1.58818 loss)
I0413 18:51:28.556005 30343 solver.cpp:228] Iteration 1340, loss = 0.335972
I0413 18:51:28.556051 30343 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0413 18:51:28.556077 30343 solver.cpp:244]     Train net output #1: loss = 0.335972 (* 1 = 0.335972 loss)
I0413 18:51:28.556089 30343 sgd_solver.cpp:106] Iteration 1340, lr = 0.1
I0413 18:51:35.932610 30343 solver.cpp:337] Iteration 1360, Testing net (#0)
I0413 18:51:39.393491 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5319
I0413 18:51:39.393545 30343 solver.cpp:404]     Test net output #1: loss = 2.37153 (* 1 = 2.37153 loss)
I0413 18:51:39.663383 30343 solver.cpp:228] Iteration 1360, loss = 0.317031
I0413 18:51:39.663424 30343 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:51:39.663439 30343 solver.cpp:244]     Train net output #1: loss = 0.317031 (* 1 = 0.317031 loss)
I0413 18:51:39.663453 30343 sgd_solver.cpp:106] Iteration 1360, lr = 0.1
I0413 18:51:47.101137 30343 solver.cpp:337] Iteration 1380, Testing net (#0)
I0413 18:51:50.523474 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6204
I0413 18:51:50.523568 30343 solver.cpp:404]     Test net output #1: loss = 1.48833 (* 1 = 1.48833 loss)
I0413 18:51:50.794853 30343 solver.cpp:228] Iteration 1380, loss = 0.371017
I0413 18:51:50.794900 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:51:50.794915 30343 solver.cpp:244]     Train net output #1: loss = 0.371017 (* 1 = 0.371017 loss)
I0413 18:51:50.794926 30343 sgd_solver.cpp:106] Iteration 1380, lr = 0.1
I0413 18:51:58.279486 30343 solver.cpp:337] Iteration 1400, Testing net (#0)
I0413 18:52:01.679594 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6691
I0413 18:52:01.679656 30343 solver.cpp:404]     Test net output #1: loss = 1.12629 (* 1 = 1.12629 loss)
I0413 18:52:01.950481 30343 solver.cpp:228] Iteration 1400, loss = 0.341275
I0413 18:52:01.950531 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:52:01.950542 30343 solver.cpp:244]     Train net output #1: loss = 0.341275 (* 1 = 0.341275 loss)
I0413 18:52:01.950556 30343 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0413 18:52:09.444766 30343 solver.cpp:337] Iteration 1420, Testing net (#0)
I0413 18:52:12.811904 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6933
I0413 18:52:12.811954 30343 solver.cpp:404]     Test net output #1: loss = 1.00723 (* 1 = 1.00723 loss)
I0413 18:52:13.087013 30343 solver.cpp:228] Iteration 1420, loss = 0.438262
I0413 18:52:13.087059 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:52:13.087071 30343 solver.cpp:244]     Train net output #1: loss = 0.438262 (* 1 = 0.438262 loss)
I0413 18:52:13.087081 30343 sgd_solver.cpp:106] Iteration 1420, lr = 0.1
I0413 18:52:20.615542 30343 solver.cpp:337] Iteration 1440, Testing net (#0)
I0413 18:52:23.944834 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6973
I0413 18:52:23.944890 30343 solver.cpp:404]     Test net output #1: loss = 0.980111 (* 1 = 0.980111 loss)
I0413 18:52:24.218700 30343 solver.cpp:228] Iteration 1440, loss = 0.259785
I0413 18:52:24.218750 30343 solver.cpp:244]     Train net output #0: accuracy = 0.917969
I0413 18:52:24.218763 30343 solver.cpp:244]     Train net output #1: loss = 0.259785 (* 1 = 0.259785 loss)
I0413 18:52:24.218775 30343 sgd_solver.cpp:106] Iteration 1440, lr = 0.1
I0413 18:52:31.794497 30343 solver.cpp:337] Iteration 1460, Testing net (#0)
I0413 18:52:35.092327 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6237
I0413 18:52:35.092386 30343 solver.cpp:404]     Test net output #1: loss = 1.18063 (* 1 = 1.18063 loss)
I0413 18:52:35.368628 30343 solver.cpp:228] Iteration 1460, loss = 0.382991
I0413 18:52:35.368680 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:52:35.368692 30343 solver.cpp:244]     Train net output #1: loss = 0.382991 (* 1 = 0.382991 loss)
I0413 18:52:35.368707 30343 sgd_solver.cpp:106] Iteration 1460, lr = 0.1
I0413 18:52:42.985949 30343 solver.cpp:337] Iteration 1480, Testing net (#0)
I0413 18:52:46.251744 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5051
I0413 18:52:46.251803 30343 solver.cpp:404]     Test net output #1: loss = 1.98155 (* 1 = 1.98155 loss)
I0413 18:52:46.522882 30343 solver.cpp:228] Iteration 1480, loss = 0.260089
I0413 18:52:46.522945 30343 solver.cpp:244]     Train net output #0: accuracy = 0.910156
I0413 18:52:46.522958 30343 solver.cpp:244]     Train net output #1: loss = 0.260089 (* 1 = 0.260089 loss)
I0413 18:52:46.522966 30343 sgd_solver.cpp:106] Iteration 1480, lr = 0.1
I0413 18:52:54.151252 30343 solver.cpp:337] Iteration 1500, Testing net (#0)
I0413 18:52:57.391258 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5574
I0413 18:52:57.391310 30343 solver.cpp:404]     Test net output #1: loss = 1.47919 (* 1 = 1.47919 loss)
I0413 18:52:57.659816 30343 solver.cpp:228] Iteration 1500, loss = 0.303502
I0413 18:52:57.659860 30343 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0413 18:52:57.659879 30343 solver.cpp:244]     Train net output #1: loss = 0.303502 (* 1 = 0.303502 loss)
I0413 18:52:57.659888 30343 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0413 18:53:05.324482 30343 solver.cpp:337] Iteration 1520, Testing net (#0)
I0413 18:53:08.549155 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6229
I0413 18:53:08.549214 30343 solver.cpp:404]     Test net output #1: loss = 1.36662 (* 1 = 1.36662 loss)
I0413 18:53:08.819622 30343 solver.cpp:228] Iteration 1520, loss = 0.345421
I0413 18:53:08.819674 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:53:08.819687 30343 solver.cpp:244]     Train net output #1: loss = 0.345421 (* 1 = 0.345421 loss)
I0413 18:53:08.819702 30343 sgd_solver.cpp:106] Iteration 1520, lr = 0.1
I0413 18:53:16.497694 30343 solver.cpp:337] Iteration 1540, Testing net (#0)
I0413 18:53:19.667127 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5895
I0413 18:53:19.667204 30343 solver.cpp:404]     Test net output #1: loss = 1.37142 (* 1 = 1.37142 loss)
I0413 18:53:19.940644 30343 solver.cpp:228] Iteration 1540, loss = 0.3269
I0413 18:53:19.940703 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:53:19.940721 30343 solver.cpp:244]     Train net output #1: loss = 0.3269 (* 1 = 0.3269 loss)
I0413 18:53:19.940733 30343 sgd_solver.cpp:106] Iteration 1540, lr = 0.1
I0413 18:53:27.673032 30343 solver.cpp:337] Iteration 1560, Testing net (#0)
I0413 18:53:30.806888 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6565
I0413 18:53:30.806942 30343 solver.cpp:404]     Test net output #1: loss = 1.17022 (* 1 = 1.17022 loss)
I0413 18:53:31.098119 30343 solver.cpp:228] Iteration 1560, loss = 0.405951
I0413 18:53:31.098167 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:53:31.098181 30343 solver.cpp:244]     Train net output #1: loss = 0.405951 (* 1 = 0.405951 loss)
I0413 18:53:31.098191 30343 sgd_solver.cpp:106] Iteration 1560, lr = 0.1
I0413 18:53:38.749797 30343 solver.cpp:337] Iteration 1580, Testing net (#0)
I0413 18:53:41.925266 30343 solver.cpp:404]     Test net output #0: accuracy = 0.716
I0413 18:53:41.925313 30343 solver.cpp:404]     Test net output #1: loss = 0.895521 (* 1 = 0.895521 loss)
I0413 18:53:42.237882 30343 solver.cpp:228] Iteration 1580, loss = 0.289428
I0413 18:53:42.237920 30343 solver.cpp:244]     Train net output #0: accuracy = 0.894531
I0413 18:53:42.237931 30343 solver.cpp:244]     Train net output #1: loss = 0.289428 (* 1 = 0.289428 loss)
I0413 18:53:42.237946 30343 sgd_solver.cpp:106] Iteration 1580, lr = 0.1
I0413 18:53:49.897984 30343 solver.cpp:337] Iteration 1600, Testing net (#0)
I0413 18:53:53.113713 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7494
I0413 18:53:53.113767 30343 solver.cpp:404]     Test net output #1: loss = 0.744622 (* 1 = 0.744622 loss)
I0413 18:53:53.425802 30343 solver.cpp:228] Iteration 1600, loss = 0.312014
I0413 18:53:53.425856 30343 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0413 18:53:53.425869 30343 solver.cpp:244]     Train net output #1: loss = 0.312014 (* 1 = 0.312014 loss)
I0413 18:53:53.425879 30343 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0413 18:54:01.035267 30343 solver.cpp:337] Iteration 1620, Testing net (#0)
I0413 18:54:04.289376 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6235
I0413 18:54:04.289427 30343 solver.cpp:404]     Test net output #1: loss = 1.26401 (* 1 = 1.26401 loss)
I0413 18:54:04.576853 30343 solver.cpp:228] Iteration 1620, loss = 0.284235
I0413 18:54:04.576892 30343 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0413 18:54:04.576905 30343 solver.cpp:244]     Train net output #1: loss = 0.284235 (* 1 = 0.284235 loss)
I0413 18:54:04.576913 30343 sgd_solver.cpp:106] Iteration 1620, lr = 0.1
I0413 18:54:12.165629 30343 solver.cpp:337] Iteration 1640, Testing net (#0)
I0413 18:54:15.452769 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6981
I0413 18:54:15.452823 30343 solver.cpp:404]     Test net output #1: loss = 1.01609 (* 1 = 1.01609 loss)
I0413 18:54:15.750829 30343 solver.cpp:228] Iteration 1640, loss = 0.422749
I0413 18:54:15.750874 30343 solver.cpp:244]     Train net output #0: accuracy = 0.871094
I0413 18:54:15.750885 30343 solver.cpp:244]     Train net output #1: loss = 0.422749 (* 1 = 0.422749 loss)
I0413 18:54:15.750897 30343 sgd_solver.cpp:106] Iteration 1640, lr = 0.1
I0413 18:54:23.353080 30343 solver.cpp:337] Iteration 1660, Testing net (#0)
I0413 18:54:26.639333 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7288
I0413 18:54:26.639389 30343 solver.cpp:404]     Test net output #1: loss = 0.837851 (* 1 = 0.837851 loss)
I0413 18:54:26.944063 30343 solver.cpp:228] Iteration 1660, loss = 0.313189
I0413 18:54:26.944111 30343 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:54:26.944123 30343 solver.cpp:244]     Train net output #1: loss = 0.313189 (* 1 = 0.313189 loss)
I0413 18:54:26.944133 30343 sgd_solver.cpp:106] Iteration 1660, lr = 0.1
I0413 18:54:34.467396 30343 solver.cpp:337] Iteration 1680, Testing net (#0)
I0413 18:54:37.813398 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6497
I0413 18:54:37.813453 30343 solver.cpp:404]     Test net output #1: loss = 1.13954 (* 1 = 1.13954 loss)
I0413 18:54:38.135715 30343 solver.cpp:228] Iteration 1680, loss = 0.314952
I0413 18:54:38.135762 30343 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0413 18:54:38.135773 30343 solver.cpp:244]     Train net output #1: loss = 0.314952 (* 1 = 0.314952 loss)
I0413 18:54:38.135782 30343 sgd_solver.cpp:106] Iteration 1680, lr = 0.1
I0413 18:54:45.606928 30343 solver.cpp:337] Iteration 1700, Testing net (#0)
I0413 18:54:48.974249 30343 solver.cpp:404]     Test net output #0: accuracy = 0.697
I0413 18:54:48.974346 30343 solver.cpp:404]     Test net output #1: loss = 0.927758 (* 1 = 0.927758 loss)
I0413 18:54:49.273783 30343 solver.cpp:228] Iteration 1700, loss = 0.315621
I0413 18:54:49.273874 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:54:49.273917 30343 solver.cpp:244]     Train net output #1: loss = 0.315621 (* 1 = 0.315621 loss)
I0413 18:54:49.273974 30343 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0413 18:54:56.784544 30343 solver.cpp:337] Iteration 1720, Testing net (#0)
I0413 18:55:00.183151 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6564
I0413 18:55:00.183215 30343 solver.cpp:404]     Test net output #1: loss = 1.19903 (* 1 = 1.19903 loss)
I0413 18:55:00.474607 30343 solver.cpp:228] Iteration 1720, loss = 0.282461
I0413 18:55:00.474656 30343 solver.cpp:244]     Train net output #0: accuracy = 0.902344
I0413 18:55:00.474671 30343 solver.cpp:244]     Train net output #1: loss = 0.282461 (* 1 = 0.282461 loss)
I0413 18:55:00.474681 30343 sgd_solver.cpp:106] Iteration 1720, lr = 0.1
I0413 18:55:07.879784 30343 solver.cpp:337] Iteration 1740, Testing net (#0)
I0413 18:55:11.304949 30343 solver.cpp:404]     Test net output #0: accuracy = 0.488
I0413 18:55:11.304997 30343 solver.cpp:404]     Test net output #1: loss = 2.09706 (* 1 = 2.09706 loss)
I0413 18:55:11.599390 30343 solver.cpp:228] Iteration 1740, loss = 0.336623
I0413 18:55:11.599439 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:55:11.599452 30343 solver.cpp:244]     Train net output #1: loss = 0.336623 (* 1 = 0.336623 loss)
I0413 18:55:11.599470 30343 sgd_solver.cpp:106] Iteration 1740, lr = 0.1
I0413 18:55:18.982183 30343 solver.cpp:337] Iteration 1760, Testing net (#0)
I0413 18:55:22.426228 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6207
I0413 18:55:22.426280 30343 solver.cpp:404]     Test net output #1: loss = 1.33423 (* 1 = 1.33423 loss)
I0413 18:55:22.721850 30343 solver.cpp:228] Iteration 1760, loss = 0.348554
I0413 18:55:22.721887 30343 solver.cpp:244]     Train net output #0: accuracy = 0.882812
I0413 18:55:22.721899 30343 solver.cpp:244]     Train net output #1: loss = 0.348554 (* 1 = 0.348554 loss)
I0413 18:55:22.721910 30343 sgd_solver.cpp:106] Iteration 1760, lr = 0.1
I0413 18:55:30.128803 30343 solver.cpp:337] Iteration 1780, Testing net (#0)
I0413 18:55:33.587144 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7396
I0413 18:55:33.587190 30343 solver.cpp:404]     Test net output #1: loss = 0.809019 (* 1 = 0.809019 loss)
I0413 18:55:33.898960 30343 solver.cpp:228] Iteration 1780, loss = 0.224178
I0413 18:55:33.899003 30343 solver.cpp:244]     Train net output #0: accuracy = 0.925781
I0413 18:55:33.899014 30343 solver.cpp:244]     Train net output #1: loss = 0.224178 (* 1 = 0.224178 loss)
I0413 18:55:33.899024 30343 sgd_solver.cpp:106] Iteration 1780, lr = 0.1
I0413 18:55:41.300874 30343 solver.cpp:337] Iteration 1800, Testing net (#0)
I0413 18:55:44.810463 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6492
I0413 18:55:44.810519 30343 solver.cpp:404]     Test net output #1: loss = 1.16408 (* 1 = 1.16408 loss)
I0413 18:55:45.130223 30343 solver.cpp:228] Iteration 1800, loss = 0.284243
I0413 18:55:45.130267 30343 solver.cpp:244]     Train net output #0: accuracy = 0.910156
I0413 18:55:45.130278 30343 solver.cpp:244]     Train net output #1: loss = 0.284243 (* 1 = 0.284243 loss)
I0413 18:55:45.130287 30343 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0413 18:55:52.451663 30343 solver.cpp:337] Iteration 1820, Testing net (#0)
I0413 18:55:55.992497 30343 solver.cpp:404]     Test net output #0: accuracy = 0.708
I0413 18:55:55.992557 30343 solver.cpp:404]     Test net output #1: loss = 0.939781 (* 1 = 0.939781 loss)
I0413 18:55:56.284541 30343 solver.cpp:228] Iteration 1820, loss = 0.342219
I0413 18:55:56.284595 30343 solver.cpp:244]     Train net output #0: accuracy = 0.886719
I0413 18:55:56.284607 30343 solver.cpp:244]     Train net output #1: loss = 0.342219 (* 1 = 0.342219 loss)
I0413 18:55:56.284621 30343 sgd_solver.cpp:106] Iteration 1820, lr = 0.1
I0413 18:56:03.580418 30343 solver.cpp:337] Iteration 1840, Testing net (#0)
I0413 18:56:07.171516 30343 solver.cpp:404]     Test net output #0: accuracy = 0.5805
I0413 18:56:07.171568 30343 solver.cpp:404]     Test net output #1: loss = 1.61145 (* 1 = 1.61145 loss)
I0413 18:56:07.458922 30343 solver.cpp:228] Iteration 1840, loss = 0.368215
I0413 18:56:07.458966 30343 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:56:07.458978 30343 solver.cpp:244]     Train net output #1: loss = 0.368215 (* 1 = 0.368215 loss)
I0413 18:56:07.458989 30343 sgd_solver.cpp:106] Iteration 1840, lr = 0.1
I0413 18:56:14.724200 30343 solver.cpp:337] Iteration 1860, Testing net (#0)
I0413 18:56:18.327899 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6276
I0413 18:56:18.327960 30343 solver.cpp:404]     Test net output #1: loss = 1.24196 (* 1 = 1.24196 loss)
I0413 18:56:18.641441 30343 solver.cpp:228] Iteration 1860, loss = 0.316885
I0413 18:56:18.641484 30343 solver.cpp:244]     Train net output #0: accuracy = 0.902344
I0413 18:56:18.641499 30343 solver.cpp:244]     Train net output #1: loss = 0.316885 (* 1 = 0.316885 loss)
I0413 18:56:18.641510 30343 sgd_solver.cpp:106] Iteration 1860, lr = 0.1
I0413 18:56:25.929810 30343 solver.cpp:337] Iteration 1880, Testing net (#0)
I0413 18:56:29.508657 30343 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0413 18:56:29.508733 30343 solver.cpp:404]     Test net output #1: loss = 0.768882 (* 1 = 0.768882 loss)
I0413 18:56:29.832450 30343 solver.cpp:228] Iteration 1880, loss = 0.403379
I0413 18:56:29.832510 30343 solver.cpp:244]     Train net output #0: accuracy = 0.859375
I0413 18:56:29.832525 30343 solver.cpp:244]     Train net output #1: loss = 0.403379 (* 1 = 0.403379 loss)
I0413 18:56:29.832540 30343 sgd_solver.cpp:106] Iteration 1880, lr = 0.1
I0413 18:56:37.113479 30343 solver.cpp:337] Iteration 1900, Testing net (#0)
I0413 18:56:40.702762 30343 solver.cpp:404]     Test net output #0: accuracy = 0.6529
I0413 18:56:40.702805 30343 solver.cpp:404]     Test net output #1: loss = 1.1195 (* 1 = 1.1195 loss)
I0413 18:56:41.028031 30343 solver.cpp:228] Iteration 1900, loss = 0.268398
I0413 18:56:41.028077 30343 solver.cpp:244]     Train net output #0: accuracy = 0.910156
I0413 18:56:41.028091 30343 solver.cpp:244]     Train net output #1: loss = 0.268398 (* 1 = 0.268398 loss)
I0413 18:56:41.028101 30343 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0413 18:56:48.301506 30343 solver.cpp:337] Iteration 1920, Testing net (#0)
I0413 18:56:51.918301 30343 solver.cpp:404]     Test net output #0: accuracy = 0.659
I0413 18:56:51.918356 30343 solver.cpp:404]     Test net output #1: loss = 1.16762 (* 1 = 1.16762 loss)
I0413 18:56:52.207356 30343 solver.cpp:228] Iteration 1920, loss = 0.351414
I0413 18:56:52.207406 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:56:52.207417 30343 solver.cpp:244]     Train net output #1: loss = 0.351414 (* 1 = 0.351414 loss)
I0413 18:56:52.207427 30343 sgd_solver.cpp:106] Iteration 1920, lr = 0.1
I0413 18:56:59.465147 30343 solver.cpp:337] Iteration 1940, Testing net (#0)
I0413 18:57:03.068842 30343 solver.cpp:404]     Test net output #0: accuracy = 0.463
I0413 18:57:03.068904 30343 solver.cpp:404]     Test net output #1: loss = 2.52315 (* 1 = 2.52315 loss)
I0413 18:57:03.363987 30343 solver.cpp:228] Iteration 1940, loss = 0.314796
I0413 18:57:03.364032 30343 solver.cpp:244]     Train net output #0: accuracy = 0.878906
I0413 18:57:03.364043 30343 solver.cpp:244]     Train net output #1: loss = 0.314796 (* 1 = 0.314796 loss)
I0413 18:57:03.364056 30343 sgd_solver.cpp:106] Iteration 1940, lr = 0.1
I0413 18:57:10.639080 30343 solver.cpp:337] Iteration 1960, Testing net (#0)
I0413 18:57:14.203141 30343 solver.cpp:404]     Test net output #0: accuracy = 0.7382
I0413 18:57:14.203209 30343 solver.cpp:404]     Test net output #1: loss = 0.828891 (* 1 = 0.828891 loss)
I0413 18:57:14.520382 30343 solver.cpp:228] Iteration 1960, loss = 0.28271
I0413 18:57:14.520429 30343 solver.cpp:244]     Train net output #0: accuracy = 0.898438
I0413 18:57:14.520445 30343 solver.cpp:244]     Train net output #1: loss = 0.28271 (* 1 = 0.28271 loss)
I0413 18:57:14.520457 30343 sgd_solver.cpp:106] Iteration 1960, lr = 0.1
I0413 18:57:21.818897 30343 solver.cpp:337] Iteration 1980, Testing net (#0)
I0413 18:57:25.392024 30343 solver.cpp:404]     Test net output #0: accuracy = 0.65
I0413 18:57:25.392081 30343 solver.cpp:404]     Test net output #1: loss = 1.26836 (* 1 = 1.26836 loss)
I0413 18:57:25.713131 30343 solver.cpp:228] Iteration 1980, loss = 0.341948
I0413 18:57:25.713183 30343 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0413 18:57:25.713196 30343 solver.cpp:244]     Train net output #1: loss = 0.341948 (* 1 = 0.341948 loss)
I0413 18:57:25.713206 30343 sgd_solver.cpp:106] Iteration 1980, lr = 0.1
I0413 18:57:33.004217 30343 solver.cpp:454] Snapshotting to binary proto file results/snapshots/ResNet-cifar8/ResNet-cifar8_iter_2000.caffemodel
I0413 18:57:33.014168 30343 sgd_solver.cpp:273] Snapshotting solver state to binary proto file results/snapshots/ResNet-cifar8/ResNet-cifar8_iter_2000.solverstate
/DyResNet/ResNet-cifar8-solver.prototxt --train-loss results/loss/ResNet-cifar8/ResNet-cifar-loss.train --val-loss results/loss/ResNet-cifar8/ResNet-cifar-loss.val --train-acc results/accuracy/ResNet-cifar8/ResNet-cifar-acc.train --val-acc results/accuracy/ResNet-cifar8/ResNet-cifar-acc.val --snapshot results/snapshots/ResNet-cifar7/*.caffemodel --threshold -100 --max_iter 2000 --record_iter 20 --test_iter 200 -e
minloss: 0.303514894098
